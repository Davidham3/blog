<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Point Process on Davidham的博客</title><link>https://davidham3.github.io/blog/tags/point-process/</link><description>Recent content in Point Process on Davidham的博客</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 23 May 2022 15:27:10 +0000</lastBuildDate><atom:link href="https://davidham3.github.io/blog/tags/point-process/index.xml" rel="self" type="application/rss+xml"/><item><title>Semi-supervised Learning for Marked Temporal Point Processes</title><link>https://davidham3.github.io/blog/p/semi-supervised-learning-for-marked-temporal-point-processes/</link><pubDate>Mon, 23 May 2022 15:27:10 +0000</pubDate><guid>https://davidham3.github.io/blog/p/semi-supervised-learning-for-marked-temporal-point-processes/</guid><description>&lt;p>&lt;a class="link" href="https://arxiv.org/pdf/2107.07729.pdf" target="_blank" rel="noopener"
>Semi-supervised Learning for Marked Temporal Point Processes&lt;/a>。MTPP的半监督学习，模型称为SSL-MTPP。有标签的地方就用RMTPP，没有标签的地方用RMTPP的编码器和解码器来重构。两边的损失加在一起优化网络。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/semi-supervised-learning-for-marked-temporal-point-processes/Fig1.jpg"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;h1 id="3-proposed-algorithm">3 Proposed Algorithm
&lt;/h1>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/semi-supervised-learning-for-marked-temporal-point-processes/Fig2.jpg"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>架构如图2所示，损失函数：&lt;/p>
$$
\tag{1} \mathcal{L}\_{SSL-MTPP} = \mathcal{L}\_{Time} + \mathcal{L}\_{Marker} + \mathcal{L}\_{Recon}
$$&lt;h2 id="31-ssl-mtpp-algorithm">3.1 SSL-MTPP Algorithm
&lt;/h2>&lt;p>有标签的数据，一组序列$(S)$，包含$n$个序列pair，$(x_i, y_i)$，$(x_i)$是事件的时间信息，$(y_i)$是marker信息。用RNN捕获marker和序列的时间信息。嵌入表示用于预测marker和时间。&lt;/p>
&lt;p>没有标签的数据，用RNN编解码器模型，只学习时间信息。学习到的时间表示用来增强marker-time embedding。&lt;/p>
&lt;p>&lt;strong>Unsupervised Reconstruction Loss Component&lt;/strong>&lt;/p>
&lt;p>重构损失，只重构时间，不考虑marker，因此有没有标签都可以用。给定$n$个序列的训练集$S = {x_1, x_2, \dots, x_n }$，每个序列$x_i$包含$k$个事件，重构损失定义为：&lt;/p>
$$
\tag{2} \mathcal{L}\_{Recon} = \sum^n\_{i=1} \Vert x\_i - \mathcal{D}(\mathcal{E}(x\_i)) \Vert^2\_2
$$&lt;p>$\mathcal{E}$和$\mathcal{D}$分别表示RNN编码器和RNN解码器。重构损失专注于在给定的时间序列上学习有意义的表示，用于后续marker的预测。重构损失在训练过程完全是无监督的。$(\mathcal{E}(x_i))$是时间序列的编码。如何用这个嵌入表示预测后续的marker后面会讲。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/semi-supervised-learning-for-marked-temporal-point-processes/Fig3.jpg"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>&lt;strong>Supervised Marker and Time Prediction Loss Components&lt;/strong>&lt;/p>
&lt;p>$(x_i, y_i)$包含事件的时间信息和marker信息，输入到RNN模块后可以获得marker和时间相互依赖的表示：&lt;/p>
$$
\tag{3} f\_i = RNN(x\_i, y\_i)
$$&lt;p>提取出的特征表示与无监督的时间表示$(\mathcal{E}(x_i))$一起生成融合嵌入表示：&lt;/p>
$$
\tag{4} f^{fused}\_i = f\_i + \lambda \ast \mathcal{E}(x\_i)
$$&lt;p>$\lambda$是权重。这个融合表示放入一个2层感知机预测下一个事件的时间和marker。预测模型通过下面的损失来训练：&lt;/p>
$$
\tag{5} \begin{align} \mathcal{L}\_{Marker} &amp;= - \sum^M\_{c=1} y^i\_{i,c} \log(p^j\_{i,c})\\ \mathcal{L}\_{Time} &amp;= \Vert x^j\_i - {x^j}'\_i \Vert \end{align}
$$&lt;p>$\mathcal{L}_{Marker}$用交叉熵，$\mathcal{L}_{Time}$用MAE损失。事件$j$是序列$i$的一个事件，时间是$x^j_i$，marker是$y^j_i$，预测的类别有$M$个。$y^j_{i,c}$是一个binary变量，表示样本$y^j_i$是否是类别$c$，$p^j_{i,c}$是样本属于类别$c$的概率，${x^j}’_i$是给定事件的预测时间。&lt;/p>
&lt;h2 id="32-implementation-details">3.2 Implementation Details
&lt;/h2>&lt;p>SSL-MTPP利用了RMTPP的架构。监督部分的RNN是一个5层LSTM模型，无监督部分是2层的RNN编码器和解码器。marker和event prediction模块分别用了2个dense层。RNN后面用了Dropout。$\lambda$设为0.1。Adam，学习率0.01，训练100轮，batch size是1024个sequence。&lt;/p></description></item><item><title>Individual Mobility Prediction via Attentive Marked Temporal Point Processes</title><link>https://davidham3.github.io/blog/p/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/</link><pubDate>Fri, 20 May 2022 15:35:04 +0000</pubDate><guid>https://davidham3.github.io/blog/p/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/</guid><description>&lt;p>&lt;a class="link" href="https://arxiv.org/pdf/2109.02715.pdf" target="_blank" rel="noopener"
>Individual Mobility Prediction via Attentive Marked Temporal Point Processes&lt;/a>。代码：&lt;a class="link" href="https://github.com/Kaimaoge/AMTPP_for_Mobility" target="_blank" rel="noopener"
>https://github.com/Kaimaoge/AMTPP_for_Mobility&lt;/a>。结合深度学习的TPP，用注意力机制增强对事件的表示，使用混合ALL分布对事件间的时间间隔建模，通过学习OD转移概率矩阵给定O预测D。&lt;/p>
&lt;p>预测用户下一个trip的开始时间$t$，起点$o$，目的地$d$。AMTPP模型用自注意力机制捕获用户travel behavior内的周期性和regularity。使用非对称的log-Laplace mixture distribution建模起始时间$t$的分布。此外，还开发了一个OD矩阵学习模块。&lt;/p>
&lt;h1 id="1-introduction">1 Introduction
&lt;/h1>&lt;p>本质上，用户的移动数据分为两类：带时间戳的位置序列${ (t_i, l_i) }^n_{i=1}$，表示时间$t_i$的位置$l_i$；trip/activity sequence ${(t_i, o_i, d_i)}^n_{i=1}$，时间$t_i$的从$o_i$出发，目的地是$d_i$。预测下一位置的研究比较多，但是预测下一个trip的工作比较少。相比前者，后者的信息量更大，时空关联更复杂。而且trip记录比轨迹应用的场景更多。但是对OD建模，假设有$S$个位置，那就要$S \times S$这个数量级，考虑到时间和travel的方式，比如car, bike, bus、旅行的目的，work, school, leisure，这个数量级就更大了。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/Fig1.jpg"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>本文的目的是给定历史的轨迹${t_i, o_i, d_i}^n_{i=1}$，预测$t_{n+1}, o_{n+1}, d_{n+1}$。如果把时间$t$看作是连续变量，$o, d$看作是离散变量，那么下一个trip的搜索空间是$[t_n, +\infty) \times {1, \dots, S} \times {1, \dots, S}$。现在处理事件序列的方法有两类：&lt;/p>
&lt;ol>
&lt;li>HMM，隐马尔可夫模型&lt;/li>
&lt;li>marked temporal point processes。&lt;/li>
&lt;/ol>
&lt;p>HMM的缺点是时间是离散的，不是连续的。TPP相比HMM，更通用。&lt;/p>
&lt;p>最近的工作把深度学习和TPP结合在一起。但是这些方法在建模用户移动或旅行数据上有一些挑战。&lt;/p>
&lt;ol>
&lt;li>OD数据之间的时空关系太复杂了。而且$S \times S$这个数量级太大。有些工作假设time和marker之间的关系是静态的。当marker的维数比较大的时候，参数会变得很多。&lt;/li>
&lt;li>很多TPP方法是用Hawkes过程来建模的，这种过程没法提现travel中的周期性。&lt;/li>
&lt;/ol>
&lt;p>本文提出的AMTPP解决了上述的挑战。用自注意力计算过去的trip对未来trip的影响。并且设计了一个新的position embedding来捕获时间信息。使用asymmetric Log-Laplace mixture distribution建模事件间的时间。ALL分布可以刻画travel behavior的rhythms和regularity。OD矩阵学习模块，可以从数据中学习到一个动态的OD关系矩阵。&lt;/p>
&lt;h1 id="problem-description">Problem Description
&lt;/h1>&lt;p>一个用户$u$直到时间$t$的trip sequence：&lt;/p>
$$
\tag{1} \mathcal{H}^u\_t = \{(t^u\_1, o^u\_1, d^u\_1), \dots, (t^u\_{n\_u}, o^u\_{n\_u}, d^u\_{n\_u}): t^u\_{n\_u} \leq t \},
$$&lt;p>$n_u$表示序列中的trip个数。$t^u_i, o^u_i, d^u_i$表示第$i$个trip的出发时间、起点和目的地。时间是连续变量，OD是离散变量。后面忽略$u$。$t_i$可以表示为事件间的时间间隔$\tau_i = t_i - t_{i - 1} \in \mathbb{R}^+$。$\tau$可以看作是事件的活动时间。这俩表示是一样的。&lt;/p>
&lt;p>目标：&lt;/p>
$$
\tag{2} p^\ast(\tau\_{n+1}, o\_{n+1}, d\_{n+1}) = p(\tau\_{n+1}, o\_{n+1}, d\_{n+1} \mid \mathcal{H}\_{t\_n}),
$$&lt;p>$\ast$表示条件概率。本文认为$o_{n+1} = d_n$，也就是上一个trip的目的地等于下一个trip的起点，这样的话，trip的TPP就变成普通的TPP了。&lt;/p>
&lt;h1 id="4-methodology">4 Methodology
&lt;/h1>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/Fig2.jpg"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>图2是AMTPP的架构。&lt;/p>
&lt;h2 id="41-self-attention-encoder">4.1 Self-attention Encoder
&lt;/h2>&lt;p>第一步是获得$t_n, o_n, d_n$的嵌入表示：&lt;/p>
$$
\tag{3} e\_n = \text{concat}(emb^t\_n, emb^o\_n, emb^d\_n),
$$&lt;p>为了考虑周期和韵律，引入位置编码：&lt;/p>
$$
\tag{4} \begin{align} pe^n\_n(pos\_n, 2i) &amp;= \text{sin}(pos\_n / L^{2i/J}\_{pos}),\\ pe^h\_n(pos\_n, 2i+1) &amp;= \text{cos}(pos\_n / L^{2i/J}\_{pos}), \end{align},
$$&lt;p>$pos_n \in {0, 1, \dots, 23 }$是第$n$个trip的小时，$J$是嵌入的维数，$i \in {1, \dots, \lfloor J/2 \rfloor }$, $L_{pos}$是缩放因子。很多方法把$L_{pos}$设置成一个定值，比如10000，但是本文把它设定为一个参数。此外，还引入了day of week作为位置编码$pe^w_n$。加上$\tau_n$，最后的事件嵌入表示：&lt;/p>
$$
\tag{5} emb^t\_n = \text{concat}(pe^w\_n, pe^h\_n, \tau\_n).
$$&lt;p>OD嵌入：&lt;/p>
$$
\tag{6} \begin{align} emb^o\_n &amp;= \text{concat}(W^o\_{em} \hat{o}\_n + b^o\_{em}, p^o\_n),\\ emb^d\_n &amp;= \text{concat}(W^d\_{em} \hat{d}\_n + b^d\_{em}, p^d\_n), \end{align}
$$&lt;p>$W^o_{em} \in \mathbb{R}^{J_o \times S}, W^d_{em} \in \mathbb{R}^{J_d \times S}, b^o_{em} \in \mathbb{R}^{J_o}, b^d_{em} \in \mathbb{R}^{J_d}$是参数，$J_o, J_d$是OD嵌入向量的维数，$S$是位置的数量，$p^o_n, p^d_n$是OD的其他信息，比如POI什么的。&lt;/p>
&lt;p>给定历史事件序列的嵌入$E_n = [e_1, e_2, \dots, e_n]^\top \in \mathbb{R}^{n \times J}$，用多头自注意力计算第$n$个trip的隐藏状态。注意力的参数矩阵$Q_l = EW^Q_l, K_l = E W^K_l, V_l = E W^V_l, l = 1, 2, \dots, L$。$W^Q_l, W^K_l \in \mathbb{R}^{J \times c_k}, W^V_l \in \mathbb{R}^{J \times C_v}$。&lt;/p>
&lt;p>注意力：&lt;/p>
$$
\tag{7} \text{Att}(Q\_l, K\_l, V\_l) = \text{softmax}(\frac{Q\_l K^\top\_l}{\sqrt{d\_k}} \cdot M) V\_l,
$$&lt;p>$M \in \mathbb{R}^{n \times n}$是mask矩阵，上三角部分设为$-\infty$，防止信息泄露。&lt;/p>
&lt;p>多头注意力：&lt;/p>
$$
\tag{8} \begin{align} H &amp;= \text{gelu}(\text{concat}(\text{head}\_1, \dots, \text{head}\_L) W^O),\\ \text{head}\_l &amp;= \text{Att}(EW^Q\_l, EW^K\_l, EW^V\_l), \end{align}
$$&lt;p>$W_O \in \mathbb{R}^{L \cdot c_v \times C_{\text{model}}}$, $c_{\text{model}}$是输出的特征数。$\text{gelu}$表示Gaussian Error Linear Unit，非线性激活函数，$H_n = [h_1, h_2, \dots, h_n]^\top \in \mathbb{R}^{n \times c_{\text{model}}}$是输出。因为用了mask，所以$h_i$只是基于历史生成的。&lt;/p>
&lt;h2 id="42-asymmetrical-log-laplace-mixture-for-inter-trip-time">4.2 Asymmetrical Log-Laplace Mixture for Inter-trip Time
&lt;/h2>&lt;p>这个部分是对事件间的时间间隔的条件概率分布 $p_\theta(\tau_{n+1} \mid h_n)$ 建模，使用参数为$\theta$的深度神经网络建模。《Intensity-Free Learning of Temporal Point Processes》这篇论文认为相比对强度函数建模，直接对时间间隔建模更方便。这篇论文用log-normal mixture model对TPP的条件概率密度$p_\theta(\tau_{n+1} \mid h_n)$建模。但是这个分布对trip之间的interval不适用，因为trip之间的interval表示了事件的持续时间，而且条件分布通常有一些明显的峰。为了更好的刻画trip间的时间间隔，本文用Aysmmetric Log-Laplace分布。这个分布经常用于对非常偏、有峰和长尾的数据建模。ALL分布有三个参数：&lt;/p>
$$
ALL(\tau; \beta, \lambda, \gamma) = \frac{\lambda \gamma}{\tau(\lambda + \gamma)} \begin{cases} (\frac{\tau}{\beta})^\lambda &amp; \text{if} \ 0 &lt; \tau &lt; \beta,\\ (\frac{\beta}{\tau})^\gamma &amp; \text{if} \ \tau \geq \beta, \end{cases}
$$&lt;p>$\beta$控制模式，$\lambda$和$\gamma$分别是左右长尾的正长尾参数。&lt;/p>
&lt;p>理想的$p_\theta(\tau \mid h)$分布能趋近任意分布。因为混合模型有趋近$\mathbb{R}$上任意概率分布的性质：universal approximation(UA)，我们使用$\mathcal{D}$，作为ALL的混合分布，来趋近$p_\theta(\tau \mid h)$：&lt;/p>
$$
\tag{9} \mathcal{D}(\tau; w, \beta, \lambda, \gamma) = \sum^K\_{k=1} w\_k ALL(\tau; \beta\_k, \lambda\_k, \gamma\_k),
$$&lt;p>$w$是混合权重。通过这个混合模型，我们可以近似一个用户的多模态旅行模式。举个例子，如果一个旅行者只有早上的通勤数据，我们在24小时内只能看到一个峰。但是对于来回通勤的人，我们希望看到的是早上一个峰，晚上一个峰。这种混合模型可以表示多个峰。&lt;/p>
&lt;p>ALL混合分布下的变量的对数服从$\text{ALMixture}(w,\hat{\beta}, \hat{\lambda}, \hat{\gamma})$，每个部分是：&lt;/p>
$$
\tag{10} AL(y) = \frac{\hat{\lambda}\_k}{\hat{\gamma}\_k + \frac{1}{\hat{\gamma}\_k}} \begin{cases} \exp (\frac{\hat{\lambda}\_k}{\hat{\gamma}\_k} (y - \hat{\beta}\_k)) &amp; \ \text{if} \ 0 &lt; y &lt; \hat{\beta}\_k,\\ \exp(- \hat{\lambda}\_k \hat{\gamma}\_k (y - \hat{\beta}\_k)) &amp; \ \text{if} \ y \geq \hat{\beta}\_k, \end{cases}
$$&lt;p>$\hat{\beta}_k = \log(\beta_k), \hat{\gamma}_k = \sqrt{\frac{\lambda_k}{\gamma_k}}, \hat{\lambda}_k = \sqrt{\lambda_k \gamma_k}$。&lt;/p>
&lt;p>公式10里面的对数似然比公式9中的原始ALL更容易学习。我们用MDN网络学习ALMixture里面的参数：&lt;/p>
$$
\tag{11} \begin{align} w\_n &amp;= \text{softmax}(\Phi\_w h\_n + b\_w),\\ \hat{\beta}\_n &amp;= \exp(\Phi\_\beta h\_n + b\_\beta),\\ \hat{\lambda}\_n &amp;= \exp(\Phi\_\lambda h\_n + b\_\lambda),\\ \hat{\gamma}\_n &amp;= \exp(\Phi\_\gamma h\_n + b\_\gamma), \end{align}
$$&lt;p>softmax和exp用来约束分布的参数，$\Phi, b$都是learnable parameters。&lt;/p>
&lt;h2 id="43-od-matrix-learning">4.3 OD Matrix Learning
&lt;/h2>&lt;p>显然OD和$t$是有关的，即$p^\ast(o_{n+1} \mid \tau_{n+1})$，这里我们没有直接对时间$\tau$建模，而是对$\tau$上面的参数${w_n, \beta_n, \lambda_n, \gamma_n }$建模，这样就不用从分布中采样了。因为ALL混合分布中的参数是有物理意义的，从学习到的模型中模拟trip也很容易。通过调整参数就可以看到OD分布的变化。举个例子，减小峰参数$\beta$来观察OD分布的变化，可以理解成一个人的出发时间提前之后他的trip会有什么变化。&lt;/p>
$$
\tag{12} \begin{align} \hat{h}\_n &amp;= \text{concat}(h\_n, w\_n, \hat{\beta}\_n, \hat{\lambda}\_n, \hat{\gamma}\_n),\\ \hat{o}\_{n+1} &amp;= \text{softmax}(\Phi\_o \hat{h}\_n + b\_o), \end{align}
$$&lt;p>下一个位置$\hat{o}_{n+1}$的分布依赖拼接向量$\hat{h}_n$，这个向量由历史编码$h_n$和trip的时间参数组成。&lt;/p>
&lt;p>$p^\ast(d_{n+1})$通过把$\hat{o}_{n+1}$乘以一个OD矩阵$OD_{n+1}$得到，这个矩阵的每一列包含了从一个O转移到所有D的转移概率。这个OD矩阵很有用，有了这个OD矩阵，我们可以知道地铁线路里面哪个结点的人比较多。但是$S \times S$太大了，学一个实时的OD矩阵太难了。我们用下面的方法学习$OD_{n+1}$里面的参数：&lt;/p>
$$
\tag{13}
\begin{align}
D^1\_{n+1} &amp;= \text{reshape}(\Phi^1\_m \hat{h}\_n),\\
D^2\_{n+1} &amp;= \text{reshape}(\Phi^2\_m \hat{h}\_n),\\
OD\_{n+1} &amp;= D^1\_{n+1}{D^2\_{n+1}}^\top \cdot M\_{od},\\
OD\_{n+1} &amp;= \text{softmax}(OD\_{n+1}).\\
\hat{d}\_{n+1} &amp;= OD\_{n+1} \hat{o}\_{n+1}
\end{align}
$$&lt;p>$D^1_{n+1}, D^2_{n+1} \in \mathbb{R}^{S \times r}$, $r \ll S$。$\Phi$是learnable parameters。$M_{od} \in \mathbb{R}^{S \times S}$用来过滤掉不可能的OD pair，方法就是把这些位置设置成 $- \infty$，包括矩阵的对角线。softmax用来约束矩阵的每一列的和都为1。这个矩阵是根据时间编码$\hat{h}_n$动态变化的。输出的$\hat{d}_{n+1}$和输入的$\hat{o}_{n+1}$与参数关联在一起，让网络训练起来更容易。&lt;/p>
&lt;h2 id="44-model-training">4.4 Model Training
&lt;/h2>&lt;p>负对数似然。随机梯度下降。短的序列要加pad。pad部分会被mask掉。损失函数：&lt;/p>
$$
\tag{14} \mathcal{L} = - \sum^U\_{u=1} \sum^{n\_u}\_{n=1} \log p^\ast\_\Theta(\tau^u\_n) + \log p^\ast\_\Theta(o^u\_n) + \log p^\ast\_\Theta(d^u\_n),
$$&lt;p>$U$是用户数，$n_u$是用户$u$的trip的个数。对于$\tau$的对数似然，在$\tau$上面加一个对数变换，得到非对称Laplace分布：$y = \log(\tau)$，最终得到：&lt;/p>
$$
\tag{15} \begin{align} \log p^\ast\_\Theta(\tau) &amp;= \log p^\ast\_\Theta(y) - \log(\tau), \ \ \ \ y = \log(\tau),\\ p^\ast\_\Theta(y) &amp;= \text{ALMixture}(w, \hat{\beta}, \hat{\lambda}, \hat{\gamma}). \end{align}
$$</description></item></channel></rss>