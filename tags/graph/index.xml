<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Graph on Davidham的博客</title><link>https://davidham3.github.io/blog/tags/graph/</link><description>Recent content in Graph on Davidham的博客</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 03 Jan 2020 20:18:29 +0000</lastBuildDate><atom:link href="https://davidham3.github.io/blog/tags/graph/index.xml" rel="self" type="application/rss+xml"/><item><title>Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</title><link>https://davidham3.github.io/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/</link><pubDate>Fri, 03 Jan 2020 20:18:29 +0000</pubDate><guid>https://davidham3.github.io/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/</guid><description>&lt;p&gt;AAAI 2020，原文链接：&lt;a class="link" href="https://arxiv.org/abs/1911.12093" target="_blank" rel="noopener"
&gt;https://arxiv.org/abs/1911.12093&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;交通预测在运输和公共安全中扮演重要角色，由于复杂的时空依赖和路网和交通状况带来的不确定性使这个问题很有挑战。最新的研究专注于使用图卷积网络 GCNs 对一个固定权重的图进行建模，即对空间依赖建模。然而，边，即两个结点之间的关系更加复杂且两者相互影响。我们提出了 Multi-Range Attentive Bicomponent GCN (MRA-BGCN)，一种新的用于交通预测的深度学习框架。我们先根据路网上结点的距离构建结点图，在根据不同的边的交互模式构造边图。然后，我们使用 bicomponent 图卷积实现结点和边的交互。这个多范围注意力机制用来聚合不同邻居范围的信息，自动地学习不同范围的重要性。大量的实验在两个真实数据集，METR-LA 和 PEMS-BAY 上开展，显示出我们的模型效果很好。&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction
&lt;/h1&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig1.png"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;讲了好多历史。。。然后是论点部分：&lt;/p&gt;
&lt;p&gt;我们认为 DCRNN 和 STGCN 虽说集成了 GCN，但是有两个点忽略了：&lt;/p&gt;
&lt;p&gt;首先，这些方法主要关注通过在一个固定权重的图上部署 GCN 对空间依赖建模。然而，边更复杂。图 1a 中，传感器 1 和 3，还有 2 和 3，通过路网连接。显然，这些关联随当前的交通状况改变，他们之间也互相交互。图 1b 所示，现存的方法根据路网距离构建一个固定的带权图，使用 GCN 实现这些结点的交互，但是结点间的关联性在邻接矩阵中通过固定的值表示，这就忽略了边的复杂性和交互性。&lt;/p&gt;
&lt;p&gt;其次，这些方法经常使用一个给定范围内聚合的信息，比如 $k$ 阶邻居，忽略多个范围的信息。然而，不同范围的信息表现出不同的交通属性。小的范围表现出局部依赖，大范围倾向于表现全局的交通模式。此外，不同范围的信息也不是永远都具有相同的分量。举个例子，一次交通事故，一个结点主要受它最近的邻居的影响，这样模型就应该更关注它，而不是给其他的 $k$ 阶邻居相同的关注。&lt;/p&gt;
&lt;p&gt;为了解决上述两点问题，我们提出了 MRA-BGCN，不仅考虑结点关联，也把边作为实体，考虑他们之间的关系，如图 1c，我们还利用了不同的范围信息。我们的贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出 MRA-BGCN，引入 bicomponent 图卷积，对结点和边直接建模。结点图根据路网距离构建，边图根据边的交互模式、stream connectivity 和 竞争关系构建。&lt;/li&gt;
&lt;li&gt;我们针对 bicomponent 图卷积提出多范围注意力机制，可以聚合不同范围邻居的信息，学习不同范围的重要性。&lt;/li&gt;
&lt;li&gt;我们开展了大量的实验，实验效果很好。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="preliminaries"&gt;Preliminaries
&lt;/h1&gt;&lt;h2 id="problem-definition"&gt;Problem Definition
&lt;/h2&gt;&lt;p&gt;给定历史的数据，预测未来的数据。$N$ 个结点组成的图 $G = (V, E, \bm{A})$。时间 $t$ 路网上的交通数据表示为图信号 $\bm{X}^{(t)} \in \mathbb{R}^{N \times P}$，$P$ 是特征数。交通预测是过去的数据预测未来：&lt;/p&gt;
$$
[\bm{X}^{(t-T'+1):t},G] \xrightarrow{f} [\bm{X}^{(t+1)}:(t+T)],
$$&lt;p&gt;$\bm{X}^{(t-T&amp;rsquo;+1):t} \in \mathbb{R}^{N \times P \times T&amp;rsquo;}$，$\bm{X}^{(t+1):(t+T)} \in \mathbb{R}^{N \times P \times T}$。&lt;/p&gt;
&lt;h2 id="graph-convolution"&gt;Graph Convolution
&lt;/h2&gt;&lt;p&gt;不介绍了。&lt;/p&gt;
&lt;h1 id="methodology"&gt;Methodology
&lt;/h1&gt;&lt;h2 id="model-overview"&gt;Model Overview
&lt;/h2&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig2.png"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;p&gt;图 2 展示了 MRA-BGCN 的架构，包含两个部分：（1）双组件图卷积模块；（2）多范围注意力层。双组件图卷积模块包含多个结点图卷积层和边图卷积层，直接对结点和边的交互建模。多范围注意力层聚合不同范围的邻居信息，学习不同范围的重要性。此外，我们融合 MRA-BGCN 和 RNN 对时间依赖建模完成交通预测。&lt;/p&gt;
&lt;h2 id="bicomponent-graph-convolution"&gt;Bicomponent Graph Convolution
&lt;/h2&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig3.png"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;图卷积可以有效聚合结点之间的交互关系，然而，交通预测中边更复杂（这句话说三遍了）。因此我们提出双组件图卷积，直接对结点和边的交互建模。&lt;/p&gt;
&lt;p&gt;Chen 等人提出边的邻近的 line graph 来建模边的关系。$G = (V, E, \bm{A})$ 表示结点有向图，$G_L = (V_L, E_L, \bm{A}_L)$ 是对应的 line graph，$G_L$ 的结点 $V_L$ 是 $E$ 中有序的边。$\bm{A}_L$ 是无权的邻接矩阵，编码了结点图中的边邻接关系，有关系就等于1。&lt;/p&gt;
&lt;p&gt;尽管 line graph 可以考虑边的邻接，它仍然是一个无权图且只认为两条边中的一条边的汇点和另一条边的源点相同时，这两条才相关。然而，对于刻画交通预测中各种各样边的交互关系来说这不够高效。如图 3 所示，我们定义两类边的交互模式来构建边图 $G_e = (V_e, E_e, \bm{A}_e)$。$V_e$ 中的每个节点表示 $E$ 中的边。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stream connectivity&lt;/strong&gt; 在交通网络中，路网可能受它上下游的路段影响。如图 3a 所示，$(i \rightarrow j)$ 是 $(j \rightarrow k)$ 的上游的边，因此他们是相互关联的。直观上来看，如果结点 $j$ 有很多数量的邻居，那么 $(i \rightarrow j)$ 和 $(j \rightarrow k)$ 之间的关系是弱的，因为它还要受其他邻居的影响。我们使用高斯核计算边的权重用来表示 $\bm{A}_e$ 中的 stream connectivity：&lt;/p&gt;
$$\tag{2}
\bm{A}\_{e, (i \rightarrow j), (j \rightarrow k)} = \bm{A}\_{e, (j \rightarrow k), (i \rightarrow j)} = \text{exp}(- \frac{(\text{deg}^-(j) + \text{deg}^+(j) - 2)^2}{\sigma^2})
$$&lt;p&gt;$\text{deg}^-(j)$ 和 $\text{deg}^+(j)$ 分别表示结点 $j$ 的入度和出度，$\sigma$ 是结点度的标准差。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Competitive relationship&lt;/strong&gt; 路网&lt;/p&gt;</description></item><item><title>GMAN: A Graph Multi-Attention Network for Traffic Prediction</title><link>https://davidham3.github.io/blog/p/gman-a-graph-multi-attention-network-for-traffic-prediction/</link><pubDate>Thu, 02 Jan 2020 17:03:30 +0000</pubDate><guid>https://davidham3.github.io/blog/p/gman-a-graph-multi-attention-network-for-traffic-prediction/</guid><description>&lt;p&gt;AAAI 2020，使用编码解码+att的架构，只不过编码和解码都使用 attention 组成。主要的论点是空间和时间的关联性是动态的，所以设计这么一个纯注意力的框架。值得注意的点是：由于注意力分数的个数是平方级别的，在计算空间注意力的时候，一旦结点数很大，这里会有超大的计算量和内存消耗，这篇文章是将结点分组后，计算组内注意力和组间注意力。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1911.08415" target="_blank" rel="noopener"
&gt;https://arxiv.org/abs/1911.08415&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;长时间范围的交通流预测是个挑战，两方面原因：交通系统的复杂性，很多影响因素的持续变化性。我们在这篇论文中，专注于时空因素，提出了一个图多注意力机智网络（GMAN），预测路网上不同区域的交通状况。GMAN 使用一个编码解码结构，编码解码器都由多个时空注意力块组成，时空注意力块对交通状况上的时空因素的影响建模。编码器将输入的交通特征编码，解码器输出预测序列。编码解码器之间，有一个变换注意力层，用来把编码器编码后的交通特征生成成未来时间步的序列表示，然后把这个表示输入到解码器里面。变换注意力机制对历史和未来时间步的关系建模，可以减轻多步预测中的错误积累。两个真实数据集上的交通预测任务（一个是流量预测，一个是速度预测）显示 GMAN 的效果优越。在1小时的预测上，GMAN 在 MAE 比 state-of-the-art 好4%。源码在：&lt;a class="link" href="https://github.com/zhengchuanpan/GMAN" target="_blank" rel="noopener"
&gt;https://github.com/zhengchuanpan/GMAN&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction
&lt;/h1&gt;&lt;p&gt;交通预测的目标是基于历史观测预测未来的交通状况。在很多应用中扮演着重要的角色。举个例子，精确的交通预测可以帮助交管部门更好的控制交通，减少拥堵。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig1.png"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;邻近区域的交通状况会互相影响。大家使用 CNN 捕获这样的空间依赖。同时，一个地方的交通状况和它的历史记录有关。RNN 广泛地用于这样时间相关性的建模。最近的研究将交通预测变为图挖掘问题，因为交通问题受限于路网。使用 GCN 的这些研究在短期预测（5 到 15 分钟）内表现出不错的效果。然而，长期预测（几个小时）仍缺乏令人满意的效果，主要受限于以下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;复杂的时空关联：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;动态的空间关联。如图 1 所示，路网中的传感器之间的关联随时间剧烈地变化，比如高峰时段的前后。如何动态地选择相关的检测器数据来预测一个检测器在未来长时间范围的交通状况是一个挑战。&lt;/li&gt;
&lt;li&gt;非线性的时间关联。图 1，一个检测器的交通状况可能变化得非常剧烈，且可能由于事故等因素，突然影响不同时间步之间的关联性。如何自适应地随时间的推移对这种非线性时间关联建模，也是一个挑战。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;对误差传递的敏感。长期预测上，每个时间步上小的错误都会被放大。这样的误差传递对于远期时间预测来说仍具有挑战性。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决上述挑战，我们提出了一个图多注意力网络（GMAN）来预测未来的交通状况。这里指的交通状况是一个交通系统中可以记录为数值的观测值。为了描述，我们这里专注于流量和速度预测，但是我们的模型是可以应用到其他数值型的交通数据上的。&lt;/p&gt;
&lt;p&gt;GMAN 使用编码解码架构，编码器编码交通特征，解码器生成预测序列。变换注意力层用来把编码历史特征转换为未来表示。编解码器都由一组时空注意力块 &lt;em&gt;ST-Attention blocks&lt;/em&gt; 组成。每个时空注意力块由一个空间注意力、一个时间注意力和一个门控融合机制组成。空间注意力建模动态空间关联，时间注意力建模非线性时间关联，门控融合机制自适应地融合空间和时间表示。变换注意力机制建模历史和未来的关系，减轻错误传播。两个真实世界数据集证明 GMAN 获得了最好的效果。&lt;/p&gt;
&lt;p&gt;我们的贡献&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出空间注意力和时间注意力对动态空间和非线性时间关联分别建模。此外，我们设计了一个门控融合机制，自适应地融合空间注意力和时间注意力机制的的信息。&lt;/li&gt;
&lt;li&gt;提出一个变换注意力机制将历史交通特征转换为未来的表示。这个注意力机制对历史和未来的关系直接建模，减轻错误传播的问题。&lt;/li&gt;
&lt;li&gt;我们在两个数据集上评估了我们的图多注意力网络，在 1 小时预测问题上比 state-of-the-art 提高了 4%。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="preliminaries"&gt;Preliminaries
&lt;/h1&gt;&lt;p&gt;路网表示为一个带全有向图 $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathcal{A})$。$\mathcal{V}$ 是 $N$ 个结点的集合；$\mathcal{E}$ 是边集；$\mathcal{A} \in \mathbb{R}^{N \times N}$ 是邻接矩阵，表示结点间的相似性，这个相似性是结点在路网上的距离。&lt;/p&gt;
&lt;p&gt;时间步 $t$ 的路网状况表示为图信号 $X_t \in \mathbb{R}^{N \times C}$，$C$ 是特征数。&lt;/p&gt;
&lt;p&gt;研究的问题：给定 $N$ 个结点历史 $P$ 个时间步的观测值 $\mathcal{X} = (X_{t_1}, X_{t_2}, \dots. X_{t_P}) \in \mathbb{R}^{P \times N \times C}$，我们的目标是预测未来 $Q$ 个时间步所有结点的交通状况，表示为 $\hat{Y} = (\hat{X}_{t_{P+1}}, \hat{X}_{t_{P+2}}, \dots, \hat{X}_{t_{P+Q}}) \in \mathbb{R}^{Q \times N \times C}$。&lt;/p&gt;
&lt;h1 id="graph-multi-attention-network"&gt;Graph Multi-Attention Network
&lt;/h1&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig2.png"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;p&gt;图 2 描述了我们模型的架构。编码和解码器都有 STAtt Block 和残差连接。每个 ST-Attention block 由空间注意力机制、时间注意力机制和一个门控融合组成。编码器和解码器之间有个变换注意力层。我们还通过一个时空嵌入 spatial-temporal embedding (STE) 继承了图结构和时间信息到多注意力机制中。此外，为了辅助残差连接，所有层的输出都是 D 维。&lt;/p&gt;
&lt;h2 id="spatio-temporal-embedding"&gt;Spatio-Temporal Embedding
&lt;/h2&gt;&lt;p&gt;因为交通状况的变化受限于路网，集成路网信息到模型中很重要。为此，我们提出一个空间嵌入，把结点嵌入到向量中以此保存图结构信息。我们利用 node2vec 学习结点表示。此外，为了协同训练模型和预学习的向量，这些向量会放入一个两层全连接神经网络中。然后就可以拿到空间表示 $e^S_{v_i} \in \mathbb{R}^D$。&lt;/p&gt;
&lt;p&gt;空间嵌入只提供了固定的表示，不能表示路网中的传感器的动态关联性。我们提出了一个时间嵌入来把每个时间步编码到向量中。假设一天是 T 个时间步。我们使用 one-hot 编码星期、时间到 $\mathbb{R}^7$ 和 $\mathbb{R}^T$ 里面，然后拼接，得到 $\mathbb{R}^{T + 7}$。接下来，使用两层全连接映射到 $\mathbb{R}^D$。在我们的模型里面，给历史的 $P$ 个时间步和未来的 $Q$ 个时间步嵌入时间特征，表示为 $e^T_{t_j} \in \mathbb{R}^D$，$t_j = t_1, \dots, t_P, \dots, t_{P+Q}$。&lt;/p&gt;
&lt;p&gt;为了获得随时间变化的顶点表示，我们融合了上述的空间嵌入和时间嵌入，得到时空嵌入（STE），如图 2b 所示。结点 $v_i$ 在时间步 $t_j$，STE 定义为 $e_{v_i,t_j} = e^S_{v_i} + e^T_{t_j}$。因此，$N$ 个结点在 $P + Q$ 的时间步里的 STE 表示为 $E \in \mathbb{R}^{(P + Q) \times N \times D}$。STE 包含图结构和时间信息。它会用在空间、时间、变换注意力机制里面。&lt;/p&gt;
&lt;h2 id="st-attention-block"&gt;ST-Attention Block
&lt;/h2&gt;&lt;p&gt;我们将第 $l$ 个块的输入表示为 $H^{(l-1)}$，结点 $v_i$ 在时间步 $t_j$ 的隐藏状态表示为 $h^{(l-1)}_{v_i,t_j}$。第 $l$ 块中的空间和时间注意力机制的输出表示为 $H^{(l)}_S$ 和 $H^{(l)}_T$，隐藏状态表示为 $hs^{(l)}_{v_i,t_j}$ 和 $ht^{(l)}_{v_i,t_j}$。门控融合后，第 $l$ 层的输出表示为 $H^{(l)}$。&lt;/p&gt;
&lt;p&gt;我们将非线性变换表示为：&lt;/p&gt;
$$\tag{1}
f(x) = \text{ReLU}(x\mathbf{W} + \mathbf{b}).
$$&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig3.png"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spatial Attention&lt;/strong&gt; 一条路的交通状况受其他路的影响，且影响不同。这样的影响是高度动态的，随时间变化。为了建模这些属性，我们设计了一个空间注意力机制动态地捕获路网中传感器间的关联性。核心点是在不同的时间步动态地给不同的结点分配权重，如图 3 所示。对于时间步 $t_j$ 的结点 $v_i$，我们计算所有结点的带权和：&lt;/p&gt;
$$\tag{2}
hs^{(l)}\_{v\_i,t\_j} = \sum\_{v \in \mathcal{V}} \alpha\_{v\_i, v} \cdot h^{(l-1)}\_{v,t\_j},
$$&lt;p&gt;$\alpha_{v_i, v}$ 是结点 $v$ 对 $v_i$ 的注意力分数，注意力分数之和为1：$\sum_{v \in \mathcal{V}} \alpha_{v_i, v} = 1$。&lt;/p&gt;
&lt;p&gt;在一个确定的时间步，当前交通状况和路网结构能够影响传感器之间的关联性。举个例子，路上的拥挤可能极大地影响它临近路段的交通状况。受这个直觉的启发，我们考虑使用交通特征和图结构两方面来学习注意力分数。我们把隐藏状态和时空嵌入拼接起来，使用 scaled dot-product approach (Vaswani et al. 2017) 来计算结点 $v_i$ 和 $v$ 之间的相关性：&lt;/p&gt;
$$\tag{3}
s\_{v\_i, v} = \frac{&lt; h^{(l-1)}\_{v\_i,t\_j} \Vert\ e\_{v\_i,t\_j}, h^{(l-1)}+{v,t\_j}, \Vert e\_{v,t\_j} &gt;}{\sqrt{2D}}
$$&lt;p&gt;其中，$\Vert$ 表示拼接操作，$&amp;lt; \bullet, \bullet &amp;gt;$ 表示内积，$2D$ 表示 $h^{(l-1)}_{v_i,t_j} \Vert e_{v_i,t_j}$ 的维度。$s_{v_i,v}$ 通过 softmax 归一化：&lt;/p&gt;
$$\tag{4}
\alpha\_{v\_i,v} = \frac{\text{exp}(s\_{v\_i,v})}{\sum\_{v\_r \in \mathcal{V}} \text{exp}(s\_{v\_i,v\_r})}.
$$&lt;p&gt;得到注意力分数 $\alpha_{v_i,v}$ 之后，隐藏状态通过公式 2 更新。&lt;/p&gt;
&lt;p&gt;为了稳定学习过程，我们把空间注意力机制扩展为多头注意力机制。我们拼接 $K$ 个并行的注意力机制，使用不同的全连接映射：&lt;/p&gt;
$$\tag{5}
s^{(k)}\_{v\_i,v} = \frac{&lt; f^{(k)}\_{s,1} (h^{(l-1)}\_{v\_i,t\_j} \Vert e\_{v\_i,t\_j}), f^{(k)}\_{s,2} (h^{(l-1)}\_{v,t\_j} \Vert e\_{v,t\_j}) &gt;}{\sqrt{d}},
$$$$\tag{6}
\alpha^{(k)}\_{v\_i,v} = \frac{\text{exp}(s^{(k)}\_{v\_i,v})}{\sum\_{v\_r \in \mathcal{V}} \text{exp}(s^{(k)}\_{v\_i,v\_r})},
$$$$\tag{7}
hs^{(l)}\_{v\_i,t\_j} = \Vert^K\_{k=1} \lbrace \sum\_{v \in \mathcal{V}} \alpha^{(k)}\_{v\_i,v} \cdot f^{(k)}\_{s,3}(h^{(l-1)}\_{v,t\_j}) \rbrace,
$$&lt;p&gt;其中 $f^{(k)}_{s,1}(\bullet), f^{(k)}_{s,2}(\bullet), f^{(k)}_{s,3}(\bullet)$ 表示第 $k$ 注意力头的三个不同的非线性映射，即公式 1 ，产生 $d = D / K$ 维的输出。&lt;/p&gt;
&lt;p&gt;当结点数 $N$ 很大的时候，时间和内存消耗都会很大，达到 $N^2$ 的数量级。为了解决这个限制，我们提出了组空间注意力，包含了组内注意力分数和组间注意力分数，如图 4 所示。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig4.png"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;p&gt;我们把 $N$ 个结点随机划分为 $G$ 个组，每个组包含 $M = N / G$ 个结点，如果必要的话可以加 padding。每个组，我们使用公式 5，6，7 计算组内的注意力，对局部空间关系建模，参数是对所有的组共享的。然后，我们在每个组使用最大池化得到每个组的表示。接下来计算组间空间注意力，对组间关系建模，给每个组生成一个全局特征。局部特征和全局特征相加得到最后的输出。&lt;/p&gt;
&lt;p&gt;组空间注意力中，我们每个时间步需要计算 $GM^2 + G^2 = NM + (N / M)^2$ 个注意力分数。通过使梯度为0，我们知道 $M = \sqrt[3]{2N}$ 时，注意力分数的个数达到最大值 $2^{-1/3} N^{4/3} \ll N^2$。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig5.png"
loading="lazy"
alt="Figure5"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Temporal Attention&lt;/strong&gt; 一个地点的交通状况和它之前的观测值有关，这个关联是非线性的。为了建模这些性质，我们设计了一个时间注意力机制，自适应地对不同时间步的非线性关系建模，如图 5 所示。可以注意到时间关联受到交通状况和对应的时间环境两者的影响。举个例子，早高峰的拥堵可能会影响交通好几个小时。因此，我们考虑交通特征和时间两者来衡量不同时间步的相关性。我们把隐藏状态和时空嵌入拼接起来，使用多头注意力计算注意力分数。对于结点 $v_i$，时间步 $t_j$ 与 $t$ 的相关性定义为：&lt;/p&gt;
$$\tag{8}
u^{(k)}\_{t\_j,t} = \frac{&lt; f^{(k)}\_{t,1}(h^{(l-1)}\_{v\_i,t\_j} \Vert e\_{v\_i,t\_j}), f^{(k)}\_{t,2}(h^{(l-1)}\_{v\_i,t} \Vert e\_{v\_i,t}) &gt;}{\sqrt{d}},
$$$$\tag{9}
\beta^{(k)}\_{t\_j,t} = \frac{\text{exp}(u^{(k)}\_{t\_j,t})}{\sum\_{t\_r \in \mathcal{N}\_{t\_j}}} \text{exp}(u^{(k)}\_{t\_j,t\_r}),
$$&lt;p&gt;$u^{(k)}_{t_j,t}$ 表示时间步 $t_j$ 和 $t$ 之间的相关性，$\beta^{(k)}_{t_j,t}$ 是第 $k$ 个头的注意力分数，表示时间步 $t$ 对时间步 $t_j$ 的重要性，两个 $f$ 是非线性变换，$\mathcal{N}_{t_j}$ 表示 $t_j$ 前的时间步的集合，即只考虑目标时间步以前的时间步，这样才有因果。一旦获得了注意力分数，时间步 $t_j$ 的结点 $v_i$ 的隐藏状态可以通过下面的公式更新：&lt;/p&gt;
$$\tag{10}
ht^{(l)}\_{v\_i,t\_j} = \Vert^K\_{k=1} \lbrace \sum\_{t \in \mathcal{N}\_{t\_j}} \beta^{(k)}\_{t\_j,t} \cdot f^{(k)}\_{t,3}(h^{(l-1)}\_{v\_i,t}) \rbrace
$$&lt;p&gt;$f$ 是非线性映射。公式 8，9，10 学习到的参数对所有结点和所有时间步共享，且并行计算。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gated Fusion&lt;/strong&gt; 一个时间步一条路上的交通状况与它自身之前的值和相邻道路上的交通状况相关。如图 2c 所示，我们设计了一个门控融合机制自适应地融合空间和时间表示。在第 $l$ 个块，空间和时间注意力的输出表示为 $H^{(l)}_S$ 和 $H^{(l)}_T$，两者的维度在编码器中是 $\mathbb{R}^{P \times N \times D}$，解码器中是 $\mathbb{R}^{Q \times N \times D}$。通过下式融合：&lt;/p&gt;
$$\tag{11}
H^{(l)} = z \odot H^{(l)}\_S + (1 - z) \odot H^{(l)}\_T,
$$$$\tag{12}
z = \sigma(H^{(l)}\_S \mathbf{W}\_{z,1} + H^{(l)}\_T \mathbf{W}\_{z,2} + \mathbf{b}\_z),
$$&lt;p&gt;门控融合机制自适应地控制每个时间步和结点上空间和时间依赖的流动。&lt;/p&gt;
&lt;h2 id="transform-attention"&gt;Transform Attention
&lt;/h2&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig6.png"
loading="lazy"
alt="Figure6"
&gt;&lt;/p&gt;
&lt;p&gt;为了减轻错误传播的问题，我们在编码器和解码器之间加入了一个变换注意力层。它能直接地对历史时间步和未来时间步的关系建模，将交通特征编码为未来的表示，作为解码器的输入。如图 6 所示，对于结点 $v_i$ 来说，预测的时间步 $t_j \ (t_j = t_{P+1}, \dots, t_{P+Q})$ 和历史的时间步 $t \ (t_1, \dots, t_P)$ 通过时空嵌入来衡量：&lt;/p&gt;
$$\tag{13}
\lambda^{(k)}\_{t\_j,t} = \frac{&lt; f^{(k)}\_{tr,1}(e\_{v\_i,t\_j}), f^{(k)}\_{tr,2}(e\_{v\_i,t}) &gt;}{\sqrt{d}},
$$$$\tag{14}
\gamma^{(k)}\_{t\_j,t} = \frac{\text{exp}(\lambda^{(k)}\_{t\_j,t})}{\sum^{t\_P}\_{t\_r=t\_1} \text{exp}(\lambda^{(k)}\_{t\_j,t\_r})}.
$$&lt;p&gt;编码的交通特征通过注意力分数 $\gamma^{(k)}_{t_j,t}$ 自适应地在历史 $P$ 个时间步选择相关的特征，变换到解码器的输入：&lt;/p&gt;
$$\tag{15}
h^{(l)}\_{v\_i,t\_j} = \Vert^K\_{k=1} \lbrace \sum^{t\_P}\_{t=t\_1} \gamma^{(k)}\_{t\_j,t} \cdot f^{(k)}\_{tr,3}(h^{(l-1)}\_{v\_i,t}) \rbrace.
$$&lt;h2 id="encoder-decoder"&gt;Encoder-Decoder
&lt;/h2&gt;&lt;p&gt;如图 2a 所示，GMAN 是编码解码架构。在进入编码器前，历史记录 $\mathcal{X} \in \mathbb{R}^{P \times N \times C}$ 通过全连接变换到 $H^{(0)} \in \mathbb{R}^{P \times N \times D}$。然后 $H^{(0)}$ 输入到 $L$ 个时空注意力块组成的编码器中，产生输出 $H^{(L)} \in \mathbb{R}^{P \times N \times D}$。然后变换注意力层把编码特征从 $H^{(L)}$ 转换为 $H^{(L+1)} \in \mathbb{R}^{Q \times N \times D}$。然后 $L$ 个时空注意力块的解码器产生输出 $H^{(2L + 1)} \in \mathbb{R}^{Q \times N \times D}$。最后，全连接层输出 $Q$ 个时间步的预测 $\hat{Y} \in \mathbb{R}^{Q \times N \times C}$。&lt;/p&gt;
&lt;p&gt;GMAN 可以通过最小化 MAE 来优化：&lt;/p&gt;
$$\tag{16}
\mathcal{L}(\Theta) = \frac{1}{Q} \sum^{t\_{P + Q}}\_{t = t\_P + 1} \vert Y\_t - \hat{Y}\_t \vert,
$$&lt;p&gt;$\Theta$ 表示可学习的参数。&lt;/p&gt;
&lt;h1 id="experiments"&gt;Experiments
&lt;/h1&gt;&lt;h2 id="datasets"&gt;Datasets
&lt;/h2&gt;&lt;p&gt;我们在两个不同规模的交通预测数据集上衡量了模型的效果：（1）厦门数据集，流量预测，包含 95 个传感器从 2015 年 8 月 1 日到 12 月 31 日 5 个月的数据；（2）PeMS 数据集上速度预测，包含 325 个传感器 6 个月的数据。检测器的分布如图 7.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig7.png"
loading="lazy"
alt="Figure7"
&gt;&lt;/p&gt;
&lt;h2 id="data-preprocessing"&gt;Data Preprocessing
&lt;/h2&gt;&lt;p&gt;一个时间步表示 5 min，使用 Z-Score 归一化，70% 用于训练，10% 验证，20% 测试。我们计算路网上传感器之间的距离，使用如下的路网构建方法：&lt;/p&gt;
$$\tag{17}
\mathcal{A}\_{v\_i,v\_j} = \begin{cases}
\text{exp}(- \frac{d^2\_{v\_i,v\_j}}{\sigma^2}), &amp; \text{if} \ \text{exp}(-\frac{d^2\_{v\_i,v\_j}}{\sigma^2}) \geq \epsilon\\
0, &amp; \text{otherwise}
\end{cases}
$$&lt;p&gt;$\epsilon$ 设定为 0.1。&lt;/p&gt;
&lt;h2 id="experimental-settings"&gt;Experimental Settings
&lt;/h2&gt;&lt;p&gt;指标：MAE, RMSE, MAPE。&lt;/p&gt;
&lt;p&gt;超参数就不描述了。&lt;/p&gt;
&lt;p&gt;Baselines都是近几年的方法。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Table1.png"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;这里值得一提的是，最后一个训练和预测时间的比较，我个人认为脱离了框架或软件，单单比较每轮训练时长是毫无意义的，因为有些静态图框架它就是很快，动态图的就是慢，而且代码质量也有区别，有的代码质量高，自然就很快，代码质量低的就很慢。拿 Graph WaveNet 举例，他们公开的代码是 pytorch 的，而且他们在 inference 的时候要对 ground truth 进行反归一化，有的代码人家就不反归一化，这也会造成 inference 的时候有差别，且有的模型是随着结点数 $N$ 的增加模型有显著的耗时增加的现象，没有考虑这些就写 computation time 的比较我觉得没有什么用，何况以 AAAI 7 页的限制来说，完全说清楚这些也毫无意义。&lt;/p&gt;</description></item><item><title>STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting</title><link>https://davidham3.github.io/blog/p/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/</link><pubDate>Fri, 12 Jul 2019 19:57:39 +0000</pubDate><guid>https://davidham3.github.io/blog/p/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/</guid><description>&lt;p&gt;IJCAI 2019. 原文链接：&lt;a class="link" href="https://arxiv.org/abs/1905.10069.pdf" target="_blank" rel="noopener"
&gt;STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger
Demand Forecasting&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;多步乘客需求预测对于按需车辆共享服务来说是个重要的任务。然而，预测多个时刻的乘客需求由于时空依赖的非线性和动态性很有挑战。我们提出了基于图的城市范围的旅客需求预测模型，使用一个层次图卷积同时捕获空间和时间关联性。我们的模型有三部分：1) 长期编码器对历史旅客需求编码；2) 短期编码器推导下一步预测结果来生成多步预测；3) 使用一个基于注意力的输出模块对动态的时间和各通道信息建模。实验在三个数据集上表明我们的方法比很多方法好。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1. Introduction
&lt;/h1&gt;&lt;h1 id="2-notations-and-problem-statement"&gt;2. Notations and Problem Statement
&lt;/h1&gt;&lt;p&gt;假设一个城市分成 $N$ 个小的区域，不考虑是分成网格还是路网。我们将区域的集合表示为 $\lbrace r_1, r_2, \dots, r_i, \dots r_N \rbrace$。在每个时间步 $t$，一个二维矩阵 $\boldsymbol{D_t} \in \mathbb{R}^{N \times d_{in}}$ 表示所有区域在时间 $t$ 的旅客需求。另一个向量 $\boldsymbol{E_t} \in \mathbb{R}^{d_e}$ 表示时间步 $t$ 的时间特征，包含了几点、星期几以及节假日的信息。&lt;/p&gt;
&lt;p&gt;给定城市范围的历史旅客需求序列 $\lbrace \bm{D_0}, \bm{D_1}, \dots, \bm{D_t} \rbrace$ 和时间特征 $\lbrace \bm{E_0}, \bm{E_1}, \dots, \bm{E_{t+\tau}} \rbrace$，目标是学习一个预测函数 $\Gamma(\cdot)$ 来预测接下来的 $\tau$ 个时间步上城市范围的旅客需求序列。我们只使用历史 $h$ 个时间步的需求序列作为输入 $\lbrace \bm{D_{t-h+1}, \bm{D_{t-h+2}}, \dots, \bm{D_t}} \rbrace$。我们的任务描述为：&lt;/p&gt;
$$\tag{1}
(\bm{D\_{t+1}}, \bm{D\_{t+2}}, \dots, \bm{D\_{t+\tau}}) = \Gamma(\bm{D\_{t-h+1}}, \bm{D\_{t-h+2}}, \dots, \bm{D\_t}; \bm{E\_0}, \bm{E\_1}, \dots, \bm{E\_{t+\tau}})
$$&lt;h1 id="3-methodology"&gt;3. Methodology
&lt;/h1&gt;&lt;p&gt;STG2Seq 的架构有三个组件：1. 长期编码器，2. 短期编码器，3.基于注意力的输出模块。长期和短期编码器由多个序列时空门控图卷积模块 (GGCM) 组成，通过在时间维度使用 GCN 可以同时捕获时间和空间相关性。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;h2 id="31-passenger-demand-on-graph"&gt;3.1 Passenger Demand on Graph
&lt;/h2&gt;&lt;p&gt;我们先介绍如何将城市范围的旅客需求在图上描述出来。之前的工作假设一个区域的旅客需求会被近邻的区域影响。然而，我们认为空间关系并不是仅依赖空间位置。如果遥远的区域和当前区域有相似的地方，比如具有相似的 POI，那么也可能拥有相同的旅客需求模式。因此，我们将城市看作一个图 $G = (v, \xi, A)$，$v$ 是区域的集合 $v = \lbrace r_i \mid i=1,2,\dots,N \rbrace$，$\xi$ 表示边的集合，$A$ 是邻接矩阵。我们根据区域间旅客需求模式的相似性定义图的边。&lt;/p&gt;
$$\tag{2}
A\_{i, j} = \begin{cases}
1, \quad \text{if} \quad Similarity\_{r\_i, r\_j} &gt; \epsilon\\
0, \quad \text{otherwise}
\end{cases}
$$&lt;p&gt;其中 $\epsilon$ 是阈值，控制 $A$ 的稀疏程度。为了定量区域间的旅客需求模式的相似性，我们使用皮尔逊相关系数。$D_{0\text{\textasciitilde}t}(r_i)$ 表示时间从 0 到 $t$ 的区域 $r_i$ 历史旅客需求序列。$r_i$ 和 $r_j$ 之间的相似度可以定义为：&lt;/p&gt;
$$\tag{3}
Similarity\_{r\_i, r\_j} = Pearson(D\_{0\text{\textasciitilde}t}(r\_i), D\_{0\text{\textasciitilde}t}(r\_j))
$$&lt;h2 id="32-long-term-and-short-term-encoders"&gt;3.2 Long-term and Short-term Encoders
&lt;/h2&gt;&lt;p&gt;很多之前的工作只考虑下一步预测，即预测下一时间步的旅客需求。在训练过程中通过减少下一时间步预测值的误差而不考虑后续时间步的误差来优化模型。因此，这些方法在多步预测的问题上会退化。仅有一些工作考虑了多步预测的问题 [Xingjian et al., 2015; Li et al., 2018]。这些工作采用了基于 RNN 的编码解码器的架构，或是它的变体，比如 ConvLSTM 这样的作为编码解码器。这些方法有两个劣势：1. 链状结构的 RNN 在编码的时候需要遍历输入的时间步。因此他们需要与输入序列等长的 RNN 单元个数（序列多长，RNN单元就有多少个）。在目标需求和前一个需求上的长距离计算会导致一些信息的遗忘。2. 在解码部分，为了预测时间步 $T$ 的需求，RNN 将隐藏状态和前一时间步 $T-1$ 作为输入。因此，前一时间步带来的误差会直接影响到预测，导致未来时间步误差的累积。&lt;/p&gt;
&lt;p&gt;不同于之前所有的工作，我们引入了一个依赖于同时使用长期和短期编码器的架构，不用 RNN 做多步预测。长期编码器取最近的 $h$ 个时间步的城市历史旅客需求序列 $\lbrace \bm{D_{t-h+1}}, \bm{D_{t-h+2}}, \dots, \bm{D_t} \rbrace$ 作为输入来学习历史的时空模式。这 $h$ 步需求合并后组织成三维矩阵，$h \times N \times d_{in}$。长期编码器由一些 GGCM 组成，每个 GCGGM 捕获在所有的 $N$ 个区域上捕获空间关联性，在 $k$ 个时间步上捕获时间关联性。$k$ 是超参数，我们会在 3.3 节讨论。因此，只需要 $\frac{h-1}{k-1}$ 个迭代的步数就可以捕获 $h$ 个时间步上的时间关联性。对比 RNN 结构，我们的基于 GGCM 的长期编码器显著的降低了遍历长度，进一步减少了信息的损失。长期编码器的输出 $Y_h$ 的维数是 $h \times N \times d_{out}$，是输入的编码表示。&lt;/p&gt;
&lt;p&gt;短期编码器用来集成已经预测的需求，用于多步预测。它使用一个长度为 $q$ 的滑动窗来捕获近期的时空关联性。当预测在 $T(T \in [t+1,t+\tau])$ 步的旅客需求时，它取最近的 $q$ 个时间步的旅客需求，即 $\lbrace \bm{D_{T-q}}, \bm{D_{T-q+1}}, \dots, \bm{D_{T-1}} \rbrace$ 作为输入。除了时间步的长度以外，短期编码器和长期编码器一样。短期编码器生成一个维数为 $q \times N \times d_{out}$ 的矩阵 $Y^T_q$ 作为近期趋势表示。和基于 RNN 的解码器不同的是，RNN的解码器只将最后一个时间步的预测结果输入回去。因此，预测误差会被长期编码器小柔，减轻基于 RNN 的解码器会导致误差累积的问题。&lt;/p&gt;
&lt;h2 id="33-gated-graph-convolutional-module"&gt;3.3 Gated Graph Convolutional Module
&lt;/h2&gt;&lt;p&gt;门控图卷积模块是长期编码器和短期编码器的核心。每个 GGCM 由几个 GCN 层组成，沿着时间轴并行。为了捕获时空关联性，每个 GCN 在一定长度的时间窗内操作($k$)。它可以提取 $k$ 个时间步内所有区域的空间关联性。通过堆叠多个 GGCM，我们的模型形成了一个层次结构，可以捕获整个输入的时空关联性。图 3 展示了只使用 GCN 捕获时空关联性，为了简化我们忽略了通道维。Yu et al., 2018 的工作和我们的 GGCM 模块很像。他们的工作首先使用 CNN 捕获时间关联性，然后使用 GCN 捕获空间关联性。我们的方法对比他们的方法极大的简化了，因为我们可以同时捕获时空关联性。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;p&gt;GGCM 模块的详细设计如图 4。第 $l$ 个 GGCM 的输入是一个矩阵，维数为 $h \times N \times C^l$。在第一个 GGCM 模块，$C^l$ 是 $d_{in}$ 维的。第 $l$ 个 GGCM 的输出是 $h \times N \times C^{l+1}$。我们先拼接一个 zero padding，维数为 $(k-1) \times N \times C^l$，得到新的输入 $(h+k-1) \times N \times C^l$，确保变换不会减少序列的长度。接下来，GGCM 中的每个 GCN 取 $k$ 个时间步的数据 $k \times N \times C^l$ 作为输入来提取时空关联性，然后 reshape 成一个二维矩阵 $N \times (k \cdot C^l)$。根据 Kipf &amp;amp; Welling 的 GCN，GCN 层可以描述如下：&lt;/p&gt;
$$\tag{4}
X^{l+1} = (\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W
$$&lt;p&gt;$\tilde{A} = A + I_n$，$\tilde{P}_{ii} = \sum_j \tilde{A}_{ij}$，$X \in \mathbb{R}^{N \times (k \cdot C^l)}$，$W \in \mathbb{R}^{(k \cdot C^l) \times C^{l+1}}$，$X^{l+1} \in \mathbb{R}^{N \times C^{l+1}}$
。&lt;/p&gt;
&lt;p&gt;除此以外，我们使用了门控机制对旅客需求预测的复杂非线性建模。式 4 重新描述如下：&lt;/p&gt;
$$\tag{5}
X^{l+1} = ((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W\_1 + X^l) \otimes \sigma((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W\_2)
$$&lt;p&gt;$\otimes$ 是对应元素相乘，$\sigma$是 sigmoid 激活函数。因此输出是一个非线性门 $\sigma((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W_2)$ 控制的线性变换 $((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W_1 + X^l)$。非线性门控制线性变换的哪个部分可以通过门影响预测。此外，我们使用残差连接来避免式 5 中的网络退化。&lt;/p&gt;
&lt;p&gt;最后，门控机制产生的 $h$ 个输出沿时间轴合并，生成 GGCM 模块的输出 $h \times N \times C^{l+1}$。&lt;/p&gt;
&lt;h2 id="34-attention-based-output-module"&gt;3.4 Attention-based Output Module
&lt;/h2&gt;&lt;p&gt;如 3.2 描述的那样，长期时空依赖和 $T$ 时间步的近期时空依赖通过两个矩阵描述 $Y_h$ 和 $Y^T_q$。我们拼接。我们拼接他们形成联合表示 $Y_{h+q} \in \mathbb{R}^{(h+q) \times N \times d_{out}}$，通过一个基于注意力机制的模块解码获得预测值。这里为了简便忽略 $T$。$Y_{h+q}$ 的三个轴分别是时间、空间、通道。&lt;/p&gt;
&lt;p&gt;我们先引入一个时间注意力机制来解码 $Y_{h+q}$。旅客需求是一个典型的时间序列，前一时刻的需求对后一时刻有影响。然而，之前的每一步对预测目标的影响是不同的，影响随时间变化。我们设计了一个时间注意力机制对每个历史时间步增加注意力分数衡量其影响。分数通过 $Y_{h+q} = [y_1, y_2, \dots, y_{h+q}](y_i \in \mathbb{R}^{N \times d_{out}})$ 和目标时间步的时间特征 $\bm{E}_T$ 生成，这个分数可以自适应地学习之前的时间步随时间的动态影响。我们定义时间注意力分数如下：&lt;/p&gt;
$$\tag{6}
\bm{\alpha} = softmax(tanh(Y\_{h+q} W^Y\_3 + E\_T W^E\_4 + b\_1))
$$&lt;p&gt;$W^Y_3 \in \mathbb{R}^{(h+q) \times (N \times d_{out}) \times 1}$，$W^E_4 \in \mathbb{R}^{d_e \times (h+q)}$，$b_1 \in \mathbb{R}^{(h+q)}$。联合表示 $Y_{h+q}$ 通过注意力分数 $\bm{\alpha}$ 转换：&lt;/p&gt;
$$\tag{7}
Y\_{\alpha} = \sum^{h+q}\_{i=1} \alpha^i y\_i \quad \in \mathbb{R}^{N \times d\_{out}}
$$&lt;p&gt;受到 [Chen et al., 2017] 的启发，每个通道的重要性是不同的，我们在时间注意力后面加了一个通道注意力模块来找到 $Y_\alpha = [y_1, y_2, \dots, y_{d_{out}}]$ 中最重要的那个。计算如下：&lt;/p&gt;
$$\tag{8}
\bm\beta = softmax(tanh(Y\_\alpha W^Y\_5 + E\_T W^E\_6 + b\_2))
$$$$\tag{9}
Y\_{\beta} = \sum^{d\_{out}}\_{i=1} \beta^i y\_i \quad \mathbb{R}^N
$$&lt;p&gt;其中，$W^Y_5 \in \mathbb{R}^{d_{out} \times N \times 1}$，$W^E_6 \in \mathbb{R}^{d_e \times d_{out}}$；$\bm\beta \in \mathbb{R}^{d_{out}}$ 是每个通道的注意力分数。当预测的维度是1时，$Y_\beta$ 就是我们预测的旅客需求 $\bm{D&amp;rsquo;_T}$。当预测维度是 2 时（预测起止需求），我们给每个通道计算注意力分数，将他们拼接起来得到最后的预测值。&lt;/p&gt;</description></item><item><title>Self-Attention Graph Pooling</title><link>https://davidham3.github.io/blog/p/self-attention-graph-pooling/</link><pubDate>Tue, 25 Jun 2019 16:34:02 +0000</pubDate><guid>https://davidham3.github.io/blog/p/self-attention-graph-pooling/</guid><description>&lt;p&gt;ICML 2019，原文地址：&lt;a class="link" href="https://arxiv.org/abs/1904.08082" target="_blank" rel="noopener"
&gt;Self-Attention Graph Pooling&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;这些年有一些先进的方法将深度学习应用到了图数据上。研究专注于将卷积神经网络推广到图数据上，包括重新定义图上的卷积和下采样（池化）。推广的卷积方法已经被证明有性能提升且被广泛使用。但是，下采样的方法仍然是一个难题且有提升空间。我们提出了一个基于自注意力的图的池化方法。使用图卷积的自注意力使得我们的池化方法可以同时考虑顶点特征和图的拓扑结构。为了确保一个公平的对比，我们使用了相同的训练步骤和模型架构。实验结果显示我们的方法有更高的分类精度。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1. Introduction
&lt;/h1&gt;&lt;p&gt;CNN 成功利用了图像、语音、视频数据中的欧氏空间（网格结构）。CNN 由卷积层和下采样层（池化层）组成。卷积层和池化层挖掘了网格数据的平移不变性和compositionality（这个我不知道是什么。。。）。结果是，CNN 用少量的参数就可以表现的很好。&lt;/p&gt;
&lt;p&gt;然而，很多数据是非欧空间上的。社交网络、生物蛋白质网络、分子网络可以表示成网络。将 CNN 应用在非欧空间上的尝试已经获得了成功。很多研究重新定义了图上的卷积和池化。&lt;/p&gt;
&lt;p&gt;对于图卷积的池化操作现在比较少。之前图的池化的研究只考虑图的拓扑结构 (Defferrard et al., 2016; Rhee et al., 2018)。一些方法利用了结点的特征获得一个小图的表示。最近，Ying et al.; Gao &amp;amp; Ji; Cangea et al. 提出了创新的池化方法，可以层级的表示图。这些方法使得图神经网络可以通过端到端的形式，在池化后获得尺寸缩减的图。&lt;/p&gt;
&lt;p&gt;然而，上述的池化方法仍有提升空间。举个例子，Ying et al. 的可微层级池化方法有平方级别的空间复杂度，参数依赖于顶点数。Gao &amp;amp; Ji; Cangea et al. 解决了复杂度的问题，但是没有考虑图的拓扑结构。&lt;/p&gt;
&lt;p&gt;我们提出的 SAGPool 是一个层次的自注意力图池化方法。我们的方法可以通过端到端的方式使用相对较少的参数学习到层次表示。自注意力机制用来区分结点是否丢弃掉还是保留。由于自注意力机制使用图卷积计算注意力分数，结点特征和图的拓扑结构可以被考虑其中。一句话，SAGPool 有前面方法的优点，是第一个使用自注意力用于池化的方法，并且获得了很好的性能。代码已经在 Github 上开源了。&lt;/p&gt;
&lt;h1 id="2-related-work"&gt;2. Related Work
&lt;/h1&gt;&lt;h2 id="21-graph-convolution"&gt;2.1. Graph Convolution
&lt;/h2&gt;&lt;p&gt;图上的卷积要么是基于谱的，要么是非谱的。谱方法专注于在傅里叶域上定义卷积，利用使用图拉普拉斯矩阵的谱滤波器。Kipf &amp;amp; Welling 提出了一个层级传播的规则，简化了使用切比雪夫展开来趋近拉普拉斯矩阵的方法。非谱方法的目标是定义一个卷积操作，可以直接应用在图上。通常来说，非谱方法，中心结点在特征传入下层之前聚合邻接结点的特征。Hamilton et al. 提出了 GraphSAGE，通过采样和聚合学习结点的嵌入。尽管 GraphSAGE 会采样固定数量的邻居，GAT 基于注意力机制，在所有的邻居上计算结点表示。两个方法在图相关的任务上都有提升。&lt;/p&gt;
&lt;h2 id="22-graph-pooling"&gt;2.2. Graph Pooling
&lt;/h2&gt;&lt;p&gt;池化层通过缩减表示的大小，使得 CNN 能减少参数的数量，因此能避免过拟合。为了泛化 CNN，GNN 上的池化是必要的。图的池化方法可以归入三类：基于拓扑的，基于全局的，基于层次的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topology based pooling&lt;/strong&gt; 早期的工作使用图的缩减算法，而不是神经网络。谱聚类算法使用特征值分解获得缩减的图。然而，特征值分解的时间复杂度高。Graclus (Dhillon et al., 2007) 不使用特征向量计算给定图的聚类结果，而是通过一个谱聚类的目标函数与一个带权的核 k-means 目标函数的等价性。即便在最近的 GNN 模型中，Graclus 也被使用作为一个池化单元。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Global pooling&lt;/strong&gt; 不像之前的方法，全局池化方法考虑图的特征。全局池化方法在每层聚合表示的时候使用加和的方式而不是用神经网络。这个方法可以处理不同结构的图，因为它获得了所有的表示。Gilmer et al. 将 GNN 看作是一种信息的传递规则，提出了一个通用框架用于图分类，整个图的表示可以通过使用 Set2Set (Vinyals et al., 2015) 来获得。SortPool (Zhang et al., 2018b) 根据一个图的结构角色对结点嵌入排序，将排序后的表示传入下一层。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical pooling&lt;/strong&gt; 全局池化方法不学习层次表示，但是对于捕获图的结构信息来说，层次表示很关键。层次池化的动机在于在每层构建一个模型，这个模型可以学习基于特征的或基于拓扑的顶点分配。Ying et al. 提出了 DiffPool，这是一种可微的图的池化方法，可以以端到端的形式学习分配矩阵。在层 $l$ 学习到的分配矩阵 $S^{(l)} \in \mathbb{R}^{n_l \times n_{l+1}}$ 包含了层 $l$ 中的结点在 $l + 1$ 层被分配到类簇的概率。$n_l$ 表示层 $l$ 的结点数。结点通过下式来分配：&lt;/p&gt;
$$\tag{1}
S^{(l)} = \text{softmax}(\text{GNN}\_l (A^{(l)}, X^{(l)})) \\
A^{(l+1)} = S^{(l)\text{T}} A^{(l)} S^{(l)}
$$&lt;p&gt;$X$ 表示矩阵的结点特征，$A$ 是邻接矩阵。&lt;/p&gt;
&lt;p&gt;Cangea et al. 使用 gPool (Gao &amp;amp; Ji, 2019) 获得了和 DiffPool 相当的性能。gPool 需要 $\mathcal{O}(\vert V \vert + \vert E \vert)$ 的空间复杂度，DiffPool 需要 $\mathcal{O}(k \vert V \vert^2)$ 的空间复杂度。$V$，
$E$，$k$ 分别表示顶点、边、池化比例。gPool 使用一个可学习的向量 $p$ 计算投影分数，然后使用这个分数选择最高的结点。投影分数通过 $p$ 和所有结点的特征向量的内积获得。分数表示结点可以获得的信息量。下面的式子大体的描述了 gPool 中的池化步骤：&lt;/p&gt;
$$\tag{2}
y = X^{(l)} \mathbf{p}^{(l)} / \Vert \mathbf{p}^{(l)} \Vert, \text{idx=top-rank}(y, \lceil kN \rceil) \\
A^{(l+1)} = A^{(l)}\_{\text{idx,idx}}
$$&lt;p&gt;如式 2，图的拓扑结构不影响投影分数。&lt;/p&gt;
&lt;p&gt;为了进一步提高图的池化，我们提出了 SAGPool，可以在可观的时间和空间复杂度上利用特征和拓扑结构生成层次表示。&lt;/p&gt;
&lt;h1 id="3-proposed-method"&gt;3. Proposed Method
&lt;/h1&gt;&lt;p&gt;SAGPool 的关键是它使用了 GNN 得到的注意力分数。SAGPool 层和模型架构分别是图 1 和图 2.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;h2 id="31-self-attention-graph-pooling"&gt;3.1 Self-Attention Graph Pooling
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Self-attention mask&lt;/strong&gt; 注意力机制广泛应用在最近的深度学习研究中。这样的机制使得模型可以更专注于重要的特征，不那么关注不重要的特征。自注意力一般称为内注意力，允许输入特征作为自身注意力的标准 (Vaswani et al., 2017)。我们使用图卷积获得自注意力分数。举个例子，如果图卷积的公式是 Kipf &amp;amp; Welling 使用的，那么自注意力分数 $Z \in \mathbb{R}^{N \times 1}$ 通过下式计算：&lt;/p&gt;
$$\tag{3}
Z = \sigma(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X \Theta\_{att})
$$&lt;p&gt;$\sigma$ 是激活函数，如 $tanh$，$\tilde{A} \in \mathbb{R}^{N \times N}$ 是有自连接的邻接矩阵，$\tilde{D} \in \mathbb{R}^{N \times N}$ 是度矩阵，$X \in \mathbb{R}^{N \times F}$ 是图的特征矩阵，$\Theta_{att} \in \mathbb{R}^{F \times 1}$ 是 SAGPool 层仅有的参数。通过利用图卷积获得自注意力分数，池化的结果是同时基于图的特征和拓扑结构的。我们利用 Gao &amp;amp; Ji; Cangea et al. 的结点选择方法，保留了输入的图的一部分结点，甚至当图的尺寸和结构改变时。池化比例 $k \in (0, 1]$ 是一个超参数决定了保留多少结点。基于 $Z$ 的值选择最高的 $\lceil kN \rceil$ 个结点。&lt;/p&gt;
$$\tag{4}
\text{idx = top-rank}(Z, \lceil kN \rceil), Z\_{mask} = Z\_{\text{idx}}
$$&lt;p&gt;$\text{top-rank}$ 返回最高的 $\lceil kN \rceil$ 个值的下标，$\cdot_{\text{idx}}$ 是下标操作，$Z_{mask}$ 是特征的注意力 mask。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph pooling&lt;/strong&gt; 输入的图通过图 1 中的 &lt;strong&gt;masking&lt;/strong&gt; 操作。&lt;/p&gt;
$$\tag{5}
X' = X\_{idx,:}, X\_{out} = X' \odot Z\_{mask}, A\_{out} = A\_{\text{idx, idx}}
$$&lt;p&gt;其中 $X_{\text{idx,:}}$ 是指定行下标的特征矩阵，每行表示一个结点，$\odot$ 是 elementwise 乘积，$A_{\text{idx, idx}}$ 是指定行下标和列下标的邻接矩阵。$X_{out}$ 和 $A_{out}$ 是新的特征矩阵和对应的邻接矩阵。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Variation of SAGPool&lt;/strong&gt; 使用图卷积的主要原因是为了反映图的特征和拓扑结构。可以使用不同的图卷积来替换式 3 中的图卷积。计算注意力机制 $Z \in \mathbb{R}^{N \times 1}$ 的泛化公式如下：&lt;/p&gt;
$$\tag{6}
Z = \sigma(\text{GNN}(X, A))
$$&lt;p&gt;$X$ 和 $A$ 是特征矩阵和邻接矩阵。&lt;/p&gt;
&lt;p&gt;除了使用邻接结点还可以使用多跳结点来计算注意力分数。式 7 和式 8 分别使用了两跳连接和堆叠 GNN 层。增加邻接矩阵的平方增加了两条邻居：&lt;/p&gt;
$$\tag{7}
Z = \sigma(\text{GNN}(X, A + A^2))
$$&lt;p&gt;堆叠 GNN 层可以间接的聚合两跳结点。这样的话，非线性层和参数的数量就增加了：&lt;/p&gt;
$$\tag{8}
Z = \sigma(\text{GNN}\_2 (\sigma(\text{GNN}\_1 (X, A)), A))
$$&lt;p&gt;式 7 和式 8 可以利用多跳连接。&lt;/p&gt;
&lt;p&gt;另一个变体是平均多个注意力分数。平均注意力分数通过 $M$ 个 GNN 获得：&lt;/p&gt;
$$\tag{9}
Z = \frac{1}{m} \sum\_m \sigma(\text{GNN}\_m (X, A))
$$&lt;p&gt;在论文中，式 7，8，9 的模型分别记为 $\rm {SAGPool}_{augmentation}$，$\rm {SAGPool}_{serial}$，$\rm {SAGPool}_{parallel}$。&lt;/p&gt;
&lt;h2 id="32-model-architecture"&gt;3.2 Model Architecture
&lt;/h2&gt;&lt;p&gt;根据 Lipton &amp;amp; Steinhardt 的研究，如果对一个模型做很多修改，那很难知道是哪部分改进起的作用。为了一个公平的对比，我们使用了 Zhang et al. 和 Cangea et al. 的模型来对比我们的方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Convolution layer&lt;/strong&gt; 如 2.1 节提到的，有很多图卷积的定义。其他类型的图卷积可能也能提升性能，但是我们利用的是 Kipf &amp;amp; Welling 提出的广泛使用的图卷积。式 10 和式3 一样，除了 $\Theta$ 的维度：&lt;/p&gt;
$$\tag{10}
h^{(l+1)} = \sigma(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} h^{(l)} \Theta)
$$&lt;p&gt;其中 $h^{(l)}$ 是第 $l$ 层的节点表示，$\Theta \in \mathbb{R}^{F \times F&amp;rsquo;}$ 是卷积核。使用 ReLU 作为激活函数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Readout layer&lt;/strong&gt; 受 JK-net 的启发，Cangea et al. 提出了一个 readout 层，聚合结点的特征生成一个固定大小的表示。readout 层的聚合特征如下：&lt;/p&gt;
$$\tag{11}
s = \frac{1}{N} \sum^N\_{i=1} x\_i \mid \mid \mathop{max}\limits^N\_{i=1} x\_i
$$&lt;p&gt;$N$ 是结点数，$x_i$ 是第 $i$ 个结点的特征向量，$\mid \mid$ 表示拼接。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Global pooling architecture&lt;/strong&gt; 我们实现了 Zhang et al. 提出的全局池化结构。如图 2 所示，全局池化结构由三层图卷积层组成，每层的输出拼接在一起。结点特征在 readout 层聚合，然后接一个池化层。图的特征表示传入线性层用来分类。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical pooling architecture&lt;/strong&gt; 在这部分设置中，我们实现了 Cangea et al. 的层次池化结构。如图 2 所示，结构包含了三个块，每个块由一个卷积层和一个池化层组成。每个块的输出通过一个 readout 层聚合。每个 readout 层的输出之和放入线性层做分类。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;h1 id="4-experiments"&gt;4. Experiments
&lt;/h1&gt;&lt;p&gt;我们在图分类上评估了全局池化和层次池化。&lt;/p&gt;
&lt;h2 id="41-datasets"&gt;4.1. Datasets
&lt;/h2&gt;&lt;p&gt;5 个数据集。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Table3.JPG"
loading="lazy"
alt="Table3"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Table4.JPG"
loading="lazy"
alt="Table4"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/self-attention-graph-pooling/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;</description></item><item><title>Session-based Social Recommendation via Dynamic Graph Attention Networks</title><link>https://davidham3.github.io/blog/p/session-based-social-recommendation-via-dynamic-graph-attention-networks/</link><pubDate>Wed, 29 May 2019 13:37:55 +0000</pubDate><guid>https://davidham3.github.io/blog/p/session-based-social-recommendation-via-dynamic-graph-attention-networks/</guid><description>&lt;p&gt;WSDM 2019，原文链接：&lt;a class="link" href="https://arxiv.org/abs/1902.09362" target="_blank" rel="noopener"
&gt;Session-based Social Recommendation via Dynamic Graph Attention Networks&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;像 Facebook 和 Twitter 这样的在线社区很流行，已经成为很多用户生活中的重要部分。通过这些平台，用户可以发掘并创建信息，其他人会消费这些信息。在这种环境下，给用户推荐相关信息变得很重要。然而，在线社区的推荐是一个难题：1. 用户兴趣是动态的，2. 用户会受其朋友的影响。此外，影响者与环境相依。不同的朋友可能关注不同的话题。对两者建模对推荐来说是重要的。&lt;/p&gt;
&lt;p&gt;我们提出了一个基于动态图注意力机制的在线社区推荐系统。我们用一个 RNN 对动态的用户行为建模，用图卷积对依赖环境的社交影响建模，可以动态地根据用户当前的兴趣推测影响者。整个模型可以高效地用于大规模的数据。几个真实数据集上的实验结果显示我们的方法很好，源码在：&lt;a class="link" href="https://github.com/DeepGraphLearning/RecommenderSystems" target="_blank" rel="noopener"
&gt;https://github.com/DeepGraphLearning/RecommenderSystems&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 Introduction
&lt;/h1&gt;&lt;p&gt;在线社区已经成为今天在线体验的重要组成部分。Facebook, Twitter, 豆瓣可以让用户创建、分享、消费信息。因此这些平台的推荐系统对平台上的表层信息和维持用户活跃度来说很重要。然而，在线社区对推荐系统提出了一些挑战。&lt;/p&gt;
&lt;p&gt;首先，用户兴趣本质上来说是动态的。一个用户可能一段时间对体育感兴趣，之后呢对音乐感兴趣。其次，因为在线社区里面的用户经常给朋友分享信息，用户也会被他们的朋友影响。举个例子，一个找电影的用户可能会被她的朋友喜欢的电影影响。此外，施加影响的一方组成的集合是动态的，因为这和环境有关。举个例子，一个用户在找一个搞笑电影的时候会听取一群喜欢喜剧的朋友的意见，在找动作电影的时候，会受到另一组朋友的影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Motivating Example.&lt;/strong&gt; 图 1 展示了 Alice 和 她的朋友在一个在线社区的行为。行为通过一个动作（比如点击操作）序列描述。为了捕获用户的动态兴趣，她们的行为被分成了不同的子序列，表示 &lt;em&gt;sessions&lt;/em&gt;。我们感兴趣的是基于 &lt;em&gt;session&lt;/em&gt; 的推荐：我们根据当前情境下 Alice 已经消费过的东西给她推荐下一个她可能消费的东西。图 1 展示出两个情景，a 和 b。此外，Alice 朋友们的消费信息也是可获得的。我们会利用这些信息生成更好的推荐。因此我们在一个基于 session 的社交推荐情景下。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/session-based-social-recommendation-via-dynamic-graph-attention-networks/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;在 session a 中，Alice 浏览了体育的物品。她的两个朋友：Bob 和 Eva，是出了名的体育粉丝（长期兴趣），他们最近正好浏览了体育相关的物品（短期兴趣）。考虑到这个情况，Alice 可能被他们两个影响，比如说接下来她可能会学习乒乓球。在 session b 中，Alice 对文学艺术物品感兴趣。这个环境和刚才不一样了因为她没有最近正在消费这样物品的朋友。但是 David 一直对这个话题感兴趣（长期兴趣）。在这种情况下，对 Alice 来说可能会被 David 影响，可能会被推荐一本 David 喜欢的书。这些例子表明了一个用户当前的兴趣是如何与他不同的朋友的兴趣相融合来提供基于情景的推荐的。我们提出了一个推荐模型来处理这两种情况。&lt;/p&gt;
&lt;p&gt;当前的推荐系统要么对用户的动态兴趣建模，要么对他们的社交影响建模，但是，据我们所知，现存的方法还没有融合过他们。最近的一个研究对 session 级别的用户行为使用 RNN 建模，忽略了社交影响。其他的研究仅考虑社交影响。举个例子，Ma et al. 探索了朋友的长期兴趣产生的社交影响。但是，不同用户的影响是静态的，没有描绘出每个用户当前的兴趣。&lt;/p&gt;
&lt;p&gt;我们提出了一个方法对用户基于 session 的兴趣和动态社交影响同时建模。也就是说，考虑了基于当前用户的 session，他的朋友的哪个子集影响了他。我们的推荐模型基于动态注意力网络。我们的方法先用一个 RNN 对一个 session 内的用户行为建模。根据用户当前兴趣——通过 RNN 的隐藏表示捕获到的——我们使用 GAT 捕获了他的朋友的影响。为了提供 session 级别的推荐，我们区分了短期兴趣和长期兴趣。在给定用户当前兴趣的基础上，每个朋友的影响通过注意力机制自动地决定。&lt;/p&gt;
&lt;p&gt;我们做了大量实验，效果比很多方法好。贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出了同时对动态用户兴趣和依赖环境的社交影响学习后对在线社区进行推荐的方法。&lt;/li&gt;
&lt;li&gt;提出了基于动态图注意力网络的推荐方法。在大数据集上也有效。&lt;/li&gt;
&lt;li&gt;实验结果比 state-of-the-art 好很多。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="2-related-work"&gt;2 Related Work
&lt;/h1&gt;&lt;p&gt;讨论三条路线：1. 对动态用户行为建模的推荐系统，2. 考虑社交影响的推荐系统，3. 图卷积网络。&lt;/p&gt;
&lt;h2 id="21-dynamic-recommendation"&gt;2.1 Dynamic Recommendation
&lt;/h2&gt;&lt;h2 id="22-social-recommendation"&gt;2.2 Social Recommendation
&lt;/h2&gt;&lt;h2 id="23-graph-convolutional-networks"&gt;2.3 Graph Convolutional Networks
&lt;/h2&gt;&lt;h1 id="3-problem-definition"&gt;3 Problem Definition
&lt;/h1&gt;&lt;p&gt;推荐系统根据历史行为推荐相关的物品。传统的推荐模型，如矩阵分解，忽略了用户的消费顺序。在线社区中，用户兴趣是快速变化的，必须要考虑用户偏好顺序，以便对用户的动态兴趣建模。实际上，因为用户全部的历史记录可以很长（有些社区存在好多年了），用户兴趣切换的很快，一个常用的方法是将用户的偏好分成不同的 session，（使用时间戳，以一个星期为时间段考虑每个用户的行为）并以 session 为级别提供推荐。定义如下：&lt;/p&gt;
&lt;p&gt;DEFINITION 1. (&lt;strong&gt;Session-based Recommendation&lt;/strong&gt;)，$U$ 表示用户的集合，$I$ 表示物品集。每个用户 $u$ 和一组带有时间步 $T$ 的 session 相关，$I^u_T = \lbrace \vec{S}^u_1, \vec{S}^u_2, \dots \vec{S}^u_T \rbrace$，其中 $\vec{S}^u_t$ 是用户 $u$ 的第 $t$ 个 session。在每个 session 内，$\vec{S}^u_t$ 由一个用户行为的序列 $\lbrace i^u_{t,1}, i^u_{t,2}, \dots, i^u_{t,N_{u,t}} \rbrace$ 组成，其中 $i^u_{t,p}$ 是在第 $t$ 个 session 中用户消费的第 $p$ 个物品，$N_{u,t}$ 是 session 中物品的总数。对于每个用户 $u$，给定一个 session $\vec{S}^u_{T+1} = \lbrace i^u_{T+1,1}, \dots i^u_{T+1,n} \rbrace$，基于 session 的推荐系统的目标是从 $I$ 中推荐一组用户可能在下来的 $n+1$ 步时感兴趣的物品，即 $i^u_{T+1, n+1}$。&lt;/p&gt;
&lt;p&gt;在在线社区中，用户的兴趣不仅与他们的历史行为相关，也受他们的朋友的影响。举个例子，一个朋友看电影，我也可能会感兴趣。这就叫社交影响。此外，从朋友那里来的影响是跟环境有关的。换句话说，从朋友那里来的影响是不一样的。如果一个用户想买个笔记本电脑，她可能更倾向于问问她喜欢高科技产品的朋友；如果她要买相机，她可能会被她的摄影师朋友影响。就像图 1，一个用户可能被她朋友的长期兴趣和短期兴趣影响。&lt;/p&gt;
&lt;p&gt;为了提供一个有效的推荐结果，我们提出对动态的用户兴趣和依赖于环境的社交影响建模。我们定义了如下的问题：&lt;/p&gt;
&lt;p&gt;DEFINITION 2. (&lt;strong&gt;Session-based Social Recommendation&lt;/strong&gt;) $U$ 表示用户集，$I$ 表示物品集合，$G=(U, E)$ 是社交网络，$E$ 是社交网络的边。给定用户 $u$ 的一个 session $\vec{S}^u_{T+1} = \lbrace i^u_{T+1,1}, \dots i^u_{T+1,n} \rbrace$，目标是利用她的动态兴趣（$\cup^{T+1}_{t=1} \vec{S}^u_t$）和社交影响（$\cup^{N(u)}_{k=1} \cup^T_{t=1} \vec{S}^k_t$，其中 $N(u)$ 是用户 $u$ 的邻居），从 $I$ 中推荐一组用户 $u$ 可能在下来的 $n+1$ 步时感兴趣的物品，即 $i^u_{T+1, n+1}$。&lt;/p&gt;
&lt;h1 id="4-dynamic-social-recommender-systems"&gt;4 Dynamic Social Recommender Systems
&lt;/h1&gt;&lt;p&gt;我们提出的模型 Dynamic Graph Recommendation (DGREC) 是个动态图注意力模型，可以对用户近期的偏好和他的朋友的偏好建模。&lt;/p&gt;
&lt;p&gt;DGREC 有 4 个模块（图 2）。首先，一个 RNN 对用户当前 session 中的物品序列建模。她朋友的偏好使用长期偏好和短期偏好融合来建模。短期偏好，或是最近一次 session 中的物品也使用 RNN 来编码。朋友的长期偏好通过一个独立的嵌入层编码。模型使用 GAT 融合当前用户的表示和她朋友的表示。这是我们模型的关键：我们提出了基于用户当前的兴趣学习每个朋友的权重的机制。最后一步，模型通过融合用户当前偏好和她的社交影响得到推荐结果。&lt;/p&gt;</description></item><item><title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</title><link>https://davidham3.github.io/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/</link><pubDate>Wed, 08 May 2019 16:40:48 +0000</pubDate><guid>https://davidham3.github.io/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/</guid><description>&lt;p&gt;AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：&lt;a class="link" href="https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf" target="_blank" rel="noopener"
&gt;DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;人口流量预测在城市规划、交通管控中的很多应用中都很重要。目的是预测流入和流出流量。我们提出了 DeepSTN+，一个基于深度学习的卷积模型，预测超大城市的人口流量。首先，DeepSTN+ 使用 &lt;em&gt;ConvPlus&lt;/em&gt; 结构对大范围的空间依赖建模。此外，POI 分布和时间因素相融合来表达区域属性的影响，以此引入人口流动的先验知识。最后，我们提出了一个有效的融合机制来稳定训练过程，提升了结果。基于两个真实数据集的大量实验结果表明我们模型的先进性，和 state-of-the-art 比高了 8% ~ 13% 左右。&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction
&lt;/h1&gt;&lt;p&gt;如图 1 所示，人口流量预测是在给定历史流量信息的前提下，预测城市内每个区域的流入和流出流量。最近，为了解决这个问题，基于深度学习的模型被相继提出，获得了很好的效果。Deep-ST 是第一个使用卷积网络捕获空间信息的模型。ST-ResNet 用卷积模块替换了卷积。通过融合金字塔型的 ConvGRU 模型和周期表示，Periodic-CRN 设计成了捕获人口流动周期性的模型。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;这些方法仍然不够有效且不精确：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;不能捕获区域间的空间依赖。&lt;/em&gt; 由于现代城市中高级的运输系统的存在，人们可以通过地铁或出租车在短时间内移动到很远的地方。因此，区域间的大范围空间依赖在人口移动中逐渐扮演重要的角色。现存的工作使用多层卷积网络来建模。然而，它们只能一步一步地捕获近邻的空间依赖，不能直接地捕获大范围的空间依赖。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;忽略了人口流动的区域功能的影响。&lt;/em&gt; 人口移动是发生在物理世界中的，会直接受到区域属性的影响。举个例子，人们通常早上从家出发到公司，晚上回来。显然，区域的功能（属性）包含了关于人类移动的先验知识。然而，现存的解决方案没有考虑过区域的属性。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;冗余以及不稳定的神经网络结构。&lt;/em&gt; ST-ResNet 利用了三个独立分支，每个分支都是残差卷积单元，用来处理不同的输入，在模型的结尾用一个线性操作融合三个输出。但是，最后的融合机制导致不同组件间的交互产生了缺陷，这个缺陷导致了网络内产生了无效的参数和不稳定的性质。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总结一下，模型应该考虑大范围的空间依赖，区域的影响，更有效的融合机制这三点因素。我们提出的 DeepSTN+ 解决了上述挑战。我们设计了一个 &lt;em&gt;ConvPlus&lt;/em&gt; 结构直接地捕获大范围空间依赖。&lt;em&gt;ConvPlus&lt;/em&gt; 放在残差单元前面作为一个全局特征提取器提取出区域间的全局特征。其次，我们设计了一个 &lt;em&gt;SemanticPlus&lt;/em&gt; 结构来学习人口在区域间移动的先验知识。用静态的 POI 分布作为输入，&lt;em&gt;SemanticPlus&lt;/em&gt; 利用时间因素给不同时间上不同的 POI 分配权重。最后，我们引入早融合和多尺度融合机制来减少训练参数，捕获不同级别特征间的复杂关系。这样，我们的系统可以对更复杂的空间关联性建模，获得更好的效果，我们的贡献有以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们设计了一个新的残差单元，ResPlus 单元用来替换原始的残差单元。我们指出了典型的卷积模型不能有效地捕获大范围依赖。ResPlus 包含了一个 &lt;em&gt;ConvPlus&lt;/em&gt; 结构，可以捕获人流间的大范围空间依赖。&lt;/li&gt;
&lt;li&gt;我们设计了一个 &lt;em&gt;SemanticPlus&lt;/em&gt; 结构来建模不同区域的影响，学习人口流动的先验知识。我们在模型头部使用早融合机制，在结尾使用多尺度融合机制，提升了模型的精度和稳定性。&lt;/li&gt;
&lt;li&gt;我们在两个数据集上开展了大量的实验，对比了 5 个 baselines，结果显示我们的模型在预测人口流动的错误上减少了 8% ~ 13%。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="preliminaries"&gt;Preliminaries
&lt;/h1&gt;&lt;p&gt;这部分，我们首先介绍人口流量预测问题，简要回顾 ST-ResNet。&lt;/p&gt;
&lt;h2 id="problem-formulation"&gt;Problem Formulation
&lt;/h2&gt;&lt;p&gt;**Definition 1 (Region (Zhang et al. 2016)) 为了表示城市的区域，我们基于经纬度将城市划分成 $H \times W$ 个区域，所有的网格有相同大小且表示一个区域。&lt;/p&gt;
&lt;p&gt;**Definition 2 (Inflow/outflow (Zhang et al. 2016)) 为了表示城市内的人口流动，我们定义了区域 $(h, w)$ 在时段 $i$ 的流入和流出流量：&lt;/p&gt;
&lt;p&gt;$$
x^{h,w,in}_{i} = \sum_{T_{r_k} \in \mathbb{P}} \vert \lbrace j &amp;gt; 1 \mid g_{j-1} \not \in (h, w) \And g_j \in (h, w) \rbrace \vert,\&lt;/p&gt;
&lt;p&gt;x^{h,w,out}_{i} = \sum_{T_{r_k} \in \mathbb{P}} \vert \lbrace j \geq 1 \mid g_{j-1} \in (h, w) \And g_j \not \in (h, w) \rbrace \vert.
$$&lt;/p&gt;
&lt;p&gt;这里 $\mathbb{P}$ 表示时段 $i$ 的轨迹集合。$T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的一条轨迹，$g_j$ 是坐标；
$g_j \in (h, w)$ 表示点 $g_j$ 在网格 $(h, w)$ 内，反之亦然；$\vert \cdot \vert$ 表示集合的基数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Crowd Flow Prediction&lt;/strong&gt;: 给定历史观测值 $\lbrace \mathbf{X}_i \mid i=1,2,\cdots, n-1 \rbrace$，预测 $\mathbf{X}_n$。&lt;/p&gt;
&lt;p&gt;ST-ResNet 包含四个组件，&lt;em&gt;closeness&lt;/em&gt;, &lt;em&gt;period&lt;/em&gt;, &lt;em&gt;trend&lt;/em&gt; 和 外部因素单元。每个组成部分通过一个分支的残差单元或全连接层预测出一个流量地图。然后模型使用一个线性组合作为末端融合方式融合这些预测值。ST-ResNet 的外部因素包含了天气、假期事件、元数据。&lt;/p&gt;
&lt;p&gt;卷积神经网络的卷积核通常很小，意味着他们不能直接捕获远距离的空间依赖。然而，大范围的空间依赖在城市中很重要。另一方面，ST-ResNet 忽略了人口流动的在位置上的影响。此外，ST-ResNet 的末端融合机制导致了模型交互上的缺点以及参数的低效，还有模型的不稳定的问题。&lt;/p&gt;
&lt;h1 id="our-model"&gt;Our Model
&lt;/h1&gt;&lt;p&gt;图 2 展示了我们模型的框架。主要有三个部分：流量输入、SemanticPlus 和 ResPlus 单元。流量慎入包含 &lt;em&gt;closeness, period, terend&lt;/em&gt;，由于数据的时间范围限制可以减少为 &lt;em&gt;closeness, period&lt;/em&gt;。SemanticPlus 包含 POI 分布和时间信息。ResPlus 单元可以捕获远距离空间依赖。每个区域的流入和流出流量通过每小时或者每半小时统计得到流量地图的时间序列。这些流量地图通过 Min-Max 归一化处理到 $[-1, 1]$。如图 2 所示，人口分布地图通过近期时间、近邻历史、远期历史选择后作为输入放入模型。不同类型的 POI 分布通过 Min-Max 归一化到 $[0, 1]$。如图 2 做部分所示，POI 分布地图通过时间信息赋予了不同的权重。之后，POI 信息和人流信息通过早融合后放入堆叠的 ResPlus 单元中。最后，ResPlus 单元不同级别的特征融合后进入卷积部分，然后通过 Tanh 映射到 $[-1, 1]$。下面会介绍细节。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;h2 id="resplus"&gt;ResPlus
&lt;/h2&gt;&lt;p&gt;很多处理人口流量预测的深度学习模型主要包含两个部分：基于 RNN 的结构，像 ConvLSTM 和 Periodic-CRN，以及基于 CNN 的结构，如 Deep-ST 和 ST-ResNet。但是，训练基于 RNN 结构的模型费时。因此我们选用基于 CNN 的结构 ST-ResNet 作为我们的基础模型。&lt;/p&gt;
&lt;p&gt;在这篇论文中，我们设计 ConvPlus 来捕获城市内远距离的空间依赖。如图 3，ResPlus 单元使用一个 ConvPlus 和一个典型卷积。我们尝试了 Batch Normalization 和 Dropout，为了简介没有在图里面画出来。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;典型卷积的每个通道对应一个卷积核。卷积核使用这些核来计算地图上的互相关系数，比如捕获梯度上的特征。卷积核的大小一般很小。在 ST-ResNet 和 DeepSTN+ 里面，卷积核的大小是 $3 \times 3$。但是城市中存在着远距离的依赖。人们可能坐地铁去上班。我们称这类关系叫远距离空间依赖关系。这种关系使得堆叠卷积难以有效地捕获这个关系。&lt;/p&gt;
&lt;p&gt;如图 3 左部分所示，在 ConvPlus 结构中，我们将典型卷积的一些通道分离来捕获每个区域的远距离空间依赖。然后用一个全连接层直接捕获每两个区域之间的远距离空间依赖，在这层前面用一个池化层来减少参数。因此，在 ConvPlus 的输出有两类通道。ConvPlus 的输出有着和普通卷积一样的输出，可以用于下一个卷积的输入。&lt;/p&gt;
&lt;p&gt;图 4 展示了两个不同区域的空间依赖热力图，分别是红色和黄色的星。这些目标区域不仅有区域上的依赖，还有一些和远处区域的远距离依赖。这也显示出不同的区域和地图上的其他区域有不一样的关系，这很难通过堆叠卷积有效地捕获。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;p&gt;因为 ConvPlus 有两类不同的输出通道，我们在 ResPlus 单元中使用 ConvPlus + Conv 而不是 ConvPlus + ConvPlus。没有 SemanticPlus 的 DeepSTN+ 形式化为：&lt;/p&gt;
$$
\widehat{\mathbf{X}} = f\_{Res}(f\_{EF}(\mathbf{X}^c + \mathbf{X}^p + \mathbf{X}^t)),
$$&lt;p&gt;三个 $\mathbf{X}$ 表示三种类型的历史地图——&lt;em&gt;closeness, period, trend&lt;/em&gt;。$\widehat{\mathbf{X}}$ 表示预测出的流量地图。$+$ 表示拼接操作。$f_{EF}$ 表示用来早融合不同类型信息的卷积函数，$f_{Res}$ 表示一个堆叠的 ResPlus 单元。&lt;/p&gt;
&lt;h2 id="semanticplus"&gt;SemanticPlus
&lt;/h2&gt;&lt;p&gt;POI 在人口流动上有很强烈的影响，这些影响随时间变化而变化。因此，我们继承这个先验知识到模型内。我们手机了包括类型、数量、位置的 POI 信息。然后统计每个网格内 POI 的数量，使用一个一维向量表示每种 POI 的分布。图 5 展示了北京的流量分布地图和餐饮分布地图。它们的分布很相似，并且互相关系数有 0.87，暗示了它们之间的潜在关系。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig5.JPG"
loading="lazy"
alt="Figure5"
&gt;&lt;/p&gt;
&lt;p&gt;我们使用一个时间向量来表示每个人口流量地图的时间。时间向量包含两个部分：一个 one-hot 向量表示一天中的各个时间，如果时段按小时走，那长度就是 24；另一个 one-hot 向量表示是一周中的哪天，长度是 7。一个时间向量拼接了这两个向量。&lt;/p&gt;
&lt;p&gt;为了建模对流量地图有变化的时间影响的 POI 信息，我们将时间向量转换为 POI 的影响强度。我们使用大小为 $PN \times H \times W$ 的 $\mathbf{X}^s$ 来表示 POI 地图（$PN$ 表示 POI 的类数，$H$ 和 $W$ 是网格的行数和列数，一个向量 $\bf{I}$ 用来表示时间向量，大小为 $PN$ 的向量 $\bf{R}$ 表示 POI 的影响强度。因此，我们有带有时间权重的 POI 分布，形式化如下：&lt;/p&gt;
$$
\mathbf{S} = \mathbf{X}^s \ast \mathbf{R} = \mathbf{X}^s \ast f\_t(\mathbf{I})
$$&lt;p&gt;函数 $f_t()$ 将时间向量转换为表示 POI 影响强度的向量。$\ast$ 表示每个 POI 分布地图会被附上一个权重，表示 POI 的影响强度。我们假设同一类在不同的区域的 POI 有相同的时间模式。因此，一个类别的 POI 分布地图会有相同的权重。图 6 展示了娱乐和居住区的影响强度。影响强度在一周内随时间的变化而变化，每天存在着一些典型的模式。很多人早上去上班，工作结束后回家，所以每天早上和下午住宅区有明显的两个峰。对比居住区，娱乐区的影响相对稳定。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig6.JPG"
loading="lazy"
alt="Figure6"
&gt;&lt;/p&gt;
&lt;h2 id="fusion"&gt;Fusion
&lt;/h2&gt;&lt;p&gt;三组件应该用更复杂的融合方式，而不是线性组合。这些带有 POI 信息的流量信息也有复杂的交互。为了建模这种相互影响，我们使用早融合而不是末端融合使得不同的信息能更早的融合起来。早融合减少了大约三分之二的参数。此外，ST-ResNet 有些时候不能收敛。我们发现这个问题可以通过早融合减少参数来简化模型解决。考虑到不同层的特征有不同的函数，我们在模型末端设定了一个多尺度的融合机制。这里我们形式化描述整个网络：&lt;/p&gt;
$$
\widehat{\mathbf{X}} = f\_{con}(f\_{Res}(f\_{EF}(\mathbf{X}^c + \mathbf{X}^p + \mathbf{X}^t + \mathbf{S}))),
$$&lt;p&gt;函数 $f_{EF}$ 表示一个早融合使用的卷积操作，在早融合之前压缩了通道数。函数 $f_{con}$ 表明了最后的多尺度融合，表示卷积层后的一个拼接层。$\bf{S}$ 表示 SemanticPlus 的输出，即 带有时间权重的 POI 分布。&lt;/p&gt;
&lt;h2 id="training"&gt;Training
&lt;/h2&gt;&lt;p&gt;算法 1 描述了训练过程。前 7 行是构建训练集和 POI 信息，模型通过 Adam 训练（8-12 行）&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Alg1.JPG"
loading="lazy"
alt="Alg1"
&gt;&lt;/p&gt;
&lt;h1 id="performance-evaluation"&gt;Performance Evaluation
&lt;/h1&gt;&lt;p&gt;这部分，我们在两个数据集上不同城市的不同类型的流量上做了大量的实验，为了回答三个研究问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们的提出的 DeepSTN+ 是否比现存的方法好？&lt;/li&gt;
&lt;li&gt;ResPlus, SemanticPlus, 早融合是怎么提升预测结果的？&lt;/li&gt;
&lt;li&gt;DeepSTN+ 的超参数如何影响预测结果？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="datasets"&gt;Datasets
&lt;/h2&gt;&lt;p&gt;表 1 包含了数据。每个数据有两个子集：流量轨迹和 POI 信息。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;MobileBJ:&lt;/strong&gt;&lt;/em&gt; 数据是中国一个很流行的社交网络应用商提供的，时间范围是4 月 1 日到 4 月 30 日。记录了用户请求区域服务时的位置。我们用定义 2 转换成了网格流量。我们选择最后一周的数据作为测试集，前面的作为训练集。表 2 展示了这个数据集的 17 类 POI 信息。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;BikeNYC:&lt;/strong&gt;&lt;/em&gt; NYC 的自行车数据，2014 年，4 月 1 日到 9 月 30 日。数据包含了旅途时长，出发和到达站的 ID，起始和结束时间。最后 14 天的数据用来测试，其他的训练。我们选了 9 类 POI 信息。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;&lt;/p&gt;
&lt;h2 id="baselines"&gt;Baselines
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;HA&lt;/li&gt;
&lt;li&gt;VAR&lt;/li&gt;
&lt;li&gt;ARIMA&lt;/li&gt;
&lt;li&gt;ConvLSTM&lt;/li&gt;
&lt;li&gt;ST-ResNet&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="metrics-and-parameters"&gt;Metrics and Parameters
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;RMSE&lt;/li&gt;
&lt;/ul&gt;
$$
RMSE = \sqrt{\frac{1}{T} \sum^T\_{i=1} \Vert \mathbf{X}\_i - \widehat{X}\_i \Vert^2\_2},
$$&lt;ul&gt;
&lt;li&gt;MAE&lt;/li&gt;
&lt;/ul&gt;
$$
MAE = \frac{1}{T} \sum^T\_{i=1} \vert \mathbf{X}\_i - \widehat{\mathbf{X}}\_i \vert,
$$&lt;p&gt;RMSE 作为 loss function。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table3.JPG"
loading="lazy"
alt="Table3"
&gt;&lt;/p&gt;
&lt;p&gt;表 3 展示了不同的参数设置。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table4.JPG"
loading="lazy"
alt="Table4"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table5.JPG"
loading="lazy"
alt="Table5"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig7.JPG"
loading="lazy"
alt="Figure7"
&gt;&lt;/p&gt;</description></item><item><title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</title><link>https://davidham3.github.io/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/</link><pubDate>Fri, 19 Apr 2019 16:40:41 +0000</pubDate><guid>https://davidham3.github.io/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/</guid><description>&lt;p&gt;TKDE 2019，网格流量预测，用一个模型同时预测每个网格的流入/流出流量和网格之间的转移流量，分别称为顶点流量和边流量，同时预测这两类流量是本文所解决的多任务预测问题。本文提出的是个框架，所以里面用什么组件应该都是可以的，文章中使用了 FCN。使用两个子模型分别处理顶点流量和边流量预测问题，使用两个子模型的输出作为隐藏状态表示，通过拼接或加和的方式融合，融合后的新表示再分别输出顶点流量和边流量。这篇文章和之前郑宇的文章一样，考虑了三种时序性质、融合了外部因素。损失函数从顶点流量预测值和真值之间的差、边流量预测值和真值之间的差、顶点流量预测值之和与边流量的预测值之差三个方面考虑。数据集是北京和纽约的出租车数据集。 &lt;a class="link" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=8606218" target="_blank" rel="noopener"
&gt;Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;——预测流量（如车流、人流、自行车流）包括结点的流入、流出流量以及不同的结点间的转移，在交通运输系统中的时空网络里扮演着重要的角色。然而，这个问题受多方面复杂因素影响，比如不同地点的空间关系、不同时段的时间关系、还有像活动和天气这样的外部因素，所以这是个有挑战性的问题。此外，一个结点的流量（结点流量）和结点之间的转移（边流量）互相影响。为了解决这个问题，我们提出了一个多任务的深度学习框架可以同时预测一个时空网络上的结点流量和边流量。基于全卷积网络，我们的方法设计了两个复杂的模型分别处理结点流量预测和边流量预测。这两个模型通过组合中间层的隐藏表示连接，而且共同训练。外部因素通过一个门控融合机制引入模型。在边流量预测模型上，我们使用了一个嵌入组件来处理顶点间的系数转移问题。我们在北京和纽约的出租车数据集上做了实验。实验结果显示比11种方法都好。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 Introduction
&lt;/h1&gt;&lt;p&gt;时空网络（ST-networks），如运输网络和传感器网络，在世界上到处都是，每个点有个空间坐标，每个边具有动态属性。时空网络中的流量有两种表示，如图 1，顶点流量（一个结点的流入和流出流量）和边流量（结点间的转移流量）。在运输系统中，这两类流量可通过4种方式测量，1. 近邻道路的车辆数，2. 公交车的旅客数，3. 行人数，4. 以上三点。图1b 是一个示意图。取顶点 $r_1$ 为例，我们可以根据手机信令和车辆 GPS 轨迹分别计算得到流入流量是 3，流出流量是 3。$r_3$ 到 $r_1$ 的转移是 3，$r_1$ 到 $r_2$ 和 $r_4$ 的转移是 2 和 1。因此，如图1c所示，我们能拿到两种类型的流量，四个结点的流入和流出分别是 $(3,3,0,5)$ 和 $(3,2,5,1)$。所有的边转移都看作是在有向图上发生的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;预测这类的流量对公共安全，交通管理，网络优化很重要。取人口流动做一个例子，2015 年跨年夜的上海，踩踏事故导致 36 人死亡。如果能预测每个区域之间的人流转移，这样的悲剧就可以通过应急预案避免或减轻。&lt;/p&gt;
&lt;p&gt;然而，同时预测所有结点和边的转移是很难的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Scale and complexity&lt;/strong&gt;: 一个地方的流入和流出依赖于它的邻居，有近邻的也有遥远的，因为人们会在这些区域之间转移，尤其是有活动的时候。给定一个城市，有 $N$ 个地点，$N$ 很大，那么就有 $N^2$ 种转移方式，尽管这些转移可能不会同时发生。因此，预测地点的流量，要么是流入、流出或是转移流量，我们需要考虑地点之间的依赖关系。而且，预测也考虑过去时段的流量。此外，我们不能单独地预测每个地点的流量，因为城市内的地点间是相连的，相关的，互相影响的。复杂度和尺度都是传统机器学习模型，如概率图模型在解决这个问题时面临的巨大挑战。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model multiple correlations and external factors&lt;/strong&gt;: 我们需要对三种关系建模来处理预测问题。第一个是不同地点流量的空间相关性，包含近邻和遥远的。第二个是一个地点不同时段的流量间的时间关系，包括时间近邻、周期和趋势性。第三，流入流出流量和转移流量高度相关，互相影响。一个区域的转入流量之和是这个区域的流入流量。精确地预测一个区域的流出流量可以让预测其他区域的转移流量更精确，反之亦然。此外，这些流量受外部因素影响，如活动、天气、事故等。如何整合这些信息还是个难题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamics and sparsity&lt;/strong&gt;: 由于 $N^2$ 种情况，区域间随时间改变的转移流量比流入流出流量要大得多。一个地点和其他地点间的转移会在接下来的时段发生，可能是 $N^2$ 中的很小一部分（稀疏）。预测这样的稀疏转移也是个难题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决上述挑战，我们提出了多任务深度学习框架MDL（图4）来同时预测顶点流量和边流量。我们的贡献有三点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MDL 设计了一个深度神经网络来预测顶点流量（命名为 NODENET），另一个深度神经网络预测边流量（命名为 EDGENET）。通过将他们的隐藏状态拼接来连接这两个深度神经网络，并一同训练。此外，这两类流量的相关性通过损失函数中的正则项来建模。基于深度学习的模型可以处理复杂性和尺度等问题，同时多任务框架增强了每类流量的预测性能。&lt;/li&gt;
&lt;li&gt;NODENET 和 EDGENET 都是 three-stream 全卷积网络（3S-FCNs），closeness-stream, period-stream, trend-stream 捕获三种不同的时间相关性。每个 FCN 也同时捕获近邻和遥远的空间关系。一个门控组件用来融合时空相关性和外部因素。为了解决转移稀疏的问题，EDGENET 中我们设计了一个嵌入组件，用一个隐藏低维表示编码了稀疏高维的输入。&lt;/li&gt;
&lt;li&gt;我们在北京和纽约的 taxicab data 上评估了方法。结果显示我们的 MDL 超越了其他 11 种方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表 1 列出了这篇文章中出现的数学符号。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;h1 id="2-problem-formulation"&gt;2 Problem Formulation
&lt;/h1&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Definition 1(Node).&lt;/strong&gt;&lt;/em&gt; 一个空间地图基于经纬度被分成 $I \times J$ 个网格，表示为 $V = \lbrace r_1, r_2, &amp;hellip;, r_{I\times J} \rbrace$，每个元素表示一个空间节点，如图2(a)。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;p&gt;令 $(\tau, x, y)$ 为时空坐标，$\tau$ 表示时间戳，$(x, y)$ 表示空间点。一个物体的移动可以记为一个按时间顺序的空间轨迹，起点和终点表示为 $s = (\tau_s, x_s, y_s)$ 和 $e = (\tau_e, x_e, y_e)$，表示出发地和目的地。$\mathbb{P}$ 表示所有的起止对。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Definition 2(In/out flows).&lt;/strong&gt;&lt;/em&gt; 给定一组起止对 $\mathbb{P}$。$\mathcal{T} = \lbrace t_1, \dots t_T\rbrace$ 表示一个时段序列。对于地图上第 $i$ 行第 $j$ 列的顶点 $r_{ij}$，时段 $t$ 流出和流入的流量分别定义为：&lt;/p&gt;
$$\tag{1}
\mathcal{X}\_t(0, i, j) = \vert \lbrace (s,e) \in \mathbb{P} : (x\_s, y\_s) \in r\_{ij} \wedge \tau\_s \in t \rbrace \vert
$$$$\tag{2}
\mathcal{X}\_t(1, i, j) = \vert \lbrace (s,e) \in \mathbb{P} : (x\_e, y\_e) \in r\_{ij} \wedge \tau\_e \in t \rbrace \vert
$$&lt;p&gt;其中 $\mathcal{X}_t(0, :, :)$ 和 $\mathcal{X}_t(1, :, :)$ 表示流出和流入矩阵。$(x, y) \in r_{ij}$ 表示点 $(x, y)$ 在顶点 $r_{ij}$ 上，$\tau_e \in t$ 表示时间戳 $\tau_e$ 在时段 $t$ 内。流入和流出矩阵在特定时间的矩阵如图2。&lt;/p&gt;
&lt;p&gt;考虑两类流量（流入和流出），一个随时间变化的空间地图一般表示一个时间有序的张量序列，每个张量对应地图在特定时间的一个快照。详细来说，每个张量包含两个矩阵：流入矩阵和流出矩阵，如图 2 所示。&lt;/p&gt;
&lt;p&gt;让 $V$ 表示时空网络中的顶点集，$N \triangleq \vert V \vert = I \times J$ 是顶点数。一个时间图包含 $T$ 个离散的不重叠的时段，表示为有向图 $G_{t_1}, \dots G_{t_T}$ 的时间有序序列。图 $G_t = (V, E_t)$ 捕获了时段 $t$ 时空系统上的拓扑状态。对于每个图 $G_t$ (其中 $t = t_1, \dots, t_T$) 存在一个对应的权重矩阵 $\mathbf{S}_t \in \mathbb{R}^{N \times N}$，表示时段 $t$ 的带权有向边。在我们的研究中，时段 $t$ 顶点 $r_s$ 到顶点 $r_e$ 的边的权重，是一个非负标量，表示 $r_s$ 到 $r_e$ 的 &lt;em&gt;transition&lt;/em&gt;，时段 $t$ 上两个顶点间没有连接的话，对应的元素在 $\mathbf{S}_t$ 中为 0。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Definition 3 (Transition).&lt;/strong&gt;&lt;/em&gt; 给定一组起止点对 $\mathbb{P}$。$\mathcal{T} = \lbrace t_1, \dots, t_T \rbrace$ 是一组时段的序列。$\mathbf{S}_t$ 是时段 $t$ 的转移矩阵，$r_s$ 到 $r_e$ 之间的转移表示为 $\mathbf{S}_t(r_s, r_e)$，定义为：&lt;/p&gt;
$$\tag{3}
\mathbf{S}\_t(r\_s, r\_e) = \vert \lbrace (s,e) \in \mathbb{P} : (x\_s, y\_s) \in r\_s \wedge (x\_e, y\_e) \in r\_e \wedge \tau\_s \in t \wedge \tau\_e \in t \rbrace \vert
$$&lt;p&gt;其中 $r_s, r_e \in V$ 是起始顶点和终止顶点。$(x, y) \in r$ 表示点 $(x, y)$ 在网格 $r$ 上。$\tau_s \in t$ 和 $\tau_e \in t$ 表示时间戳 $\tau_s$ 和 $\tau_e$ 都在时段 $t$ 内。我们考虑转移至发生在一个特定的时段内。因此，对于实际应用来说，我们可以预测起始和结束都发生在未来的转移。&lt;/p&gt;
&lt;h2 id="21-converting-time-varying-graphs-into-tensors"&gt;2.1 Converting time-varying graphs into tensors
&lt;/h2&gt;&lt;p&gt;我们将每个时间上的图转为张量。给定时间 $t$ 有向图 $G_t = (V, E_t)$，我们先做展开，然后计算有向带权矩阵（转移矩阵 $\mathbf{S}_t$），最后给定一个张量 $\mathcal{M}_t \in \mathbf{R}^{2N \times I \times J}$。图 3 是示意图。(a)给定时间 $t$ 4 个顶点 6 条边的图。(b)首先展开成有向图。(c)对每个顶点，有一个流入的转移，还有个流出的转移，由一个向量表示（维度是8）。取 $r_1$ 为例，它的流出和流入转移向量分别为 $[0, 2, 0, 1]$ 和 $[0, 0, 3, 0]$，拼接后得到一个向量 $[0, 2, 0, 1, 0, 0, 3, 0]$，包含流出和流入的信息。(d)最后，我们将矩阵 reshape 成一个张量，每个顶点根据原来地图有一个固定的空间位置，保护了空间相关性。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;h2 id="22-flow-prediction-problem"&gt;2.2 FLow Prediction Problem
&lt;/h2&gt;&lt;p&gt;流量预测，简单来说，是时间序列问题，目标是给定历史 $T$ 个时段的观测值，预测 $T+1$ 时段每个区域的流量。但是我们的文章中流量有两个层次，流入和流出以及区域间的转移流量。我们的目标是同时预测这些流量。此外，我们还融入了外部因素如房价信息，天气状况，温度等等。这些外部因素可以收集并提供一些额外有用的信息。相关的符号在表 1 之中。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Problem 1.&lt;/strong&gt;&lt;/em&gt; 给定历史观测值 $\lbrace \mathcal{X}_t, \mathcal{M}_t \mid t = t_1, \dots, t_T \rbrace$，外部特征 $\mathcal{E}_T$，我们提出一个模型共同预测 $\mathcal{X}_{t_{T+1}}$ 和 $\mathcal{M}_{t_{T+1}}$。&lt;/p&gt;
&lt;h1 id="3-multitask-deep-learning"&gt;3 Multitask Deep Learning
&lt;/h1&gt;&lt;p&gt;图 4 展示了我们的 MDL 框架，包含 3 个组成部分，分别用于数据转换，顶点流量建模，边流量建模。我们首先将轨迹（或订单）数据转换成两类流量，i) 顶点流量表示成有时间顺序的张量序列 $\lbrace\mathcal{X}_t \mid t = t_1, \dots, t_T \rbrace$ (1a); ii) 边流量是一个有时间顺序的图序列（转移矩阵）$\lbrace\mathbf{S}_t \mid t = t_1, \dots, t_T \rbrace$ (2a)，之后再根据 2.1 节的方法转换为张量的序列 $\lbrace\mathcal{M}_t \mid t = t_1, \dots, t_T \rbrace$ (2b)。这两类像视频一样的数据之后放到 NODENET 和 EDGENET 中。以 NODENET 为例，它选了三个不同类型的片段，放入 3S-FCN 中，对时间相关性建模。在这个模型中，每部分的 FCN 可以通过多重卷积捕获空间相关性。NODENET 和 EDGENET 中间的隐藏表示通过一个 BRIDGE 组件连接，使两个模型可以共同训练。我们使用一个嵌入层来处理转移稀疏的问题。一个门控融合组件用来整合外部信息。顶点流量和边流量用一个正则化来建模。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;h2 id="31-edgenet"&gt;3.1 EDGENET
&lt;/h2&gt;&lt;p&gt;根据上述的转换方法，每个时段的转移图可以转换成一个张量 $\mathcal{M}_t \in \mathbb{R}^{2N \times I \times J}$。对于每个顶点 $r_{ij}$，它最多有 $2N$ 个转移概率，包含 $N$ 个流入和 $N$ 个流出。然而，对于一个确定的时段，顶点间的转移是稀疏的。受 NLP 的嵌入方法启发，我们提出了使用空间嵌入方法，解决这样的稀疏和高维问题。详细来说，空间嵌入倾向于学习一个将 $2N$ 维映射到 $k$ 维的函数：&lt;/p&gt;
$$\tag{4}
\mathcal{Z}\_t(:, i, j) = \mathbf{W}\_m \mathcal{M}\_t (:, i, j) + \mathbf{b}\_m, 1 \leq i \leq I, 1 \leq j \leq J
$$&lt;p&gt;其中 $\mathbf{W}_m \in \mathbb{R}^{k \times 2N}$ 和 $\mathbf{b}_m \in \mathbb{R}^k$ 是参数。所有的结点共享参数。$\mathcal{M}_t(:, i, j) \in \mathbb{R}^{2N}$ 表示 $(i, j)$ 的向量。&lt;/p&gt;
&lt;p&gt;流量，比如城市中的交通流，总是受时空依赖关系影响。为了捕获不同的时间依赖（近邻、周期、趋势），Zhang et al. 提出了深度时空残差网络，沿时间轴选择不同的关键帧。受这点的启发，我们选择近邻、较近、远期关键帧来预测时段 $t$，分别表示为 $M^{dep}_t = \lbrace M^{close}_t, M^{period}_t, M^{trend}_t \rbrace$，如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Closeness&lt;/strong&gt; dependents:
$$M^{close}\_t = \lbrace \mathcal{Z}\_{t-l\_c}, \dots, \mathcal{Z}\_{t-1} \rbrace$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Period&lt;/strong&gt; dependents:
$$M^{period}\_t = \lbrace \mathcal{Z}\_{t-l\_p}, \mathcal{Z}\_{t-(l\_p - 1) \cdot p}, \dots, \mathcal{Z}\_{t-p} \rbrace$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trend&lt;/strong&gt; dependents:
$$M^{trend}\_t = \lbrace \mathcal{Z}\_{t-l\_q \cdot q}, \mathcal{Z}\_{t-(l\_q - 1)\cdot q}, \dots, \mathcal{Z}\_{t-q} \rbrace$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中 $p$ 和 $q$ 是周期和趋势范围。$l_c$, $l_p$ 和 $l_q$ 是三个序列的长度。&lt;/p&gt;
&lt;p&gt;输出（即下个时段的预测）和输入有相同的分辨率。这样的人物和图像分割问题很像，可以通过全卷积网络 (FCN) [22] 处理。&lt;/p&gt;
&lt;p&gt;受到这个启发，我们提出了三组件的 FCN，如图 4，来捕获时间近邻、周期和趋势依赖。每个组件都是个 FCN，包含了很多卷积（图 5）。根据卷积的性质，一个卷积层可以捕获空间近邻关系。随着卷积层数的增加，FCN 可以捕获更远的依赖，甚至是城市范围大小的空间依赖。然而，这样的深层卷积网络很难训练。因此我们使用残差连接来帮助训练。类似残差网络中的残差连接，我们使用一个包含 BN，ReLU，卷积的块。令三个近邻、周期、趋势三组件的输出分别为 $\mathcal{M}_c$, $\mathcal{M}_p$, $\mathcal{M}_q$。不同的顶点在近邻、周期、趋势上可能有不同的性质。为了解决这个问题，我们提出使用一个基于参数矩阵的融合方式（图 4 中的 PM 融合）：&lt;/p&gt;
$$\tag{5}
\mathcal{M}\_{fcn} = \mathbf{W}\_c \odot \mathcal{M}\_c + \mathbf{W}\_p \odot \mathcal{M}\_p + \mathbf{W}\_q \odot \mathcal{M}\_q
$$&lt;p&gt;其中 $\odot$ 是哈达玛积，$\mathbf{W}$ 是参数，调整三种时间依赖关系的影响。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig5.JPG"
loading="lazy"
alt="Figure5"
&gt;&lt;/p&gt;
&lt;h2 id="32-nodenet-and-bridge"&gt;3.2 NODENET and BRIDGE
&lt;/h2&gt;&lt;p&gt;类似 EDGENET，NODENET 也是一个 3S-GCN，我们选择近邻、较近、遥远的关键帧作为近邻、周期、趋势依赖。区别是 NODENET 没有嵌入层因为输入的通道数只有 2。这三种不同的依赖放入三个不同的 FCN 中，输出通过 PM 融合组件融合（图 4）。然后，得到 3S-FCN 的输出，表示为 $\mathcal{X}_{fcn} \in \mathbb{R}^{C_x \times I \times J}$。&lt;/p&gt;
&lt;p&gt;考虑顶点流量与边流量的相关性，所以从 NODENET 和 EDGENET 学习到的表示应该被连起来。为了连接 NODENET 和 EDGENET，假设 NODENET 和 EDGENET 的隐藏表示分别为 $\mathcal{X}_{fcn}$ 和 $\mathcal{M}_{fcn}$。我们提出两种融合方法：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SUM Fusion:&lt;/strong&gt; 加和融合方法直接将两种表示相加：&lt;/p&gt;
$$\tag{6}
\mathcal{H}(c, :, :) = \mathcal{X}\_{fcn}(c, :, :) + \mathcal{M}\_{fcn}(c, :, :), c = 0, \dots, C - 1
$$&lt;p&gt;其中 $C$ 是 $\mathcal{X}_{fcn}$ 和 $\mathcal{M}_{fcn}$ 的通道数，$\mathcal{H} \in \mathbb{R}^{C \times I \times J}$。显然这种融合方法受限于两种表示必须有相同的维度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CONCAT Fusion:&lt;/strong&gt; 为了从上述的限制中解脱，我们提出了另一种融合方法。顺着通道拼接两个隐藏表示：&lt;/p&gt;
$$\tag{7}
\mathcal{H}(c, :, :) = \mathcal{X}\_{fcn}(c, :, :), c=0, \dots, C\_x - 1
$$$$\tag{8}
\mathcal{H}(C\_x + c, :, :) = \mathcal{M}\_{fcn}(c, :, :), c=0, \dots, C\_m - 1
$$&lt;p&gt;$C_x$ 和 $C_m$ 分别是两个隐藏表示的通道数。$\mathcal{H} \in \mathbb{R}^{(C_x + C_m) \times I \times J}$。拼接融合实际上可以通过互相强化更好地融合顶点流量和边流量。像 BRIDGE 一样我们也讨论了其他的融合方式（4.3 节）。&lt;/p&gt;
&lt;p&gt;在拼接融合中，我们在 NODENET 和 EDGENET 中分别加了一层卷积。卷积用来将合并的隐藏特征 $\mathcal{H}$ 映射到 不同通道大小的输出上，即 $\mathcal{X}_{res} \in \mathbb{R}^{2 \times I \times J}$ 和 $\mathcal{M}_{res} \in \mathbb{R}^{2N \times I \times J}$，如图 6。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig6.JPG"
loading="lazy"
alt="Figure6"
&gt;&lt;/p&gt;
&lt;h2 id="33-fusing-external-factors-using-a-gating-mechanism"&gt;3.3 Fusing External Factors Using a Gating Mechanism
&lt;/h2&gt;&lt;p&gt;外部因素，活动、天气会影响时空网络不同区域的流量。举个例子，一起事故可能会阻塞一个局部区域的交通，一场暴风雨可能会减少整个城市的流量。这样的外部因素就像一个开关，如果它打开了那流量会产生巨大的变化。基于这个思路，我们开发了一种基于门控机制的融合，如图 6 所示。时间 $t$ 的外部因素表示为 $\mathcal{E}_t \in \mathbb{R}^{l_e \times I \times J}$，$\mathcal{E}_t(:, i, j) \in \mathbb{R}^{l_e}$ 表示一个特定顶点的外部信息。我们可以通过下式获得 EDGENET 的门控值：&lt;/p&gt;
$$\tag{9}
\mathbf{F}\_m(i, j) = \sigma(\mathbf{W}\_e(:, i, j) \cdot \mathcal{E}\_t(:, i, j) + \mathbf{b}\_e(i, j)), 1 \leq i \leq I, 1 \leq j \leq J
$$&lt;p&gt;其中 $\mathbf{W}_e \in \mathbb{R}^{l_e \times I \times J}$ 和 $\mathbf{b}_e \in \mathbb{R}^{I \times J}$ 是参数。$\mathbf{F}_m \in \mathbb{R}^{I \times J}$ 是 GATING 的输出，$\mathbf{F}_m(i, j)$ 是对应时空网络中结点 $r_{ij}$ 的门控值。$\sigma(\cdot)$ 是 sigmoid 激活函数，$\cdot$ 是两向量的内积。&lt;/p&gt;
&lt;p&gt;然后我们使用 PRODUCT 融合方式：&lt;/p&gt;
$$\tag{10}
\hat{\mathcal{M}}\_t(c, :, :) = \text{tanh}(\mathbf{F}\_m \odot \mathcal{M}\_{Res}(c, :, :)), c = 0, \dots, 2N - 1
$$&lt;p&gt;类似的，NODENET 最后在时间 $t$ 的预测结果为：&lt;/p&gt;
$$\tag{11}
\hat{\mathcal{X}}\_t(c, :, :) = \text{tanh} (\mathbf{F}\_x \odot \mathcal{X}\_{Res}(c, :, :)), c = 0, 1
$$&lt;p&gt;其中 $\mathbf{F}_x \in \mathbb{R}^{I \times J}$ 是 GATING 的另一个输出。对于顶点流量和边流量使用不同的门控值的一个原因是外部因素对流入/流出流量和不同地点之间的转移流量的影响是不一致的。&lt;/p&gt;
&lt;h2 id="34-losses"&gt;3.4 Losses
&lt;/h2&gt;&lt;p&gt;令 $\phi$ 为 EDGENET 中所有的参数，我们的目标是通过最小化目标函数学习这些参数：&lt;/p&gt;
$$\tag{12}
\mathop{\mathrm{argmin}}\limits\_{\phi} \mathcal{J}\_{edge} = \sum\_{t \in \mathcal{T}}\sum^{2N-1}\_{c=0} \Vert Q^c\_t \odot (\hat{\mathcal{M}}\_t(c, :, :) - \mathcal{M}\_t(c, :, :)) \Vert^2\_F
$$&lt;p&gt;其中 $Q^c_t$ 是指示矩阵，表示 $\mathcal{M}_t(c, :, :)$ 中所有非零元素。$\mathcal{T}$ 是可用的时段，$\Vert \cdot \Vert_F$ 是矩阵的 F 范数。&lt;/p&gt;
&lt;p&gt;类似的，$\theta$ 是 NODENET 的参数，目标函数是：&lt;/p&gt;
$$\tag{13}
\mathop{\mathrm{argmin}}\limits\_{\theta} \mathcal{J}\_{node} = \sum\_{t \in \mathcal{T}}\sum^1\_{c=0} \Vert P^c\_t \odot (\hat{\mathcal{X}}\_t(c, :, :) - \mathcal{X}\_t(c, :, :)) \Vert^2\_F
$$&lt;p&gt;其中 $P^c_t$ 是指示矩阵，表示 $\mathcal{X}_t(c, :, :)$ 中所有非零元素。我们知道对于一个结点来说，它的转入流量之和就是它的流入流量，转出流量之和就是流出流量。定义 2 中定义，$\hat{\mathcal{X}}_t(0, :, :)$ 和 $\hat{\mathcal{X}}_t(1, :, :)$ 分别是流出和流入矩阵。根据 2.1 节定义的方法构建转移矩阵，可知前 $N$ 个通道表示转出流量，后 $N$ 个通道表示转入流量。因此，有下面的损失函数：&lt;/p&gt;
$$\tag{14}
\mathop{\mathrm{argmin}}\limits\_{\theta, \phi} \sum\_{t \in \mathcal{T}} \sum\_i \sum\_j (\Vert \hat{\mathcal{X}}\_t(0, i, j) - \sum^{N-1}\_{c=0} \hat{\mathcal{M}}\_t(c,i,j) \Vert^2 + \Vert \hat{\mathcal{M}}\_t(1,i,j) - \sum^{2N-1}\_{c=N} \hat{\mathcal{M}}\_t(c,i,j) \Vert^2)
$$&lt;p&gt;或者等价的可以写成&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/EQ1.JPG"
loading="lazy"
alt="EQ15"
&gt;&lt;/p&gt;
&lt;p&gt;最后，我们获得融合的损失：&lt;/p&gt;
$$\tag{16}
\mathop{\mathrm{argmin}}\limits\_{\theta, \phi} \lambda\_{node} \mathcal{J}\_{node} + \lambda\_{edge} \mathcal{J}\_{edge} + \lambda\_{mdl} \mathcal{J}\_{mdl}
$$&lt;p&gt;其中，$\lambda_{node}$, $\lambda_{edge}$, $\lambda_{mdl}$ 是可调节的参数。&lt;/p&gt;
&lt;h3 id="341-optimization-algorithm"&gt;3.4.1 Optimization Algorithm
&lt;/h3&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Alg1.JPG"
loading="lazy"
alt="Alg1"
&gt;&lt;/p&gt;
&lt;p&gt;算法 1 是 MDL 的训练过程。1-4 行是构建训练样例。7-8 行是用批量样本优化目标函数。&lt;/p&gt;
&lt;h1 id="4-experiments"&gt;4 Experiments
&lt;/h1&gt;&lt;p&gt;两个数据集 &lt;strong&gt;TaxiBJ&lt;/strong&gt; 和 &lt;strong&gt;TaxiNYC&lt;/strong&gt;，看表 2。我们使用 RMSE 和 MAE 作为评价指标。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;&lt;/p&gt;
&lt;h2 id="41-settings"&gt;4.1 Settings
&lt;/h2&gt;&lt;h3 id="411-datasets"&gt;4.1.1 Datasets
&lt;/h3&gt;&lt;p&gt;我们使用表 3 中的两个数据集。每个数据集包含两个子集，轨迹/出行和外部因素，细节如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TaxiBJ&lt;/strong&gt;: 北京出租车 GPS 轨迹数据有四个时段：20130101-20131030, 20140301-20140630, 20150501-20150630, 201501101-20160410。我们用最后 4 个星期作为测试集，之前的数据作为训练集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TaxiNYC&lt;/strong&gt;: NYC 2011 到 2014 年的出租车订单数据。订单数据包含上车和下车的时间。上车和下车地点。最后四个星期作为测试集。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table3.JPG"
loading="lazy"
alt="Table3"
&gt;&lt;/p&gt;
&lt;h3 id="412-baselines"&gt;4.1.2 Baselines
&lt;/h3&gt;&lt;p&gt;HA, ARIMA, SARIMA, VAR, RNN, LSTM. GRU, ST-ANN, ConvLSTM, ST-ResNet, MRF.&lt;/p&gt;
&lt;h3 id="413-preprocessing"&gt;4.1.3 Preprocessing
&lt;/h3&gt;&lt;p&gt;MDL 的输出，我们用 $\text{tanh}$ 作为最后的激活函数。我们用最大最小归一化。评估的时候，将预测值转换为原来的值。对于外部因素，使用 one-hot，假期和天气放入二值向量中，用最大最小归一化把温度和风速归一化。&lt;/p&gt;
&lt;h3 id="414-hyperparameters"&gt;4.1.4 Hyperparameters
&lt;/h3&gt;&lt;p&gt;$\lambda_{node} = 1$ 和 $\lambda_{edge} = 1$，$\lambda_{mdl} = 0.0005$，$p$ 和 $q$ 按经验设定为一天和一周。三个依赖序列的长度分别为 $l_c \in \lbrace 1, 2, 3\rbrace$, $l_p \in \lbrace 1,2,3 \rbrace$, $l_q \in \lbrace 1,2,3 \rbrace$。卷积的数量是 5 个。训练集的 90% 用来训练，10% 来验证，用早停选最好的参数。然后使用所有的数据训练模型。网络参数通过随机初始化，Adam 优化。batch size 32。学习率 $\lbrace 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005 \rbrace$。&lt;/p&gt;
&lt;h3 id="415-evaluation-metrics"&gt;4.1.5 Evaluation Metrics
&lt;/h3&gt;&lt;p&gt;RMSE 和 MAE。&lt;/p&gt;
&lt;h2 id="42-results"&gt;4.2 Results
&lt;/h2&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table4.JPG"
loading="lazy"
alt="Table4"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Node Flow Prediction.&lt;/strong&gt; 我们先比流入和流出流量的预测。表 4 展示了两个数据集上的评价指标结果。MDL 和 MRF 比其他所有的方法多要好。我们的 MDL 在 NYC 的数据集上明显比 MRF 好。BJ 的数据集上，MDL 比 MRF 差不多。原因是 NYC 数据集比 BJ 数据集大了三倍。换句话说，在大的数据集上，我们的方法比 MRF 更好。我们也注意到训练 MRF 很好使，在 BJ 数据集上训练了一个星期。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table5.JPG"
loading="lazy"
alt="Table5"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Results of Edge Flow Prediction.&lt;/strong&gt; 表6 展示了边流量预测。边流量预测的实验很费时。MDL 比其他的都好。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table6.JPG"
loading="lazy"
alt="Table6"
&gt;&lt;/p&gt;
&lt;h2 id="43-evaluation-on-fusing-mechanisms"&gt;4.3 Evaluation on Fusing Mechanisms
&lt;/h2&gt;&lt;p&gt;融合 NODENET 和 EDGENET 有 CONCAT 和 SUM 两种方法。融合外部因素有 GATED 和 SIMPLE 融合，或者不使用。因此总共有 6 种方法。如表 7。使用同样的超参数设定。我们发现 CONCAT + GATING 比其他的方法好。&lt;/p&gt;
&lt;h2 id="44-evaluation-on-model-hyper-parameters"&gt;4.4 Evaluation on Model Hyper-parameters
&lt;/h2&gt;&lt;h3 id="441-effect-of-training-data-size"&gt;4.4.1 Effect of Training Data Size
&lt;/h3&gt;&lt;p&gt;我们选了 NYC 3 个月，6 个月，1 年，3 年数据。$l_c = 3$, $l_p = 1$, $l_q = 1$。图 8 是结果。我们观察到数据越多，效果越好。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig8.JPG"
loading="lazy"
alt="Figure8"
&gt;&lt;/p&gt;
&lt;h3 id="442-effect-of-network-depth"&gt;4.4.2 Effect of Network Depth
&lt;/h3&gt;&lt;p&gt;图 9 展示了网络深度在 NYC 3 个月数据集上的影响。网络越深，RMSE 会下降，因为网络越深越能捕获更大范围的空间依赖。然而，网络更深 RMSE 就会上升，这是因为网络加深后训练会变得困难。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig9.JPG"
loading="lazy"
alt="Figure9"
&gt;&lt;/p&gt;
&lt;h3 id="443-effect-of-multi-task-component"&gt;4.4.3 Effect of multi-task component
&lt;/h3&gt;&lt;p&gt;表 8 和图 10 展示了多任务组件的影响。&lt;/p&gt;
&lt;p&gt;我们可以看到转移流量预测任务大多数情况下可以提升，$\lambda_{node} = \lambda_{edge} = 1$，$\lambda_{mdl}=0.1$，我们的模型获得最好的效果，两种任务都获得更好的结果，证明了多任务可以互相提升。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table8.JPG"
loading="lazy"
alt="Table8"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig10.JPG"
loading="lazy"
alt="Figure10"
&gt;&lt;/p&gt;
&lt;h2 id="45-flow-predictions"&gt;4.5 Flow Predictions
&lt;/h2&gt;&lt;p&gt;图 11 描绘了我们的 MDL 在 NYC 上预测两个节点未来一小时的数据。结点 (10, 1)，总是比 (8, 3) 高。我们的模型在预测曲线上更精确。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig11.JPG"
loading="lazy"
alt="Figure11"
&gt;&lt;/p&gt;</description></item><item><title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</title><link>https://davidham3.github.io/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/</link><pubDate>Thu, 21 Mar 2019 10:43:34 +0000</pubDate><guid>https://davidham3.github.io/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/</guid><description>&lt;p&gt;AAAI 2019。网格流量预测，两个问题：空间依赖动态性，另一个是周期平移。原文链接：&lt;a class="link" href="http://export.arxiv.org/abs/1803.01254" target="_blank" rel="noopener"
&gt;Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;由于大规模的交通数据越来越多，而且交通预测在实际中很重要，交通预测在 AI 领域引起越来越多的关注。举个例子，一个精确的出租车需求预测可以协助出租车公司预分配出租车。交通预测的关键在于如何对复杂的空间依赖和时间动态性建模。尽管两个因素在建模的时候都会考虑，当前的方法仍会做很强的假设，即空间依赖在时间上是平稳的，时间依赖是严格周期的。然而，实际中的空间依赖可能是动态的（即随时间的变化而变化），而且时间动态性可能从一个时段到另一个时段有波动。在这篇文章中，我们有两个重要发现：（1）区域间的空间依赖是动态的；（2）时间依赖虽说有天和周的模式，但因为有动态时间平移，它不是严格周期的。为了解决这两个问题，我们提出了一个新的时空动态网络（STDN），我们用一个门控机制学习区域间的动态相似性，用一个周期性平移的注意力机制来处理长期周期时间平移现象。据我们所知，这是第一个在一个统一的框架中解决这两个问题的工作。我们的实验结果证明了提出的方法是有效的。&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction
&lt;/h1&gt;&lt;p&gt;交通预测是一个时空预测问题。精确的预测模型对很多应用都很重要。在传统交通预测问题中，给定历史数据（比如一个区域的流量，或一个交叉卡前几个月每小时的流量），预测未来一段时间的数据。这方面的研究已经有几十年了。在时间序列社区，ARIMA 和 Kalman filtering被广泛地应用到这一领域。然而这些早期方法是针对每个区域分别预测，最近的方法考虑了空间信息（比如针对近邻区域增加正则项）和外部因素（如地点信息，天气状况，地区活动）。然而，这些方法仍基于机器学习中的传统时间序列模型，不能很好的捕获复杂的非线性时空依赖）。&lt;/p&gt;
&lt;p&gt;最近，深度学习方法在很多任务上取得了成功。比如，一些研究将城市交通看作是热力图的图片，使用 CNN 对非线性空间关系建模。为了对非线性时间关系建模，人们提出了基于 RNN 的框架。Yao et al。 更是提出了用 CNN 和 LSTM 同时处理时间和空间依赖的框架。&lt;/p&gt;
&lt;p&gt;尽管考虑了同时对时空建模，现存的方法主要有两点不足。首先，区域间的空间依赖依赖于历史数据的相似性，模型学习到了一个静态的空间依赖。然而，区域间的依赖随时间是改变的。举个例子，早上，居民区和商业区之间的依赖关系强；深夜，关系就弱了。然而，这样的动态依赖在之前的研究中没有考虑。&lt;/p&gt;
&lt;p&gt;另一个限制是现存的研究忽略了长期周期依赖。交通数据又很强的日和周周期性，基于这种周期性的依赖关系可能用于预测。然而，一个挑战是交通数据不是严格周期的。举个例子，周末的高峰通常发生在下午的后半段，不同的日子时间不一致，从4:30pm到6:00pm变化。尽管之前的研究考虑了周期性，他们没能考虑序列性的依赖和周期性中的时间平移。&lt;/p&gt;
&lt;p&gt;为了解决前面提出的问题，我们提出了新的深度学习框架，时空动态网络用于交通预测。STDN 是基于时空神经网络的，使用局部 CNN 和 LSTM 分别处理时空信息。一个门控局部 CNN 使用区域间的动态相似性对空间依赖建模。一个周期平移的注意力机制用来学习长期周期依赖。通过注意力机制对长期周期信息和时间平移建模。我们的方法还用 LSTM 以层次的方式处理序列依赖。&lt;/p&gt;
&lt;p&gt;我们再大型的真实数据集上做了评测，纽约出租车数据和纽约的共享单车数据。和 state-of-the-art 的全面对比展示了我们模型的性能。我们的贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们提出了一个流式门控机制对动态空间相似性建模。门控制信息在邻近区域传播。&lt;/li&gt;
&lt;li&gt;我们提出了一个周期平移注意力机制，通过同时时可用长期周期信息和时间平移。&lt;/li&gt;
&lt;li&gt;我们在几个真实数据集上开展了实验，效果好。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="notations-and-problem-formulation"&gt;Notations and Problem Formulation
&lt;/h1&gt;&lt;p&gt;我们将整个城市分为 $a \times b$ 个网格，一共 $n$ 个区域（$n = a \times b$），使用 $\lbrace 1,2,\dots,n \rbrace$ 表示他们。我们将整个时间周期分为 $m$ 个登场的连续时段。任何一个个体的移动，其本质上是整个城市交通的一部分，总是从一个区域出发，过一段时间到达目的地。我们在一个时段内给每个区域定义一个开始/结束流量作为区域出发/到达的移动发生次数。$y^s_{i,t}$ 和 $y^e_{i,t}$ 表示开区域 $i$ 在时段 $t$ 的开始/结束流量。此外，对个体旅行的聚合形成交通流，描述了区域对之间的考虑时间的移动。时段 $t$ 从区域 $i$ 开始的交通流在时段 $\tau$ 于区域 $j$ 结束，表示为 $f^{j,\tau}_{i,t}$。显然，交通流反映了区域间的连通性，也反映了个体的移动。图1（c）给出了流量和流动的展示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem(Traffic Volume Prediction)&lt;/strong&gt; 给定知道时段 $t$ 的数据，交通流预测问题目标是预测时段 $t+1$ 的起始和结束流量。&lt;/p&gt;
&lt;h1 id="spatial-temporal-dynamic-network"&gt;Spatial-Temporal Dynamic Network*
&lt;/h1&gt;&lt;p&gt;这部分，我们讲一下细节。图1是我们模型的架构。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;h2 id="local-spatial-temporal-network"&gt;Local Spatial-Temporal Network
&lt;/h2&gt;&lt;p&gt;为了捕获时空序列依赖，在出租车需求预测上，融合局部 CNN 和 LSTM 展示出了非常好的表现。我们这里使用局部 CNN 和 LSTM 处理空间和短期时间依赖。为了手动地提升两种流量的预测（起始和结束），我们将他们集成起来。这部分称为 Local Spatial-Temporal Network (LSTN)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Local spatial dependency&lt;/strong&gt; 卷积神经网络用来捕获空间关系。将整个城市看作一张图片，简单地使用 CNN 不能获得最好的性能。包含了弱关系的区域会导致预测性能下降。因此，我们使用局部 CNN 对空间依赖建模。&lt;/p&gt;
&lt;p&gt;对于每个时段 $t$，我们将目标区域 $i$ 和它周围的邻居看作是 $S \times S$ 大小的图片，两个通道 $\mathbf{Y}_{i,t} \in \mathbb{R}^{S \times S \times 2}$。一个通道包含起始流量信息，另一个是结束流量信息。目标区域在图像的中间。局部 CNN 使用 $\mathbf{Y}_{i,t}$ 作为输入 $\mathbf{Y}^{(0)}_{i,t}$，每个卷积层的定义如下：&lt;/p&gt;
$$\tag{1}
\mathbf{Y}^{(k)}\_{i,t} = \text{ReLU}(\mathbf{W}^{(k)} \ast \mathbf{Y}^{(k-1)}\_{i,t} + \mathbf{b}^{(k)}),
$$&lt;p&gt;其中 $\mathbf{W}^{(k)}$ 和 $\mathbf{b}^{(k)}$ 是参数。堆叠 $K$ 层卷积后，用一个全连接来推测区域 $i$ 的空间表示，记为 $\mathbf{y}_{i,t}$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Short-term Temporal Dependency&lt;/strong&gt; 我们使用 LSTM 捕获空间序列依赖。我们使用原始版本的 LSTM：&lt;/p&gt;
$$\tag{2}
\mathbf{h}\_{i,t} = \text{LSTM}([\mathbf{y}\_{i,t};\mathbf{e}\_{i,t}], \mathbf{h}\_{i,t-1}),
$$&lt;p&gt;其中，$\mathbf{h}_{i,t}$ 是区域 $i$ 在时段 $t$ 的输出表示。$\mathbf{e}_{i,t}$ 表示外部因素。因此，$\mathbf{h}_{i,t}$ 包含空间和短期时间信息。&lt;/p&gt;
&lt;h2 id="spatial-dynamic-similarity-flow-gating-mechanism"&gt;Spatial Dynamic Similarity: Flow Gating Mechanism
&lt;/h2&gt;&lt;p&gt;局部 CNN 用于捕获空间依赖。CNN 通过局部连接和权重共享处理局部结构相似性。在局部 CNN 中，局部空间依赖依靠历史交通流量的相似度。然而，流量的空间依赖是平稳的，不能完全地反映目标区域和其邻居间的关系。一个直接的表示区域间关系的方式是交通流。如果两个区域间有很多流量，那么他们之间的关系强烈（也就是他们更相似）。交通流可以用于控制流量信息在区域间的转移。因此，我们设计了一个 Flow Gating Mechanism (FGM)，以层次的方式对动态空间依赖建模。&lt;/p&gt;
&lt;p&gt;类似局部 CNN，我们构建了局部空间流量图来保护流量的空间依赖。一个时段和一个区域相关的流量分两种，流入和流出，两个流量矩阵可以如上构建，每个元素表示对应区域的流入流出流量。图1(c) 给了一个流出矩阵。&lt;/p&gt;
&lt;p&gt;给定一个区域 $i$，我们获得过去 $l$ 个时段的相关的流量（即从 $t-l+1$ 到 $t$）。需要的流量矩阵拼接起来，表示为 $\mathbf{F}_{i,t} \in \mathbb{R}^{S \times S \times 2l}$，$2l$ 是流量矩阵的数量。因为堆叠的流量矩阵包含了过去与区域 $i$ 相关的矩阵，我们使用 CNN 对区域间的空间流量关系建模，将 $\mathbf{F}_{i,t}$ 作为输入 $\mathbf{F}^{(0)}_{i,t}$。对于每层 $k$，公式如下：&lt;/p&gt;
$$\tag{3}
\mathbf{F}^{(k)}\_{i,t} = \text{ReLU}(\mathbf{W}^{(k)}\_f \ast \mathbf{F}^{(k-1)}\_{i,t} + \mathbf{b}^{(k)}\_f),
$$&lt;p&gt;其中 $\mathbf{W}^{(k)}_f$ 和 $\mathbf{b}^{(k)}_f$ 是参数。&lt;/p&gt;
&lt;p&gt;每层，我们使用流量信息对区域间的动态相似性进行捕获，通过一个流量门限制空间信息。特别地，空间表示 $\mathbf{Y}^{i,k}_t$ 作为每层的输出，受流量门调整。我们重写式1为：&lt;/p&gt;
$$\tag{4}
\mathbf{Y}^{(k)}\_{i,t} = \text{ReLU}(\mathbf{W}^{(k)} \ast \mathbf{Y}^{(k-1)}\_{i,t} + \mathbf{b}^{(k)}) \otimes (\mathbf{F}^{i,k-1}\_t),
$$&lt;p&gt;$\otimes$ 是element-wise product。&lt;/p&gt;
&lt;p&gt;$K$ 个门控卷积层后，我们用一个全连接得到流量门控空间表示 $\mathbf{y}_{i,t}$。&lt;/p&gt;
&lt;p&gt;我们将式2中的空间表示 $\mathbf{y}_{i,t}$ 替换为 $\hat{\mathbf{y}}_{i,t}$。&lt;/p&gt;
&lt;h2 id="temporal-dynamic-similarity-periodically-shifted-attention-mechanism"&gt;Temporal Dynamic Similarity: Periodically Shifted Attention Mechanism
&lt;/h2&gt;&lt;p&gt;在上面的局部时空网络中，只有前几个时段用于预测。然而，这会忽略长期依赖（周期），但周期在时空预测问题中又很重要。这部分我们考虑长期依赖。&lt;/p&gt;
&lt;p&gt;训练 LSTM 来处理长期信息不是一个简单的任务，因为序列长度的增加导致梯度消失，因此会减弱周期性的影响。为了解决这个问题，预测目标的相对时段（即昨天的这个时候，前天这个时候）应该被建模。然而，单纯地融入相对时段是不充分的，会忽略周期的平移，即交通数据不是严格周期的。举个例子，周末的高峰通常发生在下午的后半段，不同的日子时间不一致，从4:30pm到6:00pm变化。周期的平移在交通序列中很普遍，因为事故或堵塞的发生。图 2a 和 2b 分别是不同的天和周的时间平移的例子。这两个时间序列是从 NYC 的出租车数据中算的从 Javits Center出发的流量。显然，交通序列是周期性的，但是这些序列的峰值（通过红圈标记）在不同的日子里时间不一样。此外，对比两张图，周期性不是严格按日或按周的。因此，我们设计了一个 Periodically Shifted Attention Mechanism (PSAM) 来解决问题。详细的方法如下。&lt;/p&gt;
&lt;p&gt;我们专注于解决日周期的平移问题。如图 1(a) 所示，从前 $P$ 天获得的相对时段用来处理周期依赖。对于每天，为了解决时间平移问题，我们从每天中额外的选择 $Q$ 个时段。举个例子，如果预测的时间是9:00-9:30pm，我们选之前的一个小时和之后的一个小时，即8:00-19:30pm，$\vert Q \vert = 5$。这些时段 $q \in Q$ 用来解决潜在的时间平移问题。此外，我们使用对每天 $p \in P$ 保护每天的序列信息，公式如下：&lt;/p&gt;
$$\tag{5}
\mathbf{h}^{p,q}\_{i,t} = \text{LSTM}([\mathbf{y}^{p,q}\_{i,t}; \mathbf{e}^{p,q}\_{i,t}], \mathbf{h}^{p,q-1}\_{i,t}),
$$&lt;p&gt;其中，$\mathbf{h}^{p,q}_{i,t}$ 是对于区域 $i$ 的预测时间 $t$，时段 $q$ 在前一天 $p$ 的表示。&lt;/p&gt;
&lt;p&gt;我们用了一个注意力机制捕获时间平移并且获得了前几天的每一天的一个表示。前几天每一天的表示 $\mathbf{h}^p_{i,t}$ 是时段 $q$ 每一个选中时间的带权加和，定义为：&lt;/p&gt;
$$\tag{6}
\mathbf{h}^p\_{i,t} = \sum\_{q \in Q} \alpha^{p,q}\_{i,t} \mathbf{h}^{p,q}\_{i,t},
$$&lt;p&gt;权重 $\alpha^{p,q}_{i,t}$ 衡量了在 $p \in P$ 这天时段 $q$ 的重要性。重要值 $\alpha^{p,q}_{i,t}$ 通过对比从短期记忆（式2）得到的时空表示和前一个隐藏状态 $\mathbf{h}^{p,q}_{i,t}$ 得到。权重定义为：&lt;/p&gt;
$$\tag{7}
\alpha^{p,q}\_{i,t} = \frac{\text{exp}(\text{score}(\mathbf{h}^{p,q}\_{i,t}, \mathbf{h}\_{i,t}))} {\sum\_{q \in Q} \text{exp}(\text{score} (\mathbf{h}^{p,q}\_{i,t}, \mathbf{h}\_{i,t})}
$$&lt;p&gt;类似 (Luong, Pham and Manning 2015)，注意力分数的定义可以看作是基于内容的函数：&lt;/p&gt;
$$\tag{8}
\text{score}(\mathbf{h}^{p,q}\_{i,t}, \mathbf{h}\_{i,t}) = \mathbf{v}^\text{T} \text{tanh} (\mathbf{W\_H} \mathbf{h}^{p,q}\_{i,t} + \mathbf{W\_X} \mathbf{h}\_{i,t} + \mathbf{b\_X}),
$$&lt;p&gt;其中，$\mathbf{W_H}, \mathbf{W_X}, \mathbf{b_X}, \mathbf{v}$ 是参数，$\mathbf{v}^\text{T}$ 是转置。对于前面的每一天 $p$，我们得到一个周期表示 $\mathbf{h}^p_{i,t}$。然后我们使用另一个 LSTM 用这些周期表示作为输入，保存序列信息，即&lt;/p&gt;
$$\tag{9}
\hat{\mathbf{h}}^p\_{i,t} = \text{LSTM}(\mathbf{h}^p\_{i,t}, \hat{\mathbf{h}}^{p-1}\_{i,t}).
$$&lt;p&gt;我们将最后一个时段的输出 $\hat{\mathbf{h}}^P_{i,t}$ 看作是时间动态相似度的表示（即长期周期信息）。&lt;/p&gt;
&lt;h2 id="joint-training"&gt;Joint Training
&lt;/h2&gt;&lt;p&gt;我们拼接把短期表示 $\mathbf{h}_{i,t}$ 和 长期表示 $\hat{\mathbf{h}}^P_{i,t}$ 拼接得到 $\mathbf{h}^c_{i,t}$，对于预测区域和时间来说既保留了短期依赖又保留了长期依赖。我们将 $\mathbf{h}^c_{i,t}$ 输入到全连接中，获得每个区域 $i$ 流入和流出流量的最终预测值，分别表示为 $y^i_{s,t+1}$ 和 $y^i_{e,t+1}$。最终预测函数定义为：&lt;/p&gt;
$$\tag{10}
[y^i\_{s,t+1}, y^i\_{e,t+1}] = \text{tanh}(\mathbf{W}\_{fa} \mathbf{h}^c\_{i,t} + \mathbf{b}\_{fa}),
$$&lt;p&gt;因为我们做了归一化，所以输出的范围在 $(-1, 1)$，输出值会映射回需求值。&lt;/p&gt;
&lt;p&gt;我们同时预测出发和到达流量，损失函数定义为：&lt;/p&gt;
$$\tag{11}
\mathcal{L} = \sum^n\_{i=1} \lambda (y^s\_{i,t+1} - \hat{y}^s\_{i, t+1})^2 + (1 - \lambda) (y^e\_{i,t+1} - \hat{y}^e\_{i, t+1})^2,
$$&lt;p&gt;$\lambda$ 用来平衡流入和流出的影响。区域 $i$ 在时间 $t+1$ 实际的流入和流出流量表示为 $\hat{y}^s_{i, t+1}, \hat{y}^e_{i, t+1}$。&lt;/p&gt;
&lt;h1 id="experiment"&gt;Experiment
&lt;/h1&gt;&lt;h2 id="experiment-settings"&gt;Experiment Settings
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Datasets&lt;/strong&gt; 我们在两个 NYC 的大型数据集上评价了模型。每个数据集包含旅行记录，详情如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NYC-Taxi：2015 年 22349490 个出租车的旅行记录，从 2015年1月1日到2015年3月1日。实验中，我们使用1月1日到2月10日作为训练，剩下20天测试。&lt;/li&gt;
&lt;li&gt;NYC-Bike：2016 年 NYC 自行车轨迹数据，7月1日到8月29日，包含了 2605648 条记录。前 40 天用来训练，后 20 天做测试。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Preprocessing&lt;/strong&gt; 我们将整个城市分成 $10 \times 20$ 个区域。每个区域大小是 $1km \times 1km$。时段长度设为 30min。使用最大最小归一化 volume 和 flow 到 $[0, 1]$。预测后，使用逆变换后的值评价。我们使用滑动窗采样。测试模型的时候，滤掉 volumn 小于 10 的样本，这是工业界和学界常用的技巧 (Yao et al. 2018)。因为真实数据集中，关注较小的交通数据没有太大的意义。我们选择 80% 的数据训练，20% 验证。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Evaluation Metric &amp;amp; Baselines&lt;/strong&gt; 两个指标：MAPE, RMSE。baselines：HA, ARIMA, Ridge, Lin-UOTD (Tong el al. 2017), XGBoost, MLP, ConvLSTM, DeepSD, ST-ResNet, DMVST-Net。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hyperparameter Settings&lt;/strong&gt; 我们基于验证集设定超参数。对于空间信息，64 个卷积核，$3 \times 3$ 大小。每个邻居的大小设定为 $7 \times 7$。层数 $K = 3$，对于 flow 考虑的时间跨度 $l = 2$。时间信息，短期 LSTM 长度为 7，长期周期信息 $\vert P \vert = 3$，周期平移注意力机制 $\vert Q \vert = 3$，LSTM 中隐藏表示的维度是 128。STDN 通过 Adam 优化，batch size 64，学习率 0.001。LSTM 中的 dropout 0.5。$\lambda$ 取 0.5。&lt;/p&gt;
&lt;h2 id="results"&gt;Results
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;PerformanceComparison&lt;/strong&gt; 表 1 展示了我们的方法对比其他方法在两个数据集上的结果。我们跑每个 baseline 10次，取了平均和标准差。此外，我们也做了 t 检验。我们的方法在两个数据集上指标都很好。&lt;/p&gt;</description></item><item><title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</title><link>https://davidham3.github.io/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/</link><pubDate>Fri, 08 Mar 2019 10:26:16 +0000</pubDate><guid>https://davidham3.github.io/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/</guid><description>&lt;p&gt;AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：&lt;a class="link" href="https://arxiv.org/abs/1610.00081" target="_blank" rel="noopener"
&gt;Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;对于交通管理和公共安全来说，预测人流很重要，但这个问题也很有挑战性，因为收到很多复杂的因素影响，如区域内的交通、事件、天气。我们提出了一个基于深度学习的模型 ST-ResNet，对城市内的每个区域的人流的进出一起预测。我们基于时空数据独一的属性，设计了一个端到端的结构。我们使用残差神经网络框架对时间近邻、周期、趋势属性建模。对每个属性，我们设计了残差卷积的一个分支，每个分支对人流的空间属性建模。ST-ResNet 基于数据动态地聚合三个残差神经网络的输出，给不同的分支和区域分配权重。聚合结果还融合了外部因素，像天气或日期。实验在北京和纽约两个数据集上开展。&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction
&lt;/h1&gt;&lt;p&gt;对于交通管理和公共安全来说，预测人流很重要（Zheng et al. 2014）。举个例子，2015年新年夜，上海有大量人群涌入一个区域，导致 36 人死亡。2016年六月中旬，数百名 Pokemon Go 玩家冲入纽约中央公园，为了抓一只特别稀有的怪，导致严重的踩踏事故。如果可以预测一个区域的人流，这样的悲剧可以通过应急措施避免，像提前做交通管控，发布预警，疏散人群等。&lt;/p&gt;
&lt;p&gt;我们在这篇文章中预测两类人流（Zhang et al. 2016)：如图 1（a）所示，流入和流出。流入是在给定时间段，从其他区域进入到一个区域的交通运载量。流出表示给定时段内，从一个区域向其他区域的交通运载量。两个流量都是区域间的人口流动。了解这个对风险评估和交通管理有很大帮助。流入/流出可以通过行人数量、邻近道路车辆数、公共运输系统的人数、或是所有的都加起来。图 1（b）展示了一个例子。我们可以使用手机信号测量行人数，$r_2$ 的流入和流出分别为 3 和 1。类似地，使用车辆 GPS 轨迹，分别是 0 和 3。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;然而，同时预测城市每个区域人口的流入和流出是很有难度的，有 3 个复杂的因素：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;空间依赖。区域 $r_2$ 的流入（图1（a））受邻近区域（像 $r_1$）和遥远区域流出的影响。$r_2$ 的流出也受其他区域（$r_3$）流入的影响。$r_2$ 的流入也影响其自身。&lt;/li&gt;
&lt;li&gt;时间依赖。一个区域的人流受到近期和远期时间影响。举个例子，早上8点发生的交通拥堵可能会影响到 9 点。此外，早高峰的交通状况可能在接连的几天都是相似的，每 24 小时一次。而且随着冬天的到来，早高峰时间可能越来越晚。温度下降，日初变晚会使人们起床时间变晚。&lt;/li&gt;
&lt;li&gt;外部影响。一些像天气和事件的外部因素可能会显著地改变城市内不同区域的人口流动。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决这些问题，我们提出了一个深度深空残差网络 (ST-ResNet) 对每个区域的流入和流出同时预测。我们的贡献有 4 点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ST-ResNet 使用基于卷积的残差神经网络对城市内两个邻近的和遥远的区域的空间依赖建模，同时还确信了模型的预测精度不会因为模型的深度增加而降低。&lt;/li&gt;
&lt;li&gt;我们将人口流动的时间属性分为三种，时间近邻、周期、趋势。ST-ResNet 使用三个残差网络对这些属性建模。&lt;/li&gt;
&lt;li&gt;ST-ResNet 动态地聚合三个上述网络的输出，给不同的分支和区域分配权重。聚合还融合了外部因素。&lt;/li&gt;
&lt;li&gt;我们使用北京出租车的轨迹数据和气象数据，纽约自行车轨迹数据。结果表示我们的方法比 6 个 baseline 都好。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="preliminaries"&gt;Preliminaries
&lt;/h1&gt;&lt;p&gt;简要回顾人流预测问题（Zhang el al. 2016; Hoang, Zheng, and Singh 2016），介绍残差学习（He et al. 2016）。&lt;/p&gt;
&lt;h2 id="formulation-of-crowd-flows-problem"&gt;Formulation of Crowd Flows Problem
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Definition 1(Region (Zhang et al. 2016))&lt;/strong&gt; 根据不同粒度级和语义，一个地点的定义有很多。我们根据经纬度将城市划分成 $I \times J$ 个网格，一个网格表示一个区域，如图 2(a)。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;p&gt;**Definition 2(Inflow/outflow (Zhang et al. 2016)) $\mathbb{P}$ 是第 t 时段的轨迹集合。对于第 $i$ 行第 $j$ 列的网格，时段 $t$ 流入和流出的人流分别定义为：&lt;/p&gt;
$$
x^{in,i,j}\_t = \sum\_{T\_r \in \mathbb{P}} \vert \lbrace k &gt; 1 \mid g\_{k-1} \not \in (i, j) \wedge g\_k \in (i,j) \rbrace \vert
\\
x^{out,i,j}\_t = \sum\_{T\_r \in \mathbb{P}} \vert \lbrace k \geq 1 \mid g\_k \in (i,j) \wedge g\_{k+1} \not \in (i,j) \rbrace \vert
$$&lt;p&gt;其中 $T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的轨迹，$g_k$ 是地理坐标；$g_k \in (i,j)$ 表示点 $g_k$ 落在 $(i, j)$ 内；$\vert · \vert$ 表示集合基数。&lt;/p&gt;
&lt;p&gt;时段 $t$ ，所有区域的流入和流出可以表示成 $\mathbf{X}_t \in \mathbb{R}^{2 \times I \times J}$，$(\mathbf{X}_t)_{0,i,j}=x^{in,i,j}_t, (\mathbf{X}_t)_{1,i,j} = x^{out,i,j}_t$。流入矩阵如图2(b)。&lt;/p&gt;
&lt;p&gt;空间区域可以表达成一个 $I \times J$ 的区域，有两类流动，所以观测值可以表示为 $\mathbf{X} \in \mathbb{R}^{2 \times I \times J}$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem 1&lt;/strong&gt; 给定历史观测值 $\lbrace \mathbf{X}_t \mid t = 0,\dots,n-1 \rbrace$，预测 $\mathbf{X}_n$。&lt;/p&gt;
&lt;h2 id="deep-residual-learning"&gt;Deep Residual Learning
&lt;/h2&gt;$$\tag{1}
\mathbf{X}^{(l+1)} = \mathbf{X}^{(l)} + \mathcal{F}(\mathbf{X}^{(l)})
$$&lt;h1 id="deep-spatio-temporal-residual-networks"&gt;Deep Spatio-Temporal Residual Networks
&lt;/h1&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;图 3 展示了 ST-ResNet的架构，4 个部分分别对时间近邻、周期、远期、外部因素建模。如图 3 所示，首先将流入和流出作为两个通道放到矩阵中，使用定义 1 和 2 引入的方法。我们将时间轴分为三个部分，表示近期时间、邻近历史、远期历史。三个时段的两通道的流动矩阵分别输入上述模型，对三种时间属性建模。这三个组件结构相同，都是残差网络。这样的结构捕获邻近和遥远区域间的空间依赖。外部组件中，我们手动的从数据集中提取了特征，如天气、事件等，放入两层全连接神经网络中。前三个组件的输出基于参数矩阵融合为 $\mathbf{X}_{Res}$，参数矩阵给不同的区域不同的组件分配权重。$\mathbf{X}_{Res}$ 然后与外部组件 $\mathbf{X}_{Ext}$ 集成。最后，聚合结果通过 Tanh 映射到 $[-1, 1]$，在反向传播会比 logistic function 收敛的更快 (LeCun et al. 2012)。&lt;/p&gt;
&lt;h2 id="structures-of-the-first-three-components"&gt;Structures of the First Three Components
&lt;/h2&gt;&lt;p&gt;如图 4。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Convolution&lt;/strong&gt;&lt;/em&gt; 一个城市通常很大，包含很多距离不同的区域。直观上来说，邻近区域的人流会影响其他区域，可以通过 CNN 有效地处理，CNN 也被证明在层级地捕获空间信息方面很强 (LeCun et al. 1998)。而且，如果两个遥远地方通过地铁或高速公路连接，那么这两个区域间就有依赖关系。为了捕获任何区域的空间依赖，我们需要设计一个很多层的 CNN 模型，因为一个卷积层只考虑空间近邻，受限于它卷积核的大小。同样的问题在视频序列生成任务中也有，当输入和输出有同样的分辨率的时候(Mathieu, Couprie, and LeCun 2015)。为了避免下采样导致的分辨率损失引入了几种方法，同时还保持遥远的依赖关系(Long, Shelhamer, and Darrell 2015)。与传统的 CNN 不同的是，我们没有使用下采样，而是只使用卷积 (Jain et al. 2007)。如图 4(a)，图中有 3 个多级的 feature map，通过一些卷积操作相连。一个高层次的结点依赖于 9 个中间层次的结点，这些又依赖于低层次的所有结点。这意味着一个卷积可以很自然地捕获空间近邻依赖，堆叠卷积可以更多地捕获遥远的空间依赖。&lt;/p&gt;
&lt;p&gt;图 3 的近邻组件使用了一些 2 通道流动矩阵对近邻时间依赖建模。令最近的部分为 $[\mathbf{X}_{t-l_c}, \mathbf{X}_{t-(l_c-1)}, \dots, \mathbf{X}_{t-1}]$，也称为近邻依赖序列。我们将他们沿第一个轴（时间）拼接，得到一个张量 $\mathbf{X}^{(0)}_c \in \mathbb{R}^{2l_c \times I \times J}$，然后使用卷积（图 3 中的 Conv1）：&lt;/p&gt;
$$\tag{2}
\mathbf{X}^{(1)}\_c = f(W^{(1)}\_c \ast \mathbf{X}^{(0)}\_c + b^{(1)}\_c)
$$&lt;p&gt;其中 $\ast$ 表示卷积；$f$ 是激活函数；$W^{(1)}_c, b^{(1)}_c$ 是参数。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Residual Unit.&lt;/strong&gt;&lt;/em&gt; 尽管有 ReLU 职业那个的激活函数和正则化技巧，深度卷积网络在训练上还是很难。但我们仍然需要深度神经网络捕获非常大范围的依赖。对于典型的流量数据，假设输入大小是 $32 \times 32$，卷积核大小是 $3 \times 3$，如果我们想对城市范围的依赖建模，至少需要连续 15 个卷积层。为了解决这个问题，我们使用残差学习(He et al. 2015)，在训练超过 1000 层的网络时很有效。&lt;/p&gt;
&lt;p&gt;在我们的 ST-ResNet(如图 3)，我们在 Conv1 上堆叠 $L$ 个残差单元如下：&lt;/p&gt;
$$\tag{3}
\mathbf{X}^{(l+1)}\_c = \mathbf{X}^{(l)}\_c + \mathcal{F}(\mathbf{X}^{(l)}\_c; \theta^{(l)}\_c), l = 1, \dots, L
$$&lt;p&gt;$\mathcal{F}$ 是残差函数，即 ReLU + Convolution，如图 4(b)。我们还在 ReLU 之前加了 &lt;em&gt;Batch Normalization&lt;/em&gt;。在第 $L$ 个残差单元前，我们使用了一个卷积层，图 3 中的 Conv2。2 个卷积和 $L$ 个残差单元，图 3 中的近邻组件的输出是 $\mathbf{X}^{(l+2)}_c$。&lt;/p&gt;
&lt;p&gt;同样的，使用上面的操作，我们可以构建 &lt;em&gt;周期&lt;/em&gt; 和 &lt;em&gt;趋势&lt;/em&gt; 组件，如图 3。假设时段 $p$ 有 $l_p$ 个时间间隔。那么 &lt;em&gt;时段&lt;/em&gt; 依赖序列是 $[\mathbf{X}_{t-l_p \cdot p}, \mathbf{X}_{t-(l_p - 1) \cdot p}, \dots, \mathbf{X}_{t-p}]$。使用式 2 和 式 3 那样的卷积和 $L$ 个残差单元，&lt;em&gt;周期&lt;/em&gt; 组件的输出是 $\mathbf{X}^{(L + 2)}_p$。同时，&lt;em&gt;趋势&lt;/em&gt; 组件的输出是 $\mathbf{X}^{(L+2)}_q$，输入是 $[\mathbf{X}_{t-l_q \cdot q}, \mathbf{X}_{t-(l_q - 1) \cdot q}, \dots, \mathbf{X}_{t-q}]$，$l_q$ 是&lt;em&gt;趋势&lt;/em&gt;依赖序列的长度，$q$ 是趋势跨度。需要注意的是 $p$ 和 $q$ 是两个不同类型的周期。在实际的实现中，$p$ 等于一天，描述的是日周期，$q$ 是一周，表示周级别的趋势。&lt;/p&gt;
&lt;h2 id="the-structure-of-the-external-component"&gt;The Structure of the External Component
&lt;/h2&gt;&lt;p&gt;交通流会被很多复杂的外部因素所影响，如天气或事件。图 5(a) 表示假期（春节）时的人流和平时的人流很不一样。图 5(b) 表示相比上周的同一天，突然而来的大雨会减少此时办公区域的人流。令 $E_t$ 为特征向量，表示预测的时段 $t$ 的外部因素。我们的实现中，我们主要考虑天气、假期事件、元数据（工作日、周末）。详细情况见表 1。为了预测时段 $t$ 的交通流，假期事件和元数据可以直接获得。然而，未来时段 $t$ 的天气预报不知道。可以使用时段 $t$ 的天气预报，或是 $t-1$ 时段的天气来近似。我们在 $E_t$ 上堆叠两个全连接层，第一层可以看作是每个子因素的嵌入层。第二层用来从低维映射到和 $\mathbf{X}_t$ 一样的高维上。图 3 中外部组件的输出表示为 $\mathbf{X}_{Ext}$，参数是$\theta_{Ext}$。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig5.JPG"
loading="lazy"
alt="Figure5"
&gt;&lt;/p&gt;
&lt;h2 id="fusion"&gt;Fusion
&lt;/h2&gt;&lt;p&gt;我们先用一个参数矩阵融合前三个组件，然后融合外部组件。&lt;/p&gt;
&lt;p&gt;图6(a)和(d)展示了表1展示的北京轨迹数据的比例曲线，x轴是两个时段的时间差，y轴是任意两个有相同时间差的流入的平均比例。两个不同区域的曲线在时间序列上表现出了时间联系，也就是近期的流入比远期的流入更相关，表现出了事件近邻性。两条曲线有两个不同的形状，表现出不同区域可能有不同性质的近邻性。图6(b)和(e)描绘了7天所有时段的流入。我们可以观察到两个区域明显的日周期性。在办公区域，工作日的峰值比周末的高很多。住宅区在工作日和周末有相似的峰值。图6(c)和(f)描述了2015年3月到2015年6月一个特定时段(9:00pm-9:30pm)的流入。随着时间的推移，办公区域的流入逐渐减少，住宅区逐渐增加。不同的区域表现出了不同的趋势。总的来说，两个区域的流入受到近邻、周期、趋势三部分影响，但是影响程度是不同的。我们也发现其他区域也有同样的性质。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig6.JPG"
loading="lazy"
alt="Figure6"
&gt;&lt;/p&gt;
&lt;p&gt;综上，不同区域受近邻、周期、趋势的影响，但是影响程度不同。受这些观察的启发，我们提出了一个基于矩阵参数的融合方法。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Parametric-matrix-based fusion.&lt;/strong&gt;&lt;/em&gt; 我们融合图 3 中前三个组件：&lt;/p&gt;
$$\tag{4}
\mathbf{X}\_{Res} = \mathbf{W}\_c \odot \mathbf{X}^{(L+2)}\_c + \mathbf{W}\_p \odot \mathbf{X}^{(L+2)}\_p + \mathbf{W}\_q \odot \mathbf{X}^{(L+2)}\_q
$$&lt;p&gt;$\odot$ 是哈达玛乘积，$\mathbf{W}$ 是参数，分别调整三个组件的影响程度。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Fusing the external component.&lt;/strong&gt;&lt;/em&gt; 我们直接地将前三个组件的输出和外部组件融合，如图3。最后，时段 $t$ 的预测值，表示为 $\hat{\mathbf{X}}_t$ 定义为：&lt;/p&gt;
$$\tag{5}
\hat{\mathbf{X}}\_t = \mathrm{tanh}(\mathbf{X}\_{Res} + \mathbf{X}\_{Ext})
$$&lt;p&gt;我们的 ST-ResNet 可以从三个流动与朕和外部因素特征通过最下滑 MSE 来训练：&lt;/p&gt;
$$\tag{6}
\mathcal{L}(\theta) = \Vert \mathbf{X}\_t - \hat{\mathbf{X}}\_t \Vert^2\_2
$$&lt;h2 id="algorithm-and-optimization"&gt;Algorithm and Optimization
&lt;/h2&gt;&lt;p&gt;算法1描述了 ST-ResNet 的训练过程。首先从原始序列构造训练实例。然后通过反向传播，用 Adam 算法训练。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Alg1.JPG"
loading="lazy"
alt="Algorithm1"
&gt;&lt;/p&gt;
&lt;h1 id="experiments"&gt;Experiments
&lt;/h1&gt;&lt;h2 id="settings"&gt;Settings
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Datasets.&lt;/strong&gt; 我们使用表 1 中展示的两个数据集。每个数据集都包含两个子集，轨迹和天气。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TaxiBJ: 轨迹数据是出租车 GPS 数据和北京的气象数据，2013年7月1日到10月30日，2014年5月1日到6月30日，2015年5月1日到6月30日，2015年11月1日到2016年4月1日。使用定义2，我们获得两类人流。我们选择最后四周作为测试集，之前的都为训练集。&lt;/li&gt;
&lt;li&gt;BikeNYC: 轨迹数据是2014年NYC Bike系统中取的，从4月1日到9月30日。旅行数据包含：持续时间、起点终点站点ID，起始终止时间。在数据中，最后10天选做测试集，其他选做训练集。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Baselines.&lt;/strong&gt; 我们对比了6个baselines：HA, ARIMA, SARIMA, VAR, ST-ANN, DeepST.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table3.JPG"
loading="lazy"
alt="Table3"
&gt;&lt;/p&gt;</description></item><item><title>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</title><link>https://davidham3.github.io/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/</link><pubDate>Thu, 07 Mar 2019 09:03:16 +0000</pubDate><guid>https://davidham3.github.io/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/</guid><description>&lt;p&gt;T-GCN，arxiv上面的一篇文章，用 GCN 对空间建模，GRU 对时间建模，很简单的模型。没有对比近几年的图卷积在时空数据挖掘中的模型。原文地址：&lt;a class="link" href="https://arxiv.org/abs/1811.05320" target="_blank" rel="noopener"
&gt;T-GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;精确和实时的交通预测在智能交通系统中扮演着重要的角色，对城市交通规划、交通管理、交通控制起着重要的作用。然而，交通预测由于其受限于城市路网且随时间动态变化，即有着空间依赖与时间依赖，早已成为一个公开的科学研究问题。为了同时捕获空间和时间依赖，我们提出了一个新的神经网络方法，时间图卷积网络模型 （T-GCN），将图卷积和门控循环单元融合起来。GCN 用来学习复杂的拓扑结构来捕获空间依赖，门控循环单元学习交通数据的动态变化来捕获时间依赖。实验表明我们的 T-GCN 模型比之前的方法要好。我们的 tf 实现：&lt;a class="link" href="https://github.com/lehaifeng/T-GCN" target="_blank" rel="noopener"
&gt;代码仓库地址&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 Introduction
&lt;/h1&gt;&lt;p&gt;随着智能交通系统的发展，交通预测受到了越来越多的关注。交通预测是高级交通管理系统中的关键部分，是实现交通规划、交通管理、交通控制的重要部分。交通预测是分析城市路网上交通状况、包括流量、车速、密度，挖掘交通模式，对路网上交通进行预测的一个过程。交通预测不仅能给管理者提供科学依据来预测交通拥挤并提前限制出行，还可以给旅客提供适当的出行路线并提高交通效率。然而，交通由于其空间和时间的依赖至今还是一个有难度的挑战：&lt;/p&gt;
&lt;p&gt;（1）空间依赖。流量的改变主要受路网的拓扑结构控制。上游道路的交通状态通过转移影响下游的道路，下游的交通状态会通过反馈影响上游的状态。如图 1 所示，由于邻近道路的强烈影响，短期相似性从状态 1 （上游与中游相似）转移到 状态 2（上游与下游相似）。&lt;/p&gt;
&lt;p&gt;（2）时间依赖。流量随时间动态改变，主要会出现周期性和趋势。如图 2（a）所示，路 1 的流量在一周内展示出了周期性变化。图 2（b）中，一天的流量也发生变换；举个例子，流量会被其前一时刻或更前的时刻的交通状况所影响。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;
&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig2.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;有很多交通预测方法，一些考虑时间依赖，包括 ARIMA，Kalman filtering model, SVR, knn, Beyesian model, partial neural network model.上述方法考虑交通状况在时间上的动态变化，忽略了空间依赖，导致不能精确预测。为了更好地刻画空间特征，一些研究引入了卷积神经网络对空间建模；然而，卷积适用于欧氏空间的数据，如图像、网格等。这样的模型不能在城市路网这样有着复杂拓扑结构的环境下工作，所以他们不能描述空间依赖。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们提出了新的交通预测方法，时间图卷积网络 （T-GCN），用于对基于城市路网的交通预测任务。我们的贡献有三点：&lt;/p&gt;
&lt;p&gt;（1） 我们提出的模型结合了 GCN 和 GRU，图卷积捕获路网的拓扑结构做空间建模，GRU 捕获路网上交通数据的时间依赖。T-GCN 模型可以用于其他时空预测任务上。&lt;/p&gt;
&lt;p&gt;（2） T-GCN 的预测结果比其他的方法好，表明我们的 T-GCN 模型不仅可以做短期预测，也可以做长期预测。&lt;/p&gt;
&lt;p&gt;（3）我们使用深圳市罗湖区的出租车速度数据和洛杉矶线圈数据。结果表明我们的预测误差比所有的 baseline 小了 1.5%到57.8%，表明 T-GCN 在交通预测上的优越性。&lt;/p&gt;
&lt;h1 id="2-related-work"&gt;2 Related work
&lt;/h1&gt;&lt;p&gt;智能交通系统交通预测是现在的一个重要研究问题。现存的方法分两类：模型驱动的方法和数据驱动的方法。首先，模型驱动的方法主要解释交通流量、速度、密度的瞬时性和平稳性。这样的方法需要基于先验知识的系统建模。代表方法包括排队论模型，细胞传递模型，交通速度模型，microscopic fundamental diagram model 等等。实际中，交通数据受多种因素影响，很难获得一个精准的交通模型。现存的模型不能精确地描述复杂的现实环境中的交通数据的变化。此外，这些模型的构建需要很强的计算能力，而且很容易收到交通扰乱和采样点空间等问题的影响。&lt;/p&gt;
&lt;p&gt;数据驱动的方法基于数据的规律性，从统计学推测变化局势，然后用于预测。这类方法不分析物理性质和交通系统的动态行为，有很高的灵活性。早期的方法包括历史均值模型，使用历史周期的交通流量均值作为预测值。这个方法不需要假设，计算简单而且还快，但是不能有效地拟合时间特征，预测的精准度低。随着研究的深入，很多高精度的方法涌现出来，主要分为参数模型和非参数模型。&lt;/p&gt;
&lt;p&gt;参数模型提前假设回归函数，参数通过对原始数据处理得到，基于回归函数对交通流预测。时间序列模型，线性回归模型，Kalman filtering model 是常用的方法。时间序列模型将观测到的时间序列拟合进一个模型，然后用来预测。早在 1976 年，Box and Jenkins 提出了 ARIMA，Hamed 等人使用 ARIMA 预测城市内的交通流量。为了提高模型的精度，不同的变体相继被提出，Kohonen ARIMA，subset ARIMA，seasonal ARIMA 等等。Lippi 等人对比支持向量回归和 seasonal ARIM，发现 SARIMA 模型在交通拥堵上的预测有更好的结果。线性回归模型基于历史数据构建模型来预测。2004 年，Sun 等人使用 local linear model 解决了区间预测，在真实数据集上获得了较好的效果。Kalman filtering model 基于前一时刻和当前时刻的交通状态预测未来的状态。1984 年，Okutani 等人使用 Kalman filtering 理论建立了交通流状态预测模型。后续，一些研究使用 Kalman filtering 模型解决交通预测任务。&lt;/p&gt;
&lt;p&gt;传统的参数模型算法简单，计算方便。然而，这些方法依赖平稳假设，不能反映交通数据的非线性和不确定性，也不能克服交通事件这种随机性事件。非参数模型很好地解决这些问题，只需要足够的历史信息能自动地从中学到统计规律即可。常见的非参数模型包括：k近邻，支持向量回归，Fuzzy Logic 模型等。&lt;/p&gt;
&lt;p&gt;近些年，随着深度学习的快速发展，深度神经网络可以捕获交通数据的动态特征，获得很好的效果。根据是否考虑空间依赖，模型可以划分成两类。一些方法只考虑时间依赖，如 Park 等人使用 FNN 预测交通流。Huang 等人使用深度置信网络 DBN 和回归模型在多个数据集上证明可以捕获交通数据中的随机特征，提升预测精度。此外，RNN 及其变体 LSTM, GRU 可以有效地使用自循环机制，他们可以很好地学习到时间依赖并获得更好的预测结果。&lt;/p&gt;
&lt;p&gt;这些模型考虑时间特征但是忽略空间依赖，所以交通数据的变化不受城市路网的限制，因此他们不能精确的预测路上的交通状态。解决交通预测问题的关键是充分利用空间和时间依赖。为了更好的刻画空间特征，很多研究已经在这个基础上进行了提升。Lv 等人提出了一个 SAE 模型从交通数据中捕获时空特征，实现短期交通流的预测。Zhang 等人提出了一个叫 ST-ResNet 的模型，基于人口流动的时间近邻、周期和趋势这些特征设计了残差卷积网络，然后三个网络和外部因素动态地聚合起来，预测城市内每个区域人口的流入和流出。Wu 等人设计了一个特征融合架构通过融合 CNN 和 LSTM 进行短期预测。一个一维的 CNN 用于捕获空间依赖，两个 LSTM 用来挖掘交通流的短期变化和周期性。Cao 等人提出一个叫 ITRCN 的端到端模型，将交互的网络交通转换为图像，使用 CNN 捕获交通的交互式功能，用 GRU 提取时间特征，预测误差比 GRU 和 CNN 分别高了 14.3% 和 13.0%。Ke 等人提出一个新的深度学习方法叫融合卷积长短时记忆网络（FCL-Net），考虑空间依赖、时间依赖，以及异质依赖，用于短期乘客需求预测。Yu 等人用深度卷积神经网络捕获空间依赖，用 LSTM 捕获时间动态性，在北京交通网络数据上展示出了 SRCN 的优越性。&lt;/p&gt;
&lt;p&gt;尽管上述方法引入了 CNN 对空间依赖建模，在交通预测任务上有很大的进步，但 CNN 本质上只适用于欧氏空间，在有着复杂拓扑结构的交通网络上不能刻画空间依赖。因此，这类方法有缺陷。近些年，图卷积网络的发展，可以用来捕获图网络的结构特征，提供更好的解决方案。Li 等人提出了 DCRNN 模型，通过图上的随机游走捕获空间特征，通过编码解码结构捕获时间特征。&lt;/p&gt;
&lt;p&gt;基于这个背景，我们提出了新的神经网络方法捕获复杂的时空特征，可以用于基于城市路网的交通预测任务上。&lt;/p&gt;
&lt;h1 id="3-methodology"&gt;3 Methodology
&lt;/h1&gt;&lt;h2 id="31-problem-definition"&gt;3.1 Problem Definition
&lt;/h2&gt;&lt;p&gt;目标是基于历史信息预测未来。我们的方法中，交通信息是一个通用的概念，可以是速度、流量、密度。我们在实验的时候将交通信息看作是速度。&lt;/p&gt;
&lt;p&gt;定义1：路网 $G$。我们用图 $G = (V, E)$ 描述路网的拓扑结构，每条路是一个顶点，$V$ 顶点集，$V = \lbrace v_1, v_2, \dots, v_N \rbrace$，$N$ 是顶点数，$E$ 是边集。邻接矩阵 $A$ 表示路的关系，$A \in R^{N \times N}$。邻接矩阵只有 0 和 1。如果路之间有连接就为 1， 否则为 0。&lt;/p&gt;
&lt;p&gt;定义2：特征矩阵 $X^{N \times P}$。我们将交通信息看作是顶点的特征。$P$ 表示特征数，$X_t \in R^{N \times i}$ 用来表示时刻 $i$ 每条路上的速度。&lt;/p&gt;
&lt;p&gt;时空交通预测的问题可以看作学习一个映射函数：&lt;/p&gt;
$$\tag{1}
[X\_{t+1}, \dots, X\_{t+T}] = f(G; (X\_{t-n}, \dots, X\_{t-1}, X\_t))
$$&lt;p&gt;$n$ 是历史时间序列的长度，$T$ 是需要预测的长度。&lt;/p&gt;
&lt;h2 id="32-overview"&gt;3.2 Overview
&lt;/h2&gt;&lt;p&gt;T-GCN 模型有两个部分：GCN 和 GRU。图 3 所示，我们使用历史 $n$ 个时刻的时间序列数据作为输入，图卷积网络捕获路网拓扑结构获取空间依赖。然后将带有空间特征的时间序列放入 GRU 中，通过信息在单元间的传递捕获动态变化，获得时间特征。最后，将结果送入全连接层。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;h2 id="33-methodology"&gt;3.3 Methodology
&lt;/h2&gt;&lt;h3 id="331-spatial-dependence-modeling"&gt;3.3.1 Spatial Dependence Modeling
&lt;/h3&gt;&lt;p&gt;获取复杂的空间依赖在交通预测中是一个关键问题。传统的 CNN 只能用于欧氏空间。城市路网不是网格，CNN 不能反映复杂的拓扑结构。GCN 可以处理图结构，已经广泛应用到文档分类、半监督学习、图像分类中。GCN 在傅里叶域中构建滤波器，作用在顶点及其一阶邻居上，捕获顶点间的空间特征，可以通过堆叠构建 GCN 模型。如图 4 所示，假设顶点 1 是中心道路，GCN 模型可以获取中心道路和它周围道路的拓扑关系，将这个结构和道路属性编码，获得空间依赖。总之，我们用 GCN 模型从交通数据中学习空间特征。两层 GCN 表示为：&lt;/p&gt;
$$\tag{2}
f(X, A) = \sigma(\hat{A} Relu(\hat{A} X W\_0) W\_1)
$$&lt;p&gt;$\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$ 表示预处理，$\tilde{A} = A + I_N$ 表示加了自连接的邻接矩阵。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;h3 id="332-temporal-dependence-modeling"&gt;3.3.2 Temporal Dependence Modeling
&lt;/h3&gt;&lt;p&gt;因为 GRU 比 LSTM 参数少，训练快，我们使用 GRU 获取交通数据的时间依赖。如图 5 所示，$h_{t-1}$ 表示时刻 $t-1$ 的隐藏状态；$x_t$ 表示时刻 $t$ 的交通信息；$r_t$ 表示重置门，用来控制忽略前一时刻信息的程度；$u_t$ 是更新门，用来控制将信息从上一时刻拿到这个时刻的程度；$c_t$ 是时刻 $t$ 的记忆内容；$h_t$ 是时刻 $t$ 的输出状态。GRU 通过将时刻 $t-1$ 的隐藏状态和当前时刻的交通信息作为输入，获取时刻 $t$ 的交通状态。在捕获当前时刻的交通信息的时候，模型仍保留着历史信息，且有能力捕获时间依赖。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig5.JPG"
loading="lazy"
alt="Figure5"
&gt;&lt;/p&gt;
&lt;h3 id="333-temporal-graph-convolutional-network"&gt;3.3.3 Temporal Graph Convolutional Network
&lt;/h3&gt;&lt;p&gt;为了同时从交通数据中捕获时空依赖，我们提出了时间图卷极网络（T-GCN）。如图6所示，左侧是时空交通预测的过程，右侧是一个 T-GCN 细胞的结构，$h_{t-1}$ 表示 $t-1$ 时刻的输出，GC 是图卷积过程，$u_t, r_t$ 是时刻 $t$ 的更新门和重置门，$h_t$ 表示时刻 $t$ 的输出。计算过程如下。$f(A, X_t)$ 表示图卷积过程，如式 2 定义。$W$ 和 $b$ 表示训练过程的权重与偏置。&lt;/p&gt;
$$\tag{3}
u\_t = \sigma(W\_u[f(A, X\_t), h\_{t-1}] + b\_u)
$$$$\tag{4}
r\_t = \sigma(W\_r[f(A, X\_t), h\_{t-1}] + b\_r)
$$$$\tag{5}
c\_t = tanh(W\_c[f(A, X\_t), (r\_t \ast h\_{t-1})] + b\_c)
$$$$\tag{6}
h\_t = u\_t \ast h\_{t-1} + (1 - u\_t) \ast c\_t
$$&lt;p&gt;总之，T-GCN 能处理复杂的空间依赖和时间动态性。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig6.JPG"
loading="lazy"
alt="Figure6"
&gt;&lt;/p&gt;
&lt;h3 id="334-loss-function"&gt;3.3.4 Loss Function
&lt;/h3&gt;&lt;p&gt;损失函数如式 7。第一项用来减小速度的误差。第二项 $L_{reg}$ 是一个 $L2$ 正则项，避免过拟合，$\lambda$ 是超参。&lt;/p&gt;
$$\tag{7}
loss = \Vert Y\_t - \hat{Y}\_t \Vert + \lambda L\_{reg}
$$&lt;h1 id="4-experiments"&gt;4 Experiments
&lt;/h1&gt;&lt;h2 id="41-data-description"&gt;4.1 Data Description
&lt;/h2&gt;&lt;p&gt;两个数据集，深圳出租车和洛杉矶线圈。两个数据集都和车速有关。&lt;/p&gt;
&lt;p&gt;（1）SZ-taxi。数据是2015年1月1日到1月31日的深圳出租车轨迹数据。我们选了罗湖区 156 个主要路段作为研究区域。实验数据主要有两部分。一个是 156 * 156 的邻接矩阵，另一个是特征矩阵，描述了速度随时间的变化。我们将速度以 15 分钟为单位聚合。&lt;/p&gt;
&lt;p&gt;（2）Los-loop。数据集是洛杉矶县高速公路线圈的实时数据。我们选了 207 个监测器，数据是 2012年5月1日到5月7日的数据。我们以5分钟为单位聚合车速。数据也是一个邻接矩阵和一个特征矩阵。我们用线性插值填补了缺失值。&lt;/p&gt;
&lt;p&gt;我们将输入数据归一化到 $[0, 1]$。此外，80% 的数据用来训练，20% 用来测试。我们预测未来15、30、45、60分钟的车速。&lt;/p&gt;
&lt;h2 id="42-evaluation-metrics"&gt;4.2 Evaluation Metrics
&lt;/h2&gt;&lt;p&gt;（1）RMSE:&lt;/p&gt;
$$\tag{8}
RMSE = \sqrt{\frac{1}{n} \sum^n\_{i=1} (Y\_t - \hat{Y}\_t)^2}
$$&lt;p&gt;（2）MAE:&lt;/p&gt;
$$\tag{9}
MAE = \frac{1}{n} \sum^n\_{i=1} \vert Y\_t - \hat{Y}\_t \vert
$$&lt;p&gt;（3）Accuracy:&lt;/p&gt;
$$\tag{10}
Accuracy = 1 - \frac{\Vert Y - \hat{Y} \Vert}{\Vert Y \Vert\_F}
$$&lt;p&gt;（4）Coefficient of Determination (R2):&lt;/p&gt;
$$\tag{11}
R^2 = 1 - \frac{\sum\_{i=1} (Y\_t - \hat{Y}\_t)^2}{\sum\_{i=1}(Y\_t - \bar{Y})^2}
$$&lt;p&gt;（5）Explained Variance Score(Var):&lt;/p&gt;
$$
var = 1 - \frac{Var\lbrace Y - \hat{Y}\rbrace}{Var\lbrace Y\rbrace}
$$&lt;p&gt;RMSE 和 MAE 用来评估预测误差：越小越好。精度衡量预测的精度：越大越好。$R^2$ 和 Var 计算相关系数，评估预测结果表达真实数据的能力，越大越好。&lt;/p&gt;
&lt;h2 id="43-model-parameters-designing"&gt;4.3 Model Parameters Designing
&lt;/h2&gt;&lt;p&gt;(1) Hyperparameter&lt;/p&gt;
&lt;p&gt;学习率、batch size、训练论述，隐藏层数。我们设定的是学习率0.001，batch size 64，轮数 3000 轮。&lt;/p&gt;
&lt;p&gt;隐层单元数对 T-GCN 来说是个重要的参数，因为不同的单元数可能会影响预测精度。我们通过实验选取了最优的隐藏单元数。&lt;/p&gt;
&lt;p&gt;看不下去了。。。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig7.JPG"
loading="lazy"
alt="Figure7"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;</description></item><item><title>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</title><link>https://davidham3.github.io/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/</link><pubDate>Thu, 28 Feb 2019 21:12:58 +0000</pubDate><guid>https://davidham3.github.io/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/</guid><description>&lt;p&gt;AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：&lt;a class="link" href="http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf" target="_blank" rel="noopener"
&gt;Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;区域级别的预测是网约车服务的关键任务。精确地对网约车需求预测可以指导车辆调度、提高车辆利用率，减少用户的等待时间，减轻交通拥堵。这个任务的关键在于区域间复杂的时空依赖关系。现存的方法主要关注临近区域的欧式关系建模，但是在距离较远的区域间组成的非欧式关系对精确预测也很关键。我们提出了 &lt;em&gt;spatiotemporal multi-graph convolution network&lt;/em&gt; (ST-MGCN)。我们首先将非欧的关系对编码到多个图中，然后使用 multi-graph convolution 对他们建模。为了在时间建模上利用全局的背景信息，我们提出了 &lt;em&gt;contextual gated recurrent neural network&lt;/em&gt;，用一个注意背景的门机制对不同的历史观测值重新分配权重。在两个数据集上比当前的 state-of-the-art 强 10%。&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction
&lt;/h1&gt;&lt;p&gt;我们研究的问题是区域级别网约车需求预测，是智能运输系统的重要部分。目标是通过历史观测值，预测一个城市里面各区域未来的需求。任务的挑战是复杂的时空关系。一方面，不同区域有着复杂的依赖关系。举个例子，一个区域的需求通常受其空间上临近的区域所影响，同时与有着相同背景的较远的区域有联系。另一方面，非线性的依赖关系也存在于不同的时间观测值之间。预测一个时刻通常和多个历史的观测值相关，比如一小时前、一天前、甚至一周前。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;最近在深度学习的进步使得对基于区域级别的时空关系预测有了很好的结果。使用卷积神经网络和循环神经网络，得到了很多非常好的效果(Shi et al. 2015; Yu et al. 2017; Shi et al. 2017; Zhang, Zheng, and Qi 2017; Zhang et al. 2018a; Ma et al. 2017; Yao et al. 2018b; 2018a)。尽管有了很好的效果，但是我们认为在对时空关系建模上有两点被忽略了。其一，这些方法主要对不同区域的欧式关系建模，但是我们发现非欧关系很重要。图 1 是一个例子，对于区域 1，以及邻居区域 2，可能和很远的区域 3 有相似的功能，也就是他们都靠近学校和医院。此外，区域 1 还可能被区域 4 影响，区域 4 是通过高速公路直接与区域 1 相连的。其二：这些方法中，在使用 RNN 对时间关系建模时，每个区域是独立处理的，或者只基于局部信息。然而，我们认为全局和背景信息也很重要。举个例子，网约车需求的一个全局性的增长/减小通常表明一些可能会影响未来需求的活动发生了。&lt;/p&gt;
&lt;p&gt;我们提出了 ST-MGCN 解决这些问题。在 ST-MGCN 中，我们提出了将区域间非欧关系编码进多个图的方法。不同于 Yao et al. 2018b 给每个区域使用图嵌入作为额外的不变特征，我们用图卷积对区域间的关系对直接建模。图卷积在预测的时候可以聚合邻居特征，传统的图嵌入难以做到这一点。此外，在对时间关系建模时，为了聚合全局的背景信息，我们提出了 contextual gated recurrent neural network (CGRNN)。通过一个基于全局信息计算的门机制增强 RNN，对不同时间步的观测值重新赋权重。我们在两个大型的真实数据集上做了测试，ST-MGCN 比 baselines 好了一大截。我们主要的贡献是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;识别了网约车需求预测中的非欧关系，将他们编码进多个图。利用多图卷积对这些关系建模。&lt;/li&gt;
&lt;li&gt;对时间依赖，提出了 Contextual Gated RNN (CGRNN) 来集成全局背景信息。&lt;/li&gt;
&lt;li&gt;在两个大型真实数据集上做了实验，提出的方法比 state-of-the-art 在相对误差上小了 10%.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="related-work"&gt;Related work
&lt;/h1&gt;&lt;h2 id="spatiotemporal-prediction-in-urban-computing"&gt;Spatiotemporal prediction in urban computing
&lt;/h2&gt;&lt;p&gt;时空预测是数据驱动的城市管理的基础问题。有很多关于这方面的工作，自行车流量预测(Zhang, Zheng, and Qi 2017)，出租车需求(Ke et al. 2017b; Yao et al. 2018b)，到达时间(Li et al. 2018b)，降雨量(Shi et al. 2015; 2017)，对矩形区域的聚合值进行预测，区域关系通过地理距离建模。具体来讲，城市数据的空间结构通过矩阵形式表示，每个元素表示一个矩形区域。在之前的工作中，区域和他们的关系对一般表示成欧式结构，使得卷积神经网络可以有效地利用这个结构来预测。&lt;/p&gt;
&lt;p&gt;非欧结构的数据也存在于城市计算。通常，基于站点或点的预测任务，像流量预测(Li et al. 2018c; Yu, Yin, and Zhu 2018; Yao et al. 2018a)，基于点的出租车需求预测(Tong et al. 2017)以及基于站点的自行车流量预测(Chai, Wang, and Yang 2018)是很自然的非欧结构，数据不再是矩阵形式，卷积神经网络也不那么有效了。人工定制的特征工程或图卷积网络是处理非欧结构数据目前最好的方法。不同于之前的工作，ST-MGCN 将区域间的关系对编码进语义图中。尽管 ST-MGCN 是对基于区域的预测设计的，但是区域关系的非规整性使得它实际是对非欧数据进行预测。&lt;/p&gt;
&lt;p&gt;在 (Yao et al. 2018b)，作者提出 DMVST-Net，将区域间关系编码进图中来预测出租车需求。DMVST-Net 主要使用图嵌入作为额外特征来预测，没有使用相关区域的需求值（目标值）。在 (Yao et al. 2018a) 的工作中，作者通过注意力机制对周期性的平移问题建模提升了性能。但是，这些方法都没有直接对区域间的非欧关系建模。我们的工作中，ST-MGCN 使用提出的多图卷积从相关区域聚合特征，从不同角度的相关区域的预测值中做预测。&lt;/p&gt;
&lt;p&gt;最近在对帕金森的神经图像分析 (Zhang et al. 2018b) 的研究中，图卷积在空间特征提取上很有效。他们使用 GCN 从最相似的区域中学习特征，提出了多视图结构融合了不同的 MRI。然而，上述工作没有考虑时间依赖。ST-GCN 用于基于骨骼的动作识别(Li et al. 2018a; Yan, Xiong, and Lin 2018)。ST-GCN 的变换是一个空间依赖和局部时间循环的组合。然而，我们认为这些模型，在时间依赖建模上，背景信息或全局信息被忽略了。&lt;/p&gt;
&lt;h2 id="graph-convolution-network"&gt;Graph convolution network
&lt;/h2&gt;&lt;p&gt;图卷积网络定义在图 $\mathcal{G} = (V, \boldsymbol{A})$ 上，$V$ 是顶点集，$\boldsymbol{A} \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ 是邻接矩阵，元素表示顶点间是否相连。GCN 可以用不同的感受野从不同的非欧结构中提取局部特征(Hammond et al. 2011)。令 $\boldsymbol{L} = \boldsymbol{I} - \boldsymbol{D}^{-1/2} \boldsymbol{A} \boldsymbol{D}^{-1/2}$ 表示图拉普拉斯矩阵，$\boldsymbol{D}$ 是度矩阵，图卷积操作 (Defferrard, Bresson, and Vandergheynst 2016) 定义为：&lt;/p&gt;
$$
\boldsymbol{X}\_{l+1} = \sigma (\sum^{K-1}\_{k=0} \alpha\_k \boldsymbol{L}^k \boldsymbol{X}\_l),
$$&lt;p&gt;$\boldsymbol{X}_l$ 表示第 $l$ 层的特征，$\alpha_k$ 表示可学习的参数，$\boldsymbol{L}^k$ 是图拉普拉斯矩阵的 $k$ 次幂，$\sigma$ 是激活函数。&lt;/p&gt;
&lt;h2 id="channel-wise-attention"&gt;Channel-wise attention
&lt;/h2&gt;&lt;p&gt;Channel-wise attention (Hu, Shen, and Sun 2018; Chen et al. 2017) 在 cv 的论文中提出。本质是给每个通道学习一个权重，为了找到最重要的帧，然后基于他们更高的权重。$\boldsymbol{X} \in \mathbb{R}^{W \times H \times C}$ 表示输入，$W$ 和 $H$ 是输入图像的维度，$C$ 表示通道数，channel-wise attention 计算方式如下：&lt;/p&gt;
$$\tag{1}
z\_c = F\_{pool}(\boldsymbol{X}\_{:,:,c}) = \frac{1}{WH} \sum^W\_{i=0} \sum^H\_{j=0} X\_{i,j,c} \quad \text{for} c=1,2,\dots,C \\
\boldsymbol{s} = \sigma(\boldsymbol{W}\_2 \delta (\boldsymbol{W}\_1 \boldsymbol{z})) \\
\tilde{\boldsymbol{X}}\_{:,:,c} = \boldsymbol{X}\_{:,:,c} \circ s\_c \quad \text{for} c=1,2,\dots,C
$$&lt;p&gt;$F_{pool}$ 是全局池化操作，把每个通道聚合成一个标量 $\boldsymbol{z}_c$，$c$ 是通道的下标。用一个注意力机制对聚合的向量 $\boldsymbol{z}$ 使用非线性变换生成自适应的通道权重 $\boldsymbol{s}$，$\boldsymbol{W}_1, \boldsymbol{W}_2$ 是对应的权重，$\delta, \sigma$ 是 ReLU 和 sigmoid 激活函数。$\boldsymbol{s}$ 通过矩阵乘法乘到输入上。最后，输入通道基于学习到的权重得到了缩放。我们使用这个方法，针对一系列的图生成了时间依赖的注意力分数。&lt;/p&gt;
&lt;h1 id="methodology"&gt;Methodology
&lt;/h1&gt;&lt;h2 id="region-level-ride-hailing-demand-forecasting"&gt;Region-level ride-hailing demand forecasting
&lt;/h2&gt;&lt;p&gt;我们将城市分为相同大小的网格，每个格子定义为一个区域 $v \in V$，$V$ 表示城市内所有不相交的区域。$\boldsymbol{X}^{(t)}$ 表示第 $t$ 个时段所有区域的订单。&lt;em&gt;区域级别的网约车需求预测&lt;/em&gt; 问题定义为：给定一个定长的输入，对单个时间步进行时空预测，也就是学习一个函数 $f: \mathbb{R}^{\vert V \vert \times T} \rightarrow \mathbb{R}^{\vert V \vert}$，将所有区域的历史需求映射到下一个时间步上。&lt;/p&gt;
$$
[\boldsymbol{X}^{(t-T+1)}, \dots, \boldsymbol{X}^{(t)}]
$$&lt;p&gt;&lt;strong&gt;Framework overview&lt;/strong&gt; ST-MGCN 的系统架构如图2。我们从不同的角度表示区域间的关系，顶点表示区域，边对区域间的关系编码。首先，我们使用提出的 CGRNN，考虑全局背景信息对不同时间的观测值进行聚合。然后，使用多图卷积捕获区域间不同类型的关系。最后，使用全连接神经网络将特征映射到预测上。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;h2 id="spatial-dependency-modeling"&gt;Spatial dependency modeling
&lt;/h2&gt;&lt;p&gt;我们用图将区域间关系建模成三种类型，（1）邻居图 $\mathcal{G}_N = (V, \boldsymbol{A}_N)$，编码了空间相近程度，（2）功能相似度图 $\mathcal{G}_F = (V, \boldsymbol{A}_F)$，编码了区域的 POI 的相似度，（3）连接图 $\mathcal{G}_T = (V, \boldsymbol{A}_T)$，编码了距离较远的区域的连通性。我们的方法可以轻易地扩展到其他的图上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Neighborhood&lt;/strong&gt; 区域的邻居基于空间近邻程度定义。我们将 $3 \times 3$ 区域中的最中间的那个区域与他邻接的 8 个区域相连。&lt;/p&gt;
$$\tag{3}
A\_{N, ij} = \begin{cases}
1, \quad v\_i \quad \text{and} \quad v\_j \quad \text{are} \quad \text{adjacent}\\
0, \quad \text{otherwise}
\end{cases}
$$&lt;p&gt;&lt;strong&gt;Functional similarity&lt;/strong&gt; 对一个区域做预测的时候，很自然的会想到和这个区域在功能上相似的区域会有帮助。区域功能可以由 POI 刻画，两个顶点间的边定义为 POI 的相似度：&lt;/p&gt;
$$\tag{3}
A\_{S,i,j} = \text{sim}(P\_{v\_i}, P\_{v\_j}) \in [0, 1]
$$&lt;p&gt;其中 $P_{v_i}, P_{v_j}$ 是区域 $v_i$ 和 $v_j$ 的 POI 向量，维度等于 POI 种类的个数，每个分量表示这个区域内这个 POI 类型的数量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transportation connectivity&lt;/strong&gt; 运输系统也是一个重要因素。一般来说，这些空间距离上相距较远但是可以很方便到达的区域可以关联起来。这种连接包含高速公路、公路、地铁这样的公共运输。我们定义：如果两个区域间通过这些路直接相连，那么他们之间有边：&lt;/p&gt;
$$\tag{4}
A\_{C,i,j} = max(0, \text{conn}(v\_i, v\_j) - A\_{N,i,j}) \in \lbrace 0, 1\rbrace
$$&lt;p&gt;$\text{conn}(u, v)$ 表示 $v_i$ 和 $v_j$ 之间的连通性。邻居的边在这个图中移除掉了，减少冗余的关系，所以这个图最后是一个稀疏图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi-graph convolution for spatial dependency modeling&lt;/strong&gt; 有了这些图，我们提出了多图卷积对空间关系建模：&lt;/p&gt;
$$\tag{5}
\boldsymbol{X}\_{l+1} = \sigma(\bigsqcup\_{\mathbf{A} \in \mathbb{A}} f(\mathbf{A; \theta\_i}) \boldsymbol{X}\_l \mathbf{W}\_l)
$$&lt;p&gt;其中 $\boldsymbol{X}_l \in \mathbb{R}^{\vert V \vert \times P_l}, \boldsymbol{X}_{l+1} \in \mathbb{R}^{\vert V \vert \times P_{l+1}}$ 是第 $l$ 和 $l+1$ 层的特征向量，$\sigma$ 是激活函数，$\bigsqcup$ 表示聚合函数，如 sum, max, average etc. $\mathbb{A}$ 表示图的集合，$f(\mathbf{A}; \theta_i) \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ 表示参数为 $\theta_i$ 的基于图 $\mathbf{A} \in \mathbb{A}$ 的不同样本组成的矩阵的聚合值，$\mathbf{W}_l \in \mathbb{R}^{P_l \times P_{l+1}}$ 表示特征变换矩阵，举个例子，如果 $f(\mathbf{A}, \theta_i)$ 是拉普拉斯矩阵 $\mathbf{L}$ 的多项式，那么这就是多图上的 ChebNet。如果是 $\mathbf{I}$，那就是全连接神经网络。&lt;/p&gt;
&lt;p&gt;我们实现的是 $K$ 阶 拉普拉斯 $\mathbf{L}$ 多项式，图 3 是一个中心区域通过图卷积层变换后的例子。假设邻接矩阵中的值不是 0 就是 1，$L^k_{ij} \not = 0$ 表示 $v_i$ 在 $k$ 步内可达 $v_j$。根据卷积操作，$k$ 是空间特征提取时的感受野范围。使用图 1 的道路连通性图 $\mathcal{G}_C = (V, \boldsymbol{A}_C)$ 来说明。在邻接矩阵 $\boldsymbol{A}_C$ 中，我们有：&lt;/p&gt;
$$
A\_{C,1,4} = 1; A\_{C,1,6} = 0; A\_{C,4,6} = 1,
$$&lt;p&gt;在 1 度拉普拉斯矩阵中对应的分量是：&lt;/p&gt;
$$
L^1\_{C,1,4} \not = 0; L^1\_{C,1,6} = 0; L^1\_{C,4,6} \not = 0
$$&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;如果拉普拉斯矩阵的最大度数 $K$ 设为 $1$，那么区域 1 变换的特征向量，即 $\boldsymbol{X}_{l+1, 1,:}$ 不会包含区域 6: $\boldsymbol{X}_{l,6,:}$，因为 $L^1_{C,1,6}=0$。当 $K$ 增大到 2 的时候，对应的元素 $L^2_{C,1,6}$ 变成非零，$\boldsymbol{X}_{l+1,1,:}$ 就可以利用 $\boldsymbol{X}_{l,6,:}$ 的信息了。&lt;/p&gt;
&lt;p&gt;基于多图卷积的空间依赖建模不限于上述三种图，可以轻易地扩展到其他的图上，适用于其他的时空预测问题上。多图卷积对区域间的关系进行特征提取。感受野小的时候，专注于近邻的区域。增大拉普拉斯阶数，或者堆叠卷积层可以增加感受野的范围，鼓励模型捕获全局依赖关系。&lt;/p&gt;
&lt;p&gt;图嵌入是另一种对区域间关系建模的方法。在 DMVST-Net (Yao et al. 2018b)，作者使用图嵌入表示区域间关系，然后将嵌入作为额外特征加到每个区域上。我们认为 ST-MGCN 中的空间依赖建模方法比之前的方法好，因为：ST-MGCN 将区域间关系编码到图中，通过图卷积从相关区域聚合需求值。但是在 DMVST-Net 中区域关系是嵌入到一个基于区域的不随时间变化的特征中，作为的模型的输入，&lt;/p&gt;
&lt;p&gt;尽管 DMVST-Net 也捕获了拓扑结构信息，但是它很难从相关的区域中通过区域关系聚合需求值。而且不变的特征对模型训练的贡献有限。&lt;/p&gt;
&lt;h2 id="temporal-correlation-modeling"&gt;Temporal correlation modeling
&lt;/h2&gt;&lt;p&gt;我们提出 Contextual Gated Recurrent Neural Network (CGRNN) 对不同时间步上的样本建模。CGRNN 通过使用一个上下文注意的门机制增强 RNN 将背景信息集成到时间建模中，结构如图 4。假设我们有 $T$ 个观测样本，$\boldsymbol{X}^{(t)} \in \mathbb{R}^{\vert V \vert \times P}$ 表示第 $t$ 个样本，$P$ 是特征数，如果特征只包含订单数，那就是 1。上下文门控机制如下：&lt;/p&gt;
$$tag{6}
\hat{\boldsymbol{X}}^{(t)} = [\boldsymbol{X}^{(t)}, F^{K'}\_\mathcal{G}(\boldsymbol{X}^{(t)})] \quad \text{for} \quad t = 1,2,\dots,T
$$&lt;p&gt;首先，上下文门控机制通过将临近区域的历史信息和当前区域拼接，得到了区域的描述信息。从相邻区域来的信息看作是环境信息，通过图卷积 $F^{K&amp;rsquo;}_\mathcal{G}$ 使用最大阶数为 $K&amp;rsquo;$ 的拉普拉斯矩阵提取。上下文门控机制用来用图卷积操作集成临近区域的信息，然后使用一个池化：&lt;/p&gt;
$$\tag{7}
z^{(t)} = F\_{pool}(\hat{\boldsymbol{X}}^{(t)}) = \frac{1}{\vert V \vert} \sum^{\vert V \vert}\_{i=1} \hat{X}^{(t)}\_{i,:} \quad \text{for} \quad t=1,2,\dots,T
$$&lt;p&gt;然后，我们在所有的区域上使用全局平均池化 $F_{pool}$ 生成每个时间步观测值的平均值。&lt;/p&gt;
$$tag{8}
\boldsymbol{s} = \sigma(\boldsymbol{W}\_2 \delta(\boldsymbol{W}\_1) \boldsymbol{z})
$$&lt;p&gt;然后使用一个注意力机制，$\boldsymbol{W}_1, \boldsymbol{W}_2$ 是参数，$\delta, \sigma$ 分别是 ReLU 和 sigmoid 激活。&lt;/p&gt;
$$\tag{9}
\tilde{\boldsymbol{X}^{(t)}} = \boldsymbol{X}^{(t)} \circ s^{(t)} \quad \text{for} \quad t=1,2,\dots,T
$$&lt;p&gt;最后，$\boldsymbol{s}$ 用来对每个时间样本进行缩放：&lt;/p&gt;
$$tag{10}
\boldsymbol{H}\_{i,:} = \text{RNN}(\tilde{\boldsymbol{X}}^{(1)}\_{i,:}, \dots, \tilde{\boldsymbol{X}}^{(T)}\_{i,:}; \boldsymbol{W}\_3) \quad \text{for} \quad i=1,\dots,\vert V \vert
$$&lt;p&gt;在上下文门控之后，使用一个共享的 RNN 对所有的区域进行计算，将每个区域聚合成单独的向量 $\boldsymbol{H}_{i,:}$。使用共享 RNN 的原因是我们想找到一个对所有区域通用的聚合规则，这个规则鼓励模型泛化且减少模型的复杂度。&lt;/p&gt;
&lt;h1 id="experiments"&gt;Experiments
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt; 北京和上海。时间是从2017年5月1日到2017年12月31日。5月1日到7月31日训练、8月1日到9月30日验证，剩下的测试。POI 数据是2017年的，包含13个类别。每个区域和一个 POI 向量相关，分量是这个 POI 类型在这个区域的个数。用来评估运输可达性的路网使用的是 OpenStreetMap (Haklay and Weber 2008)。&lt;/p&gt;
&lt;h2 id="experimental-settings"&gt;Experimental Settings
&lt;/h2&gt;&lt;p&gt;学习任务是：$f: \mathbb{R}^{\vert V \vert \times T} \rightarrow \mathbb{R}^{\vert V \vert}$。实验中，我们将区域以 $1km \times 1km$ 的大小划分成网格。北京和上海分别 1296 和 896 个区域。就像 Zhang, Zheng, and Qi 2017 做的那样，网络的输入包含 5 个历史观测值，三个最近邻的部分，1个周期部分，一个最新的趋势部分。在构建运输可达性网络的时候，我们考虑了高速公路、公路、地铁。两个区域间只要有这样的路直接相连就认为是连通的。&lt;/p&gt;
&lt;p&gt;$f(\mathbf{A}; \theta_i)$ 选择的是 $K = 2$ 时的切比雪夫多项式，$\bigsqcup$ 是 sum 函数。隐藏层为3，每层 64 个隐藏单元，L2 正则，weight decay 是 $1e-4$。CGRNN 中的图卷积 $K&amp;rsquo;$ 是 1。&lt;/p&gt;
&lt;p&gt;我们使用 ReLU 作为图卷积的激活函数。ST-MGCN 的学习率是 $2e-3$，使用验证集上的早停。所有的算法都用 tf 实现，adam 优化 RMSE。ST-MGCN 训练时用了 10G 内存，9G GPU 显存。在 Tesla P40 单卡上训练了一个半小时。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Methods for evaluation&lt;/strong&gt; HA, LASSO, Ridge, Auto-regressive model(VAR, STAR), Gradient boosted machine (GBM), ST-ResNet (Zhang, Zheng and Qi 2017), DMVST-Net (Yao et al. 2018b), DCRNN, ST-GCN。&lt;/p&gt;
&lt;h2 id="performance-comparison"&gt;Performance comparison
&lt;/h2&gt;&lt;p&gt;我们在验证集上用网格搜索调整了所有模型的参数，在测试集上跑了多次得到的最后的结果。我们使用 RMSE 和 MAPE 作为评价指标。表 1 展示了不同方法在 10 次以上的预测中的对比结果。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;我们在两个数据集上观测到了几个现象：（1）基于深度学习的方法能够对非线性的时空依赖关系建模，比其他的方法好；（2）ST-MGCN 在两个数据集上比其他的方法都好，比第二好的高出 10%；（3）对比其他的深度学习方法，ST-MGCN 的方差更小。&lt;/p&gt;
&lt;h2 id="effect-of-spatial-dependency-modeling"&gt;Effect of spatial dependency modeling
&lt;/h2&gt;&lt;p&gt;为了研究空间和时间依赖建模的效果，我们通过减少模型中的组成部分评估了 ST-MGCN 的几个变体，包括：（1）邻居图，（2）功能相似性图，（3）运输连通性图。结果如表 2 所示。移除任何一个图都会造成性能损失，证明了每种关系的重要性。这些图编码了重要的先验知识，也就是区域间的相关性。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;&lt;/p&gt;
&lt;p&gt;为了评估集成多个区域关系的效果，我们扩展了基于单个图的模型，包括 DCRNN 和 STGCN，分别记为 DCRNN+ 和 ST-GCN+。结果如图 3，两个算法都得到了提升。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table3.JPG"
loading="lazy"
alt="Table3"
&gt;&lt;/p&gt;
&lt;h2 id="effect-of-temporal-dependency-modeling"&gt;Effect of temporal dependency modeling
&lt;/h2&gt;&lt;p&gt;我们使用不同的方法对时间建模，评估 ST-GCN 对时间关系建模的效果。（1）平均池化：通过平均池化对历史观测值进行聚合，（2）RNN：使用 RNN 对历史观测值聚合，（3）CG：使用上下文门对不同的历史观测值赋权，不适用 RNN，（4）GRNN：不用图卷积的 CGRNN。结果如表 4。我们观察到了以下现象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平均池化会盲目地平均不同的样本，导致性能下降，能做上下文依赖非线性时间聚合的 RNN 能显著地提升性能。&lt;/li&gt;
&lt;li&gt;CGRNN 增强了 RNN。移除 RNN 和 图卷积都导致性能下降，证明了每个部件的有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table4.JPG"
loading="lazy"
alt="Table4"
&gt;&lt;/p&gt;
&lt;h2 id="effect-of-model-parameters"&gt;Effect of model parameters
&lt;/h2&gt;&lt;p&gt;我们调整了两个最重要的参数来看不同参数对模型的影响，$K$ 和图卷积层数。图 5 展示了测试集上的结果。可以观察到随着层数的增加，错误先降后增。但是随着 $K$ 的增加，错误是先减小，后不变。越大的 $K$ 或层数使得模型能捕获全局关联性，代价是模型的复杂度会增加，更易过拟合。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig5.JPG"
loading="lazy"
alt="Figure5"
&gt;&lt;/p&gt;
&lt;h1 id="conclusion-and-future-work"&gt;Conclusion and Future work
&lt;/h1&gt;&lt;p&gt;我们研究的是网约车需求预测，要找寻这个问题唯一的时空依赖关系。我们提出的深度学习模型使用多个图对区域间的非欧关系建模，使用多图卷积明显的捕获了这个关系。然后用上下文门控机制增强了 RNN，在时间建模上集成了全局背景信息。在两个大型真实数据集上评估了模型，比 state-of-the-art好。未来的工作是：（1）在其他的时空预测任务上评估模型；（2）将提出的模型扩展到多步预测上。&lt;/p&gt;</description></item><item><title>Geometric deep learning on graphs and manifolds using mixture model CNNs</title><link>https://davidham3.github.io/blog/p/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/</link><pubDate>Tue, 18 Dec 2018 20:49:15 +0000</pubDate><guid>https://davidham3.github.io/blog/p/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/</guid><description>&lt;p&gt;CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1611.08402.pdf" target="_blank" rel="noopener"
&gt;Geometric deep learning on graphs and manifolds using mixture model CNNs&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;大部分深度学习处理的是 1D，2D，3D 欧式结构数据，音频信号、图像、视频。最近大家开始研究在非欧氏空间上的数据，如复杂网络、计算社会科学、计算机图形学。我们提出了一个统一的框架，让 CNN 可以泛化到非欧氏空间上，学习局部的、平稳的、针对任务可分解的特征。我们发现之前提出的一些方法都可以放到我们的框架中。我们发现我们的方法效果比前人的方法都要好。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1. Introduction
&lt;/h1&gt;&lt;h1 id="2-deep-learning-on-graphs"&gt;2. Deep learning on graphs
&lt;/h1&gt;&lt;p&gt;无向带权图 $\mathcal{G} = (\lbrace 1, \dots, n\rbrace, \mathcal{E}, \mathbf{W})$，邻接矩阵 $\mathbf{W} = (w_{ij})$，其中 $w_{ij} = w_{ji}$，如果 $(i, j) \notin \mathcal{E}$，则 $w_{ij} = 0$，否则 $w_{ij} &amp;gt; 0$。未归一化的拉普拉斯矩阵是个 $n \times n$ 的 实对称半正定矩阵 $\Delta = \bf D - W$，其中 $\mathbf{D} = \text{diag}(\sum_{j = \not i} w_{ij})$ 是度矩阵。&lt;/p&gt;
&lt;p&gt;拉普拉斯矩阵有特征值分解 $\bf \Delta = \Phi \Lambda \Phi^T$，其中 $\Phi = (\phi_1, \dots, \phi_n)$ 是相互正交的特征向量，$\Lambda = \text{diag}(\lambda_1, &amp;hellip;, \lambda_n)$ 特征值组成的对角矩阵。在传统的谐波分析中，特征向量是拉普拉斯算子，特征值可以看作是频率。给定图上的一个信号 $\mathbf{f} = (f_1, \dots, f_n)^T$，它的图傅里叶变换是 $\hat{\mathbf{f}} = \Phi^T \mathbf{f}$。给定两个信号 $\bf f, g$，他们的谱卷积定义为傅里叶变换的 element-wise product：&lt;/p&gt;
$$\tag{1}
\mathbf{f} \star \mathbf{g} = \Phi (\Phi^T \mathbf{f}) \odot (\Phi^T g) = \Phi \ \text{diag}(\hat{g}\_1, \dots, \hat{g}\_n) \hat{f},
$$&lt;p&gt;对应了欧氏空间卷积理论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其实这里我没理解啊，我记得卷积的定义不是傅里叶变换的乘积的逆变换吗，所以感觉说的有点不对，但公式倒是对了。。。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spectral CNN.&lt;/strong&gt; Bruna et al. 使用卷积在谱上的定义将 CNN 泛化到图上，得到一个谱卷积层的定义：&lt;/p&gt;
$$\tag{2}
\mathbf{f}^{out}\_l = \xi (\sum^p\_{l'=1} \Phi\_k \hat{G}\_{l,l'} \Phi^T\_k \mathbf{f}^{in}\_{l'})
$$&lt;p&gt;这里维数为 $n \times p$ 和 $n \times q$ 的矩阵 $\mathbf{F}^{in} = (\mathbf{f}^{in}_1, \dots, \mathbf{f}^{in}_p)$，$\mathbf{F}^{out} = (\mathbf{f}^{out}_1, \dots, \mathbf{f}^{out}_q)$ 分别表示 $p$ 维和 $q$ 维的图上的输入和输出信号，$\Phi = (\phi_1, \dots, \phi_k)$ 是前几个特征向量组成的 $n \times k$ 的矩阵，$\hat{\mathbf{G}_{l,l&amp;rsquo;}} = \text{diag}(\hat{g}_{l,l&amp;rsquo;,1}, \dots, \hat{g}_{l,l&amp;rsquo;,k})$ 是一个 $k \times k$ 的对角矩阵，表示频域内一个可学习的滤波器，$\xi$ 是一个非线性激活单元（e.g. ReLU）。这个框架的池化操作在图上的模拟是一个图的缩减操作，给定一个 $n$ 个结点的图，生成一个 $n&amp;rsquo; &amp;lt; n$ 个结点的图，将信号从原来的图上变换到缩减后的图上。&lt;/p&gt;
&lt;p&gt;这个框架有几个缺点。首先，谱滤波器的系数是 &lt;em&gt;basis dependent&lt;/em&gt;，而且，在一个图上学习到的基于谱的 CNN 模型不能应用在其他的图上。其次，图傅里叶变换的计算因为 $\bf \Phi$ 和 $\bf \Phi^T$ 的乘法，会达到 $\mathcal{O}(n^2)$，因为这里没有像 FFT 一样的算法。第三，不能保证在谱域内的滤波器在顶点域上是局部化的；假设使用 $k = O(n)$ 个归一化的拉普拉斯矩阵的特征向量，一个谱卷积层需要 $pqk = O(n)$ 个参数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Smooth Spectral CNN.&lt;/strong&gt; 之后，Henaff et al. 认为 smooth 谱滤波器系数可以使得卷积核在空间上局部化，使用了这个形式：&lt;/p&gt;
$$\tag{3}
\hat{g}\_i = \sum^r\_{j=1} \alpha\_i \beta\_j (\Lambda\_i)
$$&lt;p&gt;其中 $\beta_1(\lambda), \dots, \beta_r(\lambda)$ 是一些固定的插值核，$\mathbb{\alpha} = (\alpha_1, \dots, \alpha_r)$ 是插值系数。矩阵形式中，滤波器写为 $\text{diag}(\hat{G}) = \mathbf{B\alpha}$，其中 $\bf{B} = (b_{ij}) = (\beta_j (\lambda_i))$ 是一个 $k \times r$ 的矩阵。这样一个参数化可以使参数保持在 $n$ 个。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chebyshev Spectral CNN (ChebNet).&lt;/strong&gt; 为了减轻计算图傅里叶变换的代价，Defferrard et al 使用了切比雪夫多项式来表示卷积核：&lt;/p&gt;
$$\tag{4}
g\_\alpha(\Delta) = \sum^{r-1}\_{j=0} \alpha\_j T\_j(\tilde{\Delta}) = \sum^{r-1}\_{j=0} \alpha\_j \Phi T\_j (\tilde{\Lambda}) \Phi^T,
$$&lt;p&gt;其中 $\tilde{\Delta} = 2 \lambda^{-1}_n \Delta - \bf I$ 是 rescaled 拉普拉斯矩阵，它的特征值 $\tilde{\Lambda} = 2 \lambda^{-1}_n \Lambda - \bf I$ 在区间 $[-1, 1]$ 内，$\alpha$ 是 $r$ 维的滤波器中的多项式系数，&lt;/p&gt;
$$\tag{5}
T\_j(\lambda) = 2 \lambda T\_{j-1}(\lambda) - T\_{j-2} (\lambda),
$$&lt;p&gt;表示 $j$ 阶切比雪夫多项式，$T_1(\lambda) = \lambda$，$T_0(\lambda) = 1$。&lt;/p&gt;
&lt;p&gt;这样的方法有几个优点。首先，它不需要计算拉普拉斯矩阵的特征向量。由于切比雪夫多项式的递归定义，计算滤波器 $g_\alpha(\Lambda) \bf f$ 要使用拉普拉斯矩阵 $r$ 次，会导致一个 $\mathcal{O}(rn)$ 的操作。其次，因为拉普拉斯矩阵是一个局部操作，只影响顶点的一阶邻居，它的 $(r-1)$次幂影响 $r$阶邻居，得到的滤波器是局部化的。&lt;/p&gt;</description></item><item><title>A Tutorial on Spectral Clustering</title><link>https://davidham3.github.io/blog/p/a-tutorial-on-spectral-clustering/</link><pubDate>Wed, 05 Dec 2018 15:56:49 +0000</pubDate><guid>https://davidham3.github.io/blog/p/a-tutorial-on-spectral-clustering/</guid><description>&lt;p&gt;关于谱聚类的文章，主要包含了谱聚类和拉普拉斯矩阵的内容。最近研究 GCN 的原理的时候发现了这篇论文。
Von Luxburg U. A tutorial on spectral clustering[J]. Statistics and Computing, 2007, 17(4): 395-416.
原文链接：&lt;a class="link" href="https://arxiv.org/abs/0711.0189" target="_blank" rel="noopener"
&gt;A Tutorial on Spectral Clustering&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="2-similarity-graphs"&gt;2 Similarity graphs
&lt;/h1&gt;&lt;p&gt;给定一组数据点 $x_1, &amp;hellip;, x_n$ 还有数据点 $x_i$ 和 $x_j$ 之间的相似性 $s_{ij} \geq 0$，聚类的目标是将样本点分到几个组中，组的样本相似，不同组的样本不相似。如果没有更多的信息，使用 &lt;em&gt;similarity graph&lt;/em&gt; 表示数据是一个好的方法，$G = (V, E)$。每个顶点 $v_i$ 表示一个数据点 $x_i$。如果相似度 $s_{ij}$ 是正的，且大于一个确定的阈值，那么两个顶点相连，边的权重为 $s_{ij}$。聚类的问题可以使用相似度图重新定义为：我们想找到一个划分方案，使得不同组之间的边有很小的权重（意味着不同类簇间的样本不相似），同组内的权重较高（意味着同一类簇的样本相似）。我们首先引入一些符号和性质。&lt;/p&gt;
&lt;h2 id="21-graph-notation"&gt;2.1 Graph notation
&lt;/h2&gt;&lt;p&gt;$G = (V, E)$ 是无向图，顶点集 $V = \lbrace v_1, &amp;hellip;, v_n \rbrace $。我们假设图 $G$ 是带权的，边有非负权重 $w_{ij} \geq 0$。带权的邻接矩阵是 $W = (w_{ij})_{i,j=1,&amp;hellip;,n}$。如果 $w_{ij} = 0$，表示顶点 $v_i$ 和 $v_j$之间没有边。因为 $G$ 是无向的，所以 $w_{ij} = w_{ji}$。顶点 $v_i \in V$ 的度定义为：&lt;/p&gt;
$$
d\_i = \sum^n\_{j = 1} w\_{ij}.
$$&lt;p&gt;事实上，这个加和只会在所有和 $v_i$ 邻接的顶点上做， 因为和其他的顶点之间的边权重为0。度矩阵 $D$ 定义为对角矩阵，对角线上是度 $d_1, &amp;hellip;, d_n$。给定顶点的子集 $A \subset V$，它的补集 $V \ \backslash \ A$ 表示为 $\bar{A}$。定义一个指示向量 $1_A = (f_1, \dots f_n)&amp;rsquo; \in \mathbb{R}^n$，如果 $v_i \in A$，$f_i = 1$，否则 $f_i = 0$。我们在做求和的时候，比如 $\sum_{i \in A} w_{ij}$， 把 $\lbrace i \mid v_i \in A \rbrace $ 简记为 $i \in A$。对于两个不相交的集合 $A, B \subset V$，定义：&lt;/p&gt;
$$
W(A, B) := \sum\_{i \in A, j \in B} w\_{ij}.
$$&lt;p&gt;我们考虑两个不同的方式来描述子集 $A \subset V$ 的“大小”：&lt;/p&gt;
$$
\vert A \vert := A 的顶点数\\
\text{vol}(A) := \sum\_{i \in A} d\_i.
$$&lt;p&gt;直观上来讲，$\vert A \vert$ 通过顶点数描述了 $A$ 的大小，但是 $\text{vol}(A)$ 通过对 $A$ 中所有的边进行加和得到。如果 $A$ 中的两个结点可以通过一条路径连接，而且中间的点都在 $A$ 中，那么称子集 $A \subset V$ 是连通的。如果子集是连通的，且顶点集 $A$ 和 $\bar{A}$ 之间没有结点相连，那么称 $A$ 是一个连通分量。如果 $A_i \cap A_j = \emptyset$ 且 $A_1 \cup \dots \cup A_k = V$，那么非空集合 $A_1, \dots, A_k$ 是图的一个划分。&lt;/p&gt;
&lt;h2 id="22-different-similarity-graphs"&gt;2.2 Different similarity graphs
&lt;/h2&gt;&lt;p&gt;有一些流行的方法对顶点间的相似度或距离构建图。构建相似度图的目标是对样本之间的局部邻居关系建模。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The $\varepsilon$-neighborhood graph:&lt;/strong&gt; 我们把距离小于 $\varepsilon$ 的样本连起来。因为连接起来的样本点基本是一个尺度的，考虑边的权重不会增加更多的信息。所以，$\varepsilon$-邻居图通常是无权图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;$k$-nearest neighbor graphs:&lt;/strong&gt; 如果 $v_j$ 是 $v_i$ 的 $k$-近邻邻居，那目标是连接 $v_i$ 和 $v_j$。但是，这个定义会得到一个有向图，因为邻居间的关系是非对称的。有两种方法变成有向。第一种是忽略边的方向，也就是用无向边连接。结果通常称为 $k$-近邻邻居图。第二种方法是如果两个顶点互为对方的 $k$-近邻邻居，那么相连。得到的图称为 &lt;em&gt;mutual $k$-nearest neighbor graph&lt;/em&gt;。这两种图的边都是顶点的相似度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The fully connected graph:&lt;/strong&gt; 我们简单的连接有着正的相似度的顶点，边的权重就是相似度 $s_{ij}$。因为图应该表示局部邻居关系，这个构建方法只在相似度能体现局部邻居关系时才有效。举个相似度函数的例子，高斯相似度函数 $s(x_i, x_j) = \exp(- \Vert x_i - x_j \Vert ^ 2 / (2 \sigma^2))$，参数 $\sigma$ 控制了邻居的宽度。这个参数和 $\varepsilon$-邻居图中的 $\varepsilon$ 的角色差不多。&lt;/p&gt;
&lt;p&gt;上面提到的图是谱聚类中常用的。据我们所知，相似度图如何影响谱聚类的结果还不为所知。不同的图的表现形式我们会在第八节讨论。&lt;/p&gt;
&lt;h1 id="3-graph-laplacians-and-their-basic-properties"&gt;3 Graph Laplacians and their basic properties
&lt;/h1&gt;&lt;p&gt;谱聚类的主要工具是图拉普拉斯矩阵。有一个领域致力研究这些矩阵，称为谱图理论(e.g., see Chung, 1997)。我们这节定义不同的拉普拉斯矩阵，指出他们的重要性质。我们会仔细的对比不同的拉普拉斯矩阵。注意，事实上没有一个统一的说法说哪个矩阵就是 &amp;ldquo;graph Laplacian&amp;rdquo;。通常，每个作者都称他们使用的矩阵是拉普拉斯矩阵。因此，在读关于拉普拉斯矩阵的论文的时候需要注意。&lt;/p&gt;
&lt;p&gt;假设 $G$ 是无向带权图，权重矩阵 $W$，$w_{ij} = w_{ji} \geq 0$。使用一个矩阵的特征向量时，我们没有必要假设他们是归一化的。举个例子，常向量 $1$ 和他的倍数 $a1$ 在 $a = \not 0$ 的时候被认为是相同的特征向量。特征值总时升序排列，而且会有多重性。前 $k$ 个特征值，我们指的是前 $k$ 个最小的特征值。&lt;/p&gt;
&lt;h2 id="31-the-unnormalized-graph-laplacian"&gt;3.1 The unnormalized graph Laplacian
&lt;/h2&gt;&lt;p&gt;非归一化的图拉普拉斯矩阵定义为：&lt;/p&gt;
$$
L = D - W.
$$&lt;p&gt;关于它的性质的论文在 Mohar(1991, 1997)。下面性质是谱聚类需要的性质：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 1 (Properties of $L$)&lt;/strong&gt; 拉普拉斯矩阵满足以下性质：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于每个向量 $f \in \mathbb{R}^n$，我们有：&lt;/li&gt;
&lt;/ol&gt;
$$
f'Lf = \frac{1}{2} \sum^n\_{i,j=1} w\_{ij}(f\_i - f\_j)^2.
$$&lt;ol start="2"&gt;
&lt;li&gt;$L$ 是对称且半正定的。&lt;/li&gt;
&lt;li&gt;$L$ 最小的特征值是 $0$，对应的特征向量是常向量 $1$。&lt;/li&gt;
&lt;li&gt;$L$ 有 $n$ 个非负实数特征值 $0 = \lambda_1 \leq \lambda_2 \leq \dots \lambda_n$。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;
Part (1)：由 $d_i$ 的定义得：&lt;/p&gt;
$$
\begin{aligned}
f'Lf &amp;= f'Df - f'Wf = \sum^n\_{i=1}d\_i f^2\_i - \sum^n\_{i,j=1} f\_i f\_j w\_{ij}\\
&amp;=\frac{1}{2} \Bigg( \sum^n\_{i=1} d\_i f^2\_i - 2 \sum^n\_{i,j=1} f\_i f\_j w\_{ij} + \sum^n\_{j=1} d\_j f^2\_j \Bigg) = \frac{1}{2} \sum^n\_{i,j=1} w\_{ij} (f\_i - f\_j)^2.
\end{aligned}
$$&lt;p&gt;Part (2)：$L$ 的对称性是因为 $W$ 和 $D$ 是对称的。半正定是 Part (1) 的结果，对于任意的 $f \in \mathbb{R}^n$，$f&amp;rsquo;Lf \geq 0$。&lt;/p&gt;
&lt;p&gt;Part (3)：显而易见。&lt;/p&gt;
&lt;p&gt;Part (4)：由(1) 和 (3) 推出。&lt;/p&gt;
&lt;p&gt;注意：非归一化的拉普拉斯矩阵不依赖于邻接矩阵 $W$ 的对角线上的元素。邻接矩阵非对角线上的元素得到非归一化的拉普拉斯矩阵。图中的自连接不会改变对应的拉普拉斯矩阵。
（这里说白了就是，拉普拉斯矩阵非对角线位置上的元素是邻接矩阵对应位置的元素的相反数，如果顶点加自连接，那么度矩阵就会对应地增加，D-W在对角线上还是一样的数，不会变）&lt;/p&gt;
&lt;p&gt;非归一化的拉普拉斯矩阵的特征值和特征向量可以用于描述图的很多性质，参见 Mohar(1991, 1997)。对于谱聚类来说一个重要的性质是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 2 (Number of connected components and the spectrum of $L$)&lt;/strong&gt; 图 $G$ 是无向非负权重的图。拉普拉斯矩阵的特征值 $0$ 的多重性 $k$ 等于图中的连通分量 $A_1, \dots, A_k$ 的数量。特征值 $0$ 的特征空间通过指示向量 $1_{A_1}, \dots, 1_{A_k}$ 生成。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; 我们先以 $k = 1$ 为例，也就是说只有一个连通图。假设 $f$ 是特征值 $0$ 对应的特征向量。我们知道：&lt;/p&gt;
$$
0 = f'Lf = \sum^n\_{i,j=1} w\_{ij} (f\_i - f\_j)^2.
$$&lt;p&gt;因为权重 $w_{ij}$ 是非负的，如果所有的项 $w_{ij} (f_i - f_j)^2$ 都消失了，这个和就会很小。因此，如果两个顶点相连（权重大于0），那么 $f_i$ 需要等于 $f_j$。我们可以发现，对于所有顶点 $f$ 需要是一个相同的常数，且这些点可以通过一条路径相连。此外，因为无向图内连通分量所有的顶点可以通过一条路径相连，$f$ 对于整个连通分量来说需要是一个常数。在只有一个连通分量的图中，我们因此只有一个常向量 $1$ 作为特征向量，对应的特征值为 $0$，显然这个向量就是这个连通分量的指示向量。&lt;/p&gt;
&lt;p&gt;现在考虑 $k$ 个连通分量。为了不失一般性，我们假设顶点是根据连通分量排序的。这样，邻接矩阵 $W$ 有一个块对角形式，对于矩阵 $L$ 也是如此：&lt;/p&gt;
$$
L = \begin{pmatrix}
L\_1 &amp; &amp; &amp; \\
&amp; L\_2 &amp; &amp; \\
&amp; &amp; \ddots &amp; \\
&amp; &amp; &amp; L\_k
\end{pmatrix}
$$&lt;p&gt;注意：块 $L_i$ 是一个关于它自己的拉普拉斯矩阵，也就是对应第 $i$ 个子图的拉普拉斯矩阵。在这个对角都是块矩阵的例子中，我们知道 $L$ 的谱是所有的 $L_i$ 的谱的并集，对应的 $L$ 的特征向量是 $L_i$ 的特征向量，其他方块的位置都是0.因为每个 $L_i$ 是一个连通图的拉普拉斯矩阵，我们知道每个 $L_i$ 在第 $i$ 个连通分量上，有特征值 $0$，且多重性为 $1$，对应的特征向量常向量。因此，矩阵 $L$ 的特征值 $0$ 的个数就等于连通分量数，而且对应的特征向量是连通分量的指示向量。&lt;/p&gt;
&lt;h2 id="32-the-normalized-graph-laplacians"&gt;3.2 The normalized graph Laplacians
&lt;/h2&gt;&lt;p&gt;在文献中有两个归一化的拉普拉斯矩阵。两个矩阵紧密相连，定义如下：&lt;/p&gt;
$$
\begin{aligned}
&amp; L\_{sym} := D^{-1/2} L D^{-1/2} = I - D^{-1/2} W D^{-1/2}\\
&amp; L\_{rw} := D^{-1} L = I - D^{-1} W.
\end{aligned}
$$&lt;p&gt;我们将第一个矩阵表示为 $L_{sym}$，因为它是一个对称阵，第二个矩阵表示为 $L_{rw}$，因为它和随机游走有关。接下来我们总结一下这两个矩阵的性质。关于归一化的拉普拉斯矩阵的引用在 Chung (1997)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 3 (Properties of $L_{sym}$ and $L_{rw}$)&lt;/strong&gt; 归一化的拉普拉斯矩阵满足以下性质：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于每个 $f \in \mathbb{R}^n$，我们有：&lt;/li&gt;
&lt;/ol&gt;
$$
f' L\_{sym} f = \frac{1}{2} \sum^n\_{i,j=1} w\_{ij} \Bigg( \frac{f\_i}{\sqrt{d\_i}} - \frac{f\_j}{\sqrt{d\_j}} \Bigg)^2.
$$&lt;ol start="2"&gt;
&lt;li&gt;$\lambda$ 是 $L_{rw}$ 的一个特征值，对应的特征向量 $u$，当且仅当 $\lambda$ 是 $L_{sym}$ 的一个特征值且对应的特征向量 $w = D^{1/2}u$。&lt;/li&gt;
&lt;li&gt;$\lambda$ 是 $L_{rw}$ 的一个特征值，对应的特征向量 $u$，当且仅当 $\lambda$ 和 $u$ 是 generalized eigenproblem $Lu = \lambda Du$ 的解。&lt;/li&gt;
&lt;li&gt;$0$ 是 $L_{rw}$ 的特征值，常向量 $1$ 是特征向量。$0$ 是 $L_{sym}$ 的特征值且特征向量是 $D^{1/2}1$。&lt;/li&gt;
&lt;li&gt;$L_{sym}$ 和 $L_{rw}$ 是半正定的，有 $n$ 个非负的实数特征值 $0 = \lambda_1 \leq \dots \leq \lambda_n$。&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning</title><link>https://davidham3.github.io/blog/p/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/</link><pubDate>Wed, 31 Oct 2018 21:58:41 +0000</pubDate><guid>https://davidham3.github.io/blog/p/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/</guid><description>&lt;p&gt;AAAI 2018。这篇论文很有趣，讲的是 GCN 堆得过多了之后，效果会变差的问题。作者分析了一下为什么会变差，主要是因为 GCN 的本质实际上是对每个结点的邻居特征和自身特征做线性组合，权重和邻接矩阵相关，所以对于顶点分类问题来说，如果堆得层数多了，就会让一个结点的特征聚合越来越多邻居的特征，让大家都变得相似，从而使得类间的相似度增大，自然分类效果就差了。作者提出了两个方法解决这个问题，算训练上的 trick 吧。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1801.07606" target="_blank" rel="noopener"
&gt;Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;机器学习中很多有趣的问题正在用深度学习工具来重新审视。对于基于图的半监督学习问题，最新的一个重要进展就是图卷积神经网络 (GCNs)，这个模型可以很好的将顶点局部特征和图的拓扑结构整合进卷积层内。尽管 GCN 模型和其他的 state-of-the-art 方法相比效果更好，但是它的机理目前还不是很清楚，而且需要很多的标记数据用于验证以及模型选择。&lt;/p&gt;
&lt;p&gt;在这篇论文中，我们深入了 GCN 模型，解决了它的底层限制。首先，我们发现 GCN 模型的图卷积实际上是一个拉普拉斯平滑的特殊形式，这是 GCN 工作的关键原因，但是这也会给很多卷积层带来潜在的危害。其次，为了克服 GCN 层数少的限制，我们提出了协同训练和自训练方法来训练 GCNs。我们的方法显著地提升了 GCNs 在标记样本少的情况下的学习，并且让他们避免了使用额外的标记用来验证。大量的实验证明了我们的理论和方案。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 Introduction
&lt;/h1&gt;&lt;p&gt;深度学习中的突破使得人工智能和机器学习中正在发生范式变化。一方面，很多老问题通过深度神经网络重新审视，很多原来看起来在任务中无法完成的巨大进步现在也在发生着，如机器翻译和计算机视觉。另一方面，像几何深度学习 (Bronstein et al. 2017) 这样的技术正在发展，可能会将深度神经模型泛化到新的或非传统的领域。&lt;/p&gt;
&lt;p&gt;众所周知，深度学习模型一般需要大量的标记数据，在很多标记训练数据代价很大的场景就无法满足这样的要求。为了减少用于训练的数据的数量，最近的研究开始关注 few-shot learning (Lake, Salakhutdinov, and Tenenbaum 2015; Rezende et al. 2016)——从每个类只有很少的样本中学习一个分类模型。和 few-shot learning 相近的是半监督学习，其中有大量的未标记样本可以用来和很少量的标记样本一起用于训练。&lt;/p&gt;
&lt;p&gt;很多研究者已经证实了如果使用恰当，在训练中利用未标记样本可以显著地提升学习的精度 (Zhu and Goldberg 2009)。关键问题是最大化未标记样本的结构和特征信息的有效利用。由于强力的特征抽取能力和深度学习近些年的成功案例，已经有很多人使用基于神经网络的方法处理半监督学习，包括 ladder network (Rasmus et al. 2015), 半监督嵌入 (Weston et al. 2008)，planetoid (Yang, Cohen, and Salakhutdinov 2016)，图卷积网络 (Kipf and Welling 2017)。&lt;/p&gt;
&lt;p&gt;最近发展的图卷积神经网络 (GCNNs) (Defferrard, Bresson, and Vandergheynst 2016) 是一个将欧氏空间中使用的卷积神经网络 (CNNs) 泛化到对图结构数据建模的成功尝试。在他们的初期工作 (Kipf and Welling 2017)，Kifp and Welling 提出了一个 GCNNs 的简化类型，称为图卷积网络 (GCNs)，应用于半监督分类。GCN 模型很自然地将图结构数据的连接模式和特征属性集成起来，而且比很多 state-of-the-art 方法在 benchmarks 上好很多。尽管如此，它也有很多其他基于神经网络的模型遇到的问题。用于半监督学习的 GCN 模型的工作机理还不清楚，而且训练 GCNs 仍然需要大量的标记样本用于调参和模型选择，这就和半监督学习的理念相违背。&lt;/p&gt;
&lt;p&gt;在这篇论文中，我们弄清楚了用于半监督学习的 GCN 模型。特别地，我们发现 GCN 模型中的图卷积是拉普拉斯平滑的一种特殊形式，这个平滑可以混合一个顶点和它周围顶点的特征。这个平滑操作使得同一类簇内顶点的特征相似，因此使分类任务变得简单，这使为什么 GCNs 表现的这么好的关键原因。然而，这也会带来 over-smoothing 的问题。如果 GCN 有很多卷积层后变深了，那么输出的特征可能会变得过度平滑，且来自不同类簇的顶点可能变得无法区分。这种混合在小的数据集，且只有很少的卷积层上发生的很快，就像图2展示的那样。而且，给 GCN 模型增加更多的层也会使它变得难以训练。&lt;/p&gt;
&lt;p&gt;然而，一个浅层的 GCN 模型，像 Kipf &amp;amp; Welling 2017 使用的两层 GCN 有它自身的限制。除此以外它还需要很多额外的标记用来验证，它也会遇到卷积核局部性等问题。当只有少数标记的时候，一个浅层的 GCN 模型不能有效的将标记传播到整个图上。如图1所示，GCNs 的表现会随着训练集的减少急速下降，甚至有500个额外标记用来验证。&lt;/p&gt;
&lt;p&gt;为了克服限制并理解 GCN 模型的全部潜能，我们提出了一种协同训练方法和一个自训练方法来训练 GCNs。通过使用随机游走模型来协同训练一个 GCN，随机游走模型可以补充 GCN 模型在获取整个图拓扑结构上的能力。通过自训练一个 GCN，我们可以挖掘它的特征提取能力来克服它的局部特性。融合协同训练和自训练方法可以从本质上提升 GCN 模型在半监督学习上只有少量标记的效果，而且使它不用使用额外的标记样本用来验证。如图1所示，我们的方法比 GCNs 好了一大截。&lt;/p&gt;
&lt;p&gt;总而言之，这篇论文的关键创新有：1) 对半监督学习的 GCN 模型提供了新的视角和新的分析；2) 提出了对半监督学习的 GCN 模型提升的解决方案。&lt;/p&gt;
&lt;h1 id="2-preliminaries-and-related-works"&gt;2 Preliminaries and Related Works
&lt;/h1&gt;&lt;p&gt;首先，我们定义一些符号。图表示为 $\mathcal{G} = (\mathcal{V}, \mathcal{E})$，其中 $\mathcal{V}$ 是顶点集，$\vert \mathcal{V} \vert = n$，$\mathcal{E}$ 是边集。在这篇论文中，我们考虑的是无向图。$A = [a_{ij}] \in \mathbb{R}^{n \times n}$ 是邻接矩阵，且为非负的。$D = \mathrm{diag}(d_1, d_2, &amp;hellip;, d_n)$ 表示度矩阵，$d_i = \sum_j a_{ij}$ 是顶点 $i$ 的度。图拉普拉斯矩阵 (Chung 1997) 定义为 $L := D - A$，归一化的图拉普拉斯矩阵的两个版本分别定义为：$L_{sym} := D^{-\frac{1}{2}} L D^{-\frac{1}{2}}$ 和 $L_{rw} := D^{-1}L$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph-Based Semi-Supervised Learning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这篇论文中我们考虑的问题是图上的半监督分类任务。给定一个图 $\mathcal{G} = (\mathcal{V}, \mathcal{E}, X)$，其中 $X = \mathrm{[x_1, x_2, &amp;hellip;, x_n]^T} \in R^{n \times c}$ 是特征矩阵，$\mathrm{x}_i \in R^c$ 是顶点 $i$ 的 $c$ 维特征向量。假设给定了一组顶点 $\mathcal{V}_l$ 的标记，目标是预测其余顶点 $\mathcal{V}_u$ 的标记。&lt;/p&gt;
&lt;p&gt;基于图的半监督学习在过去的二十年成为了一个流行的研究领域。通过挖掘图或数据的流形结构，是可以通过少量标记进行学习的。很多基于图的半监督学习方法形成了类簇假设 (cluster assumption) (Chapelle and Zien 2005)，假设了一个图上临近的顶点倾向于有共同的标记。顺着这条路线的研究包括 min-cuts (Blum and Chawla 2001) 和 randomized min-cuts (Blum et al. 2004)，spectral graph transducer (Joachims 2003)，label propagation (Zhu, Ghahramani, and Lafferty 2003) and its variants (Zhou et al. 2004; Bengio, Delalleau, and Le Roux 2006)，modified adsorption (Talukdar and Crammer 2009)，还有 iterative classification algorithm (Sen et al. 2008)。&lt;/p&gt;
&lt;p&gt;但是图只表示数据的结构信息。在很多应用，数据的样本是以包含信息的特征向量表示，而不是在图中表现。比如，在引文网络中，文档之间的引用链接描述了引用关系，但是文档是由 bag-of-words 向量表示的，这些向量描述的内容是文档的内容。很多半监督学习方法寻求对图结构和数据的特征属性共同建模。一个常见的想法是使用一些正则项对一个监督的学习器进行正则化。比如，manifold regularization (LapSVM) (Belkin, Niyogi, and Sindhwani 2006) 使用一个拉普拉斯正则项对 SVM 进行正则化。深度半监督嵌入 (Weston et al. 2008) 使用一个基于嵌入的正则项对深度神经网络进行正则化。Planetoid (Yang, Cohen, and Salakhutdinov 2016) 也通过共同地对类标记和样本的上下文预测对神经网络进行正则化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph Convolutional Networks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;图卷积神经网络 (GCNNs) 将传统的卷积神经网络泛化到图域中。主要有两类 GCNNs (Bronstein et al. 2017): spatial GCNNs 和 spectral GCNNs。空间 GCNNs 将卷积看作是 &amp;ldquo;patch operator&amp;rdquo;，对每个顶点使用它的邻居信息构建新的特征向量。谱 GCNNs 通过对图信号 $\bf{s} \in \mathcal{R}^n$ 在谱域上进行分解，然后使用一个在谱成分上的谱卷积核 $g_\theta$ (是 $L_{sym}$ 的特征值的一个函数) (Bruna et al. 2014; Sandryhaila and Moura 2013; Shuman et al. 2013)。然而这个模型需要计算出拉普拉斯矩阵的特征向量，这对于大尺度的图来说是不太实际的。一种缓解这个问题的方法是通过将谱卷积核 $g_\theta$ 通过切比雪夫多项式趋近到 $K^{th}$ 阶 (Hammond, Vandergheynst, and Gribonval 2011)。在 (Defferrard, Bresson, and Vandergheynst 2016)，Defferrard et al. 使用这个构建了 $K$ 阶 ChebNet，卷积定义为：&lt;/p&gt;
$$\tag{1}
g\_\theta \star \mathbf{s} \approx \sum^K\_{k=0} \theta'\_k T\_k (L\_{sym}) \mathbf{s},
$$&lt;p&gt;其中 $\bf{s} \in \mathcal{R}^n$ 是图上的信号，$g_\theta$是谱滤波器，$\star$ 是卷积操作，$T_k$ 是切比雪夫多项式，$\theta&amp;rsquo; \in \mathcal{R}^K$ 是切比雪夫系数向量。通过这种趋近，ChebNet 域谱无关。&lt;/p&gt;
&lt;p&gt;在 (Kipf and Welling 2017) 中，Kipf and Welling 将上面的模型通过让 $K = 1$ 进行了简化，将 $L_{sym}$ 的最大特征值趋近为2.在这种形式中，卷积变成：&lt;/p&gt;
$$\tag{2}
g\_\theta \star \mathbf{s} = \theta(I + D^{-\frac{1}{2}} A D^{-\frac{1}{2}}) \mathbf{s},
$$&lt;p&gt;其中 $\theta$ 是切比雪夫系数。然后对卷积矩阵使用一种正则化的技巧：&lt;/p&gt;
$$\tag{3}
I + D^{-\frac{1}{2}} A D^{-\frac{1}{2}} \rightarrow \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}},
$$&lt;p&gt;其中 $\tilde{A} = A + I$，$\tilde{D} = \sum_j \tilde{A}_{ij}$.&lt;/p&gt;
&lt;p&gt;将卷积泛化到带有 $c$ 个通道的图信号上，也就是 $X \in \mathcal{R}^{n \times c}$ (每个顶点是一个 $c$ 维特征向量)，使用 $f$ 谱卷积核，简化后的模型的传播规则是：&lt;/p&gt;
$$\tag{4}
H^{(l + 1)} = \sigma(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(l)} \Theta^{(l)}),
$$&lt;p&gt;其中，$H^{(l)}$ 是第 $l$ 层的激活值矩阵，$H^{(0)} = X$，$\Theta^{(l)} \in \mathcal{R}^{c \times f}$ 是第 $l$ 层可训练的权重矩阵，$\sigma$ 是激活函数，比如 $ReLU(\cdot) = max(0, \cdot)$。&lt;/p&gt;
&lt;p&gt;这个简化的模型称为图卷积网络 (GCNs)，是我们这篇论文关注的重点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Semi-Supervised Classification with GCNs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 Kipf and Welling 2017 中，GCN 模型以一种优雅的方式做半监督分类任务。模型是一个两层 GCN，在输出时使用一个 softmax：&lt;/p&gt;
$$\tag{5}
Z = \mathrm{softmax}(\hat{A} ReLU (\hat{A} X \Theta^{(0)}) \Theta^{(1)} ),
$$&lt;p&gt;其中 $\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$，$\mathrm{softmax}(x_i) = \frac{1}{\mathcal{Z}} exp(x_i)$，$\mathcal{Z} = \sum_i exp(x_i)$。损失函数是所有标记样本上的交叉熵：&lt;/p&gt;
$$\tag{6}
\mathcal{L} := - \sum\_{i \in \mathcal{V}\_l} \sum^F\_{f=1} Y\_{if} \mathrm{ln} Z\_{if},
$$&lt;p&gt;其中 $\mathcal{V}_l$ 是标记顶点的下标，$F$ 是输出特征的维数，等价于类别数。$Y \in \mathcal{R}^{\vert \mathcal{V}_l \vert \times F}$ 是标记矩阵。权重参数 $\Theta^{(0)}$ 和 $\Theta^{(1)}$ 可以通过梯度下降训练。&lt;/p&gt;
&lt;p&gt;GCN 模型在卷积中自然地融合了图的结构和顶点的特征，未标记的顶点的特征和临近的标记顶点的混合在一起，然后通过多个层在网络上传播。GCNs 在 Kipf &amp;amp; Welling 2017 中比很多 state-of-the-art 方法都好很多，比如在引文网络上。&lt;/p&gt;
&lt;h1 id="3-analysis"&gt;3 Analysis
&lt;/h1&gt;&lt;p&gt;尽管它的性能很好，但是用于半监督学习的 GCN 模型的机理还没有弄明白。在这部分我们会走近 GCN 模型，分析它为什么好使，并指出它的限制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why GCNs Work&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们将 GCN 和最简单的全连接神经网络 (FCN) 进行比较，传播规则是：&lt;/p&gt;
$$\tag{7}
H^{(l + 1)} = \sigma(H^{(l)} \Theta^{(l)}).
$$&lt;p&gt;GCN 和 FCN 之间的唯一一个区别是图卷积矩阵 $\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$ (式5)用在特征矩阵 $X$ 的左边。我们在 Cora 数据集上，每类 20 个 标签，做了半监督分类的测试。如表1所示。即便是只有一层的 GCN 也比一层的 FCN 好很多。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Laplacian Smoothing.&lt;/strong&gt; 考虑一个一层的 GCN。实际有两步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从矩阵 $X$ 通过一个图卷积得到新的特征矩阵 $Y$：&lt;/li&gt;
&lt;/ol&gt;
$$\tag{8}
Y = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}X.
$$&lt;ol start="2"&gt;
&lt;li&gt;将新的特征矩阵 $Y$ 放到一个全连接层。很明显，图卷积是性能提升的关键。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们来自己的检查一下图卷积。假设我们给图中的每个结点增加一个自连接，新的图的邻接矩阵就是 $\tilde{A} = A + I$。输入特征的每个通道的拉普拉斯平滑 (Taubin 1995) 定义为：&lt;/p&gt;
$$\tag{9}
\hat{\mathrm{y}}\_i = (1 - \gamma) \mathrm{x}\_i + \gamma \sum\_j \frac{\tilde{a}\_{ij}}{d\_i} \mathrm{x}\_j \quad (\text{for} \quad 1 \leq i \leq n),
$$&lt;p&gt;其中 $0 &amp;lt; \gamma &amp;lt; 1$ 是控制当前结点的特征和它的邻居的特征之间的权重。我们可以将拉普拉斯平滑写成矩阵形式：&lt;/p&gt;
$$\tag{10}
\hat{Y} = X - \gamma \tilde{D}^{-1} \tilde{L} X = (I - \gamma \tilde{D}^{-1} \tilde{L})X,
$$&lt;p&gt;其中 $\tilde{L} = \tilde{D} - \tilde{A}$。通过设定 $\gamma = 1$，也就是只使用邻居的特征，可得 $\hat{Y} = \tilde{D}^{-1} \tilde{A} X$，也就是拉普拉斯平滑的标准形式。&lt;/p&gt;
&lt;p&gt;现在如果我们把归一化的拉普拉斯矩阵 $\tilde{D}^{-1} \tilde{L}$ 替换成对阵的归一化拉普拉斯矩阵 $\tilde{D}^{-\frac{1}{2}} \tilde{L} \tilde{D}^{-\frac{1}{2}}$，让 $\gamma = 1$，可得 $\hat{Y} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X$，这恰好就是式8中的图卷积。我们因此称图卷积是一种特殊形式的拉普拉斯平滑——对称拉普拉斯平滑。注意，平滑仍然会包含顶点特征，因为每个顶点有一个自连接，还有它自己的邻居。&lt;/p&gt;
&lt;p&gt;拉普拉斯平滑计算了顶点的新的特征，也就是顶点自身和邻居的加权平均。因为同一类簇的顶点倾向于连接的更紧密，这使得分类任务变得更简单。因为我们可以从表1看出只使用一次平滑就很有效了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi-layer Structure.&lt;/strong&gt; 我们可以从表1看出尽管两层的 FCN 比 一层的 FCN 有了些许的提升，两层的 GCN 却比 一层的 GCN 好了很多。这是因为在第一层的激活值上再使用平滑使得同一个类簇中的顶点特征变得更像四了，使分类任务更简单。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When GCNs Fail&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们已经证明了图卷积本质上就是一种拉普拉斯平滑。那 GCN 中应该放多少层呢？当然不是越多越好。GCN 层多了会不好训练。而且重复使用拉普拉斯平滑可能会混合不同类簇中的顶点的特征，使得他们区分不清。我们来举个例子。&lt;/p&gt;
&lt;p&gt;我们在 Zachary 的 karate club dataset (Zachary 1977) 上跑几个层数不同的模型。这个数据集有 34 个结点，两类，78 条边。GCN 的参数像 (Glorot and Bengio 2010) 中的一样随机初始化。隐藏层的维数是 16，输出层的维度是2。每个结点的特征向量是一个 one-hot 向量。每个 GCN 的输出绘制在图2中。我们可以看到图卷积的影响（图2a）。使用两次平滑，分类效果相对较好。再次使用平滑，点就会混合（图2c，2d，2e）。因为这是个小的数据集，两类之间的顶点有很多连接，所以很快就发生了混合。&lt;/p&gt;
&lt;p&gt;接下来，我们会证明重复使用拉普拉斯平滑，顶点的特征以及图的每个连通分量会收敛到相同的值。对于对称的拉普拉斯平滑，他们收敛到的值与顶点度数的二分之一次幂成正比。&lt;/p&gt;
&lt;p&gt;假设图 $\mathcal{G}$ 有 $k$ 个连通分量 $\lbrace C_i\rbrace ^k_{i=1}$，对于第 $i$ 个连通分量的指示向量表示为 $\mathbf{1}^{(i)} \in \mathbb{R}^n$。这个向量表示顶点是否在分量 $C_i$中，即：&lt;/p&gt;
$$\tag{11}
\mathbf{1}^{(i)}\_j = \begin{cases}
1, v\_j \in C\_i,\\
0, v\_j \notin C\_i
\end{cases}
$$&lt;p&gt;**Theorem 1. ** 如果一个图没有二分的连通分量，那么对于任意 $\mathrm{w} \in \mathbb{R}^n$，$\alpha \in (0, 1]$，&lt;/p&gt;
$$
\lim\_{m \rightarrow + \infty} (I - \alpha L\_{rw})^m \mathrm{w} = [\mathbf{1}^{(1)}, \mathbf{1}^{(2)}, ..., \mathbf{1}^{(k)}]\theta\_1,
$$$$
\lim\_{m \rightarrow + \infty} (I - \alpha L\_{sym})^m \mathrm{w} = D^{-\frac{1}{2}}[\mathbf{1}^{(1)}, \mathbf{1}^{(2)}, ..., \mathbf{1}^{(k)}]\theta\_2,
$$&lt;p&gt;其中 $\theta_1 \in \mathbb{R}^k, \theta_2 \in \mathbb{R}^k$，也就是他们分别收敛到 $\lbrace \mathbf{1}^{(i)}\rbrace ^k_{i=1}$ 和 $\lbrace D^{-\frac{1}{2}} \mathbf{1}^{(i)} \rbrace ^k_{i=1}$。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; $L_{rw}$ 和 $L_{sym}$ 有相同的 $n$ 个特征值，不同的特征向量 (Von Luxbury 2007)。如果一个图没有二分的连通分量，那么特征值就会在 $[0, 2)$ 区间内 (Chung 1997)。后面就没看懂了。。。&lt;/p&gt;
&lt;h1 id="4-solutions"&gt;4. Solutions
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Co-Train a GCN with a Random Walk Model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用一个 partially absorbing random walks (Wu et al. 2012) 来捕获网络的全局结构。方法就是计算归一化的吸收概率矩阵 $P = (L + \alpha \Lambda)^{-1}$，$P_{i, j}$ 是从顶点 $i$ 出发被吸收到顶点 $j$ 的概率，表示 $i$ 和 $j$ 有多大的可能性属于同一类。然后我们对每类 $k$，计算可信向量 $\mathbf{p} = \sum_{j \in S_k} P_{:, j}$，其中 $\mathbf{p} \in \mathbb{R}^n$，$p_i$ 是顶点 $i$ 属于类 $k$ 的概率。最后，找到 $t$ 个最可信的顶点把他们加到训练集的类 $k$ 中。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/Alg1.JPG"
loading="lazy"
alt="Alg1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GCN Self-Training&lt;/strong&gt;
另一种方法就是先训练一个 GCN，然后使用这个 GCN 去预测，根据预测结果的 $\text{softmax}$ 分数选择可信的样本，加入到训练集中。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/deeper-insights-into-graph-convolutional-networks-for-semi-supervised-learning/Alg2.JPG"
loading="lazy"
alt="Alg2"
&gt;&lt;/p&gt;</description></item><item><title>Large-Scale Learnable Graph Convolutional Networks</title><link>https://davidham3.github.io/blog/p/large-scale-learnable-graph-convolutional-networks/</link><pubDate>Mon, 17 Sep 2018 15:22:43 +0000</pubDate><guid>https://davidham3.github.io/blog/p/large-scale-learnable-graph-convolutional-networks/</guid><description>&lt;p&gt;KDD 2018.将图结构数据变换到网格状数据中，使用传统的一维卷积进行卷积。变换的方式是：针对每个特征的大小，对邻居结点进行排序，取这个特征前k大的数作为它邻居这列特征的k个值。如果邻居不够，那就用0来补。这样就能得到该顶点的邻居信息，组成一个矩阵，然后使用一维卷积。但是作者没说为什么非要取最大的k个数。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1808.03965?context=stat.ML" target="_blank" rel="noopener"
&gt;Large-Scale Learnable Graph Convolutional Networks&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;卷积神经网络在网格数据上取得了很大的成功，但是在学习像图这样的数据的时候就面临着很多的挑战。CNN中，可学习的局部滤波器可以自动地捕获高层次的特征。滤波器的计算需要感受野内有固定数量的单元。然而，在图结构中，邻居单元的数量不固定，而且邻居也不有序，所以阻碍了卷积的操作。我们提出了可学习图卷积层(learnable graph convolutional layer LGCL)来解决这些挑战。基于值的排序，LGCL为每个特征自动地选择固定数量的邻居结点，以此将图结构数据变换到1维的网格结构中，然后就可以在图上使用常规的卷积操作了。为了能让模型在大尺度的图上训练，我们提出了一个子图训练方法来减少过多的内存和计算资源的开销。在顶点分类任务上，不论是transductive 还是 inductive，表现得都更好一些。我们的结果展示出了我们的子图训练方法比前人的方法更高效。&lt;/p&gt;
&lt;h1 id="3-methods"&gt;3. methods
&lt;/h1&gt;&lt;h2 id="31-challenges-of-applying-convolutional-operations-on-graph-data"&gt;3.1 Challenges of Applying Convolutional Operations on Graph Data
&lt;/h2&gt;&lt;p&gt;为了让传统的卷积操作可以应用在图上，需要解决两个图结构数据和网格数据的差异。首先，顶点的邻居数量通常会变化。其次，我们不能对邻居顶点进行排序，因为他们没有可供排序的信息。举个例子，社交网络中，每个人都可以看作是一个顶点，边表示人与人之间的关系。显然，每个顶点的邻居顶点数量是不同的，因为人们可以有不同数量的朋友。而且，如果没有额外的信息，很难对他们进行排序。&lt;/p&gt;
&lt;p&gt;网格数据可以看作是一种特殊的图结构数据，每个顶点有固定数量的邻居。因为卷积操作是直接应用在图像这样的网格数据上。为了看清楚固定邻居数量以及排序信息的重要性，我们举个例子，有一个$3 \times 3$的卷积核，扫描一张图像。我们将这张图片考虑成一个特殊的图，每个像素是一个顶点。在扫描的过程中，计算包括了中心结点和周围8个邻居结点的计算。这8个顶点在这个特殊的图中通过边连接到中心结点。与此同时，我们使用他们和中心结点的相对位置对他们排序，这对于卷积操作很重要，因为在扫描的过程中，滤波器的权重和图中的顶点要一一对应。举个例子，在上面的例子中，$3 \times 3$的卷积核，左上角的权重应该总是对应中心节点左上方的邻居结点。没有这样的排序信息，卷积的输出结果就不再是确定的。从刚才的讨论中可以看到传统卷积在图结构数据上应用的挑战。为了解决这两个挑战，我们提出了一个方法将图结构数据变换到网格数据内。&lt;/p&gt;
&lt;h2 id="32-learnable-graph-convolutional-layers"&gt;3.2 learnable Graph Convolutional Layers
&lt;/h2&gt;&lt;p&gt;为了让传统卷积可以在图上可用，我们提出了LGCL。LGCL的layer-wise传播规则写为：&lt;/p&gt;
$$\tag{3}
\tilde{X}\_l = g(X\_l, A, k),\\
X\_{l+1} = c(\tilde{X}\_l)
$$&lt;p&gt;其中，$A$是邻接矩阵，$g(\cdot)$使用了$k$-largest Node Selection，将图结构数据映射到网格结构，$c(\cdot)$表示1维常规的CNN，将顶点信息聚合，为每个顶点输出了一个新的特征向量。我们会在下面分开讨论$g(\cdot)$和$c(\cdot)$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;$k$-largest Node Selection&lt;/strong&gt;. 我们提出了一个新的方法称为$k$-largest Node Selection，将图结构映射到网格数据上，其中$k$是LGCL的超参数。在这个操作之后，每个顶点的邻居信息聚合，表示成一个有$(k+1)$个位置的1维的网格状。变换后的数据会输入到CNN中来生成新的特征向量。&lt;/p&gt;
&lt;p&gt;假设有行向量$x^1_l, x^2_l, &amp;hellip;, x^N_l$的$X_l \in \mathbb{R}^{N \times C}$，表示$N$个顶点的图，每个顶点有$C$个特征。邻接矩阵$A \in \mathbb{N}^{N \times N}$，$k$为定值。顶点$i$的特征向量是$x^i_l$，它有$n$个邻居。通过在$A$中的一个简单查找，我们可以获得这些邻居结点的下标，$i_1, i_2, &amp;hellip;, i_n$。对它们对应的特征向量$x^{i_1}_l, x^{i_2}_l, &amp;hellip;, x^{i_n}_l$进行拼接，得到$M^i_l \in \mathbb{R}^{n \times C}$。假设$n \geq k$，就没有泛化上的损失。如果$n &amp;lt; k$，我们可以使用全为0的列，给$M^i_l$加padding。$k$-largest node selection是在$M^i_l$上做的：也就是，对于每列，我们排出$n$个值，然后选最大的$k$个数。我们就可以得到一个$k \times C$的输出矩阵。因为$M^i_l$表示特征，这个操作等价于为每个特征选择$k$个最大值。通过在第一行插入$x^i_l$，输出变为$\tilde{M}^i_l \in \mathbb{R}^{(k+1) \times C}$。如图2左部分。通过对每个顶点重复这个操作，$g(\cdot)$将$X_l$变为$\tilde{X}_l \in \mathbb{R}^{N \times (k + 1) \times C}$。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/large-scale-learnable-graph-convolutional-networks/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;p&gt;注意，如果将$N$，$(k+1)$，$C$分别看作是batch size，spatial size，通道数，那么$\tilde{X}_l$可以看作是1维网格状的结构。因此，$k$个最大顶点选择函数$g(\cdot)$成功地将图结构变换为网格结构。这个操作充分利用了实数的自然顺序信息，使得每个顶点有固定数量的有序邻居。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1-D Convolutional Neural Networks&lt;/strong&gt;. 就像3.1节讨论的，传统的卷积操作可以直接应用到网格状的数据上。$\tilde{X}_l \in \mathbb{R}^{N \times (k + 1) \times C}$是1维的数据，我们部署一个一维CNN模型$c(\cdot)$。LGCL基本的功能是聚合邻居信息，为每个顶点更新特征。后续的话，它需要$X_{l + 1} \in \mathbb{R}^{N \times D}$，其中$D$是更新后的特征空间的维度。一维CNN $c(\cdot)$ 使用$\tilde{X}_l \in \mathbb{R}^{N \times (k + 1) \times C}$作为输入，输出一个$N \times D$的矩阵，或是$N \times 1 \times D$的矩阵。$c(\cdot)$可以将空间维度从$(k+1)$减小到$1$。&lt;/p&gt;
&lt;p&gt;注意，$N$看作是batch size，与$c(\cdot)$的设计无关。结果就是，我们只聚焦于一个样本，也就是图中的一个顶点。对于顶点$i$，变换得到的输出是$\tilde{M}^i_l \in \mathbb{R}^{(k + 1) \times C}$，是$c(\cdot)$的输入。由于任何一个卷积核大于1且没有padding的卷积都会减少空间的大小，最简单的$c(\cdot)$只有一个卷积核大小为$(k+1)$的卷积，没有padding。输入和输出的通道数分别为$C$和$D$。同时，可以部署任意一个多层CNN，得到最后的输出的维度是$1 \times D$。图2右侧展示了一个两层CNN的例子。再对所有的$N$个顶点使用一次$c(\cdot)$，输出$X_{l+1} \in \mathbb{R}^{N \times D}$。总结一下，我们的LGCL使用$k$最大顶点选择以及传统的一维CNN，将图结构变换到网格数据，实现了对每个顶点进行的特征聚合和特征过滤。&lt;/p&gt;
&lt;h2 id="33-可学习的图卷积网络"&gt;3.3 可学习的图卷积网络
&lt;/h2&gt;&lt;p&gt;越深的网络一般会产生越好的结果。然而，之前在图上的深度模型，如GCN，只有两层。尽管随着深度的增加，它们的性能有有所下降[Kipf &amp;amp; Welling 2017]，我们的LGCL可以构造的很深，构造出图顶点分类的可学习的图卷积网络。我们基于densely connected convolutional networks(DCNNs)，构造了LGCNs，前者获得了ImageNet分类任务最好的成绩。&lt;/p&gt;
&lt;p&gt;在LGCN中，我们先用一个图嵌入层来生成顶点的低维表示，因为原始输入一般都是高维特征，比如Cora数据集。第一层的图嵌入层本质上就是一个线性变换，表示为：&lt;/p&gt;
$$\tag{4}
X\_1 = X\_0 W\_0
$$&lt;p&gt;其中，$X_0 \in \mathbb{R}^{N \times C_0}$表示高维的输入，$W_0 \in \mathbb{R}^{C_0 \times C_1}$将特征空间从$C_0$映射到了$C_1$。结果就是，$X_1 \in \mathbb{R}^{N \times C_1}$和$C_1 &amp;lt; C_0$。或者，使用一个GCN层来做图嵌入。如第二部分描述的，GCN层中的参数数量等价于传统的图嵌入层中参数的数量。&lt;/p&gt;
&lt;p&gt;在图嵌入层后，我们堆叠多个LGCL，多少个取决于数据的复杂程度。因为每个LGCL只能聚合一阶邻居的信息，也就是直接相连的邻居顶点，堆叠LGCL可以从一个更大的顶点集中获得信息，这也是传统CNN的功能。为了提升模型的性能，帮助训练过程，我们使用skip connections来拼接LGCL的输入和输出。最后，在softmax激活前使用一个全连接层。&lt;/p&gt;
&lt;p&gt;就像LGCN的设计理念，$k$以及堆叠的LGCL的数量是最重要的超参数。顶点的平均度是选择$k$的一个重要参数。LGCL的数量应该依赖任务的复杂度，比如类别的个数，图的顶点数等。越复杂的模型需要越深的模型。&lt;/p&gt;
&lt;h2 id="34-sub-graph-training-on-large-scale-data"&gt;3.4 Sub-Graph Training on Large-Scale Data
&lt;/h2&gt;&lt;p&gt;大部分图上的深度学习模型都有另一个限制。在训练的时候，输入的是所有顶点的特征向量以及整个图的邻接矩阵。图的尺寸大的时候这个矩阵就会变大。这些方法在小尺度的图上表现的还可以。但是对于大尺度的图，这些方法一般都会导致内存和计算资源极大的开销，限制了这些模型的一些应用。&lt;/p&gt;
&lt;p&gt;其他类型的数据集也有相似的问题，比如网格数据。举个例子，图像分割上的深度模型通常使用随机切片的方式来处理大的图片。受到这种策略的启发，我们随机的将图“切分”，使用得到的小图进行训练。然而，尽管一张图片的一个矩形部分很自然地包含了像素的邻居信息。如何处理图中顶点的不规则连接还是一个问题。&lt;/p&gt;
&lt;p&gt;我们提出了子图选择算法来解决大尺度图上计算资源的问题，如算法1所示。给定一个图，我们先采样出一些初始顶点。从它们开始，我们使用广度优先搜索算法，迭代地将邻接顶点扩充到子图内。经过一定次数的迭代后，初始顶点的高阶邻居顶点就会被加进去。注意，我们在算法1中使用一个简单的参数$N_m$。实际上在每个迭代中，我们将$N_m$设置为了不同的值。图4给出了子图选择过程的一个例子。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/large-scale-learnable-graph-convolutional-networks/Alg1.JPG"
loading="lazy"
alt="Algorithm1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/large-scale-learnable-graph-convolutional-networks/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;p&gt;这样随机的切分子图，我们可以在大尺度的图上训练深层模型。此外，我们可以充分利用mini-batch训练方法来加速学习过程。在每轮训练中，我们可以使用子图训练方法采样多个子图，然后把它们放到batch中。对应的特征向量和邻接矩阵组成了网络的输入。&lt;/p&gt;
&lt;h1 id="4-experimental-studies"&gt;4. Experimental studies
&lt;/h1&gt;&lt;p&gt;代码：&lt;a class="link" href="https://github.com/divelab/lgcn/" target="_blank" rel="noopener"
&gt;https://github.com/divelab/lgcn/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="42-experimental-setup"&gt;4.2 Experimental Setup
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Transduction Learning.&lt;/strong&gt; 在transductive learning 任务中，我们像图3一样部署LGCN模型。因为transductive learning数据集使用高维的词袋表示作为顶点的特征向量，输入通过一个图嵌入层来降维。我们这里使用GCN层作为图嵌入层。&lt;/p&gt;</description></item><item><title>The Emerging Field of Signal Processing on Graphs</title><link>https://davidham3.github.io/blog/p/the-emerging-field-of-signal-processing-on-graphs/</link><pubDate>Fri, 03 Aug 2018 11:06:12 +0000</pubDate><guid>https://davidham3.github.io/blog/p/the-emerging-field-of-signal-processing-on-graphs/</guid><description>&lt;p&gt;IEEE Signal Processing Magazine 2013, 原文链接：&lt;a class="link" href="https://arxiv.org/abs/1211.0053" target="_blank" rel="noopener"
&gt;The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;社交、能源、运输、传感器、神经网络、高维数据很多都很自然地依赖于带权图的顶点。新兴的图信号处理领域融合了代数、谱图理论与计算谐波分析来处理图上的信号。在这篇教程中，我们列出了这个领域的主要挑战，讨论了定义图谱域的不同方法，点明了融合图数据域中不规则的结构在处理图信号时的重要性。然后回顾了将基础的操作，如filtering, translation, modulation, dilation, downsampling等技术泛化到图上的方法，对已经提出的高效地从图中的高维数据提取信息的localized, multisacle transforms进行了总结。最后对一些问题以及未来的扩展做了一些讨论。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1. Introduction
&lt;/h1&gt;&lt;p&gt;图是很多数据的表示形式，在描述很多应用的几何结构时很有用，如社交、能源、运输、传感器、神经网络等。图中每条边的权重，经常表示为两个顶点之间的相似度。连接性和边权重要么由问题的物理性质指明，要么从数据中推断出来。举个例子，边权重可能与网络中两个顶点之间的距离成反比。这些图的数据可以看作是一个样本的有限集合，每个顶点一个样本。我们称这些样本为一个图信号。一个图信号的例子如图1所示。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/the-emerging-field-of-signal-processing-on-graphs/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;在运输网络中，我们关心分析描述疾病传播的传染病数据，描述用户迁移的人口数据，或是描述货物仓库的后勤数据。现在，在大脑图像中，推断大脑皮层上独特的功能区结构上的连接性变为可能，这种连接可以表示为一个带权图，顶点代表了功能区。因此，noisy fMRI图像可以看作是带权图上的信号。带权图一般用来表示统计学习问题中数据点之间的相似性，如计算机视觉和文本分类问题。事实上，很多研究图数据分析的论文是从统计学习社区中发表出来的，因为基于图的方法在半监督学习问题中变得非常流行，这些问题的目标是用一些标记样本对未知的样本进行分类。在图像处理，对图像的像素构造非局部和半局部连接的图的这种，基于图的filtering methods突然流行了起来，这些方法不仅基于像素间的物理相似性，还有要处理的图像的nosiy versions。这些方法经常能更好地识别并考虑图像的边和材质。&lt;/p&gt;
&lt;p&gt;这些应用中常见的数据处理任务有filtering, denoising, inpainting, compressing graph signals。如何在不规则的域中处理他们，比如在任意结构的图上面？对数据的存储，通信，分析最有效的从高维数据中提取信息的方法是什么，统计与可视化？传统的信号处理的操作或算法可以使用吗？在图上的信号处理领域还有一些这样的问题。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A. The Main Challenges of Signal Processing on Graphs&lt;/em&gt;&lt;br&gt;
小波，时频，曲波和其他局部变化来稀疏地表示不同类别的高维数据，如欧氏空间中的音频和图像信号，这种表示能力在之前提到的信号处理任务中取得了很多的成功。&lt;/p&gt;
&lt;p&gt;$N$个顶点的图信号和一个传统的$N$个样本的离散时域信号可以看作是$\mathbb{R}^N$中的向量。然而，传统信号处理方法应用到图数据上的一个主要障碍是用离散时域信号的处理方式处理图信号时忽略了不规整的数据域内的关键依赖。此外，传统信号处理技术中的很多很简单的基础概念在图信号中变得很有挑战性：
·为了让一个模拟信号$f(t)$向右移动3，我们只要简单的改变变量，考虑$f(t-3)$即可。然而，把一个图信号向右移动3的意义就不是很清晰了。改变变量的方法不会有效因为$f(\circ - 3)$没有意义。一个朴素的方法是将顶点从$1$标到$N$，定义$f(\circ - 3) := f(\mathrm{mod}(\circ - 3, N))$，但是如果这个变换依赖于顶点的顺序的话，这个方法就不是很有用了。不可避免的是，带权图是不规则的结构，这种结构缺少一种变换的平移不变性的性质。
·通过乘以一个复杂的指数项在实数线上对信号建模对应了傅里叶域中的变换。然而，图问题中的模拟谱是离散且不规则的，因此没有好的方法定义一种对应图谱域中的变换。
·举个例子，我们凭直觉每隔一个数据点删除一个数据点，对离散时域信号做下采样。但是在图1中的图信号中这意味着什么？带权图中的“每隔一个顶点”没有明确的含义。
·甚至我们做一个固定的下采样，为了在图上做一个多分辨率，我们需要一个生成粗糙版本的图的方法，这个方法可以捕获原始图中嵌入的结构属性。&lt;/p&gt;
&lt;p&gt;此外，处理数据域的不规则性，图结构在之前提到的应用中，可以表示很多顶点的特征。为了能很好地对数据的尺度进行缩放，对于图信号的处理技术应该使用局部操作，通过对每个顶点，计算顶点的邻居，或是和它很近的顶点的信息得到。&lt;/p&gt;
&lt;p&gt;因此，图信号处理的主要挑战是：1. 有些任务中图没有直接给出，需要决定如何构建可以捕获数据几何结构的带权图；2. 将图结构整合到局部变换操作中；3. 同时利用这些年来信号处理在欧氏空间发展出的理论成果；4. 研究局部变换的高效实现，从高维的图结构数据或其他不规则数据域中提取信息。&lt;/p&gt;
&lt;p&gt;为了解决这些问题，新兴的图信号处理领域将代数和谱图理论的概念与计算谐波分析融合了起来。这是在代数图理论和谱图理论中的扩展；但是，早于十年前的研究主要是聚焦于分析图，而不是分析图的信号。&lt;/p&gt;
&lt;h1 id="2-the-graph-spectral-domains"&gt;2. The Graph Spectral Domains
&lt;/h1&gt;&lt;p&gt;谱图理论是聚焦于构建、分析、操作图的，不是图上的信号。在构建扩展图、图的可视化、谱聚类、着色问题、还有许多如化学、物理、计算科学领域的问题上都很有效。&lt;/p&gt;
&lt;p&gt;图信号处理领域，谱图理论被用作一个定义频谱和图傅里叶变换的基的扩展的工具。这部分我们会回顾一些谱图理论基本的定义与符号，研究它如何使得从传统的傅里叶分析扩展出很多重要的数学理论到图论上。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A. Weighted Graphs and Graph Signals&lt;/em&gt;&lt;br&gt;
我们分析无向、连通图$\mathcal{G} = \lbrace \mathcal{V}, \mathcal{E}, \mathbf{W} \rbrace$上的信号。边$e = (i, j)$连接了顶点$i$和$j$，$W_{i,j}$表示边的权重，否则$w_{i,j} = 0$。如果$\mathcal{G}$有$M$个连通分量，我们可以将信号分为$M$份，然后将每份看作是一个子图进行处理。&lt;/p&gt;
&lt;p&gt;当边的权重没有给出的时候，一种常用的方法是使用一个带阈值的高斯核权重函数：
&lt;/p&gt;
$$\tag{1}
W\_{i,j} = \begin{cases}
\exp{(-\frac{[dist(i,j)]^2}{2\theta^2})} \quad &amp;\text{if } dist(i, j) \leq \kappa \\
0 \quad &amp;\text{otherwise}
\end{cases},
$$&lt;p&gt;
参数是$\theta$和$\kappa$。式1中，$dist(i, j)$表示顶点$i$和$j$之间的物理距离，或是两个顶点的特征向量的欧氏空间中的距离，后者在半监督学习任务中很常用。另一个常用的方法是基于物理距离或特征空间距离，将顶点与它的$k$最近邻顶点相连。其他构建图的方法，见第四章，14。&lt;/p&gt;
&lt;p&gt;一个定义在图的顶点上的信号或函数$f: \mathcal{V} \rightarrow \mathbb{R}$可能表示成一个向量$\mathbf{f} \in \mathbb{R}^N$，第$i$个分量表示顶点集$\mathcal{V}$中的第$i$个顶点。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;B. The Non-Normalized Graph Laplacian&lt;/em&gt;
非归一化的拉普拉斯矩阵，也称为组合拉普拉斯矩阵(combinatorial graph Laplacian)，定义为$\bf L := D - W$，$\bf{D}$是对角矩阵，对角线上的第$i$个元素等于与顶点$i$相关的边的权重之和。拉普拉斯矩阵是一个差操作，因为对于任意一个信号$\mathbf{f} \in \mathbb{R}^N$，它满足：
&lt;/p&gt;
$$
(\mathbf{L}f)(i) = \sum\_{j \in \mathcal{N}\_i} W\_{i,j}[f(i) - f(j)],
$$&lt;p&gt;
邻居$\mathcal{N}_i$是与顶点$i$通过一条边相连的顶点集合。我们用$\mathcal{N}(i, k)$表示通过$k$步或小于$k$步连接到顶点$i$的顶点集合。
因为图的拉普拉斯矩阵$L$是实对称矩阵，它的特征向量相互正交，我们表示为$\lbrace \mathbf{u}_l \rbrace_{l=0,1,&amp;hellip;,N-1}$。这些特征向量对应非负的特征值$\lbrace \lambda_l\rbrace_{l=0,1,&amp;hellip;,N-1}$，满足$L \mathbf{u}_l = \lambda_l \mathbf{u}_l$，$l = 0,1,&amp;hellip;,N-1$。零作为特征值,其多重性等于图的连通分量数，因为我们考虑的是连通图，我们假设拉普拉斯矩阵的特征值的顺序为：$0 = \lambda_0 &amp;lt; \lambda_1 \leq \lambda_2 &amp;hellip; \leq \lambda_{N-1} := \lambda_{\text{max}}$。我们将整个谱表示为$\sigma(L) = \lbrace \lambda_0, \lambda_1, &amp;hellip;, \lambda_{N-1}\rbrace$。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;C. A Graph Fourier Transform and Notion of Frequency&lt;/em&gt;
传统的傅里叶变换
&lt;/p&gt;
$$
\hat{f}(\xi) := \langle f, e^{2\pi i \xi t} \rangle = \int\_\mathbb{R} f(t) e^{-2\pi i \xi t}dt
$$&lt;p&gt;
是函数$f$根据复指数的扩展，是一维拉普拉斯算子的特征函数：
&lt;/p&gt;
$$\tag{2}
-\Delta(e^{2\pi i \xi t}) = -\frac{\partial^2}{\partial t^2} e^{2\pi i \xi t} = (2 \pi \xi)^2 e^{2\pi i \xi t}.
$$&lt;p&gt;类比这个，我们可以定义任何一个在图$\mathcal{G}$的顶点上的函数$\mathbf{f} \in \mathbb{R}^N$的图傅里叶变换$\hat{\mathbf{f}}$，根据图拉普拉斯矩阵的特征向量对$\mathbf{f}$的扩展：
&lt;/p&gt;
$$\tag{3}
\hat{f}(\lambda\_l) := \langle \mathbf{f}, \mathbf{u}\_l \rangle = \sum^N\_{i = 1} f(i) u^*\_l (i).
$$&lt;p&gt;
逆图傅里叶变换为：
&lt;/p&gt;
$$\tag{4}
f(i) = \sum^{N - 1}\_{l = 0} \hat{f}(\lambda\_l) u\_l(i).
$$&lt;p&gt;传统的傅里叶分析中，式2中的特征值$\lbrace (2 \pi \xi )^2 \rbrace_{\xi \in \mathbb{R}}$对频率有特殊性：对于$\xi$接近0（低频），对应的复指数特征函数是平滑的，震荡慢的函数，而$\xi$远离0（高频）的对应的复指数特征函数震荡的很快。在图任务中，图拉普拉斯矩阵的特征值和特征向量在频率上提供了相似的特点。对于连通图，拉普拉斯矩阵的对应特征值为0的特征向量$\mathbf{u}_0$是不变的，且每个顶点的值为$\frac{1}{\sqrt{N}}$。图拉普拉斯矩阵的特征向量中对应低频的$\lambda_l$在图上变化的慢；也就是，如果两个顶点通过一条权重很大的边连接，这些地方的特征向量的值就会变得比较相似。对应大的特征值的特征向量在图上变化的更快，且边的权重越高，这些顶点上的值越不相似。图2给出了不同的随机的sensor网络的拉普拉斯矩阵的特征向量，图3展示了每个特征向量zero crossing的数量$\vert Z_\mathcal{G}(\cdot) \vert$。一个信号$\bf{f}$在图$\mathcal{G}$的zero crossing的集合定义为：
&lt;/p&gt;
$$
Z\_\mathcal{G}(\mathbf{f}) := \lbrace e = (i, j) \in \Large\varepsilon \normalsize : f(i)f(j) &lt; 0 \rbrace;
$$&lt;p&gt;
也就是，连接一个正信号和一个负信号的边的集合。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/the-emerging-field-of-signal-processing-on-graphs/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/the-emerging-field-of-signal-processing-on-graphs/Fig3.JPG"
loading="lazy"
alt="Figure3"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;D. Graph Signal Representations in Two Domains&lt;/em&gt;&lt;br&gt;
图傅里叶变换(3)和它的逆(4)给了我们一种方式在两个不同的域中等价的表示一个信号：顶点域和图谱域。尽管我们经常从顶点域的一个信号$\bf{g}$开始，直接在图谱域中定义一个信号$\hat{\bf{g}}$可能仍然是有用的。我们称这样的信号为&lt;em&gt;核(kernels)&lt;/em&gt;。图4a和图4b中，一个这样的核，一个heat kernel，分别展示了在两个域中的效果。类比传统的模拟情况，图4中展示的一个平缓的信号图傅里叶系数衰减的很快。这样的信号是&lt;em&gt;可压缩的(compressible)&lt;/em&gt;，因为可以通过调整一些图傅里叶系数来趋近他们。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/the-emerging-field-of-signal-processing-on-graphs/Fig4.JPG"
loading="lazy"
alt="Figure4"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;E. Discrete Calculus and Signal Smoothness with Respect to the Intrinsic Structure of the Graph&lt;/em&gt;&lt;br&gt;
分析信号时，需要强调一点是，属性（如smoothness）与数据域的内在结构相对应，在我们讨论的环境中，就是带权图。尽管微分几何提供了方法将潜在流形的几何结构整合进可微分流形上连续信号的分析中，*离散微积分(discrete calculus)*提供了一组可以在有限离散空间中操作的多变量微积分的定义与可微分操作器。&lt;/p&gt;
&lt;p&gt;为了增加smoothness对应图的内在结构的问题，我们简单的提一些离散可微分操作。一个信号$\bf{f}$在顶点$i$，对于边$e = (i, j)$的&lt;em&gt;边导数&lt;/em&gt;(edge derivative)定义为：
&lt;/p&gt;
$$
\left. \frac{\partial \mathbf{f}}{\partial e} \right|\_i := \sqrt{W\_{i,j}}[f(j) - f(i)],
$$&lt;p&gt;
顶点$i$处$\bf{f}$的图梯度是：
&lt;/p&gt;
$$
\nabla\_i \mathbf{f} := [\lbrace \left. \frac{\partial f}{\partial b} \right|\_i \rbrace\_{e \in \varepsilon \ \text{s.t.} \ e=(i,j) \ \text{for some} \ j \in \mathcal{V}}].
$$&lt;p&gt;顶点$i$的&lt;em&gt;local variation&lt;/em&gt;
&lt;/p&gt;
$$
\begin{aligned}
\Vert \nabla\_i \mathbf{f} \Vert\_2 : &amp; = [\sum\_{e \in \varepsilon \ \text{s.t.} \ e =(i, j) \ \text{for some} \ j \in \mathcal{V}} (\left. \frac{\partial \mathbf{f}}{\partial e} \right|\_i)^2]^{\frac{1}{2}} \\
&amp; = [\sum\_{j \in \mathcal{N}\_i} W\_{i, j} [f(j) - f(i)]^2]^{\frac{1}{2}}
\end{aligned}
$$&lt;p&gt;
可以度量顶点$i$周围的$\bf{f}$的local smootheness，当顶点$i$和它的邻居$j$的$\bf{f}$有相近的值时这个值较小。&lt;/p&gt;
&lt;p&gt;对于global smoothness，$\bf{f}$的&lt;em&gt;discrete p-Dirichlet form&lt;/em&gt;定义为：
&lt;/p&gt;
$$\tag{5}
S\_p(\mathbf{f}) := \frac{1}{p} \sum\_{i \in V} \Vert \nabla\_i \mathbf{f} \Vert^p\_2 = \frac{1}{p} \sum\_{i \in V}\LARGE[ \normalsize \sum\_{j \in \mathcal{N}\_i} W\_{i,j} [f(j) - f(i)]^2 \LARGE]^{\normalsize \frac{p}{2}}.
$$&lt;p&gt;当$p=1$时，$S_1(\mathbf{f})$是信号对图的&lt;em&gt;total variation&lt;/em&gt;。当$p = 2$时：
&lt;/p&gt;
$$\tag{6}
\begin{aligned}
S\_2(\mathbf{f}) &amp;= \frac{1}{2}\sum\_{i \in V} \sum\_{j \in \mathcal{N}\_i} W\_{i,j} [f(j) - f(i)]^2 \\
&amp;= \sum\_{(i,j) \in \varepsilon} W\_{i,j} [f(j) - f(i)]^2 = \mathbf{f^TLf}.
\end{aligned}
$$&lt;p&gt;$S_2(\mathbf{f})$被称为图拉普拉斯矩阵的二次型，semi-norm $\bf \Vert f \Vert_L$定义为：
&lt;/p&gt;
$$
\Vert \mathbf{f} \Vert\_\mathbf{L} := \Vert \mathbf{L}^{\frac{1}{2}} \mathbf{f} \Vert\_2 = \sqrt{\mathbf{f^TLf}} = \sqrt{S\_2(\mathbf{f})}.
$$&lt;p&gt;注意式6，二次型$S_2(\mathbf{f})$等于0当且仅当$\bf{f}$在所有顶点上都为常数（which is why $\Vert \mathbf{f} \Vert_L$ is only a semi-form），而且，更一般地，当信号$\bf{f}$在那些通过大权重的边连接的邻居顶点上有相似值时，$S_2(\mathbf{f})$的值较小；也就是当它平滑的时候。&lt;/p&gt;
&lt;p&gt;回到拉普拉斯矩阵的特征值和特征向量上，Courant-Fischer Theorem指出，他们也可以通过Rayleigh quotient定义为：
&lt;/p&gt;
$$\tag{7}
\lambda\_0 = \min\_{ \mathbf{f} \in \mathbb{R}^N, \Vert \mathbf{f} \Vert\_2 = 1} \lbrace \mathbf{f^TLf} \rbrace,
$$&lt;p&gt;
&lt;/p&gt;
$$\tag{8}
\text{and} \ \lambda\_l = \min\_{ \mathbf{f} \in \mathbb{R}^N, \Vert \mathbf{f} \Vert\_2 = 1, \mathbf{f} \perp span\lbrace \mathbf{u}\_0, ..., \mathbf{u}\_{l-1} \rbrace} \lbrace \mathbf{f^TLf} \rbrace, \ l = 1, 2, ..., N-1.
$$&lt;p&gt;
其中，特征向量$\mathbf{u}_l$是第$l$个问题的最小化问题的解。从式6和式7中，我们可以再次看出为什么$\mathbf{u}_0$对于连通图来说是常数。式8解释了为什么拉普拉斯矩阵中对应小的特征值的特征向量更平滑，也提供了另一个对为什么拉普拉斯矩阵的谱反映了频率的解释。&lt;/p&gt;
&lt;p&gt;总结一下，图的连通性编码进了拉普拉斯矩阵，拉普拉斯矩阵通常用于定义图傅里叶变换（通过特征向量），平滑性的不同表示。Example 1展示了smoothness和一个图信号的谱内容是如何依赖于图的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/the-emerging-field-of-signal-processing-on-graphs/Example1.JPG"
loading="lazy"
alt="“Example 1”"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;F. Other Graph Matrices&lt;/em&gt;
图拉普拉斯矩阵的基$\lbrace \mathbf{u}_l \rbrace_{l = 0, 1, &amp;hellip;, N - 1}$只是在正向(3)和逆向(4)图傅里叶变换中使用的一组可能的基。第二个常用的normalize每个权重$W_{i,j}$的方法是乘以$\frac{1}{\sqrt{d_i d_j}}$。这样可以对图的拉普拉斯矩阵归一化，定义为$\bf\tilde{L} := D^{-\frac{1}{2}} L D^{-\frac{1}{2}}$，等价于：
&lt;/p&gt;
$$
(\tilde{L}f)(i) = \frac{1}{\sqrt{d\_i}} \sum\_{j \in \mathcal{N}\_i} W\_{i,j} \LARGE[\normalsize \frac{f(i)}{\sqrt{d\_i}} - \frac{f(j)}{\sqrt{d\_j}} \LARGE].
$$&lt;p&gt;连通图$\mathcal{G}$的归一化的拉普拉斯矩阵的特征值$\lbrace \tilde{\lambda}_l \rbrace_{l=0,1,&amp;hellip;,N-1}$满足：
&lt;/p&gt;
$$
0 = \tilde{\lambda}\_0 &lt; \tilde{\lambda}\_1 \leq ... \leq \tilde{\lambda}\_{\text{max}} \leq 2,
$$&lt;p&gt;
当且仅当$\mathcal{G}$是二分图时，$\tilde{\lambda}_{\text{max}} = 2$。我们将归一化的拉普拉斯矩阵表示为$\lbrace \mathbf{\tilde{u}}_l \rbrace_{l = 0,1,&amp;hellip;N-1}$。图3b中，$\tilde{L}$的谱和频率也有关系，对应大的特征值的特征向量一般有着更多的zero crossing。然而，不像$\mathbf{u}_0$，归一化的拉普拉斯矩阵中对应特征值为0的$\tilde{\mathbf{u}}_0$不是一个常向量。&lt;/p&gt;
&lt;p&gt;归一化和非归一化的拉普拉斯矩阵都是&lt;em&gt;generalized graph Laplacians&lt;/em&gt;的例子，也称为&lt;em&gt;discrete Schrödinger operators&lt;/em&gt;。一个图$\mathcal{G}$的泛化拉普拉斯矩阵是任意的对阵矩阵，如果这个矩阵中有边连接顶点$i$和顶点$j$，那么这个矩阵的$(i, j)$是负的，如果$i \not = j$，而且$i$与$j$不相连，那么为$0$，如果$i = j$，那么有可能是任何值。&lt;/p&gt;
&lt;p&gt;第三个常用的矩阵，经常在图信号的降维技术中使用，是&lt;em&gt;random walk matrix&lt;/em&gt;，$\bf{P := D^{-1}W}$。每个值$P_{i,j}$表示在图$\mathcal{G}$上从顶点$i$到顶点$j$通过一步马尔可夫随机游走的概率。对于连通的、非周期的图，$\mathbf{P}^t$在$t$趋近于无穷时，收敛至平稳分布。与随机游走矩阵密切相关的是非对称拉普拉斯矩阵，定义为 $\mathbf{L}_a := \mathbf{I}_N - \mathbf{P}$，其中$\mathbf{I}_N$表示$N \times N$的单位阵。注意$\mathbf{L}_a$有着和$\tilde{\mathbf{L}}$同样的特征值集合，如果$\tilde{\mathbf{u}}_l$是对应$\tilde{L}$的特征值$\tilde{\lambda}_l$的特征向量，则$\bf{D}^{-\frac{1}{2}} \tilde{\mathbf{u}}_l$是对应$\mathbf{L}_a$的特征值$\tilde{\lambda}_l$的特征向量。&lt;/p&gt;
&lt;p&gt;正如下一节要讨论的，归一化和非归一化的拉普拉斯矩阵都能用于filtering。没有明确的规定要求什么时候必须使用归一化的，什么时候使用非归一化的拉普拉斯矩阵的特征向量，什么时候使用其他的基。归一化的拉普拉斯矩阵有很好的性质，它的谱总时在$[0, 2]$区间内，而且对于二分图，spectral folding phenomenon可以研究。然而，非归一化的拉普拉斯矩阵中对应特征值为0的特征向量是常向量，这在从传统filtering理论扩展关于信号的DC components上是一个有用的性质。&lt;/p&gt;
&lt;h1 id="3-generalized-operators-for-signals-on-graphs"&gt;3. Generalized Operators For Signals on Graphs
&lt;/h1&gt;&lt;p&gt;在这部分，我们会回顾不同的方式来泛化基本操作到图上，如filtering, translation, modulation, dilation, downsampling。这些泛化的操作是第四部分要讨论的localized, multiscale transforms的基础。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A. Filtering&lt;/em&gt;
第一个泛化的操作是filtering。我们从扩展频率滤波的概念到图上开始，然后讨论顶点域上的局部滤波。&lt;/p&gt;
&lt;h2 id="1-frequency-filtering"&gt;1. Frequency Filtering:
&lt;/h2&gt;&lt;p&gt;在传统的信号处理中，频率滤波是将输入信号表示成一个复指数的线性组合，扩大或缩小一些复指数贡献的过程
&lt;/p&gt;
$$\tag{9}
\hat{f}\_{out}(\xi) = \hat{f}\_{in}(\xi) \hat{h}(\xi),
$$&lt;p&gt;
其中，$\hat{h}(\cdot)$是滤波器的传递函数。取式9的逆傅里叶变换，傅里叶域中的乘法对应了时域中的卷积：
&lt;/p&gt;
$$\tag{10}
f\_{out}(t) = \int\_\mathbb{R} \hat{f}\_{in}(\xi) \hat{h}(\xi)e^{2 \pi i \xi t} d\xi
$$&lt;p&gt;
&lt;/p&gt;
$$\tag{11}
=\intop\_\mathbb{R} f\_{in}(\tau) h(t-\tau)d\tau =: (f\_in * h)(t).
$$&lt;p&gt;
一旦我们fix一个图谱表示，我们的图傅里叶变换的概念，我们可以直接将式9泛化到定义频率滤波上，或&lt;em&gt;图谱滤波&lt;/em&gt;(graph spectral filtering)上：
&lt;/p&gt;
$$\tag{12}
\hat{f}\_{out}(\lambda\_l) = \hat{f}\_{in}(\lambda\_l) \hat{h}(\lambda\_l),
$$&lt;p&gt;
或者，等价的，取逆图傅里叶变换，
&lt;/p&gt;
$$\tag{13}
f\_{out}(i) = \sum^{N-1}\_{l=0} \hat{f}\_{in}(\lambda\_l) \hat{h}(\lambda\_l) u\_l(i).
$$&lt;p&gt;接用matrix functions[38]理论中的符号，我们可以将式12和式13写成$\mathbf{f}_{out} = \hat{h}(\mathbf{L})\mathbf{f}_{in}$，其中
&lt;/p&gt;
$$\tag{14}
\hat{h}(\mathbf{L}) := \mathbf{U} \begin{bmatrix}
\hat{h}(\lambda\_0) &amp; &amp; 0 \\
&amp; \ddots &amp; \\
0 &amp; &amp;\hat{h}(\lambda\_{N-1})
\end{bmatrix}\mathbf{U^T}
$$&lt;p&gt;基础的图谱滤波可以用来实现连续滤波技术的离散版，如高斯平滑，双边滤波，total variation filtering，anisotropic diffusion，non-local means filtering。特别地，这些滤波器中的很多成为了解决variational problems的方法，对ill-posed inverse problems进行正则化，这些问题如denoising，inpainting，super-resolution。举个例子，离散正则框架：
&lt;/p&gt;
$$\tag{15}
\min\_\mathbf{f}\lbrace \Vert \mathbf{f} - \mathbf{y} \Vert^2\_2 + \gamma S\_p(\mathbf{f}) \rbrace,
$$&lt;p&gt;
其中，$S_p(\mathbf{f})$是式5的p-Dirichlet form。在Example 2中，我们举了个式15的$p = 2$时处理图像去噪的问题的例子。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/the-emerging-field-of-signal-processing-on-graphs/Example2.JPG"
loading="lazy"
alt="Example2"
&gt;&lt;/p&gt;
&lt;h2 id="2-filtering-in-the-vertex-domain"&gt;2. Filtering in the Vertex Domain:
&lt;/h2&gt;&lt;p&gt;在顶点域中filter一个信号，只要简单的将顶点$i$的输出$f_{out}(i)$写成一个顶点$i$的$K-hop$局部邻居上输入信号各分量的线性组合：
&lt;/p&gt;
$$\tag{18}
f\_{out}(i) = b\_{i, i} f\_{in}(i) + \sum\_{j \in \mathcal{N}(i, K)} b\_{i,j} f\_{in}(j),
$$&lt;p&gt;
$\lbrace b_{i,j} \rbrace_{i,j \in \mathcal{V}}$是常数。式18只说明了顶点域上的滤波是一个局部的线性变换。&lt;/p&gt;
&lt;p&gt;我们现在简单地将图谱域上的滤波关联到了顶点域的滤波上。当式12中的频率滤波是$K$阶多项式$\hat{h}(\lambda_l) = \sum^K_{k=0} a_k \lambda^k_l$时，其中$\lbrace a_k\rbrace_{k=0,1,&amp;hellip;K}$是常数，我们也可以将式12在顶点域中解释。由式13，我们得到：
&lt;/p&gt;
$$\tag{19}
\begin{aligned}
f\_{out}(i) &amp; = \sum^{N-1}\_{l=0} \hat{f}\_{in}(\lambda\_l) \hat{h}(\lambda\_l) u\_l(i) \\
&amp; = \sum^N\_{j=1} f\_{in}(j) \sum^K\_{k=0} a\_k \sum^{N-1}\_{l=0} \lambda^k\_l u^*\_l(j) u\_l(i) \\
&amp; = \sum^N\_{j=1} f\_{in}(j) \sum^K\_{k=0} a\_k(\mathbf{L}^k)\_{i,j}.
\end{aligned}
$$&lt;p&gt;然而，在顶点$i$到顶点$j$之间的最短路径距离$d_\mathcal{G}(i,j)$大于$k$时，$(\mathbf{L}^k)_{i,j} = 0$。因此，我们可以将式19写成式18，常数定义为：
&lt;/p&gt;
$$
b\_{i,j} := \sum^K\_{k=d\_\mathcal{G}(i,j)} a\_k (\mathbf{L}^k)\_{i,j}.
$$&lt;p&gt;
所以当频率滤波是一个$K$阶多项式时，顶点$i$上频率滤波后的信号，$f_{out}(i)$，是顶点$i$的$K-hop$邻居上的输入信号的线性组合。这个性质在关联一个卷积核的平滑性与顶点域中滤波后信号的局部化之间很有用。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;B. Convolution&lt;/em&gt;
我们不能直接将卷积的定义（11）泛化到图上，因为$h(t - \tau)$。然而，一种定义图上的卷积的方式是替换式10中的复指数为拉普拉斯矩阵的特征向量：
&lt;/p&gt;
$$\tag{20}
(f * h)(i) := \sum^{N-1}\_{l=0} \hat{f}(\lambda\_l) \hat{h}(\lambda\_l) u\_l(i),
$$&lt;p&gt;
这个使得在顶点域上的卷积等价于在图谱域的乘法。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;C. Translation&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</title><link>https://davidham3.github.io/blog/p/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/</link><pubDate>Tue, 31 Jul 2018 14:37:10 +0000</pubDate><guid>https://davidham3.github.io/blog/p/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/</guid><description>&lt;p&gt;ICLR 2018，DCRNN，模型借鉴了&lt;a class="link" href="https://davidham3.github.io/blog/2018/07/23/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/" target="_blank" rel="noopener"
&gt;Structured Sequence Modeling With Graph Convolutional Recurrent Networks (ICLR 2017 reject)&lt;/a&gt;里面的DCRNN，将该模型应用于了交通预测上。而且后者的论文使用的卷积是Defferrard提出的图卷积，这篇论文中使用的是扩散卷积，这种扩散卷积使用的是随机游走，与&lt;a class="link" href="https://davidham3.github.io/blog/2018/07/19/diffusion-convolutional-neural-networks/" target="_blank" rel="noopener"
&gt;Diffusion-Convolutional Neural Networks (NIPS 2016)&lt;/a&gt;的扩散卷积还不一样。构造出来的DCRNN使用了&lt;a class="link" href="https://davidham3.github.io/blog/2018/07/23/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/" target="_blank" rel="noopener"
&gt;Structured Sequence Modeling With Graph Convolutional Recurrent Networks (ICLR 2017 reject)&lt;/a&gt;两种形式中的模型2，即使用扩散卷积学习出空间表示后，放入GRU中进行时间上的建模。原文链接：&lt;a class="link" href="http://arxiv.org/abs/1707.01926" target="_blank" rel="noopener"
&gt;Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;交通预测的挑战：1. 对路网复杂的空间依赖关系， 2. 路况变换与非线性的时间动态性， 3. 长期预测的困难性。我们提出了在有向图上对交通流以扩散形式进行建模的方法，介绍了 &lt;em&gt;Diffusion Convolutional Recurrent Neural Network&lt;/em&gt; (DCRNN)，用于交通预测的深度学习框架，同时集成了交通流中的空间与时间依赖。DCRNN 使用图上的双向随机游走捕获了空间依赖，使用编码解码框架以及 scheduled sampling 捕获时间依赖。我们在两个真实的交通数据集上评估了模型，比 state-of-the-art 强了12%-15%。&lt;/p&gt;
&lt;h1 id="1-引言"&gt;1 引言
&lt;/h1&gt;&lt;p&gt;对一个在动态系统中运行的学习系统来说，时空预测是一个很关键的任务。自动驾驶、电网优化、供应链管理等都是它的应用。我们研究了一个重要的任务：路网上的交通预测，这是智能交通系统中的核心部分。目标是给定历史车速与路网数据，预测未来的车速。&lt;/p&gt;
&lt;p&gt;任务有挑战性的原因是复杂的时空依赖关系以及长期预测的上的难度。一方面，交通数据序列表现出了强烈的时间动态性(temporal dynamics)。反复的事件如高峰期或交通事故导致了数据的非平稳性，使得长期预测很困难。另一方面，路网上的监测器包含了复杂但是唯一的空间联系(spatial correlations)。图1展示了一个例子。路1和路2是相关联的，但是路1和路3没有关联。尽管路1和路3在欧氏空间中很近，但是他们表现出了不同的形式。此外，未来的车速更容易受到下游交通的影响，而非上游。这就意味着交通上的空间结构不是欧氏空间的，而是有向的。&lt;/p&gt;
&lt;div align="center"&gt;![Figure1](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig1.JPG)
&lt;p&gt;交通预测已经研究了几十年，有两个主要类别：知识驱动的方法和数据驱动的方法。在运输和操作研究中，知识驱动的方法经常使用排队论，模拟交通中的用户行为(Cascetta, 2013)。时间序列社区中，数据驱动的方法如 Auto-Regressive Integrated Moving Average(ARIMA) 模型，Kalman filtering 还是很流行的(Liu et al., 2011; Lippi et al., 2013)。然而，简单的时间序列模型通常依赖平稳假设，这经常与实际交通数据不符。最近开始在交通预测上应用深度学习模型 (Lv et al., 2015; Yu et al., 2017b) ，但是没有考虑空间结构。Wu &amp;amp; Tan 2016和Ma et al. 2017 使用 CNN 对空间关系进行建模，但是在欧氏空间中的。Bruna et al. 2014，Defferrard et al. 2016 研究了图卷积，但是只能处理无向图。&lt;/p&gt;
&lt;p&gt;我们使用一个有向图来表示 pair-wise spatial correlations。图的顶点是sensors，边是权重，通过路网上 sensor 之间的距离得到。我们使用扩散卷积 (diffusion convolution) 操作来捕获空间依赖关系，以扩散性是对交通流的动态性建模。提出了 &lt;em&gt;Diffusion Convolutional Recurrent Neural Network&lt;/em&gt; (DCRNN)，整合了 &lt;em&gt;diffusion convolution&lt;/em&gt; 和 &lt;em&gt;sequence to sequence&lt;/em&gt; 架构以及 &lt;em&gt;scheduled sampling&lt;/em&gt; 技术。在真实数据集上衡量模型时，DCRNN 比state-of-the-art好很多。
· 我们研究了交通预测问题，在有向图上对交通的空间依赖以扩散形式建模。提出了 &lt;em&gt;diffusion convolution&lt;/em&gt;，有着直观的解释以及高效的计算。
· 我们提出了 &lt;em&gt;Diffusion Convolutional Recurrent Neural Network&lt;/em&gt; (DCRNN)，使用 &lt;em&gt;diffusion convolution&lt;/em&gt;，&lt;em&gt;sequence to sequence&lt;/em&gt;，&lt;em&gt;scheduled sampling&lt;/em&gt; 同时对时间和空间依赖关系进行捕获的方法。DCRNN 不限于运输领域，可以应用到其他的时空预测问题上。
· 做了很多实验，效果很好。&lt;/p&gt;
&lt;h1 id="2-methodology"&gt;2 Methodology
&lt;/h1&gt;&lt;h2 id="21-traffic-forecasting-problem"&gt;2.1 Traffic Forecasting Problem
&lt;/h2&gt;&lt;p&gt;$N$ 个sensors。检测器网络表示成带权有向图 $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \boldsymbol{W})$，$\mathcal{V}$ 是顶点集，$\vert \mathcal{V} \vert = N$，$\mathcal{E}$ 是边集，$\boldsymbol{W} \in \mathbb{R}^{N \times N}$ 是带权邻接矩阵，表示顶点相似性（如路网距离的一个函数）。图信号矩阵$\boldsymbol{X} \in \mathbb{R}^{N \times P}$，$P$ 是每个顶点的特征数。$\boldsymbol{X}^{(t)}$ 表示时间 $t$ 观测到的图信号，交通预测问题目的是学习一个函数 $h(\cdot)$，将 $T&amp;rsquo;$ 个历史的图信号映射到未来的 $T$ 个图信号上，给定图 $\mathcal{G}$:
&lt;/p&gt;
$$[\boldsymbol{X}^{(t-T'+1)}, ..., \boldsymbol{X}^{(t)}; \mathcal{G}] \xrightarrow{h(\cdot)} [\boldsymbol{X}^{(t+1)}, ..., \boldsymbol{X}^{(t+T)}]$$&lt;h2 id="22-spatial-dependency-modeling"&gt;2.2 Spatial Dependency Modeling
&lt;/h2&gt;&lt;p&gt;扩散形式以 $\mathcal{G}$ 上的随机游走来刻画，重启概率 $\alpha \in [0, 1]$，状态转移矩阵 $\boldsymbol{D}^{-1}_O \boldsymbol{W}$。这里，$\boldsymbol{D}_{\boldsymbol{O}} = \mathrm{diag}(\boldsymbol{W1})$ 是出度的对角矩阵，$\mathbf{1} \in \mathbb{R}^N$ 表示所有都为1的向量。多个时间步之后，Markov process 会收敛到平稳分布 $\mathcal{P} \in \mathbb{R}^{N \times N}$上，第 $i$ 行 $\mathcal{P}_{i,:} \in \mathbb{R}^N$ 表示从顶点 $v_i \in \mathcal{V}$ 扩散的可能性，也就是对顶点 $v_i$ 的 proximity。下面的引理是平稳分布的闭式解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lemma 2.1&lt;/strong&gt; (Teng et al., 2016) 扩散过程的平稳分布可以表示为图上的无限随机游走的带权组合，可以通过以下式子计算：
&lt;/p&gt;
$$\tag{1}
\mathcal{P} = \sum^\infty\_{k=0} \alpha(1 - \alpha)^k (\boldsymbol{D}^{-1}\_O \boldsymbol{W})^k
$$&lt;p&gt;
其中 $k$ 是diffusion step。实际上，我们使用有限的 $K$ 阶扩散过程，给每一步分配一个可训练的权重。我们也融入反向扩散过程，因为双向扩散可以让模型更灵活地去捕获上游和下游交通带来的影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diffusion Convolution&lt;/strong&gt; 图信号 $\boldsymbol{X} \in \mathbb{R}^{N \times P}$ 和滤波器 $f_\theta$ 的扩散卷积操作的结果是：
&lt;/p&gt;
$$\tag{2}
\boldsymbol{X}\_{:,p} \star\_{\mathcal{G}} f\_\theta = \sum^{K-1}\_{k=0} (\theta\_{k,1} (\boldsymbol{D}^{-1}\_O \boldsymbol{W})^k + \theta\_{k,2}(\boldsymbol{D}^{-1}\_I \boldsymbol{W}^T)^k) \boldsymbol{X}\_{:,p} \ \ \ \ \mathrm{for} \ \ p \in \lbrace 1, ..., P \rbrace
$$&lt;p&gt;
其中 $\theta \in \mathbb{R}^{K \times 2}$ 表示卷积核参数，$\boldsymbol{D}^{-1}_O \boldsymbol{W}$ 和 $\boldsymbol{D}^{-1}_I \boldsymbol{W}^T$ 表示扩散过程和反向扩散的转移概率矩阵。一般，计算卷积是很耗时的。然而，如果 $\mathcal{G}$ 是稀疏的，式2可以通过递归的复杂度为 $O(K)$ 的sparse-dense矩阵乘法高效的计算，总时间复杂度为 $O(K \vert \mathcal{E} \vert) \ll O(N^2)$。附录B有详细的描述。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diffusion Convolutional Layer&lt;/strong&gt; 式2定义的卷积操作，我们可以构建一个扩散卷积层，将 $P$ 维特征映射到 $Q$ 维输出上。将参数表示为 $\mathbf{\Theta} \in \mathbb{R}^{Q \times P \times K \times 2} = [ \boldsymbol{\theta} ]_{q, p}$，其中 $\mathbf{\Theta}_{q,p,:,:} \in \mathbb{R}^{K \times 2}$ 是第 $p$ 个输入和 $q$ 个输出的参数。扩散卷积层为：
&lt;/p&gt;
$$\tag{3}
\boldsymbol{H}\_{:,q} = \boldsymbol{a}(\sum^P\_{p=1} \boldsymbol{X}\_{:,p} \star\_{\mathcal{G}} f\_{\mathbf{\Theta}\_{q,p,:,:}}) \ \ \ \ \mathrm{for} \ q \in \lbrace 1, ..., Q \rbrace
$$&lt;p&gt;
其中，$\boldsymbol{X} \in \mathbb{R}^{N \times P}$ 是输入，$\boldsymbol{H} \in \mathbb{R}^{N \times Q}$ 是输出，$\lbrace f_{\mathbf{\Theta}_{q,p,:,:}} \rbrace $ 是滤波器，$a$ 是激活函数。扩散卷积层学习图结构数据的表示，我们可以使用基于随机梯度的方法训练它。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relation with Spectral Graph Convolution:&lt;/strong&gt; 扩散卷积是定义在有向和无向图上的。当使用在无向图上时，我们发现很多现存的图结构卷积操作，包括流行的普图卷积，ChebNet，可以看作是一个扩散卷积的特例。令 $\boldsymbol{D}$ 表示度矩阵，$\boldsymbol{L} = \boldsymbol{D}^{-\frac{1}{2}}(\boldsymbol{D} - \boldsymbol{W}) \boldsymbol{D}^{-\frac{1}{2}}$ 是图归一化的拉普拉斯矩阵，接下来的Proposition解释了连接。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 2.2.&lt;/strong&gt; 谱图卷积的定义：
&lt;/p&gt;
$$
\boldsymbol{X}\_{:,p} \star\_{\mathcal{G}} f\_\boldsymbol{\theta} = \Phi F(\boldsymbol{\theta}) \Phi^T \boldsymbol{X}\_{:,p}
$$&lt;p&gt;
特征值分解 $\boldsymbol{L} = \Phi \Lambda \Phi^T$，当图 $\mathcal{G}$是无向图时，$F(\boldsymbol{\theta}) = \sum^{K-1}_0 \theta_k \Lambda^k$，等价于图的扩散卷积。
证明见后记C。&lt;/p&gt;
&lt;h2 id="23-temporal-dynamics-modeling"&gt;2.3 Temporal Dynamics Modeling
&lt;/h2&gt;&lt;p&gt;我们利用 RNN 对时间依赖建模。我们使用 GRU，简单有效的 RNN 变体。我们将 GRU 中的矩阵乘法换成了扩散卷积，得到了我们的扩散卷积门控循环单元 &lt;em&gt;Diffusion Convolutional Gated Recurrent Unit(DCGRU)&lt;/em&gt;.
&lt;/p&gt;
$$
\boldsymbol{r}^{(t)} = \sigma(\mathbf{\Theta}\_r \star\_\mathcal{G} [\boldsymbol{X}^{(t)}, \boldsymbol{H}^{(t-1)}] + \boldsymbol{b}\_r) \\
\boldsymbol{u}^{(t)} = \sigma( \mathbf{\Theta}\_u \star\_\mathcal{G} [\boldsymbol{X}, \boldsymbol{H}^{(t-1)}] + \boldsymbol{b}\_u) \\
\boldsymbol{C}^{(t)} = \mathrm{tanh}(\mathbf{\Theta}\_C \star\_\mathcal{G} [\boldsymbol{X}^{(t)}, (\boldsymbol{r}^{(t)} \odot \boldsymbol{H}^{(t-1)})] + \boldsymbol{b}\_c) \\
\boldsymbol{H}^{(t)} = \boldsymbol{u}^{(t)} \odot \boldsymbol{H}^{(t-1)} + (1 - \boldsymbol{u}^{(t)}) \odot \boldsymbol{C}^{(t)}
$$&lt;p&gt;
其中 $\boldsymbol{X}^{(t)}, \boldsymbol{H}^{(t)}$ 表示时间 $t$ 的输入和输出，$\boldsymbol{r}^{(t)}, \boldsymbol{u}^{(t)}$ 表示时间 $t$ 的reset gate和 update gate。$\star_\mathcal{G}$ 表示式2中定义的混合卷积，$\mathbf{\Theta}_r, \mathbf{\Theta}_u, \mathbf{\Theta}_C$ 表示对应的滤波器的参数。类似 GRU，DCGRU 可以用来构建循环神经网络层，使用 BPTT 训练。&lt;/p&gt;
&lt;div align="center"&gt;![Figure2](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig2.JPG)
&lt;p&gt;在多步预测中，我们使用 &lt;em&gt;Sequence to Sequence&lt;/em&gt; 架构。编码解码器都是 DCGRU。训练时，我们把历史的时间序列放到编码器，使用最终状态初始化解码器。解码器生成预测结果。测试时，ground truth 替换成模型本身生成的预测结果。训练和测试输入的分布的差异会导致性能的下降。为了减轻这个问题的影响，我们使用了 &lt;em&gt;scheduled sampling&lt;/em&gt; (Bengio et al., 2015)，在训练的第 $i$ 轮时，模型的输入要么是概率为 $\epsilon_i$ 的 ground truth，要么是概率为 $1 - \epsilon_i$ 的预测结果。在训练阶段，$\epsilon_i$ 逐渐的减小为0，使得模型可以学习到测试集的分布。&lt;/p&gt;
&lt;p&gt;图2展示了 DCRNN 的架构。整个网络通过 BPTT 循环生成目标时间序列的最大似然得到。DCRNN 可以捕获时空依赖关系，应用到多种时空预测问题上。&lt;/p&gt;
&lt;h1 id="3-related-work"&gt;3 Related Work
&lt;/h1&gt;&lt;p&gt;运输领域和运筹学中交通预测是传统问题，主要依赖于排队论和仿真(Drew, 1968)。数据驱动的交通预测方法最近受到了很多的关注，详情可以看近些年的 paper (Vlahogianni et al., 2014)。然而，现存的机器学习模型要么有着很强的假设（如 auto-regressive model ）要么不能考虑非线性的时间依赖（如 latent space model Yu et al. 2016; Deng et al. 2016）。深度学习模型为解决时间序列预测问题提供了新的方法。举个例子，在 Yu et al. 2017b; Laptev et al. 2017 的工作中，作者使用深度循环神经网络研究时间序列预测问题。卷积神经网络已经被应用到交通预测上。Zhang et al. 2016; 2017 将路网转换成了 2D 网格，使用传统的 CNN 预测人流。Cheng et al. 2017 提出了DeepTransport，通过对每条路收集上下游邻居路段对空间依赖建模，在这些邻居上分别使用卷积操作。&lt;/p&gt;
&lt;p&gt;最近，CNN 基于谱图理论已经泛化到任意的图结构上。图卷积神经网络由 Bruna et al. 2014 首次提出，在深度神经网络和谱图理论之间建立了桥梁。Defferrard et al. 2016 提出了 ChebNet，使用快速局部卷积滤波器提升了 GCN。Kipf &amp;amp; Welling 2017 简化了 ChebNet，在半监督分类任务上获得了 state-of-the-art 的表现。Seo et al. 2016 融合了 ChebNet 和 RNN 用于结构序列建模。Yu et al. 2017a 对检测器网络以无向图的形式，使用 Chebnet 和卷积序列模型 (Gehring et al. 2017) 进行建模做预测。这些提及的基于谱的理论的限制之一是，他们需要图是无向的，来计算有意义的谱分解。从谱域到顶点域，Atwood &amp;amp; Towsley 2016 提出了扩散卷积神经网络 (DCNN)，以图结构中每个顶点的扩散过程定义了卷积。Hechtlinger et al. 2017 提出了 GraphCNN 对每个顶点的 $p$ 个最近邻邻居进行卷积，将卷积泛化到图上。然而，这些方法没有考虑时间的动态性，主要处理的是静态图。&lt;/p&gt;
&lt;p&gt;我们的方法不同于这些方法，因为问题的设定不一样，而且图卷积的公式不同。我们将 sensor network 建立成一个带权有向图，比网格和无向图更真实。此外，我们提出的卷积操作使用双向图随机游走来定义，集成了序列到序列模型以及 scheduled sampling ，对长时间的时间依赖建模。&lt;/p&gt;
&lt;h1 id="4-experiments"&gt;4 Experiments
&lt;/h1&gt;&lt;p&gt;我们在两个数据集上做了实验：（1）&lt;strong&gt;METR-LA&lt;/strong&gt; 这个交通数据集包含了洛杉矶高速公路线圈收集的数据 (Jagadish et al., 2014)。我们选择了207个检测器，收集了从2012年3月1日到2012年6月30日4个月的数据用于实验。（2）&lt;strong&gt;PEMS_BAY&lt;/strong&gt; 这个交通数据集由 California Transportation Agencies(CalTrans)Performance Measurement System (PeMS) 收集。我们选了 Bay Area 的325个检测器，收集了从2017年1月1日到2017年5月31日6个月的数据用于实验。两个数据集监测器的分布如图8所示。&lt;/p&gt;
&lt;p&gt;这两个数据集，我们将车速聚合到了5分钟的窗口内，使用了 Z-Score normalization。70%的数用于训练，20%用于测试，10%用于验证。为了构建检测器网络，我们计算了任意两个 sensor 的距离，使用了 thresholded Gaussian kernel 来构建邻接矩阵(Shuman et al., 2013)。$W_{ij} = \exp{(-\frac{\mathrm{dist}(v_i, v_j)^2}{\sigma^2})} \ \text{if} \ \text{dist}(v_i, v_j) \leq \mathcal{\kappa}, \mathrm{otherwise} \ 0$，其中 $W_{ij}$ 表示了检测器 $v_i$ 和 $v_j$ 之间的权重，$\mathrm{dist}(v_i, v_j)$ 表示检测器 $v_i$ 到 $v_j$ 之间的距离。$\sigma$ 表示距离的标准差，$\kappa$ 表示阈值。&lt;/p&gt;
&lt;div align="center"&gt;![Figure8](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig8.JPG)
&lt;div align="center"&gt;![Table](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Table1.JPG)
&lt;h2 id="41-experimental-settings"&gt;4.1 Experimental Settings
&lt;/h2&gt;&lt;p&gt;Baselines 1. $\rm{HA}$：历史均值，将交通流建模成周期性过程，使用之前的周期的加权平均作为预测。2. $\mathrm{ARIMA}_{kal}$：Auto-Regressive Integrated Moving Average model with Kalman filter，广泛地应用于时间序列预测上。3. $\rm{VAR}$: Vector Auto-Regression(Hamilton, 1994)。4. $\rm{SVR}$：Support Vector Regression，使用线性支持向量机用于回归任务。5. Feed forward Neural network (FNN)：前向传播神经网络，两个隐藏层，L2正则化。6. Recurrent Neural Network with fully connected LSTM hidden units (FC-LSTM)(Sutskever et al., 2014).&lt;/p&gt;
&lt;p&gt;所有的神经网络方法都是用 Tensorflow 实现，使用 Adam 优化器，学习率衰减。使用 Tree-structured Parzen Estimator(TPE)(Bergstra et al., 2011) 在验证集上选择最好的超参数。DCRNN 的详细参数设置和 baselines 的超参数设置见附录E。&lt;/p&gt;
&lt;h2 id="42-traffic-forecasting-performance-comparison"&gt;4.2 Traffic Forecasting Performance Comparison
&lt;/h2&gt;&lt;p&gt;表1展示了不同的方法在15分钟，30分钟，1小时在两个数据集上预测的对比。这些方法在三种常用的 metrics 上进行了评估，包括1. MAE， 2. MAPE（Mean Absolute Percentage Error）， 3. RMSE。这些 metrics 中的缺失值被排除出去。这些公式在后记E.2。我们观察到这两个数据集上有以下现象：1. RNN-based methods，包括FC-LSTM和DCRNN，一般比其他的方法表现得好，这强调对时间依赖的建模的重要性。2. DCRNN在所有的 forecasting horizons 中的所有 metrics 上都获得了最好的表现，这说明对空间依赖建模的有效性。3. 深度学习模型，包括 FNN，FC-LSTM，DCRNN 在长期预测上，倾向于比线性的 baseline 有更好的结果。比如，1小时。这是因为随着 horizon 的增长，时间依赖变得更加非线性。此外，随着历史均值不依赖短期数据，它的表现对于 forecasting horizon 的小增长是不变的。&lt;/p&gt;
&lt;p&gt;需要注意的是，METR-LA（Los Angeles，有很复杂的交通环境）数据比 PEMS-BAY 更有挑战性，所以我们将 METR-LA 的数据作为以下实验的默认数据集。&lt;/p&gt;
&lt;h2 id="43-effect-of-spatial-dependency-modeling"&gt;4.3 Effect of Spatial Dependency Modeling
&lt;/h2&gt;&lt;p&gt;为了继续深入对空间依赖建模的影响，我们对比了 DCRNN 和以下变体： 1. DCRNN-NoConv，这个通过使用单位阵替换扩散卷积（式2）中的转移矩阵，忽略了空间依赖。这就意味着预测只能通过历史值预测。 2. DCRNN-UniConv，扩散卷积中只使用前向随机游走；图3展示了这三个模型使用大体相同数量的参数时的学习曲线。没有扩散卷积，DCRNN-NoConv 有着更大的 validation error。此外，DCRNN获得了最低的 validation error，说明了使用双向随机游走的有效性。这个告诉我们双向随机游走赋予了模型捕获上下游交通影响的能力与灵活性。&lt;/p&gt;
&lt;div align="center"&gt;![Figure3](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig3.JPG)
&lt;p&gt;为了研究图的构建方法的影响，我们构建了一个无向图，$\widehat{W}_{ij} = \widehat{W}_{ji} = \max(W_{ij}, W_{ji})$，其中 $\widehat{\boldsymbol{W}}$ 是新的对称权重矩阵。然后我们使用了 DCRNN 的一个变体，表示成 GCRNN，使用 &lt;em&gt;ChebNet&lt;/em&gt; 卷积的序列到序列学习，并用大体相同的参数数量。表2展示了 DCRNN 和 GCRNN 在 METR-LA 数据集上的对比。DCRNN 都比 GCRNN 好。这说明有向图能更好的捕获交通检测器之间的非对称关系。图4展示了不同参数的影响。$K$ 大体对应了卷积核感受野的大小，单元数对应了卷积核数。越大的 $K$ 越能使模型捕获更宽的空间依赖，代价是增加了学习的复杂度。我们观测到随着 $K$ 的增加，验证集上的误差先是快速下降，然后微微上升。改变不同数量的单元也会有相似的情况。&lt;/p&gt;
&lt;div align="center"&gt;![Table2](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Table2.JPG)
&lt;div align="center"&gt;![Figure4](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig4.JPG)
&lt;h2 id="44-effect-of-temporal-dependency-modeling"&gt;4.4 Effect of Temporal Dependency Modeling
&lt;/h2&gt;&lt;p&gt;为了衡量时间建模的影响，包括序列到序列框架以及 scheduled sampling 技术，我们设计 DCRNN 的三种变体：1. DCNN：我们拼接历史的观测值为一个固定长度的向量，将它放到堆叠的扩散卷积层中，预测未来的时间序列。我们训练一个模型只预测一步，将之前的预测结果放到模型中作为输入，使用多步前向预测。2. DCRNN-SEQ：使用编码解码序列到序列学习框架做多步预测。3. DCRNN：类似 DCRNN-SEQ ，除了增加了 scheduled sampling。&lt;/p&gt;
&lt;p&gt;图5展示了这四种方法针对 MAE 的对比。我们观察到：1. DCRNN-SEQ 比 DCNN 好很多，符合了对时间建模的重要性。2. DCRNN 达到了最好的效果，随着预测 horizon 的增加，它的先进性变得越来越明显。这主要是因为模型在训练的时候就在处理多步预测时出现的误差，因此会很少的受到误差反向传播的影响。我们也训练了一个总是将输出作为输入扔到模型中的模型。但是它的表现比这三种变体都差，这就强调了 scheduled sampling 的重要性。&lt;/p&gt;
&lt;div align="center"&gt;![Figure5](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig5.JPG)
&lt;h2 id="45-模型的解释性"&gt;4.5 模型的解释性
&lt;/h2&gt;&lt;p&gt;为了更好的理解模型，我们对预测结果和学习到的滤波器进行性了可视化。图6展示了预测1小时的效果。我们观察到了以下情况：1. DCRNN 在交通流速度中存在小的震荡时，用均值生成了平滑的预测结果（图6a）。这反映了模型的鲁棒性。2. DCRNN 比 baseline 方法（如FC-LSTM）更倾向于精确的预测出突变。图6b展示了 DCRNN 预测了高峰时段的起始和终止。这是因为 DCRNN 捕获了空间依赖，能够利用邻居检测器速度的变换来精确预测。图7展示了以不同顶点为中心学习到的滤波器的样例。星表示中心，颜色表示权重。我们可以观察到权重更好的在中心周围局部化，而且权重基于路网距离进行扩散。更多的可视化在附录F。&lt;/p&gt;
&lt;div align="center"&gt;![Figure6](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig6.JPG)
&lt;div align="center"&gt;![Figure7](/blog/images/diffusion-convolutional-recurrent-neural-network-data-driven-traffic-forecasting/Fig7.JPG)
&lt;h1 id="5-conclusion"&gt;5 Conclusion
&lt;/h1&gt;&lt;p&gt;我们对路网上的交通预测做了时空上的建模，提出了 &lt;em&gt;diffusion convolutional recurrent neural network&lt;/em&gt;，可以捕获时空依赖。特别地，我们使用双向随机游走，对空间依赖建模，使用循环神经网络捕获时间的动态性。还继承了编码解码架构和 scheduled sampling 技术来提升长期预测的性能。在两个真实的数据集上评估了性能，我们的方法比 baselines 好很多。未来的工作，1. 使用提出的网络解决其他的时空预测问题；2. 对不断演化的图结构的时空依赖关系建模。&lt;/p&gt;
&lt;h1 id="appendix"&gt;Appendix
&lt;/h1&gt;&lt;h2 id="b-efficient-calculation-of-equation"&gt;B Efficient Calculation Of Equation
&lt;/h2&gt;&lt;p&gt;式2可以分解成两个有相同时间复杂度的部分，一部分是 $\boldsymbol{D}^{-1}_O \boldsymbol{W}$，另一部分是 $\boldsymbol{D}^{-1}_I \boldsymbol{W}^T$。因此我们只研究第一部分的时间复杂度。&lt;/p&gt;
&lt;p&gt;令 $T_k(x) = (\boldsymbol{D}^{-1}_O \boldsymbol{W})^k \boldsymbol{x}$，式2的第一部分可以重写为：
&lt;/p&gt;
$$\tag{4}
\sum^{K-1}\_{k=0} \theta\_k T\_k (X\_{:,p})
$$&lt;p&gt;
因为 $T_{k+1}(x) = \boldsymbol{D}^{-1}_O \boldsymbol{W} T_k(\boldsymbol{x})$ 和 $\boldsymbol{D}^{-1}_O \boldsymbol{W}$ 是稀疏的，可以很容易看出式4可以通过 $O(K)$ 的递归稀疏-稠密矩阵乘法，每次时间复杂度为 $O(\vert \varepsilon \vert)$ 得到。然后，式2和式4的时间复杂度都为 $O(K\vert \varepsilon \vert)$。对于稠密图，我们可以使用 spectral sparsification(Cheng et al., 2015) 使其稀疏。&lt;/p&gt;
&lt;h2 id="c-relation-with-spectral-graph-convolution"&gt;C Relation With Spectral Graph Convolution
&lt;/h2&gt;&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt; 谱图卷积利用归一化的拉普拉斯矩阵 $\boldsymbol{L = D^{-\frac{1}{2}}(D - W)D^{\frac{1}{2}}} = \mathbf{\Phi \Lambda \Phi^T}$。ChebNet 使 $f_\theta$ 参数化为一个 $\Lambda$ 的 $K$ 阶多项式，使用稳定的切比雪夫多项式基计算这个值。
&lt;/p&gt;
$$\tag{5}
\boldsymbol{X}\_{:,p} \star\_\mathcal{G} f\_\theta = \mathbf{\Phi} (\sum^{K-1}\_{k=0} \theta\_k \mathbf{\Lambda}^k) \mathbf{\Phi^T X}\_{:,p} = \sum^{K-1}\_{k=0} \theta\_k \boldsymbol{L}^k \boldsymbol{X}\_{:,p} = \sum^{K-1}\_{k=0} \tilde{\theta}\_k T\_k(\tilde{\boldsymbol{L}})\boldsymbol{X}\_{:,p}
$$&lt;p&gt;
其中 $T_0(x)=1, T_1(x)=x, T_k(x) = xT_{k-1}(x) - T_{k-2}(x)$ 是切比雪夫多项式的基。令 $\lambda_{\mathrm{max}}$ 表示 $\boldsymbol{L}$ 最大的特征值，$\tilde{\boldsymbol{L}} = \frac{2}{\lambda_{\text{max}}} \boldsymbol{L - I}$ 表示将拉普拉斯矩阵的缩放，将特征值从 $[0, \lambda_{\text{max}}]$ 映射到 $[-1, 1]$，因为切比雪夫多项式生成了一个在 $[-1, 1]$ 内正交的基。式5可以看成一个关于 $\tilde{\boldsymbol{L}}$ 的多项式，我们一会儿可以看到，ChebNet 卷积的输出和扩散卷积到常数缩放因子的输出相似。假设 $\lambda_{\text{max}} = 2$，无向图 $\boldsymbol{D}_I = \boldsymbol{D}_O = \boldsymbol{D}$。
&lt;/p&gt;
$$\tag{6}
\tilde{\boldsymbol{L}} = \boldsymbol{D}^{-\frac{1}{2}}(\boldsymbol{D} - \boldsymbol{W}) \boldsymbol{D}^{-\frac{1}{2}} - \boldsymbol{I} = - \boldsymbol{D}^{-\frac{1}{2}} \boldsymbol{W} \boldsymbol{D}^{-\frac{1}{2}} \sim - \boldsymbol{D}^{-1} \boldsymbol{W}
$$&lt;p&gt;
$\tilde{\boldsymbol{L}}$ 和负的随机游走转移矩阵相似，因此式5的输出也和式2直到常数缩放因子的输出相似。&lt;/p&gt;</description></item><item><title>Structured Sequence Modeling With Graph Convolutional Recurrent Networks</title><link>https://davidham3.github.io/blog/p/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/</link><pubDate>Mon, 23 Jul 2018 10:59:15 +0000</pubDate><guid>https://davidham3.github.io/blog/p/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/</guid><description>&lt;p&gt;ICLR 2017(reject)，两个模型，第一个是将数据扔到Defferrard的图卷积里面，然后将输出扔到LSTM里面。第二个模型是将RNN中的矩阵乘法换成了图卷积操作，最后对动态的mnist进行了识别。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1612.07659v1" target="_blank" rel="noopener"
&gt;Structured Sequence Modeling With Graph Convolutional Recurrent Networks&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;GCRN(Graph Convolutional Recurrent Network)，一个可以预测结构化序列数据的深度学习模型。GCRN是传统的循环神经网络的在任意的图结构上的一种泛化形式。这样的结构化数据可以表示成视频中的一系列帧，检测器组成的网络监测到的时空监测值，或是用于自然语言建模的词网中的随机游走。我们提出的模型合并了图上的CNN来辨识空间结构，RNN寻找动态模型。我们研究了两种GCRN，对Penn Treebank数据集进行建模。实验显示同时挖掘图的空间与动态信息可以同时提升precision和学习速度。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 Introduction
&lt;/h1&gt;&lt;p&gt;很多工作，Donahue et al. 2015; Karpathy &amp;amp; Fei-Fei 2015; Vinyals et al. 2015，利用CNN和RNN的组合来挖掘时空规律性。这些模型那个处理时间变化的视觉输入来做变长的预测。这些网络架构由视觉特征提取的CNN，和一个在CNN后面，用于序列学习的RNN组成。这样的架构成功地用于视频活动识别，图像注释生成以及视频描述。&lt;/p&gt;
&lt;p&gt;最近，大家开始对时空序列建模时融合CNN和RNN感兴趣。受到语言模型的启发，Ranzato et al. 2014提出了通过发现时空相关性的能表示复杂变形和动作模式的模型。他们的实验表明在通过quantizing the image patches获得到的visual words上，使用RNN建模，可以很好的预测视频的下一帧以及中间帧。他们的表现最好的模型是recursive CNN(rCNN)，对输入和状态同时使用卷积。Shi et al. 2015之后提出了卷积LSTM(convLSTM)，一个使用2D卷积利用输入数据的空间相关性，用于时空序列建模的RNN模型。他们成功的对降雨临近预报的雷达回波图的演化进行了预测。&lt;/p&gt;
&lt;p&gt;很多重要问题中，空间结构不是简单的网格状。气象站就不是网格状。而且空间结构不一定是空间上的，如社交网络或生物网络。最后，Mikolov et al. 2013等人认为，句子可以解释成在词网上的随机游走，使得我们转向了分析图结构的句子建模问题。&lt;/p&gt;
&lt;p&gt;我们的工作利用了近期的模型——Defferrard et al. 2016; Ranzato et al. 2014; Shi et al. 2015——来设计GCRN模型对时间变化的图结构数据建模和预测。核心思想是融合图结构上的CNN和RNN来同时辨识空间结构和动态模式。图1给出了GCRN的架构。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;h1 id="2-preliminaries"&gt;2 Preliminaries
&lt;/h1&gt;&lt;h2 id="21-structured-sequence-modeling"&gt;2.1 Structured Sequence Modeling
&lt;/h2&gt;&lt;p&gt;序列建模是给定前$J$个观测值，对未来最可能的长度为$K$的序列进行预测：
&lt;/p&gt;
$$\tag{1}
\hat{x}\_{t+1},...,\hat{x}\_{t+K} = \mathop{\mathrm{argmax}}\limits\_{x\_{t+1},...,x\_{t+K}}P(x\_{t+1},...,x\_{t+K} \mid x\_{t-J+1},...,x\_t),
$$&lt;p&gt;
$x_t \in \mathbf{D}$是时间$t$的观测值，$\mathbf{D}$表示观测到的特征的域。原型应用是$n-\mathrm{gram}$模型$(n = J + 1)$，$P(x_{t+1} \mid x_{t-J+1},&amp;hellip;,x_t)$对在句子中给定过去$J$个词时$x_{t+1}$出现的概率进行建模。&lt;/p&gt;
&lt;p&gt;我们感兴趣的是特别的结构化的句子，也就是句子中$x_t$的特征不是相互独立的，而是有着两两相连的关系。这样的关系广义上通过带权图建模。&lt;/p&gt;
&lt;p&gt;$x_t$可以看作是一个图信号，也就是一个定义在无向带权图$\mathcal{G} = ( \mathcal{V}, \Large{\varepsilon}, \normalsize{A )}$，其中$\mathcal{V}$是$\vert \mathcal{V} \vert = n$个顶点的有限集，$\Large{\varepsilon}$是边集，$A \in \mathbb{R}^{n \times n}$是带权邻接矩阵，编码了两个顶点之间的连接权重。定义在图的顶点上的信号$x_t: \mathcal{V} \rightarrow \mathbb{R}^{d_x}$可以当作是一个矩阵$x_t \in \mathbb{R}^{n \times d_x}$，列$i$是$d_x$维向量，表示$x_t$在第$i$个顶点的值。尽管自由变量的数量在长度为$K$的结构化序列中本质上是$\mathcal{O}(n^K{d_x}^K)$，我们仍然试图去挖掘可能的预测结果的空间结构以减少维度，来使这些问题变得容易解决。&lt;/p&gt;
&lt;h2 id="22-long-short-term-memory"&gt;2.2 Long Short-Term Memory
&lt;/h2&gt;&lt;p&gt;防止梯度过快消失，由Hochreiter &amp;amp; Schmidhuber 1997发明的一种RNN，LSTM。这个模型已经被证明在各种序列建模任务中，对长期依赖关系是稳定且强劲的模型(Graves, 2013; Srivastava et al., 2015; Sutskever et al., 2014)。全连接LSTM(FC-LSTM)可以看作是一个多变量版本的LSTM，其中$x_t \in \mathbb{R}^d_x$是输入，$h_t \in [-1, 1]^{d_h}$是细胞状态，$c_t \in \mathbb{R}^{d_h}$是隐藏状态，他们都是向量。我们使用Graves 2013的FC-LSTM：
&lt;/p&gt;
$$\tag{2}
i = \sigma(W\_{xi} x\_t + W\_{hi}h\_{t-1} + w\_{ci} \odot c\_{t-1} + b\_i),\\
f = \sigma(W\_{xf} x\_t + W\_{hf} h\_{t-1} + w\_{cf} \odot c\_{t-1} + b\_f),\\
c\_t = f\_t \odot c\_{t-1} + i\_t \odot \mathrm{tanh}(W\_{xc} x\_t + W\_{hc} h\_{t-1} + b\_c),\\
o = \sigma(W\_{xo} x\_t + W\_{ho} h\_{t-1} + w\_{co} \odot c\_t + b\_o),\\
h\_t = o \odot \mathrm{tanh}(c\_t),
$$&lt;p&gt;
其中$\odot$表示Hadamard product，$\sigma(\cdot)$表示sigmoid function $\sigma(x) = 1/(1+e^{-x})$，$i,f,o \in [0, 1]^{d_h}$是输入门，遗忘门，输出门。权重$W_{x\cdot} \in \mathbb{R}^{d_h \times d_x}$，$W_{h\cdot} \in \mathbb{R}^{d_h \times d_h}$，$w_{c\cdot} \in \mathbb{R}^{d_h}$，偏置$b_i,b_f,b_c,b_o \in \mathbb{R}^{d_h}$是模型参数。这个模型之所以称为全连接是因为$W_{x\cdot}$和$W_{h\cdot}$与$x$和$h$所有分量进行线性组合。由Gers &amp;amp; Schmidhuber 2000引入可选的peephole connections $w_{c\cdot} \odot c_t$，在某些特定任务上可以提升性能。&lt;/p&gt;
&lt;h2 id="23-convolutional-neural-networks-on-graphs"&gt;2.3 Convolutional Neural Networks On Graphs
&lt;/h2&gt;&lt;p&gt;Defferrard et al., 2016选择了谱上的卷积操作：
&lt;/p&gt;
$$\tag{3}
y = g\_\theta \ast\_\mathcal{G} x = g\_\theta (L)x = g\_\theta (U \Lambda U^T)x = U g\_\theta (\Lambda) U^T x \in \mathbb{R}^{n \times d\_x},
$$&lt;p&gt;
对于归一化的拉普拉斯矩阵$L = I_n - D^{-1/2} A D^{-1/2} = U \Lambda U^T \in \mathbb{R}^{n \times n}$来说，$U \in \mathbb{R}^{n \times n}$是矩阵的特征向量，$\Lambda \in \mathbb{R}^{n \times n}$是特征值的对角矩阵。式3的时间复杂度很高，因为$U$的乘法的时间复杂度是$\mathcal{O}(n^2)$。此外，计算$L$的特征值分解对于大的图来说很慢。Defferrard et al., 2016使用切比雪夫多项式：
&lt;/p&gt;
$$\tag{4}
g\_\theta(\Lambda) = \sum^{K-1}\_{k=0} \theta\_k T\_k(\tilde{\Lambda}),
$$&lt;p&gt;
参数$\theta \in \mathbb{R}^K$是切比雪夫系数的向量，$T_k(\tilde{\Lambda}) \in \mathbb{R}^{n \times n}$是切比雪夫多项式的k阶项在$\tilde{\Lambda} = 2\Lambda/\lambda_{max} - I_n$的值。图卷积操作可以写为：
&lt;/p&gt;
$$\tag{5}
y = g\_\theta \ast\_{\mathcal{G}} x = g\_\theta (L) x = \sum^{K-1}\_{k=0} \theta\_k T\_k (\tilde{L})x,
$$&lt;p&gt;
$T_0 = 1$，$T_1 = x$，$T_k(x) = 2xT_{k-1}(x)-T_{k-2}(x)$，时间复杂度是$\mathcal{O}(K \vert \Large{\varepsilon} \normalsize \vert)$，也就是和边数相关。这个图卷积是$K$阶局部化的。&lt;/p&gt;
&lt;h1 id="3-related-works"&gt;3 Related Works
&lt;/h1&gt;&lt;p&gt;Shi et al. 2015提出了针对常规网格结构的序列的模型，可以看作是图是图像网格且顶点有序的特殊情况。他们的模型本质上是FC-LSTM，$W$的乘法替换为卷积核$W$：
&lt;/p&gt;
$$\tag{6}
i = \sigma(W\_{xi} \ast x\_t + W\_{hi} \ast h\_{t-1} + w\_{ci} \odot c\_{t-1} + b\_i),\\
f = \sigma(W\_{xf} \ast x\_t + W\_{hf} \ast h\_{t-1} + w\_{cf} \odot c\_{t-1} + b\_f),\\
c\_t = f\_t \odot c\_{t-1} + i\_t \odot \mathrm{tanh}(W\_{xc} \ast x\_t + W\_{hc} \ast h\_{t-1} + b\_c),\\
o = \sigma(W\_{xo} \ast x\_t + W\_{ho} \ast h\_{t-1} + w\_{co} \odot c\_t + b\_o),\\
h\_t = o \odot \mathrm{tanh}(c\_t),
$$&lt;p&gt;
$\ast$表示一组卷积核的2D卷积。在他们的设定中$x_t \in \mathbb{R}^{n_r \times n_c \times d_x}$是一个动态系统中，时间$t$的$d_x$的观测值，这个动态系统建立在一个表示为$n_r$行$n_c$列的空间区域上。模型有着空间分布的隐藏核细胞状态，大小是$d_h$，由张量$c_t$体现，$h_t \in \mathbb{R}^{n_r \times n_c \times d_h}$。卷积核$W_{h\cdot} \in \mathbb{R}^{m \times m \times d_h \times d_h}$和$W_{x\cdot} \in \mathbb{R}^{m \times m \times d_h \times d_x}$的尺寸$m$决定了参数的数量，与网格大小$n_r \times n_c$无关。更早一点，Ranzato et al. 2014提出了相似的RNN变体，使用卷积层而不是全连接层。时间$t$的隐藏状态：
&lt;/p&gt;
$$\tag{7}
h\_t = \mathrm{tanh}(\sigma(W\_{x2} \ast \sigma(W\_{x1} \ast x\_t)) + \sigma(W\_h \ast h\_{t-1})),
$$&lt;p&gt;
卷积核$W_h \in \mathbb{R}^{d_h \times d_h}$受限到$1 \times 1$的大小。&lt;/p&gt;
&lt;p&gt;观察到自然语言表示出语法性质，自然的将词融入短语中，Tai et al. 2015提出了一个处理树结构的模型，每个LSTM可以获取他们的孩子的状态。他们在semantic relatedness and sentiment classification上获得了state-of-the-art的结果。Liang et al. 2016在之后提出了在图上的变体。他们复杂的网络结构在4个数据集上获得了semantic object parsing的state-of-the-art结果。这些模型中，状态通过一个可训练的权重矩阵的带权加和从邻居上聚集。然而这些权重并不在图上共享，否则需要对顶点排序，就像其他图卷积的空间定义一样。此外，他们的公式受限于当前顶点的一阶邻居，给其他的邻居相同的权重。&lt;/p&gt;
&lt;p&gt;受到如人体动作和物体交互等时空任务的启发，Jain et al 2016提出了一个方法将时空图看作是一个富RNN的混合，本质上是将一个RNN连接到每个顶点与每条边上。同样的，通信受限于直接连接的顶点与边。&lt;/p&gt;
&lt;p&gt;和我们的工作最相关的模型可能是Li et al 2015提出的模型，在program verification上表现出了最好的结果。尽管他们使用Scarselli et al. 2009提出的GNN，以迭代的步骤传播顶点的表示，直到收敛，我们使用的是Defferrard et al. 2016提出的GCN在顶点间扩散信息。尽管他们的动机和我们很不一样，这些模型的关联是使用$K$阶多项式定义的谱滤波器可以实现成一个$K$层的GNN。&lt;/p&gt;
&lt;h1 id="4-proposed-gcrn-models"&gt;4 Proposed GCRN Models
&lt;/h1&gt;&lt;p&gt;我们提出了两种GCRN架构&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model 1.&lt;/strong&gt;
&lt;/p&gt;
$$\tag{8}
x^{\mathrm{CNN}}\_t = \mathrm{CNN}\_\mathcal{G}(x\_t)\\
i = \sigma(W\_{xi} x^{\mathrm{CNN}}\_t + W\_{hi}h\_{t-1} + w\_{ci} \odot c\_{t-1} + b\_i),\\
f = \sigma(W\_{xf} x^{\mathrm{CNN}}\_t + W\_{hf} h\_{t-1} + w\_{cf} \odot c\_{t-1} + b\_f),\\
c\_t = f\_t \odot c\_{t-1} + i\_t \odot \mathrm{tanh}(W\_{xc} x^{\mathrm{CNN}}\_t + W\_{hc} h\_{t-1} + b\_c),\\
o = \sigma(W\_{xo} x^{\mathrm{CNN}}\_t + W\_{ho} h\_{t-1} + w\_{co} \odot c\_t + b\_o),\\
h\_t = o \odot \mathrm{tanh}(c\_t).
$$&lt;p&gt;
我们简单地写成$x^{\mathrm{CNN}}_t = W^{\mathrm{CNN}} \ast_\mathcal{G} x_t$，其中$W^{\mathrm{CNN}} \in \mathbb{R}^{K \times d_x \times d_x}$是切比雪夫系数。Peepholes由$w_{c\cdot} \in \mathbb{R}^{n \times d_h}$控制。这样的架构可能足以捕获数据的分布，通过挖掘局部静止性以及性质的组合性，还有动态属性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model 2.&lt;/strong&gt;
&lt;/p&gt;
$$\tag{9}
i = \sigma(W\_{xi} \ast\_\mathcal{G} x\_t + W\_{hi} \ast\_\mathcal{G} h\_{t-1} + w\_{ci} \odot c\_{t-1} + b\_i),\\
f = \sigma(W\_{xf} \ast\_\mathcal{G} x\_t + W\_{hf} \ast\_\mathcal{G} h\_{t-1} + w\_{cf} \odot c\_{t-1} + b\_f),\\
c\_t = f\_t \odot c\_{t-1} + i\_t \odot \mathrm{tanh}(W\_{xc} \ast\_\mathcal{G} x\_t + W\_{hc} \ast\_\mathcal{G} h\_{t-1} + b\_c),\\
o = \sigma(W\_{xo} \ast\_\mathcal{G} x\_t + W\_{ho} \ast\_\mathcal{G} h\_{t-1} + w\_{co} \odot c\_t + b\_o),\\
h\_t = o \odot \mathrm{tanh}(c\_t),
$$&lt;p&gt;
图卷积核是切比雪夫系数$W_{h\cdot} \in \mathbb{R}^{K \times d_h \times d_h}$，$W_{x\cdot} \in \mathbb{R}^{K \times d_h \times d_x}$决定了参数的数目，与顶点数$n$无关。
这种RNN和CNN的混合，不限于LSTM。普通的RNN $h_t = \mathrm{tanh}(W_x x_t + W_h h_{t-1})$可以写为：
&lt;/p&gt;
$$\tag{10}
h\_t = \mathrm{tanh}(W\_x \ast\_\mathcal{G} x\_t + W\_h \ast\_\mathcal{G} h\_{t-1}),
$$&lt;p&gt;
GRU的版本可以写为：
&lt;/p&gt;
$$\tag{11}
z = \sigma(W\_{xz} \ast\_\mathcal{G} x\_t + W\_{hz} \ast\_\mathcal{G} h\_{t-1}),\\
r = \sigma(W\_{xr} \ast\_\mathcal{G} x\_t + W\_{hr} \ast\_\mathcal{G} h\_{t-1}),\\
\tilde{h} = \mathrm{tanh}(W\_{xh} \ast\_\mathcal{G} x\_t + W\_{hh} \ast\_\mathcal{G} (r \odot h\_{t-1})),\\
h\_t = z \odot h\_{t-1} + (1 - z) \odot \tilde{h}.
$$&lt;h1 id="5-experiments"&gt;5 Experiments
&lt;/h1&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;数据集是moving-MNIST(Shi et al., 2015)。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/structured-sequence-modeling-with-graph-convolutional-recurrent-networks/Fig3.JPG"
loading="lazy"
alt="“Figure3 &amp; Figure4”"
&gt;&lt;/p&gt;</description></item><item><title>GCN论文汇总</title><link>https://davidham3.github.io/blog/p/gcn%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB/</link><pubDate>Mon, 23 Jul 2018 09:29:28 +0000</pubDate><guid>https://davidham3.github.io/blog/p/gcn%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB/</guid><description>&lt;p&gt;对看过的图神经网络做个总结，目前主要是GCN。&lt;/p&gt;
&lt;p&gt;Semi-Supervised Classification With Graph Convolutional Networks. Kipf &amp;amp; Welling 2017&lt;br&gt;
ICLR 2017。使用切比雪夫多项式的1阶近似完成了高效的图卷积架构。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;优点&lt;/th&gt;
&lt;th style="text-align: center"&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;1阶近似，比k阶近似高效&lt;/td&gt;
&lt;td style="text-align: center"&gt;卷积需使用整个图的拉普拉斯矩阵，图不能扩展&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Convolution on Graph: A High-Order and Adaptive Approach.&lt;br&gt;
NIPS 2016，重新定义了卷积的定义，利用k阶邻接矩阵，定义考虑k阶邻居的卷积，利用邻接矩阵和特征矩阵构建能同时考虑顶点特征和图结构信息的卷积核。在预测顶点、预测图、生成图三个任务上验证了模型的效果。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;优点&lt;/th&gt;
&lt;th style="text-align: center"&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Graph Convolutional Neural Networks for Web-Scale Recommender Systems.&lt;br&gt;
KDD 2018。使用图卷积对顶点进行表示，学习顶点的embedding，通过卷积将该顶点的邻居信息融入到向量中。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;优点&lt;/th&gt;
&lt;th style="text-align: center"&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;超大规模的图&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Diffusion-Convolutional Neural Networks.&lt;br&gt;
NIPS 2016。在卷积操作中融入了h-hop转移概率矩阵，通过对每个顶点计算该顶点到其他所有顶点的转移概率与特征矩阵的乘积，构造顶点新的特征表示，即diffusion-convolutional representation，表征顶点信息的扩散，然后乘以权重矩阵W，加激活函数，得到卷积的定义。在顶点分类和图分类上做了测试。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;优点&lt;/th&gt;
&lt;th style="text-align: center"&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;没有增加模型的复杂度&lt;/td&gt;
&lt;td style="text-align: center"&gt;空间复杂度高&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;使用转移概率矩阵&lt;/td&gt;
&lt;td style="text-align: center"&gt;模型不能捕获尺度较大的空间依赖关系&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;&lt;/td&gt;
&lt;td style="text-align: center"&gt;不同的分类任务（顶点、图）有不同的卷积表达式&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Graph Attention Networks.&lt;br&gt;
ICLR 2018。图注意力网络，使用self-attention来构建graph attentional layer，attention会考虑当前顶点所有的邻居对它的重要度，基于谱理论的模型不能应用到其他不同结构的图上，而这个基于attention的方法能有效的解决这个问题。&lt;/p&gt;
&lt;p&gt;Inductive Representation Learning on Large Graphs.&lt;br&gt;
NIPS 2017。提出的方法叫GraphSAGE，针对的问题是之前的NRL是transductive，作者提出的GraphSAGE是inductive。主要考虑了如何聚合顶点的邻居信息，对顶点或图进行分类。&lt;/p&gt;
&lt;p&gt;应用：&lt;/p&gt;
&lt;p&gt;Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic.&lt;br&gt;
IJCAI 2018，大体思路：使用Kipf &amp;amp; Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。&lt;/p&gt;
&lt;p&gt;Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition.&lt;br&gt;
AAAI 2018，以人体关节为图的顶点，构建空间上的图，然后通过时间上的关系，连接连续帧上相同的关节，构成一个三维的时空图。针对每个顶点，对其邻居进行子集划分，每个子集乘以对应的权重向量，得到时空图上的卷积定义。实现时使用Kipf &amp;amp; Welling 2017的方法实现。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;优点&lt;/th&gt;
&lt;th style="text-align: center"&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;将空间和时间一体化&lt;/td&gt;
&lt;td style="text-align: center"&gt;实现上仍是Kipf &amp;amp; Welling的方法&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description></item><item><title>复杂网络基础</title><link>https://davidham3.github.io/blog/p/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 21 Jul 2018 18:10:09 +0000</pubDate><guid>https://davidham3.github.io/blog/p/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</guid><description>&lt;p&gt;觉得最近应该把复杂网络的基础知识捡一捡，去年上课虽然学过，不过基本都忘了，什么betweeness，都不知道是什么了。最近要做复杂网络方面的研究，这些知识是必需的。打算看一下Newman的书&amp;quot;Networks an Introduction&amp;quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么我们对复杂网络感兴趣？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;很多系统都是由网络组成的。因特网，人类社会都是。有人研究个体组成，即顶点的性质，有人研究关系，即连接，还有人研究这些系统，也就是components和connections之间的&lt;em&gt;pattern&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;特殊的模式会在系统中产生很大影响。除非我们知道网络结构，否则很难完全理解整个系统如何工作。&lt;/p&gt;
&lt;p&gt;网络是对一个系统的简单表示，只有基本的连接模式和其他的一点东西。顶点和边可以标记上额外的信息，来详细描述这个系统，但是在表示网络的时候通常会丢失信息。这就是它的缺点，但是也有优点。&lt;/p&gt;
&lt;p&gt;这些年来，科学家们使用数学、计算机、统计学方法对复杂网络进行分析、建模、理解。很多工具从一个简单的网络表示开始，一组顶点和边，在适当的计算后会得到一些有用的信息：比如哪个是最好的顶点，或是一个顶点到另一个顶点的路径长度。其他工具使用可以做预测的网络的形式，比如互联网流量或传染病在社区内扩散的途径。因为这些工具是在抽象形式下工作，所以理论上可以应用到任何可以表示成网络的系统上。因此如果你感兴趣的系统可以表示成网络，那就有很多工具可以使用。当然不是所有的工具都能给出有效的结果，有些方法是用在特定问题上的。但是如果你有一个关于网络的well-posed question，大多数型框架，还是有一个可以解决这个问题的工具的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一些网络的例子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/%e5%a4%8d%e6%9d%82%e7%bd%91%e7%bb%9c%e5%9f%ba%e7%a1%80/Fig1.1.JPG"
loading="lazy"
alt="Figure1"
&gt;
&lt;img src="https://davidham3.github.io/blog/images/%e5%a4%8d%e6%9d%82%e7%bd%91%e7%bb%9c%e5%9f%ba%e7%a1%80/Fig1.1-2.JPG"
loading="lazy"
alt="Figure1"
&gt;
最出名的且广泛研究的网络之一就是好论文。计算机组成的网络，计算机是顶点，物理数据连接是边，如光纤或电话线。图1.1展示了互联网的结构，2003年的一个snapshot，通过数据包的流通构建的网络。尽管互联网是人工制造的，而且是很细致的工程，但是我们并不知道它的结构是什么，因为它是由很多不同的人群构建出来的，大家并不了解其他人的行动，很少有中央控制。&lt;/p&gt;
&lt;p&gt;有很多令人激动的实用原因让我们想研究因特网的结构。因特网的功能是在不同地方的计算机之间传播数据，他们会将数据分成片或包，然后再网络中的顶点间传送，直到这些包到达他们的目的地。网络的结构会影响他们完成这些任务的效率，而且如果我们直到网络的结构，我们可以解决很多实际问题。我们应该选择哪个路由来传输数据？最短路径总是最快的吗？如果不是，怎么才能找到最快的？我们怎么避免bottleneck使流量阻塞？当一个顶点或一条边挂掉时会发生什么？等等问题。&lt;/p&gt;
&lt;p&gt;因特网结构的知识在研发新的通讯标准中是至关重要的。新的标准和协议还是为因特网所设计，老的会被翻新。协议的参数会为了网络的结构而优化。在网络的早些时候，不是网络结构的主要模型在调整过程中使用，而是那些更好的结构数据变得可获得后，我们可以更好的理解这些数据并且提升模型的性能。&lt;/p&gt;</description></item><item><title>Inductive Representation Learning on Large Graphs</title><link>https://davidham3.github.io/blog/p/inductive-representation-learning-on-large-graphs/</link><pubDate>Thu, 19 Jul 2018 18:53:17 +0000</pubDate><guid>https://davidham3.github.io/blog/p/inductive-representation-learning-on-large-graphs/</guid><description>&lt;p&gt;NIPS 2017。提出的方法叫 GraphSAGE，针对的问题是之前的 NRL 是 transductive，不能泛化到新结点上，而作者提出的 GraphSAGE 是 inductive。主要考虑了如何聚合顶点的邻居信息，对顶点或图进行分类。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1706.02216" target="_blank" rel="noopener"
&gt;Inductive Representation Learning on Large Graphs&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="abstract"&gt;Abstract
&lt;/h1&gt;&lt;p&gt;现存的方法需要图中所有的顶点在训练 embedding 的时候都出现；这些前人的方法本质是 &lt;em&gt;transductive&lt;/em&gt;，不能自然地泛化到未见过的顶点上。我们提出了 GraphSAGE，一个 &lt;em&gt;inductive&lt;/em&gt; 框架，利用顶点特征信息（比如文本属性）来高效地为没有见过的顶点生成 embedding。与其为每个顶点训练单独的 embedding，我们的方法是学习一个函数，这个函数通过从一个顶点的局部邻居采样并聚合顶点特征。我们的算法在三个 inductive 顶点分类数据集上超越了那些很强的 baseline：在 citation 和 Reddit post 数据的演化的信息图中对未见过的顶点分类，在 PPI 多图数据集上可以泛化到完全未见过的图上。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 Introduction
&lt;/h1&gt;&lt;p&gt;顶点嵌入的基本思想是使用降维技术从高维信息中提炼一个顶点的邻居信息，存到低维向量中。这些顶点嵌入之后会作为后续的机器学习系统的输入，解决像顶点分类、聚类、链接预测这样的问题。&lt;/p&gt;
&lt;p&gt;然而，前人的工作专注于对一个固定的图中的顶点进行表示，很多真实的应用需要很快的对未见过的顶点或是全新的图（子图）生成 embedding。这个推断的能力对于高吞吐的机器学习系统来说很重要，这些系统都运作在不断演化的图上，而且时刻都会遇到未见过的顶点（比如 Reddit 上的文章，Youtube 上的用户或视频）。一个生成顶点 embedding 的推断方法也会帮助在拥有同样形式特征的图上进行泛化：举个例子，我们可以从一个有机物得到的 PPI 图上训练一个 embedding 生成器，然后很简单的使用这个模型利用新的有机物上收集的数据生成他们的顶点嵌入。&lt;/p&gt;
&lt;p&gt;对比 transductive 问题，推断顶点嵌入问题很困难，因为泛化未见过的顶点需要将新观测到的子图“对齐”到算法已经优化好的顶点嵌入上。一个推断模型必须学习到可以识别一个顶点邻居的结构性质，这个性质既反映了顶点在图中的局部角色，也反映了它的全局位置。&lt;/p&gt;
&lt;p&gt;很多现存的生成顶点嵌入的方法是继承于 transductive。这些方法的主流是直接使用矩阵分解目标函数对每个顶点的 embedding 进行优化，因为他们在一个固定的单个图上的顶点做预测，所以不能自然地泛化到未见过的数据。这些方法可以被修改然后在 inductive 问题上运行，但是这些修改往往计算复杂度高，在新的预测之前需要额外的梯度下降优化。当然也有一些在图结构上使用卷积神经网络的方法，在 embedding 上表现的很好。迄今为止，GCN 只在固定的图上的 transductive 问题上应用过。我们工作是扩展了 GCN 到无监督推断任务上，同时还提出了一个方法，可以让 GCN 使用可训练的聚合函数（并不是只有简单的卷积）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Present work.&lt;/strong&gt; 我们提出了一个通用的框架，叫 GraphSAGE(SAmple and aggreGatE)，用于学习 inductive node embedding。不像基于矩阵分解的嵌入方法，我们利用了顶点特征（比如文本属性，顶点信息，顶点的度）来学习可以生成未见过的顶点的嵌入的函数。通过在算法中结合顶点信息，我们同时学习了每个顶点邻居的拓扑结构和顶点特征在邻居中的分布。尽管我们的研究更专注于富特征的图（如有文本信息的引文网络，有功能/分子组成的生物数据），我们的方法仍能充分利用所有图展现的结构特征（比如顶点的度）。因此我们的算法可以应用在没有顶点特征的图上。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/inductive-representation-learning-on-large-graphs/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;我们没有对每个顶点都训练一个单独的 embeddding，我们训练了一组 &lt;em&gt;aggregator functions&lt;/em&gt;，这些函数学习如何从一个顶点的局部邻居聚合特征信息（图1）。每个聚合函数从一个顶点的不同搜索深度聚合信息。测试的时候，或是说推断的时候，我们使用我们训练的系统来对完全未见过的顶点，通过使用学习到的聚合函数来生成 embedding。跟随着前人在生成顶点上的工作，我们设计了无监督的损失函数，使得 GraphSAGE 可以在没有任务监督的情况下训练。我们也展示了如何使用监督的方法训练 GraphSAGE。&lt;/p&gt;
&lt;p&gt;我们在三个顶点分类数据集上评估了我们的算法，测试了 GraphSAGE 在未见过的数据上生成有效 embedding 的能力。使用了两个基于 citation 数据和 Reddit post 数据的演化网络（分别预测 paper 和 post 类别），还有一个基于 PPI 的多图泛化实验（预测蛋白质功能）。我们的方法效果很好，跨领域，监督的方法在 F1 值上对比只使用顶点特征的方法平均提高了 51%，而且 GraphSAGE 一直都比 transductive baseline 强很多，尽管 baseline 在未见过的顶点上的运行时间要长 100 倍以上。我们提出的新的聚合结构比受图卷积启发的聚合函数更好（平均提升了 7.4%）。最后我们通过实验证明了我们方法的表达能力，尽管 GraphSAGE 是基于特征的，它却能学习到一个顶点在一个图中的结构信息，（第 5 部分）。&lt;/p&gt;
&lt;h1 id="2-related-work"&gt;2 Related work
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Factorization-based embedding approaches.&lt;/strong&gt; 最近的 node embedding 方法使用随机游走的统计和矩阵分解的目标函数。这些方法和传统的方法如谱聚类，multi-dimensional scaling，PageRank 关系很近。因为这些嵌入方法对每个顶点直接训练 embedding，本质上是 transductive，而且需要大量的额外训练（如随机梯度下降）使他们能预测新的顶点。此外，这些方法中的大部分方法，目标函数对于 embedding 的正交变换是不变的，意味着嵌入空间不能自然地在图之间泛化，而且在再次训练的时候会 drift。一个值得注意的例外是 Yang et al. 的 Planetoid-I 算法，是一个 inductive 的方法，基于嵌入的半监督学习。然而，Planetoid-I 在推断的时候不使用任何图结构信息，而在训练的时候将图结构作为一种正则化的形式。不同于前面提到的这些方法，我们是利用特征信息训练可以对未见过的顶点生成 embedding 的模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervised learning over graphs.&lt;/strong&gt; 除了顶点嵌入方法，还有很多在图结构数据上的监督学习方法。包括很多核方法，图的特征向量从多个图的核得到。最近有很多用于图结构的监督学习的神经网络方法。我们的方法从概念上是受到了这些方法的启发。然而，这些方法试图对整个图（或子图）进行分类，我们的工作关注的是如何对单个顶点生成有效的表示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph convolutional networks.&lt;/strong&gt; 近些年，一些用于图的卷积神经网络被相继提出。这些方法中的大部分不能扩展到大的图上，或者是为了整个图的分类而设计（或是两点都有）。我们的方法与 Kipf et al. 提出的图卷积很相关，GCN 在训练的时候需要整个图的拉普拉斯矩阵。我们算法的一个简单的变体可以看作是 GCN 框架在 inductive setting 上的扩展，我们会在 3.3 说明。&lt;/p&gt;
&lt;h1 id="3-graphsage"&gt;3 GraphSAGE
&lt;/h1&gt;&lt;p&gt;我们的核心思想在于如何从一个顶点的局部邻居聚合特征信息（比如度或近邻顶点的文本特征）。3.1 描述 embedding 的生成算法。3.2 描述随机梯度下降学习参数。&lt;/p&gt;
&lt;h2 id="31-embedding-generation-ie-forward-propagation-algorithm"&gt;3.1 Embedding generation (i.e., forward propagation) algorithm
&lt;/h2&gt;&lt;p&gt;假设已经学习到了 $K$ 个聚合函数（表示为 $AGGERGATE_k, \forall k \in \lbrace 1,&amp;hellip;,K\rbrace$ ）的参数，对顶点的信息聚合，还有一组权重矩阵 $\mathbf{W}^k, \forall k \in \lbrace 1,&amp;hellip;,K\rbrace$，用来在模型的不同层或搜索深度间传播信息。下一节描述参数是怎么训练的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/inductive-representation-learning-on-large-graphs/Alg1.JPG"
loading="lazy"
alt="Algo1"
&gt;&lt;/p&gt;
&lt;p&gt;算法 1 的思路是在每次迭代，或每一个搜索深度，顶点从他们的局部邻居聚合信息，而且随着这个过程的迭代，顶点会从越来越远的地方获得信息。&lt;/p&gt;
&lt;p&gt;算法 1 描述了在各整个图上生成 embedding 的过程，$\mathcal{G} = \left( \mathcal{V}, \Large{\varepsilon} \right)$，以及所有顶点的特征$X_v, \forall v \in \mathcal{V}$作为输入。在算法 1 最外层循环的每一步如下，$k$ 表示外循环（或搜索深度）的当前步，$\mathbf{h}^k$ 表示当前这步的一个顶点的表示：首先，每个顶点 $v \in \mathcal{V}$聚合了在它在中间邻居的表示，$\lbrace \mathbf{h}^{k-1}_u, \forall u \in \mathcal{N}(u) \rbrace$，聚合到向量$\mathbf{h}^{k-1}_{\mathcal{N}(v)}$中。注意，这个聚合步骤依赖于外循环前一次迭代生成的表示（比如$k - 1$），$k = 0$表示输入的顶点特征。聚合邻居特征向量后，GraphSAGE之后拼接了顶点当前的表示，$\mathbf{h}^{k-1}_v$，核聚合的邻居向量一起，$\mathbf{h}^{k-1}_{\mathcal{N}(v)}$，拼接后的向量输入到了激活函数为$\sigma$的全连接层中，将表示变换为下一步使用的形式（$\mathbf{h}^k_v, \forall v \in \mathcal{V}$）。为了记号的简单，我们将深度为$K$的输出表示记为$\mathbf{z} \equiv \mathbf{h}^K_v, \forall v \in \mathcal{V}$。邻居表示的聚合可以通过多个聚合架构得到（在算法1中表示为$\mathrm{AGGERGATE}$），我们会在3.3讨论不同的架构。&lt;/p&gt;
&lt;p&gt;为了将算法1扩展到minibatch设定上，给定一组输入顶点，我们先采样采出需要的邻居集合（到深度$K$），然后运行内部循环（算法1的第三行），但不是迭代所有的顶点，我们在每个深度只计算必须满足的表示（后记A包括了完整的minibatch伪代码）。&lt;/p&gt;
&lt;h2 id="32-learning-the-parameters-of-graphsage"&gt;3.2 Learning the parameters of GraphSAGE
&lt;/h2&gt;&lt;p&gt;为了在半监督设定下学习一个有效的表示，我们使用基于图的损失函数来输出表示$\mathbf{z}_u, \forall u \in \mathcal{V}$，调整权重矩阵$\mathbf{W}^k, \forall k \in \lbrace 1,&amp;hellip;,K\rbrace$，聚合函数的参数通过随机梯度下降训练。基于图的损失函数倾向于使得相邻的顶点有相似的表示，尽管这会使相互远离的顶点的表示很不一样：
&lt;/p&gt;
$$\tag{1}
J\mathcal{G}(\mathbf{z}\_u) = -\log(\sigma(\mathbf{z}^T\_u \mathbf{z}\_v)) - Q \cdot \mathbb{E}\_{v\_n \sim P\_n(v)} \log(\sigma(-\mathbf{z}^T\_u \mathbf{z}\_{v\_n})),
$$&lt;p&gt;
其中$v$是通过定长随机游走得到的$u$旁边的共现顶点，$\sigma$是sigmoid函数，$P_n$是负采样分布，$Q$定义了负样本的数目。重要的是，不像之前的那些方法，我输入到损失函数的表示$\mathbf{z}_u$是从包含一个顶点局部邻居的特征生成出来的，而不是对每个顶点训练一个独一无二的embedding（通过一个embedding查询表）。&lt;/p&gt;
&lt;p&gt;这个无监督设定模拟了顶点特征提供给后续机器学习应用的情况。在那些表示只在后续的任务中使用的情况下，无监督损失（式1）可以被替换或改良，通过一个以任务为导向的目标函数（比如cross-entropy）。&lt;/p&gt;
&lt;h2 id="33-聚合架构"&gt;3.3 聚合架构
&lt;/h2&gt;&lt;p&gt;不像在$N$维网格（如句子、图像、$3\rm{D}$）上的机器学习，一个顶点的邻居是无序的；因此，算法1中的聚合函数必须在以一个无序的向量上运行。理想上来说，一个聚合函数需要是对称的（也就是对它输入的全排列来说是不变的），而且还要可训练，且保持表示的能力。聚合函数的对称性之确保了我们的神经网络模型可以被训练且可以应用于任意顺序的顶点邻居特征集合上。我们检验了三种聚合函数：
&lt;strong&gt;Mean aggregator.&lt;/strong&gt; 第一个聚合函数是均值聚合，我们简单的取$\lbrace \mathbf{h}^{k-1}_u, \forall v \in \mathcal{N}(v) \rbrace$中的向量的element-wise均值。均值聚合近似等价在transducttive GCN框架[17]中的卷积传播规则。特别地，我们可以通过替换算法1中的4行和5行为以下内容得到GCN的inductive变形：
&lt;/p&gt;
$$\tag{2}
\mathbf{h}^k\_v \leftarrow \sigma(\mathbf{W} \cdot \mathrm{MEAN}(\lbrace \mathbf{h}^{k-1}\_v \rbrace \cup \lbrace \mathbf{h}^{k-1}\_u, \forall u \in \mathcal{N}(v) \rbrace)).
$$&lt;p&gt;
我们称这个修改后的基于均值的聚合器是&lt;em&gt;convolutional&lt;/em&gt;，因为它是一个粗略的，局部化谱卷积的的线性近似[17]。这个卷积聚合器和我们的其他聚合器的重要不同在于它没有算法1中第5行的拼接操作——卷积聚合器没有将顶点前一层的表示$\mathbf{h}^{k-1}_v$和聚合的邻居向量$\mathbf{h}^k_{\mathcal{N}(v)}$拼接起来。拼接操作可以看作一个是在不同的搜索深度或层之间的简单的skip connection的形式，它使得模型获得了巨大的提升。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LSTM aggregator.&lt;/strong&gt; 我们也检验了一个基于LSTM的复杂的聚合器。对比均值聚合器，LSTM有更强的表达能力。然而，LSTM不是对称的这个需要注意，因为他们处理他们的输入是以一个序列的方式。我们简单地将LSTM应用在一个顶点邻居的随机序列上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pooling aggregator.&lt;/strong&gt; 我们检验的最后一个聚合器既是对称的，又是可训练的。在这个&lt;em&gt;池化&lt;/em&gt;方法种，每个邻居的向量都是相互独立输入到全连接神经网络中的；随着这种变化，一个element-wise最大池化操作应用在邻居集合上来聚合信息：
&lt;/p&gt;
$$\tag{3}
\mathrm{AGGREGATE}^{pool}\_k = \mathrm{max}(\lbrace \sigma (\mathbf{W}\_{pool} \mathbf{h}^k\_{u\_i} + \mathbf{b}), \forall u\_i \in \mathcal{N}(v) \rbrace),
$$&lt;p&gt;
其中，$\mathrm{max}$表示element-wise最大值操作，$\sigma$是非线性激活函数。原则上，在最大池化使用之前，函数可以是任意的深度多层感知机，但是我们关注的是单个的单层结构。方法是搜到了最近的神经网络架构在学习general point sets上的启发[29]。直觉上来说，多层感知机可以看作是一组函数，这组函数为邻居集合中的每个顶点计算表示。通过对每个计算得到的特征使用最大池化操作，模型有效地捕获了邻居集合的不同方面。注意，原则上，任何对称的向量函数都可以替换$\mathrm{max}$操作器（比如element-wise mean）。我们发现最大池化和均值池化在测试时没有太大的差别，所以使用了最大池化完成了后续的实验。&lt;/p&gt;
&lt;h1 id="4-实验"&gt;4 实验
&lt;/h1&gt;&lt;p&gt;我们在三个benchmark上测试了GraphSAGE：1. 使用Web of Science citation dataset对不同的学术文章进行主题分类。2. 对属于不同社区的Reddit posts进行分类，3. 对多个PPI图进行蛋白质功能分类。在所有的实验中，我们在训练时没有见过的顶点上做预测，对PPI上对完全未见过的图做预测。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Experimental set-up.&lt;/strong&gt; 为了在inductive benchmark上面将经验结果置于上下文中考虑，我们对比了四个baseline：随即分类器，基于特征的逻辑回归，raw features和DeepWalk embedding拼接的embedding。我们也比较了GraphSAGE的四个变体，分别使用不同的聚合函数（3.3部分）。因为，GraphSAGE的卷积变体是一种扩展形式，是Kipf et al. 半监督GCN的inductive version，我们称这个变体为GraphSAGE-GCN。我们测试了根据式1的损失函数训练的GraphSAGE变体，还有在cross-entropy上训练的监督变体。对于所有的GraphSAGE变体我们使用ReLU作为激活，$K = 2$，邻居采样大小$S_1 = 25$，$S_2 = 10$（详情见4.4节）。&lt;/p&gt;
&lt;p&gt;对于Reddit和citation数据集，我们使用&amp;quot;online&amp;quot;来训练DeepWalk，如Perozzi et al. 提到的那样，我们在做预测前，跑一轮新的SGD来嵌入新的测试顶点（详情见后记）。在多图设定中，我们不能使用DeepWalk，因为通过DeepWalk在不同不相交的图上运行后生成的嵌入空间对其他来说可以是arbitrarily rotated（后记D）。&lt;/p&gt;
&lt;p&gt;所有的模型都是用tf实现的，用Adam优化（除了DeepWalk，使用梯度下降效果更好）。我们设计的实验目标是1. 验证GraphSAGE比其他方法好。 2. 严格对比集中聚合架构，为了严格对比，所有的方法使用相同的实现，如minibatch迭代器，损失函数和邻居采样（如果可以的话）。此外，为了防止对比聚合器时非有意的&amp;quot;hyperparameter hacking&amp;quot;，我们检查了所有GraphSAGE变体的超参数集合（为每个变体根据他们在验证集上的表现选择最好的设定）。可能的超参数集合在早期的验证集上决定，这个验证集是citation和Reddit的子集，后续就丢掉了。后记包含了实现的细节。&lt;/p&gt;</description></item><item><title>Diffusion-Convolutional Neural Networks</title><link>https://davidham3.github.io/blog/p/diffusion-convolutional-neural-networks/</link><pubDate>Thu, 19 Jul 2018 11:17:40 +0000</pubDate><guid>https://davidham3.github.io/blog/p/diffusion-convolutional-neural-networks/</guid><description>&lt;p&gt;NIPS 2016。DCNNs，写的云里雾里的，不是很懂在干什么。。。就知道是融入了转移概率矩阵，和顶点的特征矩阵相乘，算出每个顶点到其他所有顶点的 $j$ 步转移的特征与转移概率的乘积，成为新的顶点表示，称为diffusion-convolutional representation，然后乘以一个卷积核，套一个激活，卷积就定义好了。应用还是在顶点分类与图分类上。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1511.02136" target="_blank" rel="noopener"
&gt;Diffusion-Convolutional Neural Networks&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;我们提出了diffusion-convolutional neural networks(DCNNs)，是图结构数据上的新模型。引入diffusion-convolution操作，可以从图结构数据中得到基于扩散性质的表示，用于顶点分类。DCNN还有几个性质，关于一个图数据的隐含表示，还有多项式时间复杂度的预测以及高效的GPU实现。通过多个真实数据集的实验，DCNN表现出了在关系顶点分类任务上超越概率关系模型以及kernel-on-graph的结果。&lt;/p&gt;
&lt;h1 id="1-引言"&gt;1 引言
&lt;/h1&gt;&lt;p&gt;处理结构化数据很难。一方面是找到正确的方式表示并挖掘数据的结构可以提升预测的性能；另一方面，找到这样的表示很难，增加结构信息到模型中会急剧地增加预测和学习的复杂度。&lt;/p&gt;
&lt;p&gt;我们的工作是为一类结构化数据设计一个灵活的模型，这个模型增强预测能力且避免复杂度的增加。为了完成这个模型，我们通过引入&amp;quot;diffusion-convolution&amp;quot;操作将卷积神经网络扩展到图结构数据上。简单地说，并不是像标准卷积操作一样扫描一个矩形的参数，diffusion-convolution操作通过扩散性的过程扫描图结构输入中每个顶点，构建一个隐含表示。&lt;/p&gt;
&lt;p&gt;我们的受到的启发是：捕获了图扩散性的表示在预测上可以提供比图本身更好的结果。图扩散性可以表达成矩阵的幂序列，提供了一个简单的机制来包含关于实体的上下文信息，这些实体可以在多项式时间复杂度内计算出来，并在GPU上实现。&lt;/p&gt;
&lt;p&gt;我们提出了diffusion-convolutional神经网络(DCNN)，在图数据的各种各样的分类任务上测试了性能。在分类任务中很多技术包含了结构的信息，比如概率关系模型和核方法；DCNN提供了一个补充的方法，在顶点分类上获得了巨大的提升。&lt;/p&gt;
&lt;p&gt;DCNN的优势：
·&lt;strong&gt;精度：&lt;/strong&gt; DCNN比其他方法在顶点分类任务上精度更高，图分类上表现的也不错。
·&lt;strong&gt;灵活性：&lt;/strong&gt; DCNN提供了图数据的灵活表示，使用简单的处理对顶点特征、边特征以及结构信息进行编码。DCNN可以用于很多分类任务，包括顶点分类，边分类，图分类。
·&lt;strong&gt;速度：&lt;/strong&gt; DCNN的预测可以表示成一系列多项式时间复杂度的tensor操作，模型可以在GPU上实现。&lt;/p&gt;
&lt;h1 id="2-模型"&gt;2 模型
&lt;/h1&gt;&lt;p&gt;长度为 $T$ 的一个图的集合 $\mathcal{G} = \lbrace G_t \mid t \in 1&amp;hellip;T \rbrace $。每个图 $G_t = (V_t, E_t)$ 由顶点 $V_t$ 和边 $E_t$ 组成。顶点一起表示为一个 $N_t \times F$ 的特征矩阵 $X_t$，其中 $N_t$ 是 $G_t$ 的顶点数，边 $E_t$ 通过一个 $N_t \times N_t$ 的邻接矩阵 $A_t$ 编码，通过这个我们可以计算出一个度归一化的转移矩阵 $P_t$，这个矩阵给出了从顶点 $i$ 一步转移到 $j$ 的概率。图 $G_t$ 没有限制，有向无向，带权不带权都可以。对于我们的任务来说，要么是顶点、边有标签 $Y$，要么是图有标签 $Y$，不同情况下 $Y$ 的维度不同。&lt;/p&gt;
&lt;p&gt;如果 $T=1$，也就是只有一个图，标签是顶点或边，那么预测标签 $Y$ 就转换为了半监督分类问题了；如果输入中没有边的表示，就变成了标准的监督问题。如果 $T&amp;gt;1$，标签是每个图的标签，那就是监督图分类问题。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/diffusion-convolutional-neural-networks/Fig1.JPG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;DCNN接受 $\mathcal{G}$ 作为输入，返回一个 $Y$ 的hard prediction或是条件概率分布 $\mathbb{P}(Y \mid X)$。每个实体（顶点、图、或边）被转换为扩散卷积表示，由 $F$ 个特征上 $H$ 步扩散的维度为 $H \times F$ 的实数矩阵定义，每个实体是由 $H \times F$ 的实数矩阵 $W^c$ 和一个非线性可微分函数 $f$ 计算激活定义的。所以对于顶点分类任务，图 $t$ 的扩散卷积(diffusion-convolutional)表示 $Z_t$，是一个 $N_t \times H \times F$ 的tensor，如图1a所示；对于图或边分类任务，$Z_t$ 是一个 $H \times F$ 或 $N_t \times H \times F$ 的矩阵，如图1b和图1c。(原文里面写的是 $M_t \times H \times F$，我觉得是写错了)&lt;/p&gt;
&lt;p&gt;术语&amp;quot;diffusion-convolution&amp;quot;的意思是唤起卷积神经网络的特征的特征：feature learning, parameter tying, invariance。DCNN核心操作是从顶点和他们的特征映射到从那个顶点开始的扩散过程的结果上。不同于标准的CNN，DCNN参数根据搜索的深度而不是他们在网格中的位置而绑定起来。扩散卷积表示对于顶点的index是不变的，而不是他们的位置；换句话说，两个同质的图的扩散卷积激活会是一样的。不像标准的CNN，DCNN没有池化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;顶点分类&lt;/strong&gt; $P^\ast_t$ 是一个 $N_t \times H \times N_t$ 的tensor，包含了 $P_t$ 的幂序列，对顶点 $i$，$j$ 步，图 $t$ 的特征 $k$ 的扩散卷积的激活值 $Z_{tijk}$ 是：
&lt;/p&gt;
$$\tag{1}
Z\_{tijk} = f(W^c\_{jk} \cdot \sum^{N\_t}\_{l=1}P^*\_{tijl}X\_{tlk})
$$&lt;p&gt;激活使用矩阵形式可以写成：
&lt;/p&gt;
$$\tag{2}
Z\_t = f(W^c \odot P^\ast\_t X\_t)
$$&lt;p&gt;其中 $\odot$ 表示element-wise乘法；图1a。模型只有 $O(H \times F)$ 个参数，使得隐扩散卷积表示的参数数量与输入大小无关。&lt;/p&gt;
&lt;p&gt;模型通过一个连接 $Z$ 和 $Y$ 的dense layer完成。对于 $Y$ 的hard prediction，表示为 $\hat{Y}$，可以通过最大的激活值得到，条件概率分布 $\mathbb{P}(Y \mid X)$ 可以通过使用softmax得到：
&lt;/p&gt;
$$\tag{3}
\hat{Y} = \arg\max(f(W^d \odot Z))
$$&lt;p&gt;
&lt;/p&gt;
$$\tag{4}
\mathbb{P}(Y \mid X) = \mathrm{softmax}(f(W^d \odot Z))
$$&lt;p&gt;&lt;strong&gt;图分类&lt;/strong&gt; DCNN可以通过在顶点上取均值激活扩展成图分类
&lt;/p&gt;
$$\tag{5}
Z\_t = f(W^c \odot 1^T\_{N\_t} P^\ast\_t X\_t / N\_t)
$$&lt;p&gt;
其中 $1_{N_t}$ 是一个 $N_t \times 1$ 的向量，如图1b所示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;学习&lt;/strong&gt; DCNN使用随机梯度下降训练。每轮，顶点的index随机的分到几个batches中。每个batch的error通过取taking slices of the graph definition power series，然后正向、反向、梯度上升更新权重。也使用了windowed early stopping，如果validation error大于前几轮的平均值，就stop。&lt;/p&gt;</description></item><item><title>Convolution on Graph: A High-Order and Adaptive Approach</title><link>https://davidham3.github.io/blog/p/convolution-on-graph-a-high-order-and-adaptive-approach/</link><pubDate>Mon, 16 Jul 2018 11:01:00 +0000</pubDate><guid>https://davidham3.github.io/blog/p/convolution-on-graph-a-high-order-and-adaptive-approach/</guid><description>&lt;p&gt;重新定义了卷积的定义，利用$k$阶邻接矩阵，定义考虑$k$阶邻居的卷积，利用邻接矩阵和特征矩阵构建能同时考虑顶点特征和图结构信息的卷积核。在预测顶点、预测图、生成图三个任务上验证了模型的效果。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1706.09916" target="_blank" rel="noopener"
&gt;Graph Convolution: A High-Order and Adaptive Approach&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;我们提出了两个新的模块为图结构数据而设计：k阶卷积器和自适应滤波模块。重要的是，我们的框架(HA-GCN)是一种通用框架，可以在顶点和图上适应多种应用，还有图生成模型。我们的实验效果很好。在顶点分类和分子属性预测上超越了state-of-the-art。生成了超过32%的真实分子，在材料设计和药物筛选上很有效。&lt;/p&gt;
&lt;h1 id="引言"&gt;引言
&lt;/h1&gt;&lt;p&gt;图卷积网络通常应用在两个学习任务上：
·以顶点为中心：预测任务与顶点相关。GCN对图中的每个顶点输出一个特征向量，有效地反映顶点属性和邻居结构。举个例子，社交网络中，向量用于顶点分类和链路预测。有时也和顶点表示学习有关。
·以图为中心：预测任务和图相关。举个例子，化学领域中，分子可以被看作是一个图，原子作顶点，化学键是边。根据分子的物理和化学性质，构建图卷积网络对分子进行有意义地编码。这些任务对很多生活中的应用如材料设计、药物筛选很重要。在这种情况下，图卷积通常对图进行编码，使用编码进行图的预测。&lt;/p&gt;
&lt;p&gt;和我们的工作最相关的是Kipf &amp;amp; Welling 2016a，他们的卷积只考虑了一阶邻居。我们的高阶操作器有着到达k阶邻居的高效设计。此外，我们还引入了自适应模块动态地基于局部图的连接和顶点属性调整权重。对比Li et al., 2015，他们将LSTM引入图中，我们的自适应模块可以解释成Xu et al., 2015提出的注意力机制。不像前人设计的模型要么是以顶点为重，要么是以图为中心，我们的HA-GCN框架是个通用的模型。除此以外，我们用HA-GCN构建了针对分子生成的图生成模型，比state-of-the-art的效果提高了很多。&lt;/p&gt;
&lt;p&gt;贡献有两点：
·引入两个模块，构建新的图卷积网络架构HA-GCN
·提出了可以应用到以顶点为中心、图为中心的通用框架和图生成模型。在所有的任务上获得了state-of-the-art的效果。&lt;/p&gt;
&lt;h1 id="preliminaries"&gt;Preliminaries
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;The Graph Model&lt;/strong&gt;
一个图$\mathcal{G}$表示为一个对$(V, E)$，$V = \lbrace v_1, &amp;hellip;, v_n \rbrace $是顶点集，$E \in V \times V$是边集。我们不区分有向和无向，因为我们的模型都能做。每个图可以表示为一个$n \times n$的邻接矩阵$A$，如果$v_i$到$v_j$有边，$A_{i,j} = 1$否则为$0$。基于邻接矩阵，我们可以得到距离函数$d(v_i, v_j)$表示$v_i$到$v_j$的距离（最短距离）。此外，我们认为每个顶点$v_i$与一个特征向量$X_i \in \mathcal{R}^m$相关，我们使用$X = (X^T_1, X^T_2, &amp;hellip;, X^T_n) \in \mathcal{R}^{n \times m}$表示特征矩阵。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph Convolutional Networks (GCNs)&lt;/strong&gt;
首先，一个顶点$v_j$在图$\mathcal{G}$上的卷积操作可以表示为：
&lt;/p&gt;
$$
L\_{conv}(j) = \sum\_{i \in \mathcal{N}\_j} w\_{ij} X\_i + b\_j
$$&lt;p&gt;
其中$X_i \in R_m$是顶点$v_i$的输入特征，$b_j$是偏置，$w_{ij}$是权重，对$j$是非平稳且变化的。集合$\mathcal{N}_j$表示scope of convolution。对于传统的应用，CNN通常设计成低维度的网格且对每个顶点有着相同的连接。举个例子，图像可以看作二维网格，图$\mathcal{G}$通过邻接的像素组成。$\mathcal{N}_j$可以简单的定义为一个围绕在像素$j$的固定大小的block或window。&lt;/p&gt;
&lt;p&gt;在更一般的图上，可以将$\mathcal{N}_j$定义为顶点$v_j$的邻接顶点的集合。比如，在Duvenaud et al. 2015的工作中，fingerprint(FP)卷积操作器的核心是计算邻居的均值，也就是对于所有的$(i, j)$，$w_{ij} = 1$。通过邻接矩阵$A$，我们可以将这个操作写为
&lt;/p&gt;
$$\tag{1}
L\_{FP} = AX.
$$&lt;p&gt;$A$和特征矩阵$X$的乘积得到一个所有邻居顶点特征的均值。Kipf &amp;amp; Welling 2016a提出的node-GCN使用线性组合与非线性变换得到的均值为：
&lt;/p&gt;
$$\tag{2}
L\_{node-GCN} = \sigma(AXW).
$$&lt;p&gt;权重矩阵$W$，函数$\sigma(\cdot)$分别是特征$X$上的线性组合与非线性变换。&lt;/p&gt;
&lt;p&gt;Bruna et al., 2013与Defferrard et al., 2016提采用了不同的方式在图的拉普拉斯矩阵的谱上做了卷积。$H$为拉普拉斯矩阵，正交分解为$H = U \Lambda U^T$($U$是正交矩阵，$\Lambda$是对角矩阵)。与其在式2中加入权重矩阵，谱卷积考虑的是$H$上的一个参数化的卷积操作；
&lt;/p&gt;
$$\tag{3}
L\_{spectral} = U g\_\theta U^T X.
$$&lt;p&gt;这里$g_\theta(\cdot)$是一个多项式函数，element-wisely应用在对角矩阵$\Lambda$上。&lt;/p&gt;
&lt;p&gt;在讨论谱图卷积的优点时，作者提到$k$阶多项式多项式$g_\theta(\cdot)$就是图的$k$阶局部，也就是说卷积会到达$k$阶邻居。对比式1和式2一阶邻居的均值，这能使信息在图上快速的传播。然而，考虑到$U \Lambda^n U^T = A^n$，多项式$g_\theta(\cdot)$的选择并没有给$k$阶邻居一个明确的卷积操作，因为在卷积中不是所有的邻居都是占相同的份量。这使得我们提出了我们的高阶卷积操作。这些卷积的其他问题是，他们在图中是不变的。因此几乎不能捕获到使用卷积时不同地方的不同。这使得我们提出了自适应模块，成功的考虑了局部特征和图结构。（这里看的云里雾里的。。。）&lt;/p&gt;
&lt;h1 id="high-order-and-adaptive-graph-convolutional-network-ha-gcn"&gt;High-Order and Adaptive Graph Convolutional Network (HA-GCN)
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;K-th Order Graph Convolution&lt;/strong&gt;
定义顶点$v_j$的$k$阶邻居：$\mathcal{N}_j = \lbrace v_i \in V \mid d(v_i, v_j) \leq k \rbrace $。可以通过对邻接矩阵$A$连乘得到$k$阶邻居。
&lt;strong&gt;Proposition 1.&lt;/strong&gt; $A$是图$\mathcal{G}$的邻接矩阵，$A^k$的第$i$行第$j$列表示的是顶点$i$到顶点$j$的$k$步路径的个数。
我们定义$k$阶卷积如下：
&lt;/p&gt;
$$\tag{4}
\tilde{L}^{(k)}\_{gconv} = (W\_k \circ \tilde{A}^k)X + B\_k,
$$&lt;p&gt;其中
&lt;/p&gt;
$$\tag{5}
\tilde{A}^k = \min\lbrace A^k + I, 1\rbrace .
$$&lt;p&gt;其中$\circ$和$\min$分别表示element-wise矩阵乘法和最小值。$W_k \in \mathcal{R}^{n \times n}$是权重矩阵，$B_k \in \mathcal{R}^{n \times m}$是偏置矩阵。$\tilde{A}^k$是通过将$A^k + I$砍到1获得的。在$A^k$上增加单位阵是为了让图上的每个顶点都有自连接。砍到1是因为如果$A^k$有大于1的元素，砍到1确实会得到k阶邻居的卷积。卷积的输入$\tilde{L}^{(k)}_{gconv}$是邻接矩阵$A \in \lbrace 0, 1\rbrace ^{n \times n}$和特征矩阵$X \in \mathcal{r}^{n \times m}$。输出的维度和$X$一样。如同名字所示，卷积操作$\tilde{L}^{(k)}_{gconv}$取一个顶点的$k$阶邻居的特征向量作为输入，输出他们的加权平均。&lt;/p&gt;
&lt;p&gt;式4的操作优雅地实现了我们在图上$k$阶邻居的idea，和传统的卷积一样，是kernel size为$k$的卷积。一方面，它可以看作是式2从1阶邻居到高阶的高效的泛化。另一方面，卷积器与式3的谱图卷积关系紧密，因为谱图中的$k$阶多项式也可以被看作是一种范围为$k$阶邻居$\mathcal{N}_j$的操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adaptive Filtering Module&lt;/strong&gt;
基于式4，我们引入图卷积的自适应滤波器模块。它根据一个顶点的特征以及邻居的连接过滤卷积的权重。以化学中分子的图为例，在预测分子性质时，benzene rings比alkyl chains更重要。没有自适应模块，图卷积在空间上不变，而且不能按预期的那样工作。自适应滤波器的引入使得网络自适应地找到卷积目标并且更好的捕获局部的不一致。&lt;/p&gt;
&lt;p&gt;自适应滤波器的想法来源于注意力机制Xu et al., 2015，他们在生成输出序列中对应的词时，自适应地的了有趣的像素。也可以看作是一种门的变体，这个门有选择的让信息通过LSTM。从技术上来讲，我们的自适应滤波器是一个在权重矩阵$W_k$上的非线性操作器$g$：
&lt;/p&gt;
$$\tag{6}
\tilde{W\_k} = g \circ W\_k,
$$&lt;p&gt;其中$\circ$表示element-wise矩阵乘法。事实上，操作器$g$是由$\tilde{A}^k$和$X$共同决定的，反映了顶点特征与图的连接，
&lt;/p&gt;
$$
g = f\_{adp}(\tilde{A}^k, X).
$$&lt;p&gt;我们考虑了函数$f_{adp}$的两个选项：
&lt;/p&gt;
$$\tag{7}
f\_{adp/prod} = \mathrm{sigmoid}(\tilde{A}^kXQ)
$$&lt;p&gt;
和
&lt;/p&gt;
$$\tag{8}
f\_{adp/lin} = \mathrm{sigmoid}(Q \cdot [\tilde{A}^k, X]).
$$&lt;p&gt;这里，$[\cdot, \cdot]$表示矩阵拼接。第一个操作器通过$A$和$X$的内积考虑了顶点特征和图连接的的交互，第二个通过线性变换也实现了这个目的。事实上，我们发现线性自适应滤波器(8)比(7)在大多数任务上表现的更好。因此，我们在实验部分会采用并且记录线性的表现。自适应滤波器为了顶点的权重选择而设计出来，因此我们用了一个sigmoid非线性激活使它二值化。参数矩阵$Q$会让$f_{adp}$的输出的维度与矩阵$A$对齐。不像当前已有的动态滤波器只从顶点或边的特征中生成权重，我们的自适应滤波器模块通过同时考虑顶点特征与图的连通性有着更全面的考虑。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Framework of HA-GCN&lt;/strong&gt;
通过在高阶卷积式4中加入自适应模块式6，我们得到HA的定义为：
&lt;/p&gt;
$$
\tilde{L}^{(k)}\_{HA} = (\tilde{W}\_k \circ \tilde{A}^k)X = B\_k
$$&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/convolution-on-graph-a-high-order-and-adaptive-approach/Fig1.JPG"
loading="lazy"
alt="Fig1"
&gt;
图1给了卷积器和HA-GCN框架的可视化。图1a展示了对于一个顶点，$k = 2$时的$\tilde{L}^{(k)}_{HA}$：自适应滤波器$g$的底层加到权重矩阵$W_1$和$W_2$上，得到了自适应权重$\tilde{W}_1$和$\tilde{W}_2$（橙色和绿色线）；第二层把自适应权重和对应的邻接矩阵拼到一起为了卷积使用。图1b强调了卷积是在图上每个顶点都做的，并且是一层一层的。需要注意的是高阶卷积器和自适应权重可以和其他的神经网络架构/操作一起使用，比如全连接层，池化层，非线性变换。我们将我们的HA操作的图卷积层命名为HA-GCN。&lt;/p&gt;
&lt;p&gt;在所有的卷积层之后，我们将那些来自不同阶的卷积层的输出特征拼接起来：
&lt;/p&gt;
$$
L\_{HA} = [\tilde{L}^{(1)}\_{HA}, ..., \tilde{L}^{(K)}\_{HA}].
$$&lt;p&gt;HA-GCN的架构以特征矩阵$X \in \mathcal{R}^{n \times m}$（$n$是图的顶点数，$m$是顶点特征的维数）作为输入，输出一个维度为$n \times (mK)$的矩阵，特征的维数会乘以$K$倍。现在，我们将详细描述如何将HA-GCN应用到各种各样的问题上。&lt;/p&gt;
&lt;p&gt;**以顶点为中心的预测：**HA-GCN的卷积之后，每个顶点和一个特征向量有关。特征向量可以用于顶点分类或回归。与网络表示学习也密切相关。使用以顶点为中心的设定，意味着我们可以给每个顶点学习出一个向量，向量反映了那个顶点周围的图的局部结构。我们的HA-GCN也给图中的每个顶点输出了一个向量。在这个场景下，HA-GCN可以看成是一个监督的图表示学习框架。&lt;/p&gt;
&lt;p&gt;**以图为中心的预测：**为了解决不同尺度的图，输入的邻接矩阵和特征矩阵在底部和右侧加入了为0的padding。以顶点为中心和以图为中心的一个小不同是：以顶点为中心的任务中，一部分有标签/值的顶点作为训练，其他的作验证和输出，而以图为中心的任务，数据集是一组图（可能尺度不同），分为训练/验证/测试集。HA-GCN在这两种情况都能工作，HA卷积层中的参数是$(n^2)$，$n$是图的size（或是那些图中最大的size）。HA-GCN在顶点为中心的任务中比在图为中心的任务更容易过拟合，我们会在后面的实验部分描述这个问题。&lt;/p&gt;
&lt;p&gt;**图生成模型：**从一组图$\bar{\mathcal{G}} = \lbrace \mathcal{G}_1, &amp;hellip;, \mathcal{G}_N \rbrace $中学习一个概率模型，通过这个模型我可以生成之前没见过但是和$\bar{\mathcal{G}}$中相似的图。通过variational auto-encoder(Kingma and Welling 2013)和adversarial auto-encoder(Makhzani et al., 2015)，图卷积网络可以适用于生成模型的任务甚至是判别模型。&lt;/p&gt;
&lt;p&gt;一个自编码器总是由两部分组成：一个编码器和一个解码器。编码器将输入数据$X \in \mathcal{X}$映射到一个编码向量$Y \in \mathcal{Y}$，解码器将$\mathcal{Y}$映射回$\mathcal{X}$。我们称编码空间$\mathcal{Y}$为隐藏空间。为了使他成为一个生成模型，我们通常假设隐藏空间中有一个概率分布（比如高斯分布）。图生成模型能让我们生成分子的连续表达，通过搜索隐藏空间生成新的化学结构，可以用来指导材料设计和药物筛选。&lt;/p&gt;
&lt;h1 id="实验"&gt;实验
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Node-centric learning&lt;/strong&gt;
citation graphs上的监督文档分类，每个图包含文档的bag-of-words特征向量，还有文档之间的引用连接。我们把这个网络当成无向图，构建一个二值对称邻接矩阵$A$。每个文档有一个类标，目标是从文档的特征和引用的图对文档标签预测。统计数据(Sen et al., 2008)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;Dataset&lt;/th&gt;
&lt;th style="text-align: center"&gt;Nodes&lt;/th&gt;
&lt;th style="text-align: center"&gt;Edges&lt;/th&gt;
&lt;th style="text-align: center"&gt;Classes&lt;/th&gt;
&lt;th style="text-align: center"&gt;Features&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Citeseer&lt;/td&gt;
&lt;td style="text-align: center"&gt;3327&lt;/td&gt;
&lt;td style="text-align: center"&gt;4732&lt;/td&gt;
&lt;td style="text-align: center"&gt;6&lt;/td&gt;
&lt;td style="text-align: center"&gt;3703&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Cora&lt;/td&gt;
&lt;td style="text-align: center"&gt;2708&lt;/td&gt;
&lt;td style="text-align: center"&gt;5429&lt;/td&gt;
&lt;td style="text-align: center"&gt;7&lt;/td&gt;
&lt;td style="text-align: center"&gt;1433&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Pubmed&lt;/td&gt;
&lt;td style="text-align: center"&gt;19717&lt;/td&gt;
&lt;td style="text-align: center"&gt;44338&lt;/td&gt;
&lt;td style="text-align: center"&gt;210&lt;/td&gt;
&lt;td style="text-align: center"&gt;5414&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;**训练和架构：**我们使用和Kipf &amp;amp; Welling同样的GCN网络结构，除了将他们的一阶图卷积层换成了我们的HA层。我们使用$gcn_{1,&amp;hellip;,k}$表示$1$阶到$k$阶的图卷积层。$\mathrm{fc}k$表示有$k$个隐藏单元的全连接层。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;Name&lt;/th&gt;
&lt;th style="text-align: center"&gt;Architectures&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;GCN&lt;/td&gt;
&lt;td style="text-align: center"&gt;gcn_{1}-fc128-gcn_{1}-fc1-softmax&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;gcn_{1, 2}&lt;/td&gt;
&lt;td style="text-align: center"&gt;gcn{1, 2}-fc128-gcn{1, 2}-fc1-softmax&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;adp_gcn_{1, 2}&lt;/td&gt;
&lt;td style="text-align: center"&gt;adp_gcn{1, 2}-fc128-adp_gcn{1, 2}-fc1-softmax&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;为了比较不同模型的性能，我们将数据集随机划分成训练/验证/测试集，比例为$7:1.5:1.5$，记录测试集的预测精度，表1。超参数：dropout rate $0.7$，L2 regularization $0.5 \cdot 10^{-8}$，hidden units $128$。从顶点表示学习角度看，前三个是半监督的模型，后四个是半监督的模型。这也解释了为什么后面的模型效果更好。我们的二姐邻居HA图卷积在精度上提升了2%。自适应模块没能继续提升。这是因为自适应模块是为了对不同的图生成不同的滤波器权重。然而，在顶点为中心的任务中，只有一个图，卷积权重直接就学出来了。因此自适应模块在顶点为中心的任务中是冗余的。
&lt;img src="https://davidham3.github.io/blog/images/convolution-on-graph-a-high-order-and-adaptive-approach/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph-centric learning&lt;/strong&gt;
预测分子图。目标是给定分子图，预测分子性质。我们使用Duvenaud et al., 2015描述的数据集，评估三种属性：
Solubility, Drug efficacy, Organic photovolatic efficiency。
训练和架构：
l1_gcn和l2_gcn分别表示有一个和两个卷积层的卷积神经网络。我们记录了RMSE（表2）。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;Name&lt;/th&gt;
&lt;th style="text-align: center"&gt;Architectures&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;l1_gcn&lt;/td&gt;
&lt;td style="text-align: center"&gt;gcn_{1,2,3}-ReLU-fc64-ReLU-fc16-ReLU-fc1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;l1_adp_gcn&lt;/td&gt;
&lt;td style="text-align: center"&gt;adp_gcn{1,2,3}-ReLU-fc64-ReLU-fc16-ReLU-fc1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;l2_gcn&lt;/td&gt;
&lt;td style="text-align: center"&gt;[gcb_{1,2,3}-ReLU]*2-fc64-ReLU-fc16-ReLU-fc1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;l2_adp_gcn&lt;/td&gt;
&lt;td style="text-align: center"&gt;[adp_gcn_{1,2,3}-ReLU]*2-fc64-ReLU-fc16-ReLU-fc1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/convolution-on-graph-a-high-order-and-adaptive-approach/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;&lt;/p&gt;
&lt;p&gt;node-GCN就是没有自适应滤波模块的一阶HA-GCN。对比node-GCN,l1_gcn,l2_gcn，可以看到我们的卷积层的效果。有自适应滤波器的比没有的效果好。&lt;/p&gt;
&lt;p&gt;还有一部分图生成模型，就不说了。&lt;/p&gt;</description></item><item><title>Graph Attention Networks</title><link>https://davidham3.github.io/blog/p/graph-attention-networks/</link><pubDate>Fri, 13 Jul 2018 16:54:31 +0000</pubDate><guid>https://davidham3.github.io/blog/p/graph-attention-networks/</guid><description>&lt;p&gt;ICLR 2018。图注意力网络，使用 self-attention 来构建 graph attentional layer，attention 会考虑当前顶点所有的邻居对它的重要性，基于谱图理论的模型不能应用到其他不同结构的图上，而这个基于attention的方法能有效的解决这个问题。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1710.10903" target="_blank" rel="noopener"
&gt;Graph Attention Networks&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;我们提出了图注意力网络(GAT)，新型图神经网络，利用自注意力层解决基于图卷积及其相似方法的缺点。通过堆叠这种层（层中的顶点会注意邻居的特征），我们可以给邻居中的顶点指定不同的权重，不需要任何一种耗时的矩阵操作（比如求逆）或依赖图结构的先验知识。我们同时解决了基于谱的图神经网络的几个关键挑战，并且使我们的模型很轻松的应用在 inductive 或 transductive 问题上。我们的 GAT 模型在4个 transductive 和 inductive 图数据集上达到且匹敌当前最先进的算法：&lt;em&gt;Cora&lt;/em&gt;, &lt;em&gt;Citeseer&lt;/em&gt;, &lt;em&gt;Pubmed citation networks&lt;/em&gt;，&lt;em&gt;protein-protin interaction&lt;/em&gt;。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 INTRODUCTION
&lt;/h1&gt;&lt;p&gt;CNN 结构可以有效的重复使用卷积核，在网格型的数据上应用。然而很多问题都是基于图结构的。&lt;/p&gt;
&lt;p&gt;早期的工作使用RNN来处理图结构中数据的表示。2005 年和 2009 年提出了 GNN（Graph Neural Networks）的概念，作为 RNN 的泛化，可以直接处理更一般的图结构，比如带环图、有向、无向图。GCN 包含了迭代的过程，迭代时顶点状态向前传播，后面使用一个神经网络来产生输出。Li et al., 2016使用了Cho et al., 2014提出的门控循环单元进行改进。&lt;/p&gt;
&lt;p&gt;进一步的研究分为谱方法和非谱方法。&lt;/p&gt;
&lt;p&gt;一方面，谱方法使用图的谱表示，成功应用到了顶点分类的问题上。Bruna et al., 2014在傅里叶域中定义了卷积操作，通过计算拉普拉斯矩阵的特征值分解，由于潜在的大量的计算，引出了后续的非谱方法。Henaff et al., 2015引入了带有 smooth coefficients 的谱滤波器，可以使他们在空间局部化。后来 Defferrard et al., 2016 提出了通过拉普拉斯矩阵的切比雪夫多项式展开的近似表达。最后，Kipf &amp;amp; Welling 2017 通过限制滤波器只考虑 1 阶邻居从而简化了之前的方法。然而，前面提到的所有的谱方法，学习到的卷积核参数都依赖于拉普拉斯特征值分解后的特征向量，也就是说依赖于图结构。因此，训练在一个指定图结构的模型不能应用到不同结构的图上。&lt;/p&gt;
&lt;p&gt;另一方面，还有一些非谱方法 (Duvenaud et al., 2015; Atwood &amp;amp; Towsley, 2016; Hamilton et al., 2017)，这些方法直接在图上定义卷积操作，直接在空间上相近的邻居上应用卷积操作。这些方法的一个挑战是需要定义一个能处理不同数量邻居的卷积操作，并且保证 CNN 权重共享的性质。在某些情况下，这需要学习为每个 node degree 学习一个权重矩阵 (Duvenaud et al., 2015)，在对每个 input channel 和 neighborhood degree 训练权重时，使用转移矩阵的幂定义邻居 (Atwood &amp;amp; Towsley, 2016)，或是对有着固定数量顶点的邻居进行提取和归一化(Niepert et al., 2016)。Monti et al., 2016提出了混合模型 CNN，(MoNet)，这个空间方法提供了一个 CNN 在图上泛化的统一的模型。最近，Hamilton et al., 2017提出了 GraphSAGE，对每个顶点采样采出一个固定数量的邻居，然后使用一个指定的聚合操作聚集他们（比如取所有采样邻居的均值，或是将他们放进RNN后产生的结果）。这个方法在几个大规模的 inductive 数据集上获得了很惊人的效果。&lt;/p&gt;
&lt;p&gt;注意力机制在很多基于序列的任务中已经成为了一个标准 (Bahdanau et al., 2015; Gehring et al., 2016)。注意力机制的一个好处是可以处理变长输入，专注于输入中最相关的部分来做决策。使用注意力机制计算一个序列的表示时，一般提到的是 &lt;em&gt;self-attention&lt;/em&gt; 或 &lt;em&gt;intra-attention&lt;/em&gt;。与 RNN 或卷积一起使用时，self-attention 在机器阅读(Cheng et al., 2016)和学习句子表示(Lin et al., 2017)这些任务上很有用。然而，Vaswani et al., 2017的研究表明，self-attention 不仅可以提升 RNN 和卷积的模型，在机器翻译任务上也是可以构建出性能最强的模型的。&lt;/p&gt;
&lt;p&gt;受最近工作的启发，我们提出了基于 attention 的架构对图结构的顶点进行分类。思路是通过对顶点邻居的注意，计算图中每个顶点的表示，然后使用一个 self-attention 机制。注意力架构有几个有趣的性质：(1) 操作高效，因为它可以“顶点-邻居”对上并行计算；(2) 通过指定对邻居任意的权重，它可以在有着不同度的顶点上使用；(3) 模型可以直接应用在 inductive learning 任务上，包括模型必须要生成完整的未见过的图等任务。我们在4个 benchmark 上验证了我们的方法：&lt;em&gt;Cora&lt;/em&gt;，&lt;em&gt;Citeseer&lt;/em&gt;，&lt;em&gt;Pubmed citation networks&lt;/em&gt;，&lt;em&gt;protein-protein interaction&lt;/em&gt;，获得了比肩 state-of-the-art 的结果，展现了基于 attention 的模型在处理任意结构的图的可能性。&lt;/p&gt;
&lt;p&gt;值得注意的是，如 Kipf &amp;amp; Welling 2017和Atwood &amp;amp; Towsley 2016，我们的工作可以重写为 MoNet(Monti et al., 2016)的一种特殊形式。除此以外，我们的分享神经网络跨边计算时是对关系网络公式的联想(Santoro et al., 2017)和VAIN(Hoshen, 2017)，在这两篇文章中，object 和 agent 间的关系被聚合成对，通过使用一种共享机制。相似地，我们的注意力模型可以与 Duan et al., 2017 和 Denil et al., 2017 的工作相连，他们使用一个邻居注意力操作来计算环境中不同 object 的注意力系数。其他相关的方法包括局部线性嵌入(LLE)(Roweis &amp;amp; Saul, 2000)和记忆网络(Weston et al., 2014)。LLE 在每个数据点选择了固定数量的邻居，为每个邻居学习了权重系数，以此将每个数据点重构为邻居的加权之和。之后的优化提取了顶点嵌入的特征。记忆网络与我们的工作也有关系，如果我们将一个顶点的邻居解释为记忆，通过注意它的值可以计算顶点特征，之后通过在同样的位置存储新特征进行更新。&lt;/p&gt;
&lt;h1 id="2-gat-architecture"&gt;2 GAT ARCHITECTURE
&lt;/h1&gt;&lt;p&gt;我们会在这部分描述如何创建 block layer 来构造任意的 graph attention networks，并且指明理论和实际上的优点以及相比于之前在神经图处理上的工作的缺点。&lt;/p&gt;
&lt;h2 id="21-graph-attentional-layer"&gt;2.1 Graph Attentional Layer
&lt;/h2&gt;&lt;p&gt;首先描述单个 graph attentional layer，因为这种层会在整个 GAT 架构中使用。我们使用的 attention 和 Bahdanau et al., 2015 的工作相似。&lt;/p&gt;
&lt;p&gt;输入是一组顶点特征，${\mathbf{h}} = \lbrace \vec{h}_1, \vec{h}_2, &amp;hellip;, \vec{h}_N \rbrace , \vec{h}_i \in \mathbb{R}^F$，其中 $N$ 是顶点数，$F$ 是每个顶点的特征数。这个层会生成一组新的顶点特征，${\mathbf{h}&amp;rsquo;} = \lbrace \vec{h}&amp;rsquo;_1, \vec{h}&amp;rsquo;_2, &amp;hellip;, \vec{h}&amp;rsquo;_N\rbrace , \vec{h}&amp;rsquo;_i \in \mathbb{R}^{F&amp;rsquo;}$，作为输出。&lt;/p&gt;
&lt;p&gt;为了在将输入特征变换到高维特征时获得充足的表现力，至少需要一个可学习的线性变换。为了到达这个目的，每个顶点都会使用一个共享参数的线性变换，参数为 ${\mathbf{W}} \in \mathbb{R}^{F&amp;rsquo; \times F}$。然后在每个顶点上做一个 self-attention ——一个共享的attention机制 $a : \mathbb{R}^{F&amp;rsquo;} \times \mathbb{R}^{F&amp;rsquo;} \rightarrow \mathbb{R}$ 来计算注意力分数 &lt;em&gt;attention coefficients&lt;/em&gt;：&lt;/p&gt;
$$\tag{1}
e\_{ij} = a(\mathbf{W} \vec{h}\_i, \mathbf{W} \vec{h}\_j)
$$&lt;p&gt;表示顶点 $j$ 的特征对顶点 $i$ 的重要性(&lt;em&gt;importance&lt;/em&gt;)。在一般的公式中，模型可以使每个顶点都注意其他的每个顶点，扔掉所有的结构信息。我们使用 &lt;em&gt;mask attention&lt;/em&gt; 使得图结构可以注入到注意力机制中——我们只对顶点 $j \in \mathcal{N_i}$ 计算$e_{ij}$，其中$\mathcal{N_i}$ 是顶点 $i$ 在图中的一些邻居。在我们所有的实验中，这些是 $i$ 的一阶邻居（包括 $i$ ）。为了让系数在不同的顶点都可比，我们对所有的 $j$ 使用 softmax 进行了归一化：&lt;/p&gt;
$$\tag{2}
\alpha\_{ij} = \mathrm{softmax}\_j (e\_{ij}) = \frac{\exp{e\_{ij}}}{\sum\_{k \in \mathcal{N}\_i} \exp{e\_{ik}}}
$$&lt;div align="center"&gt;![Figure1](/blog/images/graph-attention-networks/Fig1.JPG)&lt;/div&gt;
&lt;p&gt;在我们的实验中，注意力机制 $a$ 是一个单层的前向传播网络，参数为权重向量 $\vec{\text{a}} \in \mathbb{R}^{2F&amp;rsquo;}$，使用LeakyReLU作为非线性层（斜率$\alpha = 0.2$）。整个合并起来，注意力机制计算出的分数（如图1左侧所示）表示为：&lt;/p&gt;
$$\tag{3}
\alpha\_{ij} = \frac{ \exp{ ( \mathrm{LeakyReLU} ( \vec{\text{a}}^T [\mathbf{W} \vec{h}\_i \Vert \mathbf{W} \vec{h}\_j ] ))}}{\sum\_{k \in \mathcal{N\_i}} \exp{(\mathrm{LeakyReLU}(\vec{\text{a}}^T [\mathbf{W} \vec{h}\_i \Vert \mathbf{W} \vec{h}\_k]))}}
$$&lt;p&gt;其中 $·^T$ 表示转置，$\Vert$ 表示concatenation操作。&lt;/p&gt;
&lt;p&gt;得到归一化的分数后，使用归一化的分数计算对应特征的线性组合，作为每个顶点最后的输出特征（最后可以加一个非线性层，$\sigma$）：&lt;/p&gt;
$$\tag{4}
\vec{h}'\_i = \sigma(\sum\_{j \in \mathcal{N}\_i} \alpha\_{ij} \mathbf{W} \vec{h}\_j)
$$&lt;p&gt;为了稳定 self-attention 的学习过程，我们发现使用 &lt;em&gt;multi-head attention&lt;/em&gt; 来扩展我们的注意力机制是很有效的，就像 Vaswani et al., 2017。特别地，$K$ 个独立的 attention 机制执行 式4 这样的变换，然后他们的特征连(concatednated)在一起，就可以得到如下的输出：&lt;/p&gt;
$$\tag{5}
\vec{h}'\_i = \Vert^{K}\_{k=1} \sigma(\sum\_{j \in \mathcal{N}\_i} \alpha^k\_{ij} \mathbf{W}^k \vec{h}\_j)
$$&lt;p&gt;其中 $\Vert$ 表示concatenation，$\alpha^k_{ij}$ 是通过第 $k$ 个注意力机制 $(a^k)$ 计算出的归一化的注意力分数，$\mathbf{W}^k$ 是对应的输入线性变换的权重矩阵。注意，在这里，最后的返回输出 $\mathbf{h}&amp;rsquo;$，每个顶点都会有 $KF&amp;rsquo;$ 个特征（不是 $F&amp;rsquo;$ ）。
特别地，如果我们在网络的最后一层使用 multi-head attention，concatenation 就不再可行了，我们会使用 &lt;em&gt;averaging&lt;/em&gt;，并且延迟使用最后的非线性层（分类问题通常是 softmax 或 sigmoid ）：&lt;/p&gt;
$$
\vec{h}'\_i = \sigma(\frac{1}{K} \sum^K\_{k=1} \sum\_{j \in \mathcal{N}\_i} \alpha^k\_{ij} \mathbf{W}^k \vec{h}\_j)
$$&lt;p&gt;multi-head 图注意力层的聚合过程如图1右侧所示。&lt;/p&gt;
&lt;h2 id="22-comparisons-to-related-work"&gt;2.2 Comparisons to related work
&lt;/h2&gt;&lt;p&gt;2.1节描述的图注意力层直接解决了之前在图结构上使用神经网络建模的方法的几个问题：
· 计算高效：self-attention层的操作可以在所有的边上并行，输出特征的计算可以在所有顶点上并行。没有耗时的特征值分解。单个的GAT计算$F&amp;rsquo;$个特征的时间复杂度可以压缩至$O(\vert V \vert F F&amp;rsquo; + \vert E \vert F&amp;rsquo;)$，$F$是输入的特征数，$\vert V \vert$和$\vert E \vert$是图中顶点数和边数。复杂度与Kipf &amp;amp; Welling, 2017的GCN差不多。尽管使用multi-head attention可以并行计算，但也使得参数和空间复杂度变成了$K$倍。
· 对比GCN，我们的模型允许对顶点的同一个邻居分配不同的重要度，使得模型能力上有一个飞跃。不仅如此，对学习到的attentional权重进行分析可以得到更好的解释性，就像机器翻译领域一样（比如Bahdanau et al., 2015的定性分析）。
· 注意力机制以一种共享的策略应用在图的所有的边上，因此它并不需要在之前就需要得到整个图结构或是所有的顶点的特征（很多之前的方法的缺陷）。因此这个方法有几个影响：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图不需要是无向的（如果边$j \rightarrow i$没有出现，我们可以直接抛弃掉$\alpha_{ij}$的计算）&lt;/li&gt;
&lt;li&gt;这个方法可以直接应用到&lt;em&gt;inductive learning&lt;/em&gt;——包括在训练过程中在完全未见过的图上评估模型的任务上。最近发表的Hamilton et al., 2017的inductive方法为了保持计算过程的一致性，对每个顶点采样采了一个固定数量的邻居；这就使得这个方法在推断的时候不能考虑所有的邻居。此外，在使用一个基于LSTM的邻居聚合方式时（Hochreiter &amp;amp; Schmidhuber, 1997），这个方法在某些时候能达到最好的效果。这意味着存在邻居间存在一个一致的顶点序列顺序，作者通过将随机顺序的序列输入至LSTM来验证它的一致性。我们的方法不会受到这些问题中任意一个的影响——它在所有的邻居上运算（虽说会有计算上的开销，但扔能和GCN这样的速度差不多），并且假设任意顺序都可以。
· 如第一节提到的，GAT可以重写成MoNet(Monti et al., 2016)的一种特殊形式。更具体的来说，设pseudo-coordinate function为$u(x, y) = f(x) \Vert f(y)$，$f(x)$表示$x$的特征（可能是MLP变换后的结果），$\Vert$表示concatenation；权重函数为$w_j(u) = \mathrm{softmax}(\mathrm{MLP}(u))$（softmax在一个顶点所有的邻居上计算）会使MoNet的patch operator和我们的很相似。尽管如此，需要注意到的是，对比之前MoNet的实例，我们的模型使用顶点特征计算相似性，而不是顶点的结构性质（这需要之前就已经直到图结构）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以做出一种使用稀疏矩阵操作的GAT层，将空间复杂度降低到顶点和边数的线性级别，使得GAT模型可以在更大的图数据集上运行。然而，我们使用的tensor操作框架只支持二阶tensor的稀疏矩阵乘法，限制了当前实现的版本的模型能力（尤其在有多个图的数据集上）。解决这个问题是未来的一个重要研究方向。在这些使用稀疏矩阵的场景下，在某些图结构下GPU的运算并不能比CPU快多少。另一个需要注意的地方是我们的模型的感受野的大小的上届取决于网络的深度（与GCN和其他模型相似）。像skip connections(He et al., 2016)这样的技术可以来近似的扩展模型的深度。最后，在所有边上的并行计算，尤其是分布式的计算可以设计很多冗余的计算，因为图中的邻居往往高度重叠。&lt;/p&gt;
&lt;h1 id="3-evaluation"&gt;3 Evaluation
&lt;/h1&gt;&lt;p&gt;我们与很多强力的模型进行了对比，在四个基于图的数据集上，达到了state-of-the-art的效果。这部分将总结一下我们的实验过程与结果，并对GAT提取特征表示做一个定性分析。
&lt;img src="https://davidham3.github.io/blog/images/graph-attention-networks/Table1.JPG"
loading="lazy"
alt="Table1"
&gt;&lt;/p&gt;
&lt;h2 id="31-datasets"&gt;3.1 Datasets
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Transductive learning&lt;/strong&gt; 我们使用了三个标准的citation network benchmark数据集——Cora, Citeseer和Pubmed(Sen et al., 2008)——并按Yang et al., 2016做的transductive实验。这些数据集中，顶点表示文章，边（无向）表示引用。顶点特征表示文章的BOW特征。每个顶点有一个类标签。我们使用每类20个顶点用来训练，训练算法使用所有的顶点特征。模型的预测性能是在1000个测试顶点上进行评估的，我们使用了500个额外的顶点来验证意图（像Kipf &amp;amp; Welling 2017）。Cora数据集包含了2708个顶点，5429条边，7个类别，每个顶点1433个特征。Citeseer包含3327个顶点，4732条边，6类，每个顶点3703个特征。Pubmed数据集包含19717个顶点，44338条边，3类，每个顶点500个特征。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inductive learning&lt;/strong&gt; 我们充分利用protein-protein interaction(PPI)数据集，这个数据集包含了不同的人体组织（Zitnik &amp;amp; Leskovec, 2017）。数据集包含了20个图来训练，2个验证，2个测试。关键的是，测试的图包含了训练时完全未见过的图。为了构建图，我们使用Hamilton et al., 2017预处理后的数据。平均每个图的顶点数为2372个。每个顶点有50个特征，组成了positional gene sets，motif gene sets and immunological signatures。从基因本体获得的每个顶点集有121个标签，由Molecular Signatures Database(Subramanian et al., 2005)收集，一个顶点可以同时拥有多个标签。&lt;/p&gt;
&lt;p&gt;这些数据集的概貌在表1中给出。&lt;/p&gt;
&lt;h2 id="32-state-of-the-art-methods"&gt;3.2 State-of-the-art methods
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Transductive learning&lt;/strong&gt; 对于transductive learning任务，我们对比了Kipf &amp;amp; Welling 2017的工作，以及其他的baseline。包括了label propagation(LP)(Zhu et al., 2003)，半监督嵌入(SemiEmb)(Weston et al., 2012)，manifold regulariization(ManiReg)(Belkin et al., 2006)，skip-gram based graph embeddings(DeepWalk)(Perozzi et al., 2014)，the iterative classification algorithm(ICA)(Lu &amp;amp; Getoor, 2003)和Planetoid(Yang et al., 2016)。我们也直接对比了GCN(Kipf &amp;amp; Welling 2017)，还有利用了高阶切比雪夫的图卷积模型(Defferrard et al., 2016)，还有Monti et al., 2016提出的MoNet。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inductive learning&lt;/strong&gt; 对于inductive learning任务，我们对比了Hamilton et al., 2017提出的四个不同的监督的GraphSAGE 这些方法提供了大量的聚合特征：GraphSAGE-GCN（对图卷积操作扩展inductive setting），GraphSAGE-mean（对特征向量的值取element-wise均值），GraphSAGE-LSTM（通过将邻居特征输入到LSTM进行聚合），GraphSAGE-pool（用一个共享的多层感知机对特征向量进行变换，然后使用element-wise取最大值）。其他的transductive方法要么在inductive中完全不合适，要么就认为顶点是逐渐加入到一个图中，使得他们不能在完全未见过的图上使用（如PPI数据集）。&lt;/p&gt;
&lt;p&gt;此外，对于两种任务，我们提供了每个顶点共享的MLP分类器（完全没有整合图结构信息）的performance。&lt;/p&gt;
&lt;h2 id="33-experimental-setup"&gt;3.3 Experimental Setup
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Transductive learning&lt;/strong&gt; 我们使用一个两层的GAT模型。超参数在Cora上优化过后在Citeseer上复用。第一层包含$K = 8$个attention head，计算得到$F&amp;rsquo; = 8$个特征（总共64个特征），之后接一个指数线性单元（ELU）（Clevert et al., 2016）作为非线性单元。第二层用作分类：一个单个的attention head计算$C$个特征（其中$C$是类别的数量），之后用softmax激活。处理小训练集时，在模型上加正则化。在训练时，我们使用$L_2$正则化，$\lambda = 0.0005$。除此以外，两个层的输入都使用了$p = 0.6$的dropout(Srivastava et al., 2014)，在&lt;em&gt;normalized attention coefficients&lt;/em&gt;上也使用了（也就是在每轮训练时，每个顶点都被随机采样邻居）。如Monti et al., 2016观察到的一样，我们发现Pubmed的训练集大小(60个样本)需要微调：我们使用$K = 8$个attention head，加强了$L_2$正则，$\lambda = 0.001$。除此以外，我们的结构都和Cora和Citeseer的一样。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inductive learning&lt;/strong&gt;
我们使用一个三层的GAT模型。前两层$K = 4$，计算$F&amp;rsquo; = 256$个特征（总共1024个特征），然后使用ELU。最后一层用于多类别分类：$K = 6$，每个计算121个特征，取平均后使用logistic sigmoid激活。训练集充分大所以不需要使用$L_2$正则或dropout——但是我们使用了skip connections(He et al., 2016)在attentional layer间。训练时batch size设置为2个图。为了严格的衡量出使用注意力机制的效果（与GCN相比），我们也提供了&lt;em&gt;constant attention mechanism&lt;/em&gt;，$a(x, y) = 1$，使用同样的架构——也就是每个邻居上都有相同的权重。&lt;/p&gt;
&lt;p&gt;两个模型都使用了Glorot初始化(Glorot &amp;amp; Bengio, 2010)，使用Adam SGD(Kingma &amp;amp; Ba, 2014)优化cross-entropy，Pubmed上初始学习率是0.01，其他数据集是0.005。我们在cross-entropy loss和accuracy(transductive)或micro-F1(inductive)上都使用了early stopping策略，迭代次数为100轮。
代码：https://github.com/PetarV-/GAT&lt;/p&gt;
&lt;h2 id="34-results"&gt;3.4 Results
&lt;/h2&gt;&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/graph-attention-networks/Table2.JPG"
loading="lazy"
alt="Table2"
&gt;
对于transductive任务，我们提交了我们的方法100次的平均分类精度（还有标准差），也用了Kipf &amp;amp; Welling., 2017和Monti et al., 2016的metrics。特别地，对于基于切比雪夫方法(Defferrard et al., 2016)，我们提供了二阶和三阶最好的结果。为了公平的评估注意力机制的性能，我们还评估了一个计算出64个隐含特征的GCN模型，并且尝试了ReLU和ELU激活，记录了100轮后更好的那个结果（GCN-64*）（结果显示ReLU更好）。
&lt;img src="https://davidham3.github.io/blog/images/graph-attention-networks/Table3.JPG"
loading="lazy"
alt="Table3"
&gt;
对于inductive任务，我们计算了micro-averaged F1 score在两个从未见过的测试图上，平均了10次结果，也使用了Hamilton et al., 2017的metrics。特别地，因为我们的方法是监督的，我们对比了GraphSAGE。为了评估聚合所有的邻居的优点，我们还提供了我们通过修改架构（三层GraphSAGE-LSTM分别计算[512, 512, 726]个特征，128个特征用来聚合邻居）所能达到的GraphSAGE最好的结果（GraphSAGE*）。最后，为了公平的评估注意力机制对比GCN这样的聚合方法，我们记录了我们的constant attention GAT模型的10轮结果（Const-GAT）。
结果展示出我们的方法在四个数据集上都很好，和预期一致，如2.2节讨论的那样。具体来说，在Cora和Citeseer上我们的模型上升了1.5%和1.6%，推测应该是给邻居分配不同的权重起到了效果。值得注意的是在PPI数据集上：我们的GAT模型对于最好的GraphSAGE结果提升了20.5%，这意味着我们的模型可以应用到inductive上，通过观测所有的邻居，模型会有更强的预测能力。此外，针对Const-GAT也提升3.9%，再一次展现出给不同的邻居分配不同的权重的巨大提升。&lt;/p&gt;
&lt;p&gt;学习到的特征表示的有效性可以定性分析——我们提供了t-SNE(Maaten &amp;amp; Hinton, 2008)的可视化——我们对在Cora上面预训练的GAT模型中第一层的输出做了变换（图2）。representation在二维空间中展示出了可辩别的簇。注意，这些簇对应了数据集的七个类别，验证了模型在Cora上对七类的判别能力。此外，我们可视化了归一化的attention系数（对所有的8个attention head取平均）的相对强度。像Bahdanau et al., 2015那样适当的解释这些系数需要更多的领域知识，我们会在未来的工作中研究。
&lt;img src="https://davidham3.github.io/blog/images/graph-attention-networks/Fig2.JPG"
loading="lazy"
alt="Figure2"
&gt;&lt;/p&gt;
&lt;h1 id="4-conclusions"&gt;4 Conclusions
&lt;/h1&gt;&lt;p&gt;我们展示了图注意力网络(GAT)，新的卷积风格神经网络，利用masked self-attentional层。图注意力网络计算高效（不需要耗时的矩阵操作，在图中的顶点上并行计算），处理不同数量的邻居时对邻居中的不同顶点赋予不同的重要度，不需要依赖整个图的结构信息——因此解决了之前提出的基于谱的方法的问题。我们的这个利用attention的模型在4个数据集针对transductive和inductive（特别是对完全未见过的图），对顶点分类成功地达到了state-of-the-art的performance。&lt;/p&gt;
&lt;p&gt;未来在图注意力网络上有几点可能的改进与扩展，比如解决2.2节描述的处理大批数据时的实际问题。还有一个有趣的研究方向是利用attention机制对我们的模型进行一个深入的解释。此外，扩展我们的模型从顶点分类到图分类也是一个更具应用性的方向。最后，扩展我们的模型到整合边的信息（可能制视了顶点关系）可以处理更多的问题。&lt;/p&gt;</description></item><item><title>Semi-Supervised Classification With Graph Convolutional Networks</title><link>https://davidham3.github.io/blog/p/semi-supervised-classification-with-graph-convolutional-networks/</link><pubDate>Mon, 02 Jul 2018 20:04:20 +0000</pubDate><guid>https://davidham3.github.io/blog/p/semi-supervised-classification-with-graph-convolutional-networks/</guid><description>&lt;p&gt;ICLR 2017。图卷积中谱图领域理论上很重要的一篇论文，提升了图卷积的性能，使用切比雪夫多项式的1阶近似完成了高效的图卷积架构。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1609.02907v4" target="_blank" rel="noopener"
&gt;Semi-Supervised Classification with Graph Convolutional Networks. Kipf &amp;amp; Welling 2017&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;我们提出了一种在图结构数据上的半监督可扩展学习方法，基于高效的图卷积变体。契机是通过一个谱图卷积的局部一阶近似得到的我们的图卷积结构。我们的模型与图的边数呈线性关系，学习到的隐藏层可以对图的顶点和局部图结构同时进行编码。在引文网络和一个知识图谱数据集上的大量实验结果表明我们的方法比相关方法好很多。&lt;/p&gt;
&lt;h1 id="引言"&gt;引言
&lt;/h1&gt;&lt;p&gt;我们考虑一个对图顶点进行分类的问题，只有一小部分的顶点有标签。这个问题可以通过基于图的半监督学习任务建模，通过某些明确的图正则化方法(Zhu et al., 2003; Zhou et al., 2004; Belkin et al., 2006; Weston et al., 2012)可以平滑标签信息，举个例子，通过在loss function使用一个图拉普拉斯正则项：
&lt;/p&gt;
$$\tag{1} \mathcal{L} = \mathcal{L\_0} + \lambda \mathcal{L\_{reg}}, \rm with \ \mathcal{L\_{reg}} = \sum\_{i.j}A\_{ij} \Vert f(X\_i) - f(X\_j) \Vert^2 = f(X)^T \Delta f(X)$$&lt;p&gt;
其中，$\mathcal{L_0}$表示对于图的标签部分的监督损失，$f(\cdot)$可以是一个神经网络类的可微分函数，$\lambda$是权重向量，$X$是定点特征向量$X_i$的矩阵。$N$个顶点$v_i \in \mathcal{V}$，边$(v_i, v_j) \in \varepsilon$，邻接矩阵$A \in \mathbb{R}^{N \times N}$（二值的或者带权重的），还有一个度矩阵$D_{ii} = \sum_jA_{ij}$。式1依赖于“图中相连的顶点更有可能具有相同的标记”这一假设。然而，这个假设，可能会限制模型的能力，因为图的边并不是必须要编码成相似的，而是要包含更多的信息。
在我们的研究中，我们将图结构直接通过一个神经网络模型$f(X, A)$进行编码，并且在监督的目标$\mathcal{L_0}$下对所有有标记的顶点进行训练，因此避免了损失函数中刻意的对图进行正则化。在图的邻接矩阵上使用$f(\cdot)$可以使模型从监督损失$\mathcal{L_0}$中分布梯度信息，并且能够从有标记和没有标记的顶点上学习到他们的表示。
我们的贡献有两点，首先，我们引入了一个简单的，表现很好的针对神经网络的对层传播规则，其中，这个神经网络是直接应用到图上的，并且展示了这个规则是如何通过谱图卷积的一阶近似启发得到的。其次，我们展示了这种形式的基于图的神经网络可以用于对图中的顶点进行更快更可扩展的半监督分类任务。在大量数据集上的实验表明我们的模型在分类精度和效率上比当前在半监督学习中的先进算法要好。&lt;/p&gt;
&lt;h1 id="图上的快速近似卷积"&gt;图上的快速近似卷积
&lt;/h1&gt;&lt;p&gt;在这部分，我们会讨论一个特殊的基于图的神经网络$f(X, A)$。考虑一个多层图卷积网络(GCN)，通过以下的传播规则：
&lt;/p&gt;
$$\tag{2} H^{(l+1)} = \sigma(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(l)} W^{(l)})$$&lt;p&gt;
其中，$\tilde{A} = A + I_N$是无向图$\mathcal{G}$加了自连接的邻接矩阵。$I_N$是单位阵，$\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$，$W^{(l)}$是一个针对层训练的权重矩阵。$\sigma(\cdot)$表示一个激活函数，比如$\rm ReLU(\cdot) = \rm max(0, \cdot)$，$H^{(l)} \in \mathbb{R}^{N \times D}$是第$l$层的激活矩阵；$H^{(0)} = X$。接下来我们将展示通过图上的一阶近似局部谱滤波器(Hammond et al., 2011; Defferrard et al., 2016)的传播过程。&lt;/p&gt;
&lt;h2 id="谱图卷积-spectral-graph-convolutions"&gt;谱图卷积 spectral graph convolutions
&lt;/h2&gt;&lt;p&gt;定义图上的谱图卷积为信号$x \in \mathbb{R}^N$和一个滤波器$g_\theta = \rm diag(\theta)$，参数是傅里叶域中的$\theta \in \mathbb{R}^N$，也就是：
&lt;/p&gt;
$$\tag{3} g\_\theta \ast x = U g\_\theta U^T x$$&lt;p&gt;
其中$U$是归一化的拉普拉斯矩阵$L = I_N - D^{-\frac{1}{2}}AD^{-\frac{1}{2}} = U \Lambda U^T$的特征向量组成的矩阵，$\Lambda$是特征值组成的对角阵，$U^Tx$是$x$的图傅里叶变换。可以认为$g_\theta$是关于$L$的特征值的函数，也就是说$g_\theta(\Lambda)$。式3的计算量很大，因为特征向量矩阵$U$的乘法的时间复杂度是$O(N^2)$。此外，对于大尺度的图来说，对$L$进行特征值分解是计算量非常大的一件事。为了避开这个问题，Hammond et al.(2001)建议使用$K$阶切比雪夫多项式$T_k(x)$来近似$g_\theta(\Lambda)$：
&lt;/p&gt;
$$\tag{4} g\_\theta' \approx \sum^K\_{k=0} \theta'\_k T\_k(\tilde{\Lambda})$$&lt;p&gt;
其中，$\tilde{\Lambda} = \frac{2}{\lambda_{max}} \Lambda - I_N$。$\lambda_{max}$表示$L$的最大特征值。$\theta&amp;rsquo; \in \mathbb{R}^K$是切比雪夫系数向量。切比雪夫多项式的定义是：$T_k(x) = 2xT_{k-1}(x) - T_{k-2}(x)$，$T_0(x) = 1$，$T_1(x) = x$。
回到我们对于一个信号$x$和一个滤波器$g_\theta&amp;rsquo;$的卷积的定义：
&lt;/p&gt;
$$\tag{5} g\_\theta' \ast x \approx \sum^K\_{k=0} \theta'\_k T\_k(\tilde{L}) x$$&lt;p&gt;
其中，$\tilde{L} = \frac{2}{\lambda x_{max}} L - I_N$；注意$(U \Lambda U^T)^k = U \Lambda^k U^T$。这个表达式目前是$K$阶局部的，因为这个表达式是拉普拉斯矩阵的$K$阶多项式，也就是说从中心节点向外最多走$K$步，$K$阶邻居。式5的时间复杂度是$O(\vert \varepsilon \vert)$，也就是和边数呈线性关系。Defferrard et al.(2016)使用这个$K$阶局部卷积定义了在图上的卷积神经网络。&lt;/p&gt;
&lt;h2 id="按层的线性模型-layer-wise-linear-model"&gt;按层的线性模型 layer-wise linear model
&lt;/h2&gt;&lt;p&gt;一个基于图卷积的神经网络模型可以通过堆叠式5这样的多个卷积层来实现，每层后面加一个非线性激活即可。现在假设$K=1$，也就是对$L$线性的一个函数，因此得到一个在图拉普拉斯谱(graph Laplacian spectrum)上的线性函数。这样，我们仍然能通过堆叠多个这样的层获得一个卷积函数，但是我们就不会再受限于明显的参数限制，比如切比雪夫多项式。我们直觉上期望这样一个模型可以减轻在度分布很广泛的图上局部图结构模型过拟合的问题，如社交网络、引文网络、知识图谱和其他很多真实数据集。此外，这个公式可以让我们搭建更深的网络，一个可以提升模型学习能力的实例是He et al., 2016。
在GCN的线性公式中，我们让$\lambda_{max}$近似等于2，因为我们期望神经网络参数可以在训练中适应这个变化。在这个近似下，式5可以简化为：
&lt;/p&gt;
$$\tag{6} g\_\theta' \ast x \approx \theta'\_0x + \theta'\_1 (L - I\_N)x = \theta'\_0x - \theta'\_1 D^{-\frac{1}{2}} A D^{-\frac{1}{2}} x$$&lt;p&gt;
两个参数$\theta&amp;rsquo;_0$和$\theta&amp;rsquo;_1$。滤波器参数可以在整个图上共享。连续的使用这种形式的卷积可以有效的对一个顶点的$k$阶邻居进行卷积，$k$是连续的卷积操作或模型中卷积层的个数。
实际上，通过限制参数的数量可以进一步的解决过拟合的问题，并且最小化每层的操作数量（比如矩阵乘法）。这时的我们得到了下面的式子：
&lt;/p&gt;
$$\tag{7} g\_\theta \ast x \approx \theta(I\_N + D^{-\frac{1}{2}} A D^{-\frac{1}{2}}) x$$&lt;p&gt;
只有一个参数$\theta = \theta&amp;rsquo;_0 = - \theta&amp;rsquo;_1$。注意，$I_N + D^{-\frac{1}{2}} A D^{-\frac{1}{2}}$现在的特征值在$[0, 2]$之间。在深层模型中重复应用这个操作会导致数值不稳定和梯度爆炸、消失的现象。为了减轻这个问题，我们引入了如下的重新正则化技巧：$I_N + D^{-\frac{1}{2}} A D^{-\frac{1}{2}} \to \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$，$\tilde{A} = A + I_N$，$\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$。
我们可以将这个定义泛化到一个有着$C$个通道的信号$X \in \mathbb{R}^{N \times C}$上，也就是每个顶点都有一个$C$维的特征向量，对于$F$个滤波器或$F$个feature map的卷积如下：
&lt;/p&gt;
$$\tag{8} Z = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X \Theta$$&lt;p&gt;
其中$\Theta \in \mathbb{R}^{C \times F}$是一个滤波器的参数矩阵，$Z \in \mathbb{R}^{N \times F}$是卷积的信号矩阵。卷积操作的时间复杂度是$O(\vert \varepsilon \vert F C)$，因为$\tilde{A} X$可以被实现成一个稀疏矩阵和一个稠密矩阵的乘积。&lt;/p&gt;
&lt;h1 id="半监督顶点分类"&gt;半监督顶点分类
&lt;/h1&gt;&lt;p&gt;介绍过这个简单、灵活的可以在图上传播信息的模型$f(X, A)$后，我们回到半监督顶点分类的问题上。如介绍里面所说的，我们可以减轻在基于图的半监督学习任务中的假设，通过在图结构上的数据$X$和邻接矩阵$A$上使用模型$f(X, A)$。我们期望这个设置可以在邻接矩阵表达出数据$X$没有的信息的这种情况时表现的很好，比如引文网络中，引用的关系或是知识图谱中的关系。整个模型是一个多层的GCN，如图1所示。
&lt;img src="https://davidham3.github.io/blog/images/semi-supervised-classification-with-graph-convolutional-networks/Fig1.PNG"
loading="lazy"
alt="Fig1"
&gt;&lt;/p&gt;
&lt;h2 id="例子"&gt;例子
&lt;/h2&gt;&lt;p&gt;我们考虑一个两层GCN对图中的顶点进行半监督分类，邻接矩阵是对称的。我们首先在预处理中计算$\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$。前向传播模型的形式如下：
&lt;/p&gt;
$$\tag{9} Z = f(X, A) = \rm softmax( \hat{A} \ \rm ReLU( \hat{A}XW^{(0)})W^{(1)})$$&lt;p&gt;
这里，$W^{(0)} \in \mathbb{R}^{C \times H}$是输入到隐藏层的权重矩阵，有$H$个feature map。$W^{(1)} \in \mathbb{R}^{H \times F}$是隐藏层到输出的权重矩阵。softmax激活函数定义为$\rm softmax(x_i) = \frac{1}{\mathcal{Z}} \exp(x_i)$，$\mathcal{Z} = \sum_i \exp(x_i)$，按行使用。对于半监督多类别分类，我们使用交叉熵来衡量所有标记样本的误差：
&lt;/p&gt;
$$\tag{10} \mathcal{L} = - \sum\_{l \in \mathcal{Y}\_L} \sum^F\_{f = 1} Y\_{lf} \ln(Z\_{lf})$$&lt;p&gt;
其中，$\mathcal{Y}_L$是有标签的顶点的下标集合。
神经网络权重$W^{(0)}$和$W^{(1)}$使用梯度下降训练。我们每次训练的时候都是用全部的训练集来做梯度下降，只要数据集能放到内存中。对$A$进行稀疏矩阵的表示，内存的使用量是$O(\vert \varepsilon \vert)$。训练过程中使用了dropout增加随机性。我们将在未来的工作使用mini-batch随机梯度下降。&lt;/p&gt;
&lt;h2 id="实现"&gt;实现
&lt;/h2&gt;&lt;p&gt;我们使用Tensorflow实现了基于GPU的，稀疏稠密矩阵乘法形式。式9的时间复杂度是$O(\vert \varepsilon \vert C H F)$。&lt;/p&gt;</description></item><item><title>Graph Convolutional Neural Networks for Web-Scale Recommender Systems</title><link>https://davidham3.github.io/blog/p/graph-convolutional-neural-networks-for-web-scale-recommender-systems/</link><pubDate>Sun, 17 Jun 2018 21:24:48 +0000</pubDate><guid>https://davidham3.github.io/blog/p/graph-convolutional-neural-networks-for-web-scale-recommender-systems/</guid><description>&lt;p&gt;KDD 2018。使用图卷积对顶点进行表示，学习顶点的 embedding ，通过卷积将该顶点的邻居信息融入到向量中。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1806.01973v1" target="_blank" rel="noopener"
&gt;Graph Convolutional Neural Networks for Web-Scale Recommender Systems&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id="abstract"&gt;ABSTRACT
&lt;/h1&gt;&lt;p&gt;最近在图数据上的深度神经网络在推荐系统上表现的很好。然而，把这些算法应用到数十亿的物品和数百亿的用户上仍然是个挑战。&lt;/p&gt;
&lt;p&gt;我们提出了一种在 Pinterest 上的大规模深度推荐引擎，开发了一种高效的图卷积算法 PinSage，融合了随机游走和图卷积，来生成顶点（物品）的表示，同时整合了顶点信息和图结构。对比之前的 GCN 方法，我们研究的模型基于高效的随机游走来结构化卷积操作，而且还设计了一个新型的训练策略，这个策略依赖于 harder-and-harder 训练样本，来提高模型的鲁棒性和收敛能力。&lt;/p&gt;
&lt;p&gt;我们的 PinSage 在 Pinterest 上面的75亿个样本上进行训练，图上有30亿个顶点表示 &lt;em&gt;pins&lt;/em&gt; 和 &lt;em&gt;boards&lt;/em&gt;，180亿条边。根据离线指标、用户研究和 A/B 测试，PinSage 生成了相比其他深度学习和基于图的方法更高质量的推荐结果。据我们所知，这是深度图表示目前规模最大的应用，并且为新一代基于图卷积结构的大规模推荐系统奠定了基础。&lt;/p&gt;
&lt;h1 id="1-introduction"&gt;1 INTRODUCTION
&lt;/h1&gt;&lt;p&gt;深度学习方法在推荐系统中越来越重要，用来学习图像、文本、甚至是用户的有效的低维表示。使用深度学习学习到的表示可以用来补充、或是替换像协同过滤这样传统的推荐算法。这些表示很有用，因为他们可以在各种推荐任务中重复使用。举个例子，使用深度模型学习得到的物品的表示，可以用来做 “物品-物品” 推荐，也可以来按主题推荐（比如，歌单、或是 Feed流的内容）。&lt;/p&gt;
&lt;p&gt;近些年可以看到这个领域的很多重要的发展，尤其是新的可以学习图结构的深度学习方法的发展，是一些推荐应用的基础（比如在用户-物品网络上或社交网络上推荐）。&lt;/p&gt;
&lt;p&gt;在这些成功的深度学习框架中比较重要的是图卷积网络（GCN）。核心的原理是学习如何迭代地使用神经网络从局部图邻居中聚合特征信息（图1）。这里，一个简单的卷积操作从一步邻居中变换并聚合特征信息，并且通过堆叠多个这样的卷积，信息可以传播到图中很广的地方。不像纯基于内容的深度模型（如 RNN ），GCN 利用内容信息和图结构。基于 GCN 的模型的方法已经在无数推荐系统中形成了新的标准（参见[19]的综述）。然而，这些b enchmark 上面获得的提升，还没有被转换到真实环境的应用中去。&lt;/p&gt;
&lt;p&gt;主要挑战是要将训练和基于 GCN 的顶点表示在数十亿的顶点和数百亿的边的图中进行。扩展 GCN 很困难，因为很多在大数据环境中，很多基于这些 GCN 设计的假设都不成立了。比如，所有的基于 GCN 的推荐系统需要在训练时使用图的拉普拉斯矩阵，但是当顶点数很大的时候，这就不现实了，因为算不出来。&lt;/p&gt;
&lt;h1 id="3-method"&gt;3 METHOD
&lt;/h1&gt;&lt;p&gt;在这部分，我们将描述 PinSage 的结构和训练的技术细节，也会讲一下使用训练好的 PinSage 模型来高效地生成 embedding 的MapReduce pipeline。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/graph-convolutional-neural-networks-for-web-scale-recommender-systems/Fig1.PNG"
loading="lazy"
alt="Figure1"
&gt;&lt;/p&gt;
&lt;p&gt;我们方法的计算关键在于局部图卷积的表示(notion)。我们使用多个卷积模块来聚合一个顶点局部的邻域特征信息（图1），来生成这个顶点的 embedding（比如一个物品）。每个模块学习如何从一个小的图邻域中聚合信息，并且通过堆叠多个这样的模块，我们的方法可以获得局部网络的拓扑结构信息。更重要的是，这些局部卷积模块的参数对所有的顶点来说是共享的，这使得我们的方法的参数的计算复杂度与输入的图的大小无关。&lt;/p&gt;
&lt;h1 id="31-problem-setup"&gt;3.1 Problem Setup
&lt;/h1&gt;&lt;p&gt;Pinterest 是一个内容挖掘应用，在这里用户与 &lt;em&gt;pins&lt;/em&gt; 进行交互，这些 &lt;em&gt;pins&lt;/em&gt; 是在线内容的可见标签（比如用户做饭时的食谱，或者他们想买的衣服）。用户用 &lt;em&gt;boards&lt;/em&gt; 将 &lt;em&gt;pins&lt;/em&gt; 组织起来，&lt;em&gt;boards&lt;/em&gt; 里面包含了 &lt;em&gt;pins&lt;/em&gt; 组成的集合，这些 &lt;em&gt;pins&lt;/em&gt; 在用户看来是主题相关的。Pinterest 组成的图包含了 20 亿的 &lt;em&gt;pins&lt;/em&gt;，10 亿的 &lt;em&gt;boards&lt;/em&gt;，超过 180 亿的边（也就是 &lt;em&gt;pins&lt;/em&gt; 对应 &lt;em&gt;boards&lt;/em&gt; 的关系）。&lt;/p&gt;
&lt;p&gt;我们的任务是生成可以用于推荐的高质量的 embedding 或 &lt;em&gt;pins&lt;/em&gt; 的表示（比如，使用最近邻来查找 &lt;em&gt;pin&lt;/em&gt; 的推荐，或是使用下游的再评分系统进行推荐）。为了学习这些 embedding，我们对 Pinterest 环境进行建模，得到一个二部图，顶点分为两个不相交的集合，$\mathcal{I}$ 表示 &lt;em&gt;pins&lt;/em&gt;，$\mathcal{C}$ 表示 &lt;em&gt;boards&lt;/em&gt;。当然，我们的方法是可以泛化到其他方面的，比如 $\mathcal{I}$ 看作是物品，$\mathcal{C}$ 看作是用户定义的环境或收藏品集合等。&lt;/p&gt;
&lt;p&gt;再来说说图结构，我们假设 &lt;em&gt;pins/items&lt;/em&gt; $u \in \mathcal{I}$ 与特征 $x_u \in \mathbb{R}^d$ 相关。通常来说，这些特征可能是物品的元数据或上下文信息，在 Pinterest 的例子中，&lt;em&gt;pins&lt;/em&gt; 是和富文本与图片特征相关的。我们的目标是利用这些输入特征，也利用二部图的图结构性质来生成高质量的 embedding。这些 embedding 可以用于推荐系统，通过最近邻查找来生成推荐，或是作为用评分来推荐的机器学习系统的特征。&lt;/p&gt;
&lt;p&gt;为了符号的简洁，我们使用 $\mathcal{V} = \mathcal{I} \cup \mathcal{C}$ 来表示图中的顶点集，没有特殊需要不区分 &lt;em&gt;pin&lt;/em&gt; 和 &lt;em&gt;board&lt;/em&gt; 顶点，一律使用 &lt;em&gt;node&lt;/em&gt; 来表示顶点。&lt;/p&gt;
&lt;h2 id="32-model-architecture"&gt;3.2 Model Architecture
&lt;/h2&gt;&lt;p&gt;我们使用局部卷积模块对顶点生成 embeddings。首先输入顶点的特征，然后学习神经网络，神经网络会变换并聚合整个图上的特征来计算顶点的 embeddings（图1）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Forward propagation algorithm.&lt;/strong&gt; 考虑对顶点 $u$ 生成 embedding $z_u$ 的任务，需要依赖顶点的输入特征和这个顶点周围的图结构。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/graph-convolutional-neural-networks-for-web-scale-recommender-systems/algo1.PNG"
loading="lazy"
alt="“Algorithm 1”"
&gt;&lt;/p&gt;
&lt;p&gt;我们的 PinSage 算法是一个局部卷积操作，我们可以通过这个局部卷积操作学到如何从 $u$ 的邻居聚合信息（图1）。这个步骤在算法1 CONVOLVE 中有所描述。从本质上来说，我们通过一个全连接神经网络对 $\forall{v} \in \mathcal{N}(u)$，也就是 $u$ 的邻居的表示 $z_v$ 进行了变换，之后在结果向量集合上用一个聚合/池化函数（例如：一个 element-wise mean 或是加权求和，表示为 $\gamma$）（Line 1）。这个聚合步骤生成了一个 $u$ 的邻居$\mathcal{N}(u)$ 的表示 $n_u$。之后我们将这个聚集邻居向量 $n_u$ 和 $u$ 的当前表示向量进行拼接后，输入到一个全连接神经网络做变换（Line 2）。通过实验我们发现使用拼接操作会获得比平均操作[21]好很多的结果。除此以外，第三行的 normalization 使训练更稳定，而且对近似最近邻搜索来说归一化的 embeddings 更高效（Section 3.5）。算法的输出是集成了 $u$ 自身和他的局部邻域信息的表示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Importance-based neighborhoods.&lt;/strong&gt; 我们方法中的一个重要创新是如何定义的顶点邻居 $\mathcal{N}(u)$，也就是我们在算法1中是如何选择卷积的邻居集合。尽管之前的 GCN 方法简单地检验了 k-hop 邻居，在 PinSage 中我们定义了基于重要性的邻域，顶点 $u$ 的邻居定义为 $T$ 个顶点，这 $T$ 个顶点对 $u$ 是最有影响力的。具体来说，我们模拟了从顶点 $u$ 开始的随机游走，并且计算了通过随机游走&lt;a class="link" href="https://arxiv.org/abs/1711.07601" target="_blank" rel="noopener"
&gt;[14]&lt;/a&gt;对顶点的访问次数的 $L_1$ 归一化值。$u$ 的邻居因此定义为针对顶点 $u$ 来说 $T$ 个最高的归一化的访问数量的顶点。&lt;/p&gt;
&lt;p&gt;这个基于重要性的邻域定义的优点有两点。第一点是选择一个固定数量的邻居顶点来聚集可以在训练过程中控制内存开销[18]。第二，在算法1中聚集邻居的向量表示时可以考虑邻居的重要性。特别地，我们在算法1中实现的 $\gamma$ 是一个加权求均值的操作，权重就是 $L_1$ 归一化访问次数。我们将这个新的方法称为重要度池化(&lt;em&gt;importance pooling&lt;/em&gt;)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stacking convolutions.&lt;/strong&gt; 每次使用算法1的 CONVOLVE 操作都会得到一个顶点的新的表示，我们可以在每个顶点上堆叠卷积来获得更多表示顶点 $u$ 的局部邻域结构的信息。特别地，我们使用多层卷积，其中对第 $k$ 层卷积的输入依赖于 $k-1$ 层的输出（图1），最初的表示（&amp;ldquo;layer 0&amp;rdquo;）等价于顶点的输入特征。需要注意的是，算法1中的模型参数（$Q$, $q$, $W$ 和 $w$）在顶点间是共享的，但层与层之间不共享。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/graph-convolutional-neural-networks-for-web-scale-recommender-systems/algo2.PNG"
loading="lazy"
&gt;&lt;/p&gt;
&lt;p&gt;算法2详细描述了如何堆叠卷积操作，针对一个 minibatch 的顶点 $\mathcal{M}$ 生成 embeddings。首先计算每个顶点的邻居，然后使用 $K$ 个卷积迭代来生成目标顶点的 K 层表示。最后一层卷积层的输出之后会输入到一个全连接神经网络来生成最后的 embedding $z_u$，$\forall{u} \in \mathcal{M}$。&lt;/p&gt;
&lt;p&gt;模型需要学习的参数有：每个卷积层的权重和偏置（$Q^{(k)}$，$q^{(k)}$，$W^{(k)}$，$w^{(k)}$，$\forall{k} \in \lbrace 1,&amp;hellip;,K\rbrace $），还有最后的全连接网络中的参数 $G_1$，$G_2$，$g$。算法1的第一行的每层输出的维度（也就是 $Q$ 的列空间的维度）设为 $m$。为了简单起见，我们将所有卷积层（算法1的第三行的输出）的输出都设为同一个数，表示为 $d$。模型最后的输出（算法2第18行之后）也设为 $d$。&lt;/p&gt;
&lt;h2 id="33-model-training"&gt;3.3 Model Training
&lt;/h2&gt;&lt;p&gt;我们使用 max-margin ranking loss 来训练 PinSage。在这步，假设我们有了一组标记的物品对 $\mathcal{L}$，$(q,i) \in \mathcal{L}$ 认为是相关的，也就是当查询 $q$ 时，物品 $i$ 是一个好的推荐候选项。训练阶段的目标是优化 PinSage 的参数，使得物品对 $(q,i) \in \mathcal{L}$ 的 embedding 在标记集合中尽可能的接近。&lt;/p&gt;
&lt;p&gt;我们先来看看 margin-based loss function。首先我们来看看我们使用的可以高效地计算并且使 PinSage 快速收敛的一些技术，这些技术可以让我们训练包含数十亿级别的顶点的图，以及数十亿训练样本。最后，我们描述我们的 curriculum-training scheme，这个方法可以全方位的提升我们的推荐质量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loss function.&lt;/strong&gt; 为了训练模型的参数，我们使用了一个基于最大边界的损失函数。基本的思想是我们希望最大化正例之间的内积，也就是说，查询物品的 embedding 和对应的相关物品的 embedding 之间的内积。与此同时我们还想确保负例之间的内积，也就是查询物品的 embedding 和那些不相关物品 embedding 之间的内积要小于通过提前定义好的边界划分出的正例的内积。对于单个顶点对 embeddings $(z_q, z_i):(q, i) \in \mathcal{L}$ 的损失函数是：&lt;/p&gt;
$$
J\_{\mathcal{G}}(z\_qz\_i) = \mathbb{E}\_{n\_k \thicksim p\_n(q)}\max\lbrace 0, z\_q \cdot z\_{n\_k}-z\_q \cdot z\_i + \Delta\rbrace
$$&lt;p&gt;其中，$P_n(q)$ 表示物品 $q$ 的负样本分布，$\Delta$ 表示 margin 超参数。一会儿会讲负样本采样。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi-GPU training with large minibatches.&lt;/strong&gt; 为了在训练中充分利用单台机器的多个 GPU，我们以一种 multi-tower 的方法运行前向和反向传播。我们首先将每个 minibatch（图1底部）分成相等大小的部分。每个 GPU 获得 minibatch 的一部分，使用同一组参数来运算。在反向传播之后，所有 GPU 上的针对每个参数的梯度进行汇集，然后使用一个同步的 SGD。由于训练需要极大数量的样本，我们在运行时使用了很大的 batch size，范围从 512 到 4096。&lt;/p&gt;
&lt;p&gt;我们使用与 Goyal et al.[16] 提出的相似的技术来确保快速收敛，而且在处理大 batch size 时训练的稳定和泛化精度。我们在第一轮训练的时候根据线性缩放原则使用一个 gradual warmup procedure，使学习率从小增大到一个峰值。之后学习率以指数级减小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer-consumer minibatch construction.&lt;/strong&gt; 在训练的过程中，由于邻接表和特征矩阵有数十亿的顶点，所以放在了 CPU 内存中。然而，在训练 PinSage 的 CONVOLVE 步骤时，每个 GPU 需要处理邻居和顶点邻居的特征信息。从 GPU 访问 CPU 内存中的数据时会有很大的开销。为了解决这个问题，我们使用了一个 &lt;em&gt;re-indexing&lt;/em&gt; 的方法创建包含了顶点和他们的邻居的子图 $G&amp;rsquo; = (V&amp;rsquo;, E&amp;rsquo;)$，在当前的 minibatch 中会被加入到计算中。只包含当前 minibatch 计算的顶点特征信息的小的特征矩阵会被抽取出来，顺序与 $G&amp;rsquo;$ 中顶点的 index 一致。$G&amp;rsquo;$ 的邻接表和小的特征矩阵会在每个 minibatch 迭代时输入到 GPU 中，这样就没有了 GPU 和 CPU 间的通信开销了，极大的提高了 GPU 的利用率。&lt;/p&gt;
&lt;p&gt;训练过程改变了 CPU 和 GPU 的使用方式。模型计算是在 GPU，特征抽取、re-indexing、负样本采样是在 CPU 上运算的。使用 multi-tower 训练的 GPU 并行和 CPU 计算使用了 OpenMP[25]，我们设计了一个生产者消费者模式在当前迭代中使用 GPU 计算，在下一轮使用 CPU 计算，两者并行进行。差不多减少了一半的时间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sampling negative items.&lt;/strong&gt; 负样本采样在我们的损失函数中作为 edge likelihood[23] 的归一化系数的近似值。为了提升 batch size 较大时的训练效率，我们采样了 500 个负样本作为一组，每个 minibatch 的训练样本共同使用这一组。相比于对每个顶点在训练时都进行负样本采样，这极大地减少了每次训练时需要计算的 embeddings 的数量。从实验上来看，我们发现这两种方法在表现上没什么特别大的差异。&lt;/p&gt;
&lt;p&gt;在最简单的情况中，我们从整个样本集中使用均匀分布的抽样方式。然而，确保正例($(q, i)$)的内积大于 $q$ 和 500 个负样本中每个样本的内积是非常简单的，而且这样做不能提供给系统足够学习的分辨率。我们的推荐算法应该能从 200 亿个商品中找到对于物品 $q$ 来说最相关的 1000 个物品。换句话说，我们的模型应该能从超过 2 千万的物品中区分/辨别出 1 件物品。但是通过随机采样的 500 件物品，模型的分辨率只是 $\frac{1}{500}$。因此，如果我们从 200 亿物品中随机抽取 500 个物品，这些物品中的任意一个于当前这件查询的物品相关的几率都很小。因此，模型通过训练不能获得好的参数，同时也不能对相关的物品进行区分的概率很大。为了解决上述问题，对于每个正训练样本（物品对$(q, i)$），我们加入了&amp;quot;hard&amp;quot;负例，也就是那些与查询物品 $q$ 有某种关联的物品，但是又不与物品 $i$ 有关联。我们称这些样本为&amp;quot;hard negative items&amp;quot;。通过在图中根据他们对查询物品 $q$ 的个性化 PageRank 分数来生成[14]。排名在 2000-5000 的物品会被随机采样为 hard negative items。如图2所示，hard negative examples 相比于随机采样的负样本更相似于查询物品，因此对模型来说挑战是排名，迫使模型学会在一个好的粒度上分辨物品。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/graph-convolutional-neural-networks-for-web-scale-recommender-systems/Fig2.PNG"
loading="lazy"
&gt;&lt;/p&gt;
&lt;p&gt;使用 hard negative items 会让能使模型收敛的训练轮数翻倍。为了帮助模型收敛，我们使用了 curriculum training scheme[4]。在训练的第一轮，不适用 hard negative items，这样算法可以快速地找到 loss 相对较小的参数空间。之后我们在后续的训练中加入了 hard negative items，专注于让模型学习如何从弱关系中区分高度关联的pins。在第 $n$ 轮，我们对每个物品的负样本集中加入了 $n-1$ 个 hard negative items。&lt;/p&gt;
&lt;h2 id="34-node-embeddings-via-mapreduce"&gt;3.4 Node Embeddings via MapReduce
&lt;/h2&gt;&lt;p&gt;在模型训练结束后，对于所有的物品（包括那些在训练中未见过的物品）直接用训练好的模型生成 embeddings 还是有挑战的。使用算法2对顶点直接计算 embedding 的方法会导致重复计算，这是由顶点的K-hop 邻居导致的。如图1所示，很多顶点在针对不同的目标顶点生成 embedding 的时候被很多层重复计算多次。为了确保推算的有效性，我们使用了一种 MapReduce 架构来避免在使用模型进行推算的时候的重复计算问题。&lt;/p&gt;
&lt;p&gt;我们发现顶点的 embedding 在推算的时候会很好的将其自身带入到 MR 计算模型中。图3详细地表述了 pin-to-board Pinterest 二部图上的数据流，我们假设输入（&amp;ldquo;layer-0&amp;rdquo;）顶点是 pins/items（layer-1 顶点是 boards/contexts）。MR pipeline 有两个关键的组成部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一个 MapReduce 任务将所有的 pins 投影到一个低维隐空间中，在这个空间中会进行聚合操作（算法1，第一行）&lt;/li&gt;
&lt;li&gt;另一个 MR 任务是将结果的 pins 表示和他们出现在的 boards 的 id 进行连接，然后通过 board 的邻居特征的池化来计算 board 的 embedding。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意，我们的方法避免了冗余的计算，对于每个顶点的隐向量只计算一次。在获得 boards 的 embedding 之后，我们使用两个以上的 MR 任务，用同样的方法计算第二层 pins 的 embedding，这个步骤也是可以迭代的（直到 K 个卷积层）。&lt;/p&gt;
&lt;h3 id="35-efficient-nearest-neighbor-lookups"&gt;3.5 Efficient nearest-neighbor lookups
&lt;/h3&gt;&lt;p&gt;由 PinSage 生成的 embeddings 可以用在很多下游推荐任务上，在很多场景中我们可以直接使用这些 embeddings 来做推荐，通过在学习到的嵌入空间中使用最近邻查找。也就是，给定一个查询物品 $q$，我们使用 K-近邻的方式来查找查询物品 embedding 的 K 个邻居的嵌入。通过局部敏感哈希[2]的近似 K 近邻算法很高效。在哈希函数计算出后，查找物品可以通过一个基于 Weak AND 操作[5]的两阶段查询实现。PinSage 模型是离线计算的并且所有节点的表示通过 MR 计算后存放到数据库中，高效的最近邻查找方法可以使系统在线提供推荐结果。&lt;/p&gt;</description></item><item><title>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic</title><link>https://davidham3.github.io/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/</link><pubDate>Thu, 10 May 2018 15:35:47 +0000</pubDate><guid>https://davidham3.github.io/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/</guid><description>&lt;p&gt;IJCAI 2018，大体思路：使用Kipf &amp;amp; Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1709.04875v4" target="_blank" rel="noopener"
&gt;Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="摘要"&gt;摘要
&lt;/h1&gt;&lt;p&gt;实时精确的交通预测对城市交通管控和引导很重要。由于交通流的强非线性以及复杂性，传统方法并不能满足中长期预测的要求，而且传统方法经常忽略对时空数据的依赖。在这篇文章中，我们提出了一个新的深度学习框架，时空图卷积(Spatio-Temporal Graph Convolutional Networks)，来解决交通领域的时间序列预测问题。我们在图上将问题形式化，并且建立了完全卷积的结构，并不是直接应用传统的卷积以及循环神经单元，这可以让训练速度更快，参数更少。实验结果显示通过在多尺度的交通网络上建模，STGCN模型可以有效地捕获到很全面的时空相关性并且在各种真实数据集上表现的要比很多state-of-the-art算法好。&lt;/p&gt;
&lt;h1 id="引言"&gt;引言
&lt;/h1&gt;&lt;p&gt;交通运输在每个人的生活中都扮演着重要的角色。根据2015年的调查，美国的司机们平均每天要在车上呆48分钟。这种情况下，精确的实时交通状况预测对于路上的用户，private sector和政府来说变得至关重要。广泛使用的交通服务，如交通流控制、路线规划和导航，也依赖于高质量的交通状况预测。总的来说，多尺度的交通预测的研究很有前景而且是城市交通流控制和引导的基础，也是智能交通系统的一个主要功能。&lt;/p&gt;
&lt;p&gt;在交通研究中，交通流的基本变量，也就是速度、流量和密度，通常作为监控当前交通状态以及未来预测的指示指标。根据预测的长度，交通预测大体分为两个尺度：短期(5~30min)，中和长期预测(超过30min)。大多数流行的统计方法(比如，线性回归)可以在短期预测上表现的很好。然而，由于交通流的不确定性和复杂性，这些方法在相对长期的预测上不是那么的有效。&lt;/p&gt;
&lt;p&gt;之前在中长期交通预测上的研究可以大体的分为两类：动态建模和数据驱动的方法。动态建模使用了数学工具（比如微分方程）和物理知识通过计算模拟来形式化交通问题[Vlahogiani, 2015]。为了达到一个稳定的状态，模拟进程不仅需要复杂的系统编程，还需要消耗大量的计算资源。模型中不切实际的假设和化简也会降低预测的精度。因此，随着交通数据收集和存储技术的快速发展，一大群研究者正在将他们的目光投向数据驱动的方法。
典型的统计学和机器学习模型是数据驱动方法的两种体现。在时间序列分析上，自回归移动平均模型（ARIMA）和它的变形是众多统一的方法中基于传统统计学的方法[Ahmed and Cook, 1979; Williams and Hoel, 2003; Lippi $et al.$, 2013]。然而，这种类型的模型受限于时间序列的平稳分布，而且不能考虑时空相关性。因此，这些方法限制了高度非线性的交通流的表示能力。最近，传统的统计方法在交通预测上已经受到了机器学习方法的冲击。这些模型可以获得更高的精度，对更复杂的数据建模，比如k近邻（KNN），支持向量机（SVM）和神经网络（NN）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深度学习方法&lt;/strong&gt; 最近，深度学习已经被广泛且成功地应用于各式各样的交通任务中，在最近的工作中已经取得了很显著的成果，比如，深度置信网络（DBN）[Jia &lt;em&gt;et al.&lt;/em&gt;, 2016; Huang &lt;em&gt;et al.&lt;/em&gt;, 2014]和层叠自编码器(stacked autoencoder)(SAE)[Lv &lt;em&gt;et al.&lt;/em&gt;, 2015; Chen &lt;em&gt;et al.&lt;/em&gt;, 2016]。然而，这些全连接神经网络很难从输入中提取空间和时间特征。而且，空间属性的严格限制甚至完全缺失，这些网络的表示能力被限制的很严重。&lt;/p&gt;
&lt;p&gt;为了充分利用空间特征，一些研究者使用了卷积神经网络来捕获交通网络中的临近信息，同时也在时间轴上部署了循环神经网络。通过组合长短期记忆网络[Hochreiter and Schmidhuber, 1997]和1维卷积，Wu和Tan[2016]首先提出一个特征层面融合的架构CLTFP来预测短期交通状况。尽管它采取了一个很简单的策略，CLTFP仍然是第一个尝试对时间和空间规律性对齐的方法。后来，Shi &lt;em&gt;et al.&lt;/em&gt;[2015]提出了卷积LSTM，这是一个带有嵌入卷积层的全连接LSTM的扩展。然而，常规的卷积操作限制了模型只能处理常规的网格结构（如图像或视频），而不是其他的大部分领域（比如Graph）。与此同时，循环神经网络对于序列的学习需要迭代训练，这会导致误差的积累。更进一步地说，循环神经网络（包括基于LSTM的RNN）的难以训练和计算量大是众所周知的。&lt;/p&gt;
&lt;p&gt;为了克服这些问题，我们引入了一些策略来有效的对交通流的时间动态和空间依赖进行建模。为了完全利用空间信息，我们通过一个广义图对交通网络建模，而不是将交通流看成各个离散的部分（比如网格或碎块）。为了处理循环神经网络的缺陷，我们在时间轴上部署了一个全卷积结构来阻止累积效应（cumulative effects）并且加速模型的训练过程。综上所述，我们提出了一个新的神经网络架构，时空图卷积网络，来预测交通情况。这个架构由多个时空图卷积块组成，这些都是图卷积层和卷积序列学习层（convolutional sequence learning layers）的组合，用来对时间和空间依赖关系进行建模。&lt;/p&gt;
&lt;p&gt;我们的主要贡献可以归纳为以下三点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们研究了在交通领域时间与空间依赖结合的好处。为了充分利用我们的知识，这是在交通研究中第一次应用纯卷积层来同时从图结构的时间序列中提取时空信息。&lt;/li&gt;
&lt;li&gt;我们提出了一个新的由时空块组成的神经网络结构。由于这个架构中是纯卷积操作，它比基于RNN的模型的训练速度快10倍以上，而且需要的参数更少。这个架构可以让我们更有效地处理更大的路网，这部分将在第四部分展示。&lt;/li&gt;
&lt;li&gt;我们在两个真实交通数据集上验证了提出来的网络。这个实验显示出我们的框架比已经存在的在多长度预测和网络尺度上的模型表现的更好。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="准备工作"&gt;准备工作
&lt;/h1&gt;&lt;h2 id="路网上的交通预测"&gt;路网上的交通预测
&lt;/h2&gt;&lt;p&gt;交通预测是一个典型的时间序列预测问题，也就是预测在给定前M个观测样本接下来H个时间戳后最可能的交通流指标（比如速度或交通流），&lt;/p&gt;
&lt;p&gt;$$&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\tag{1} \hat{v}\_{t+1}, ..., \hat{v}\_{t+H} = \mathop{\arg\min}\_{v\_{t+1},...,v\_{t+H}}logP(v\_{t+1},...,v\_{t+H}\vert v\_{t-M+1},...v\_t)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;$$&lt;/p&gt;
&lt;p&gt;这里$v_t \in \mathbb{R}^n$是$n$个路段在时间戳$t$观察到的一个向量，每个元素记录了一条路段的历史观测数据。&lt;/p&gt;
&lt;p&gt;在我们的工作中，我们在一个图上定义了一个交通网络，并专注于结构化的交通时间序列。观测到的样本$v_t$间不是相互独立的，而是在图中两两相互连接的。因此，数据点$v_t$可以被视为定义在权重为$w_{ij}$，如图1展示的无向图（或有向图）$\mathcal{G}$上的一个信号。在第$t$个时间戳，在图$\mathcal{G_t}=(\mathcal{V_t}, \mathcal{\varepsilon}, W)$, $\mathcal{V_t}$是当顶点的有限集，对应在交通网络中$n$个监测站；$\epsilon$是边集，表示观测站之间的连通性；$W \in \mathbb{R^{n \times n}}$表示$\mathcal{G_t}$的邻接矩阵。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig1.PNG"
loading="lazy"
alt="Fig1"
&gt;&lt;/p&gt;
&lt;h2 id="图上的卷积"&gt;图上的卷积
&lt;/h2&gt;&lt;p&gt;传统网格上的标准卷积很明显是不能应用在广义图上的。现在有两个基本的方法正在探索如何泛化结构化数据上的CNN。一个是扩展卷积的空间定义[Niepert &lt;em&gt;et al.&lt;/em&gt;, 2016]，另一个是使用图傅里叶变换在谱域中进行操作[Bruna &lt;em&gt;et al.&lt;/em&gt;, 2013]。前一个方法重新将顶点安排至确定的表格形式内，然后就可以使用传统的卷积方法了。后者引入了谱框架，在谱域中应用图卷积，经常被称为谱图卷积。一些后续的研究通过将时间复杂度从$O(n^2)$降至线性[Defferrard &lt;em&gt;et al.&lt;/em&gt;, 2016;Kipf and Welling, 2016]使谱图卷积的效果更好。
我们基于谱图卷积的定义引入图卷积操作“$\ast_{\mathcal{G}}$”的符号，也就是一个核$\Theta$和信号$x \in \mathbb{R}^n$的乘法，&lt;/p&gt;
$$\tag{2} \Theta \ast\_{\mathcal{G}}x=\Theta(L)x=\Theta(U \Lambda U^T)x=U\Theta(\Lambda)U^Tx$$&lt;p&gt;这里图的傅里叶基$U \in \mathbb{R}^{n \times n}$是归一化的拉普拉斯矩阵$L=I_n-D^{-1/2}WD^{-1/2}= U \Lambda U^T \in \mathbb{R}^{n \times n}$的特征向量组成的矩阵，其中$I_n$是单位阵，$D \in \mathbb{R}^{n \times n}$是对角的度矩阵$D_{ii}=\sum_j{W_{ij}}$；$\Lambda \in \mathbb{R}^{n \times n}$是$L$的特征值组成的矩阵，卷积核$\Theta(\Lambda)$是一个对角矩阵。通过这个定义，一个图信号$x$是被一个核$\Theta$通过$\Theta$和图傅里叶变换$U^Tx$[Shuman &lt;em&gt;et al.&lt;/em&gt;, 2013]过滤的。&lt;/p&gt;
&lt;h1 id="提出的模型"&gt;提出的模型
&lt;/h1&gt;&lt;h2 id="网络架构"&gt;网络架构
&lt;/h2&gt;&lt;p&gt;在这部分，我们详细说明了时空图卷积网络的框架。如图二所示，STGCN有多个时空卷积块组成，每一个都是像一个“三明治”结构的组成，有两个门序列卷积层和一个空间图卷积层在中间。每个模块的细节如下。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig2.PNG"
loading="lazy"
alt="Fig2"
&gt;&lt;/p&gt;
&lt;p&gt;图二：时空图卷积网络的架构图。STGCN的架构有两个时空卷积块和一个全连接的在末尾的输出层组成。每个ST-Conv块包含了两个时间门卷积层，中间有一个空间图卷积层。每个块中都使用了残差连接和bottleneck策略。输入$v_{t-M+1},&amp;hellip;v_t$被ST-Conv块均匀的（uniformly）处理，来获取时空依赖关系。全部特征由一个输出层来整合，生成最后的预测$\hat{v}$。&lt;/p&gt;
&lt;h2 id="提取空间特征的图卷积神经网络"&gt;提取空间特征的图卷积神经网络
&lt;/h2&gt;&lt;p&gt;交通网络大体上是一个图结构。由数学上的图来构成路网是很自然也很合理的。然而，之前的研究忽视了交通网络的空间属性：因为交通网络被分成了块或网格状，所以网络的全局性和连通性被过分的关注了。即使是在网格上的二维卷积，由于数据建模的折中，也只能捕捉到大体的空间局部性。根据以上情况，在我们的模型中，图卷积被直接的应用在了图结构数据上为了在空间中抽取很有意义的模式和特征。集是在图卷积中由式2可以看出核$\Theta$的计算的时间复杂度由于傅里叶基的乘法可以达到$O(n^2)$，两个近似的策略可以解决这个问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;切比雪夫多项式趋近&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了局部化过滤器并且减少参数，核$\Theta$可以被一个关于$\Lambda$的多项式限制起来，也就是$\Theta(\Lambda)=\sum_{k=0}^{K-1} \theta_k \Lambda^k$，其中$\theta \in \mathbb{R}^K$是一个多项式系数的向量。$K$是图卷积核的大小，它决定了卷积从中心节点开始的最大半径。一般来说，切比雪夫多项式$T_k(x)$被用于近似核，作为$K-1$阶展开的一部分，也就是$\Theta(\Lambda) \approx \sum_{k=0}^{K-1} \theta_k T_k(\widetilde{\Lambda})$，其中$\widetilde{\Lambda}=2\Lambda/\lambda_{max}-I_n$（$\lambda_{max}$表示$L$的最大特征值）[Hammond &lt;em&gt;et al.&lt;/em&gt;, 2011]。图卷积因此可以被写成&lt;/p&gt;
$$
\tag{3} \Theta \ast\_{\mathcal{G}} x = \Theta(L)x \approx \sum\_{k=0}^{K-1}\theta\_k T\_k(\widetilde{L})x
$$&lt;p&gt;其中$T_k(\widetilde{L}) \in \mathbb{R}^{n \times n}$是k阶切比雪夫多项式对缩放后（scaled）的拉普拉斯矩阵$\widetilde{L}=2L/\lambda_{max}-I_n$。通过递归地使用趋近后的切比雪夫多项式计算K阶卷积操作，式2的复杂度可以被降低至$O(K\vert \varepsilon \vert)$，如式3所示[Defferrard &lt;em&gt;et al.&lt;/em&gt;, 2016]。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1阶近似&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个针对层的线性公式可以由堆叠多个使用拉普拉斯矩阵的一阶近似的局部图卷积层[Kipf and Welling, 2016]。结果就是，这样可以构建出一个深的网络，这个网络可以深入地恢复空间信息并且不需要指定多项式中的参数。由于在神经网络中要缩放和归一化，我们可以进一步假设$\lambda_{max} \approx 2$。因此，式3可以简写为&lt;/p&gt;
$$
\begin{aligned}
\Theta \ast\_{\mathcal{G}}x \approx &amp; \theta\_0x+\theta\_1(\frac{2}{\lambda\_{max}}L-I\_n)x\\
\approx &amp; \theta\_0 x- \theta\_1(D^{-\frac{1}{2}} W D^{-\frac{1}{2}}) x
\end{aligned}
$$&lt;p&gt;其中，$\theta_0$，$\theta_1$是核的两个共享参数。为了约束参数并为稳定数值计算，$\theta_0$和$\theta_1$用一个参数$\theta$来替换，$\theta=\theta_0=-\theta_1$；$W$和$D$是通过$\widetilde{W}=W+I_n$和$\widetilde{D}_{ii}=\sum_j\widetilde{W}_{ij}$重新归一化得到的。之后，图卷积就可以表达为&lt;/p&gt;
$$
\begin{aligned}
\Theta \ast\_{\mathcal{G}} x = &amp; \theta(I\_n + D^{-\frac{1}{2}} W D^{\frac{1}{2}})x\\
= &amp; \theta (\widetilde{D}^{-\frac{1}{2}} \widetilde{W} \widetilde{D}^{-\frac{1}{2}})x
\end{aligned}
$$&lt;p&gt;竖直地堆叠一阶近似的图卷积可以获得和平行的K阶卷积相同的效果，所有的卷积可以从一个顶点的$K-1$阶邻居中获取到信息。在这里，$K$是连续卷积操作的次数或是模型中的卷积层数。进一步说，针对层的线性结构是节省参数的，并且对大型的图来说是效率很高的，因为多项式趋近的阶数为1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图卷积的泛化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;图卷积操作$\ast_{\mathcal{G}}$也可以被扩展到多维张量上。对于一个有着$C_i$个通道的信号$X \in \mathbb{R}^{n \times C_i}$，图卷积操作可以扩展为&lt;/p&gt;
$$
y\_j = \sum\_{i=1}^{C\_i} \Theta\_{i,j}(L) x\_i \in \mathbb{R}^n, 1 \leq j \leq C\_o
$$&lt;p&gt;其中，$C_i \times C_o$个向量是切比雪夫系数$\Theta_{i,j} \in \mathbb{R}^K$（$C_i$，$C_o$分别是feature map的输入和输出大小）。针对二维变量的图卷积表示为$\Theta \ast_{\mathcal{G}} X$，其中$\Theta \in \mathbb{R}^{K \times C_i \times C_o}$。需要注意的是，输入的交通预测是由$M$帧路网组成的，如图1所示。每帧$v_t$可以被视为一个矩阵，它的第$i$列是图$\mathcal{G_t}$中第$i$个顶点的一个为$C_i$维的值，也就是$X \in \mathbb{R}^{n \times C_i}$（在这个例子中，$C_i=1$）。对于$M$中的每个时间步$t$，相同的核与相同的图卷积操作是在$X_t \in \mathbb{R}^{n \times C_i}$中并行进行的。因此，图卷积操作也可以泛化至三维，记为$\Theta \ast_{\mathcal{G}} \mathcal{X}$，其中$\mathcal{X} \in \mathbb{R}^{M \times n \times C_i}$&lt;/p&gt;
&lt;h2 id="抽取时间特征的门控卷积神经网络"&gt;抽取时间特征的门控卷积神经网络
&lt;/h2&gt;&lt;p&gt;尽管基于RNN的模型可以广泛的应用于时间序列分析，用于交通预测的循环神经网络仍然会遇到费时的迭代，复杂的门控机制，对动态变化的响应慢。相反，CNN训练快，结构简单，而且不依赖于前一步。受到[Gehring &lt;em&gt;et al.&lt;/em&gt;, 2017]的启发，我们在时间轴上部署了整块的卷积结构，用来捕获交通流的动态时间特征。这个特殊的设计可以让并行而且可控的训练过程通过多层卷积结构形成层次表示。&lt;/p&gt;
&lt;p&gt;如图2右侧所示，时间卷积层包含了一个一维卷积，核的宽度为$K_t$，之后接了一个门控线性单元(GLU)作为激活。对于图$\mathcal{G}$中的每个顶点，时间卷积对输入元素的$K_t$个邻居进行操作，导致每次将序列长度缩短$K_t-1$。因此，每个顶点的时间卷积的输入可以被看做是一个长度为$M$的序列，有着$C_i$个通道，记作$Y \in \mathbb{R}^{M \times C_i}$。卷积核$\Gamma \in \mathbf{R}^{K_t \times C_i \times 2C_o}$是被设计为映射$Y$到一个单个的输出$[P Q] \in \mathbb{R}^{(M-K_t+1) \times (2C_o)}$($P$, $Q$是通道数的一半)。作为结果，时间门控卷积可以定义为：&lt;/p&gt;
$$
\Gamma \ast\_ \tau Y = P \otimes \sigma (Q) \in \mathbb{R}^{(M-K\_t+1) \times C\_o}
$$&lt;p&gt;其中，$P$, $Q$分别是GLU的输入门，$\otimes$表示哈达玛积，sigmoid门$\sigma(Q)$控制当前状态的哪个输入$P$对于发现时间序列中的组成结构和动态方差是相关的。非线性门通过堆叠时间层对挖掘输入也有贡献。除此以外，在堆叠时间卷积层时，实现了残差连接。相似地，通过在每个节点$\mathcal{Y_i} \in \mathbb{R}^{M \times C_i}$(比如监测站)上都使用同样的卷积核$\Gamma$，时间卷积就可以泛化至3D变量上，记作$\Gamma \ast_\tau \mathcal{Y}$，其中$\mathcal{Y} \in \mathbb{R}^{M \times n \times C_i}$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里我之前认为残差是用了 padding 的，其实不是，看了作者的代码后发现作者是用了一半数量的卷积核完成卷积，这样就和 P 的维度一致了，然后直接和 P 相加，然后与 sigmoid 激活后的值进行点对点的相乘。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id="时空卷积块"&gt;时空卷积块
&lt;/h2&gt;&lt;p&gt;为了同时从空间和时间领域融合特征，时空卷积块(ST-Conv block)的构建是为了同时处理图结构的时间序列的。如图2（中）所示，bottleneck策略的应用形成了三明治的结构，其中含有两个时间门控卷积层，分别在上下两层，一个空间图卷积层填充中间的部分。空间卷积层导致的通道数$C$的减小促使了参数的减少，并且减少了训练的时间开销。除此以外，每个时空块都使用了层归一化来抑制过拟合。&lt;/p&gt;
&lt;p&gt;ST-Conv块的输入和输出都是3D张量。对于块$l$的输入$v^l \in \mathbb{R}^{M \times n \times C^l}$，输出$v^{l+1} \in \mathbb{R}^{(M-2(K_t-1)) \times n \times C^{l+1}}$通过以下式子计算得到：&lt;/p&gt;
$$
v^{l+1} = \Gamma^l\_1 \ast\_\tau \rm ReLU(\Theta^l \ast\_{\mathcal{G}}(\Gamma^l\_0 \ast\_\tau v^l))
$$&lt;p&gt;其中$\Gamma^l_0$，$\Gamma^l_1$是块$l$的上下两个时间层；$\Theta^l$是图卷积谱核；$\rm ReLU(·)$表示ReLU激活函数。我们在堆叠两个ST-Conv块后，加了一个额外的时间卷积和全连接层作为最后的输出层（图2左侧）。时间卷积层将最后一个ST-Conv块的输出映射到一个最终的单步预测上。之后，我们可以从模型获得一个最后的输出$Z \in \mathbb{R}^{n \times c}$，通过一个跨$c$个通道的线性变换$\hat{v} = Zw+b$来预测$n$个节点的速度，其中$w \in \mathbb{R}^c$是权重向量,$b$是偏置。对交通预测的STGCN的损失函数可以写成：&lt;/p&gt;
$$
L(\hat{v}; W\_\theta) = \sum\_t \Vert \hat{v}(v\_{t-M+1, ..., v\_t, W\_\theta}) - v\_{t+1} \Vert^2
$$&lt;p&gt;其中，$W_\theta$是模型中所有的训练参数; $v_{t+1}$是ground truth，$\hat{v}(·)$表示模型的预测。&lt;/p&gt;
&lt;p&gt;我们来总结一下我们的STGCN的主要特征：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;STGCN是处理结构化的时间序列的通用框架，不仅可以解决交通网络建模，还可以应用到其他的时空序列学习的挑战中，比如社交网络和推荐系统。&lt;/li&gt;
&lt;li&gt;时空块融合了图卷积和门控时间卷积，可以同时抽取有用的空间信息，捕获本质上的时间特征。&lt;/li&gt;
&lt;li&gt;模型完全由卷积层组成，因此可以在输入序列上并行运算，空间域中参数少易于训练。更重要的是，这个经济的架构可以使模型更高效的处理大规模的网络。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="实验"&gt;实验
&lt;/h1&gt;&lt;h2 id="数据集描述"&gt;数据集描述
&lt;/h2&gt;&lt;p&gt;我们在两个真实的数据集上验证了模型，分别是&lt;strong&gt;BJER4&lt;/strong&gt;和&lt;strong&gt;PeMSD7&lt;/strong&gt;，由北京市交委和加利福尼亚运输部提供。每个数据集包含了交通观测数据的关键属性和对应时间的地图信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BJER4&lt;/strong&gt;是通过double-loop detector获取的东四环周边的数据。我们的实验中有12条道路。交通数据每五分钟聚合一次。时间是从2014年的7月1日到8月31日，不含周末。我们选取了第一个月的车速速度记录作为训练集，剩下的分别做验证和测试。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PeMSD7&lt;/strong&gt;是Caltrans Performance Measurement System(PeMS)通过超过39000个监测站实时获取的数据，这些监测站分布在加州高速公路系统主要的都市部分[Chen &lt;em&gt;et al&lt;/em&gt;., 2001]。数据是30秒的数据样本聚合成5分钟一次的数据。我们在加州的District 7随机选取了一个小的和一个大的范围作为数据源，分别有228和1026个监测站，分别命名为PeMSD7(S)和PeMSD7(L)（如图3左侧所示）。PeMSD7数据集的时间范围是2012年五月和六月的周末。我们使用同样的原则对数据进行了训练集和测试集的划分。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://davidham3.github.io/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig3.PNG"
loading="lazy"
alt="Fig1"
&gt;&lt;/p&gt;
&lt;h2 id="数据预处理"&gt;数据预处理
&lt;/h2&gt;&lt;p&gt;两个数据集的间隔设定为5分钟。因此，路网中的每个顶点每天就有288个数据点。数据清理后使用了线性插值的方法来填补缺失值。通过核对相关性，每条路的方向和OD(origin-destination)点，环路系统可以被数值化成一个有向图。&lt;/p&gt;
&lt;p&gt;在PeMSD7，路网的邻接矩阵通过交通网络中的监测站的距离来计算。带权邻接矩阵$W$通过以下公式计算：&lt;/p&gt;
$$
w\_{ij} = \begin{cases}
\exp{(-\frac{d^2\_{ij}}{\sigma^2})}&amp;,i \neq j \ \rm and \exp{(-\frac{d^2\_{ij}}{\sigma^2}) \geq \epsilon} \\
0&amp;, \rm otherwise
\end{cases}
$$&lt;p&gt;其中$w_{ij}$是边的权重，通过$d_{ij}$得到，也就是$i$和$j$之间的距离。$\sigma^2$和$\epsilon$是来控制矩阵$W$的分布和稀疏性的阈值，我们用了10和0.5。$W$的可视化在图3的右侧。&lt;/p&gt;
&lt;h1 id="代码"&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class="link" href="https://github.com/VeritasYin/STGCN_IJCAI-18" target="_blank" rel="noopener"
&gt;作者代码&lt;/a&gt;，这个是作者提供的代码。&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://github.com/Davidham3/STGCN" target="_blank" rel="noopener"
&gt;仓库地址&lt;/a&gt;，我按照论文结合作者的代码进行了复现与修正。&lt;/p&gt;</description></item></channel></rss>