<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spatial-Temporal on Davidham的博客</title><link>https://davidham3.github.io/blog/tags/spatial-temporal/</link><description>Recent content in Spatial-Temporal on Davidham的博客</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 03 Jan 2020 20:18:29 +0000</lastBuildDate><atom:link href="https://davidham3.github.io/blog/tags/spatial-temporal/index.xml" rel="self" type="application/rss+xml"/><item><title>Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</title><link>https://davidham3.github.io/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/</link><pubDate>Fri, 03 Jan 2020 20:18:29 +0000</pubDate><guid>https://davidham3.github.io/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/</guid><description>&lt;p>AAAI 2020，原文链接：&lt;a class="link" href="https://arxiv.org/abs/1911.12093" target="_blank" rel="noopener"
>https://arxiv.org/abs/1911.12093&lt;/a>。&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>交通预测在运输和公共安全中扮演重要角色，由于复杂的时空依赖和路网和交通状况带来的不确定性使这个问题很有挑战。最新的研究专注于使用图卷积网络 GCNs 对一个固定权重的图进行建模，即对空间依赖建模。然而，边，即两个结点之间的关系更加复杂且两者相互影响。我们提出了 Multi-Range Attentive Bicomponent GCN (MRA-BGCN)，一种新的用于交通预测的深度学习框架。我们先根据路网上结点的距离构建结点图，在根据不同的边的交互模式构造边图。然后，我们使用 bicomponent 图卷积实现结点和边的交互。这个多范围注意力机制用来聚合不同邻居范围的信息，自动地学习不同范围的重要性。大量的实验在两个真实数据集，METR-LA 和 PEMS-BAY 上开展，显示出我们的模型效果很好。&lt;/p>
&lt;h1 id="introduction">Introduction
&lt;/h1>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig1.png"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>讲了好多历史。。。然后是论点部分：&lt;/p>
&lt;p>我们认为 DCRNN 和 STGCN 虽说集成了 GCN，但是有两个点忽略了：&lt;/p>
&lt;p>首先，这些方法主要关注通过在一个固定权重的图上部署 GCN 对空间依赖建模。然而，边更复杂。图 1a 中，传感器 1 和 3，还有 2 和 3，通过路网连接。显然，这些关联随当前的交通状况改变，他们之间也互相交互。图 1b 所示，现存的方法根据路网距离构建一个固定的带权图，使用 GCN 实现这些结点的交互，但是结点间的关联性在邻接矩阵中通过固定的值表示，这就忽略了边的复杂性和交互性。&lt;/p>
&lt;p>其次，这些方法经常使用一个给定范围内聚合的信息，比如 $k$ 阶邻居，忽略多个范围的信息。然而，不同范围的信息表现出不同的交通属性。小的范围表现出局部依赖，大范围倾向于表现全局的交通模式。此外，不同范围的信息也不是永远都具有相同的分量。举个例子，一次交通事故，一个结点主要受它最近的邻居的影响，这样模型就应该更关注它，而不是给其他的 $k$ 阶邻居相同的关注。&lt;/p>
&lt;p>为了解决上述两点问题，我们提出了 MRA-BGCN，不仅考虑结点关联，也把边作为实体，考虑他们之间的关系，如图 1c，我们还利用了不同的范围信息。我们的贡献：&lt;/p>
&lt;ul>
&lt;li>提出 MRA-BGCN，引入 bicomponent 图卷积，对结点和边直接建模。结点图根据路网距离构建，边图根据边的交互模式、stream connectivity 和 竞争关系构建。&lt;/li>
&lt;li>我们针对 bicomponent 图卷积提出多范围注意力机制，可以聚合不同范围邻居的信息，学习不同范围的重要性。&lt;/li>
&lt;li>我们开展了大量的实验，实验效果很好。&lt;/li>
&lt;/ul>
&lt;h1 id="preliminaries">Preliminaries
&lt;/h1>&lt;h2 id="problem-definition">Problem Definition
&lt;/h2>&lt;p>给定历史的数据，预测未来的数据。$N$ 个结点组成的图 $G = (V, E, \bm{A})$。时间 $t$ 路网上的交通数据表示为图信号 $\bm{X}^{(t)} \in \mathbb{R}^{N \times P}$，$P$ 是特征数。交通预测是过去的数据预测未来：&lt;/p>
$$
[\bm{X}^{(t-T'+1):t},G] \xrightarrow{f} [\bm{X}^{(t+1)}:(t+T)],
$$&lt;p>$\bm{X}^{(t-T&amp;rsquo;+1):t} \in \mathbb{R}^{N \times P \times T&amp;rsquo;}$，$\bm{X}^{(t+1):(t+T)} \in \mathbb{R}^{N \times P \times T}$。&lt;/p>
&lt;h2 id="graph-convolution">Graph Convolution
&lt;/h2>&lt;p>不介绍了。&lt;/p>
&lt;h1 id="methodology">Methodology
&lt;/h1>&lt;h2 id="model-overview">Model Overview
&lt;/h2>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig2.png"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>图 2 展示了 MRA-BGCN 的架构，包含两个部分：（1）双组件图卷积模块；（2）多范围注意力层。双组件图卷积模块包含多个结点图卷积层和边图卷积层，直接对结点和边的交互建模。多范围注意力层聚合不同范围的邻居信息，学习不同范围的重要性。此外，我们融合 MRA-BGCN 和 RNN 对时间依赖建模完成交通预测。&lt;/p>
&lt;h2 id="bicomponent-graph-convolution">Bicomponent Graph Convolution
&lt;/h2>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig3.png"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>图卷积可以有效聚合结点之间的交互关系，然而，交通预测中边更复杂（这句话说三遍了）。因此我们提出双组件图卷积，直接对结点和边的交互建模。&lt;/p>
&lt;p>Chen 等人提出边的邻近的 line graph 来建模边的关系。$G = (V, E, \bm{A})$ 表示结点有向图，$G_L = (V_L, E_L, \bm{A}_L)$ 是对应的 line graph，$G_L$ 的结点 $V_L$ 是 $E$ 中有序的边。$\bm{A}_L$ 是无权的邻接矩阵，编码了结点图中的边邻接关系，有关系就等于1。&lt;/p>
&lt;p>尽管 line graph 可以考虑边的邻接，它仍然是一个无权图且只认为两条边中的一条边的汇点和另一条边的源点相同时，这两条才相关。然而，对于刻画交通预测中各种各样边的交互关系来说这不够高效。如图 3 所示，我们定义两类边的交互模式来构建边图 $G_e = (V_e, E_e, \bm{A}_e)$。$V_e$ 中的每个节点表示 $E$ 中的边。&lt;/p>
&lt;p>&lt;strong>Stream connectivity&lt;/strong> 在交通网络中，路网可能受它上下游的路段影响。如图 3a 所示，$(i \rightarrow j)$ 是 $(j \rightarrow k)$ 的上游的边，因此他们是相互关联的。直观上来看，如果结点 $j$ 有很多数量的邻居，那么 $(i \rightarrow j)$ 和 $(j \rightarrow k)$ 之间的关系是弱的，因为它还要受其他邻居的影响。我们使用高斯核计算边的权重用来表示 $\bm{A}_e$ 中的 stream connectivity：&lt;/p>
$$\tag{2}
\bm{A}\_{e, (i \rightarrow j), (j \rightarrow k)} = \bm{A}\_{e, (j \rightarrow k), (i \rightarrow j)} = \text{exp}(- \frac{(\text{deg}^-(j) + \text{deg}^+(j) - 2)^2}{\sigma^2})
$$&lt;p>$\text{deg}^-(j)$ 和 $\text{deg}^+(j)$ 分别表示结点 $j$ 的入度和出度，$\sigma$ 是结点度的标准差。&lt;/p>
&lt;p>&lt;strong>Competitive relationship&lt;/strong> 路网&lt;/p></description></item><item><title>GMAN: A Graph Multi-Attention Network for Traffic Prediction</title><link>https://davidham3.github.io/blog/p/gman-a-graph-multi-attention-network-for-traffic-prediction/</link><pubDate>Thu, 02 Jan 2020 17:03:30 +0000</pubDate><guid>https://davidham3.github.io/blog/p/gman-a-graph-multi-attention-network-for-traffic-prediction/</guid><description>&lt;p>AAAI 2020，使用编码解码+att的架构，只不过编码和解码都使用 attention 组成。主要的论点是空间和时间的关联性是动态的，所以设计这么一个纯注意力的框架。值得注意的点是：由于注意力分数的个数是平方级别的，在计算空间注意力的时候，一旦结点数很大，这里会有超大的计算量和内存消耗，这篇文章是将结点分组后，计算组内注意力和组间注意力。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1911.08415" target="_blank" rel="noopener"
>https://arxiv.org/abs/1911.08415&lt;/a>。&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>长时间范围的交通流预测是个挑战，两方面原因：交通系统的复杂性，很多影响因素的持续变化性。我们在这篇论文中，专注于时空因素，提出了一个图多注意力机智网络（GMAN），预测路网上不同区域的交通状况。GMAN 使用一个编码解码结构，编码解码器都由多个时空注意力块组成，时空注意力块对交通状况上的时空因素的影响建模。编码器将输入的交通特征编码，解码器输出预测序列。编码解码器之间，有一个变换注意力层，用来把编码器编码后的交通特征生成成未来时间步的序列表示，然后把这个表示输入到解码器里面。变换注意力机制对历史和未来时间步的关系建模，可以减轻多步预测中的错误积累。两个真实数据集上的交通预测任务（一个是流量预测，一个是速度预测）显示 GMAN 的效果优越。在1小时的预测上，GMAN 在 MAE 比 state-of-the-art 好4%。源码在：&lt;a class="link" href="https://github.com/zhengchuanpan/GMAN" target="_blank" rel="noopener"
>https://github.com/zhengchuanpan/GMAN&lt;/a>&lt;/p>
&lt;h1 id="introduction">Introduction
&lt;/h1>&lt;p>交通预测的目标是基于历史观测预测未来的交通状况。在很多应用中扮演着重要的角色。举个例子，精确的交通预测可以帮助交管部门更好的控制交通，减少拥堵。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig1.png"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>邻近区域的交通状况会互相影响。大家使用 CNN 捕获这样的空间依赖。同时，一个地方的交通状况和它的历史记录有关。RNN 广泛地用于这样时间相关性的建模。最近的研究将交通预测变为图挖掘问题，因为交通问题受限于路网。使用 GCN 的这些研究在短期预测（5 到 15 分钟）内表现出不错的效果。然而，长期预测（几个小时）仍缺乏令人满意的效果，主要受限于以下几点：&lt;/p>
&lt;ol>
&lt;li>复杂的时空关联：&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>动态的空间关联。如图 1 所示，路网中的传感器之间的关联随时间剧烈地变化，比如高峰时段的前后。如何动态地选择相关的检测器数据来预测一个检测器在未来长时间范围的交通状况是一个挑战。&lt;/li>
&lt;li>非线性的时间关联。图 1，一个检测器的交通状况可能变化得非常剧烈，且可能由于事故等因素，突然影响不同时间步之间的关联性。如何自适应地随时间的推移对这种非线性时间关联建模，也是一个挑战。&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>对误差传递的敏感。长期预测上，每个时间步上小的错误都会被放大。这样的误差传递对于远期时间预测来说仍具有挑战性。&lt;/li>
&lt;/ol>
&lt;p>为了解决上述挑战，我们提出了一个图多注意力网络（GMAN）来预测未来的交通状况。这里指的交通状况是一个交通系统中可以记录为数值的观测值。为了描述，我们这里专注于流量和速度预测，但是我们的模型是可以应用到其他数值型的交通数据上的。&lt;/p>
&lt;p>GMAN 使用编码解码架构，编码器编码交通特征，解码器生成预测序列。变换注意力层用来把编码历史特征转换为未来表示。编解码器都由一组时空注意力块 &lt;em>ST-Attention blocks&lt;/em> 组成。每个时空注意力块由一个空间注意力、一个时间注意力和一个门控融合机制组成。空间注意力建模动态空间关联，时间注意力建模非线性时间关联，门控融合机制自适应地融合空间和时间表示。变换注意力机制建模历史和未来的关系，减轻错误传播。两个真实世界数据集证明 GMAN 获得了最好的效果。&lt;/p>
&lt;p>我们的贡献&lt;/p>
&lt;ul>
&lt;li>提出空间注意力和时间注意力对动态空间和非线性时间关联分别建模。此外，我们设计了一个门控融合机制，自适应地融合空间注意力和时间注意力机制的的信息。&lt;/li>
&lt;li>提出一个变换注意力机制将历史交通特征转换为未来的表示。这个注意力机制对历史和未来的关系直接建模，减轻错误传播的问题。&lt;/li>
&lt;li>我们在两个数据集上评估了我们的图多注意力网络，在 1 小时预测问题上比 state-of-the-art 提高了 4%。&lt;/li>
&lt;/ul>
&lt;h1 id="preliminaries">Preliminaries
&lt;/h1>&lt;p>路网表示为一个带全有向图 $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathcal{A})$。$\mathcal{V}$ 是 $N$ 个结点的集合；$\mathcal{E}$ 是边集；$\mathcal{A} \in \mathbb{R}^{N \times N}$ 是邻接矩阵，表示结点间的相似性，这个相似性是结点在路网上的距离。&lt;/p>
&lt;p>时间步 $t$ 的路网状况表示为图信号 $X_t \in \mathbb{R}^{N \times C}$，$C$ 是特征数。&lt;/p>
&lt;p>研究的问题：给定 $N$ 个结点历史 $P$ 个时间步的观测值 $\mathcal{X} = (X_{t_1}, X_{t_2}, \dots. X_{t_P}) \in \mathbb{R}^{P \times N \times C}$，我们的目标是预测未来 $Q$ 个时间步所有结点的交通状况，表示为 $\hat{Y} = (\hat{X}_{t_{P+1}}, \hat{X}_{t_{P+2}}, \dots, \hat{X}_{t_{P+Q}}) \in \mathbb{R}^{Q \times N \times C}$。&lt;/p>
&lt;h1 id="graph-multi-attention-network">Graph Multi-Attention Network
&lt;/h1>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig2.png"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>图 2 描述了我们模型的架构。编码和解码器都有 STAtt Block 和残差连接。每个 ST-Attention block 由空间注意力机制、时间注意力机制和一个门控融合组成。编码器和解码器之间有个变换注意力层。我们还通过一个时空嵌入 spatial-temporal embedding (STE) 继承了图结构和时间信息到多注意力机制中。此外，为了辅助残差连接，所有层的输出都是 D 维。&lt;/p>
&lt;h2 id="spatio-temporal-embedding">Spatio-Temporal Embedding
&lt;/h2>&lt;p>因为交通状况的变化受限于路网，集成路网信息到模型中很重要。为此，我们提出一个空间嵌入，把结点嵌入到向量中以此保存图结构信息。我们利用 node2vec 学习结点表示。此外，为了协同训练模型和预学习的向量，这些向量会放入一个两层全连接神经网络中。然后就可以拿到空间表示 $e^S_{v_i} \in \mathbb{R}^D$。&lt;/p>
&lt;p>空间嵌入只提供了固定的表示，不能表示路网中的传感器的动态关联性。我们提出了一个时间嵌入来把每个时间步编码到向量中。假设一天是 T 个时间步。我们使用 one-hot 编码星期、时间到 $\mathbb{R}^7$ 和 $\mathbb{R}^T$ 里面，然后拼接，得到 $\mathbb{R}^{T + 7}$。接下来，使用两层全连接映射到 $\mathbb{R}^D$。在我们的模型里面，给历史的 $P$ 个时间步和未来的 $Q$ 个时间步嵌入时间特征，表示为 $e^T_{t_j} \in \mathbb{R}^D$，$t_j = t_1, \dots, t_P, \dots, t_{P+Q}$。&lt;/p>
&lt;p>为了获得随时间变化的顶点表示，我们融合了上述的空间嵌入和时间嵌入，得到时空嵌入（STE），如图 2b 所示。结点 $v_i$ 在时间步 $t_j$，STE 定义为 $e_{v_i,t_j} = e^S_{v_i} + e^T_{t_j}$。因此，$N$ 个结点在 $P + Q$ 的时间步里的 STE 表示为 $E \in \mathbb{R}^{(P + Q) \times N \times D}$。STE 包含图结构和时间信息。它会用在空间、时间、变换注意力机制里面。&lt;/p>
&lt;h2 id="st-attention-block">ST-Attention Block
&lt;/h2>&lt;p>我们将第 $l$ 个块的输入表示为 $H^{(l-1)}$，结点 $v_i$ 在时间步 $t_j$ 的隐藏状态表示为 $h^{(l-1)}_{v_i,t_j}$。第 $l$ 块中的空间和时间注意力机制的输出表示为 $H^{(l)}_S$ 和 $H^{(l)}_T$，隐藏状态表示为 $hs^{(l)}_{v_i,t_j}$ 和 $ht^{(l)}_{v_i,t_j}$。门控融合后，第 $l$ 层的输出表示为 $H^{(l)}$。&lt;/p>
&lt;p>我们将非线性变换表示为：&lt;/p>
$$\tag{1}
f(x) = \text{ReLU}(x\mathbf{W} + \mathbf{b}).
$$&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig3.png"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>&lt;strong>Spatial Attention&lt;/strong> 一条路的交通状况受其他路的影响，且影响不同。这样的影响是高度动态的，随时间变化。为了建模这些属性，我们设计了一个空间注意力机制动态地捕获路网中传感器间的关联性。核心点是在不同的时间步动态地给不同的结点分配权重，如图 3 所示。对于时间步 $t_j$ 的结点 $v_i$，我们计算所有结点的带权和：&lt;/p>
$$\tag{2}
hs^{(l)}\_{v\_i,t\_j} = \sum\_{v \in \mathcal{V}} \alpha\_{v\_i, v} \cdot h^{(l-1)}\_{v,t\_j},
$$&lt;p>$\alpha_{v_i, v}$ 是结点 $v$ 对 $v_i$ 的注意力分数，注意力分数之和为1：$\sum_{v \in \mathcal{V}} \alpha_{v_i, v} = 1$。&lt;/p>
&lt;p>在一个确定的时间步，当前交通状况和路网结构能够影响传感器之间的关联性。举个例子，路上的拥挤可能极大地影响它临近路段的交通状况。受这个直觉的启发，我们考虑使用交通特征和图结构两方面来学习注意力分数。我们把隐藏状态和时空嵌入拼接起来，使用 scaled dot-product approach (Vaswani et al. 2017) 来计算结点 $v_i$ 和 $v$ 之间的相关性：&lt;/p>
$$\tag{3}
s\_{v\_i, v} = \frac{&lt; h^{(l-1)}\_{v\_i,t\_j} \Vert\ e\_{v\_i,t\_j}, h^{(l-1)}+{v,t\_j}, \Vert e\_{v,t\_j} >}{\sqrt{2D}}
$$&lt;p>其中，$\Vert$ 表示拼接操作，$&amp;lt; \bullet, \bullet &amp;gt;$ 表示内积，$2D$ 表示 $h^{(l-1)}_{v_i,t_j} \Vert e_{v_i,t_j}$ 的维度。$s_{v_i,v}$ 通过 softmax 归一化：&lt;/p>
$$\tag{4}
\alpha\_{v\_i,v} = \frac{\text{exp}(s\_{v\_i,v})}{\sum\_{v\_r \in \mathcal{V}} \text{exp}(s\_{v\_i,v\_r})}.
$$&lt;p>得到注意力分数 $\alpha_{v_i,v}$ 之后，隐藏状态通过公式 2 更新。&lt;/p>
&lt;p>为了稳定学习过程，我们把空间注意力机制扩展为多头注意力机制。我们拼接 $K$ 个并行的注意力机制，使用不同的全连接映射：&lt;/p>
$$\tag{5}
s^{(k)}\_{v\_i,v} = \frac{&lt; f^{(k)}\_{s,1} (h^{(l-1)}\_{v\_i,t\_j} \Vert e\_{v\_i,t\_j}), f^{(k)}\_{s,2} (h^{(l-1)}\_{v,t\_j} \Vert e\_{v,t\_j}) >}{\sqrt{d}},
$$$$\tag{6}
\alpha^{(k)}\_{v\_i,v} = \frac{\text{exp}(s^{(k)}\_{v\_i,v})}{\sum\_{v\_r \in \mathcal{V}} \text{exp}(s^{(k)}\_{v\_i,v\_r})},
$$$$\tag{7}
hs^{(l)}\_{v\_i,t\_j} = \Vert^K\_{k=1} \lbrace \sum\_{v \in \mathcal{V}} \alpha^{(k)}\_{v\_i,v} \cdot f^{(k)}\_{s,3}(h^{(l-1)}\_{v,t\_j}) \rbrace,
$$&lt;p>其中 $f^{(k)}_{s,1}(\bullet), f^{(k)}_{s,2}(\bullet), f^{(k)}_{s,3}(\bullet)$ 表示第 $k$ 注意力头的三个不同的非线性映射，即公式 1 ，产生 $d = D / K$ 维的输出。&lt;/p>
&lt;p>当结点数 $N$ 很大的时候，时间和内存消耗都会很大，达到 $N^2$ 的数量级。为了解决这个限制，我们提出了组空间注意力，包含了组内注意力分数和组间注意力分数，如图 4 所示。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig4.png"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;p>我们把 $N$ 个结点随机划分为 $G$ 个组，每个组包含 $M = N / G$ 个结点，如果必要的话可以加 padding。每个组，我们使用公式 5，6，7 计算组内的注意力，对局部空间关系建模，参数是对所有的组共享的。然后，我们在每个组使用最大池化得到每个组的表示。接下来计算组间空间注意力，对组间关系建模，给每个组生成一个全局特征。局部特征和全局特征相加得到最后的输出。&lt;/p>
&lt;p>组空间注意力中，我们每个时间步需要计算 $GM^2 + G^2 = NM + (N / M)^2$ 个注意力分数。通过使梯度为0，我们知道 $M = \sqrt[3]{2N}$ 时，注意力分数的个数达到最大值 $2^{-1/3} N^{4/3} \ll N^2$。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig5.png"
loading="lazy"
alt="Figure5"
>&lt;/p>
&lt;p>&lt;strong>Temporal Attention&lt;/strong> 一个地点的交通状况和它之前的观测值有关，这个关联是非线性的。为了建模这些性质，我们设计了一个时间注意力机制，自适应地对不同时间步的非线性关系建模，如图 5 所示。可以注意到时间关联受到交通状况和对应的时间环境两者的影响。举个例子，早高峰的拥堵可能会影响交通好几个小时。因此，我们考虑交通特征和时间两者来衡量不同时间步的相关性。我们把隐藏状态和时空嵌入拼接起来，使用多头注意力计算注意力分数。对于结点 $v_i$，时间步 $t_j$ 与 $t$ 的相关性定义为：&lt;/p>
$$\tag{8}
u^{(k)}\_{t\_j,t} = \frac{&lt; f^{(k)}\_{t,1}(h^{(l-1)}\_{v\_i,t\_j} \Vert e\_{v\_i,t\_j}), f^{(k)}\_{t,2}(h^{(l-1)}\_{v\_i,t} \Vert e\_{v\_i,t}) >}{\sqrt{d}},
$$$$\tag{9}
\beta^{(k)}\_{t\_j,t} = \frac{\text{exp}(u^{(k)}\_{t\_j,t})}{\sum\_{t\_r \in \mathcal{N}\_{t\_j}}} \text{exp}(u^{(k)}\_{t\_j,t\_r}),
$$&lt;p>$u^{(k)}_{t_j,t}$ 表示时间步 $t_j$ 和 $t$ 之间的相关性，$\beta^{(k)}_{t_j,t}$ 是第 $k$ 个头的注意力分数，表示时间步 $t$ 对时间步 $t_j$ 的重要性，两个 $f$ 是非线性变换，$\mathcal{N}_{t_j}$ 表示 $t_j$ 前的时间步的集合，即只考虑目标时间步以前的时间步，这样才有因果。一旦获得了注意力分数，时间步 $t_j$ 的结点 $v_i$ 的隐藏状态可以通过下面的公式更新：&lt;/p>
$$\tag{10}
ht^{(l)}\_{v\_i,t\_j} = \Vert^K\_{k=1} \lbrace \sum\_{t \in \mathcal{N}\_{t\_j}} \beta^{(k)}\_{t\_j,t} \cdot f^{(k)}\_{t,3}(h^{(l-1)}\_{v\_i,t}) \rbrace
$$&lt;p>$f$ 是非线性映射。公式 8，9，10 学习到的参数对所有结点和所有时间步共享，且并行计算。&lt;/p>
&lt;p>&lt;strong>Gated Fusion&lt;/strong> 一个时间步一条路上的交通状况与它自身之前的值和相邻道路上的交通状况相关。如图 2c 所示，我们设计了一个门控融合机制自适应地融合空间和时间表示。在第 $l$ 个块，空间和时间注意力的输出表示为 $H^{(l)}_S$ 和 $H^{(l)}_T$，两者的维度在编码器中是 $\mathbb{R}^{P \times N \times D}$，解码器中是 $\mathbb{R}^{Q \times N \times D}$。通过下式融合：&lt;/p>
$$\tag{11}
H^{(l)} = z \odot H^{(l)}\_S + (1 - z) \odot H^{(l)}\_T,
$$$$\tag{12}
z = \sigma(H^{(l)}\_S \mathbf{W}\_{z,1} + H^{(l)}\_T \mathbf{W}\_{z,2} + \mathbf{b}\_z),
$$&lt;p>门控融合机制自适应地控制每个时间步和结点上空间和时间依赖的流动。&lt;/p>
&lt;h2 id="transform-attention">Transform Attention
&lt;/h2>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig6.png"
loading="lazy"
alt="Figure6"
>&lt;/p>
&lt;p>为了减轻错误传播的问题，我们在编码器和解码器之间加入了一个变换注意力层。它能直接地对历史时间步和未来时间步的关系建模，将交通特征编码为未来的表示，作为解码器的输入。如图 6 所示，对于结点 $v_i$ 来说，预测的时间步 $t_j \ (t_j = t_{P+1}, \dots, t_{P+Q})$ 和历史的时间步 $t \ (t_1, \dots, t_P)$ 通过时空嵌入来衡量：&lt;/p>
$$\tag{13}
\lambda^{(k)}\_{t\_j,t} = \frac{&lt; f^{(k)}\_{tr,1}(e\_{v\_i,t\_j}), f^{(k)}\_{tr,2}(e\_{v\_i,t}) >}{\sqrt{d}},
$$$$\tag{14}
\gamma^{(k)}\_{t\_j,t} = \frac{\text{exp}(\lambda^{(k)}\_{t\_j,t})}{\sum^{t\_P}\_{t\_r=t\_1} \text{exp}(\lambda^{(k)}\_{t\_j,t\_r})}.
$$&lt;p>编码的交通特征通过注意力分数 $\gamma^{(k)}_{t_j,t}$ 自适应地在历史 $P$ 个时间步选择相关的特征，变换到解码器的输入：&lt;/p>
$$\tag{15}
h^{(l)}\_{v\_i,t\_j} = \Vert^K\_{k=1} \lbrace \sum^{t\_P}\_{t=t\_1} \gamma^{(k)}\_{t\_j,t} \cdot f^{(k)}\_{tr,3}(h^{(l-1)}\_{v\_i,t}) \rbrace.
$$&lt;h2 id="encoder-decoder">Encoder-Decoder
&lt;/h2>&lt;p>如图 2a 所示，GMAN 是编码解码架构。在进入编码器前，历史记录 $\mathcal{X} \in \mathbb{R}^{P \times N \times C}$ 通过全连接变换到 $H^{(0)} \in \mathbb{R}^{P \times N \times D}$。然后 $H^{(0)}$ 输入到 $L$ 个时空注意力块组成的编码器中，产生输出 $H^{(L)} \in \mathbb{R}^{P \times N \times D}$。然后变换注意力层把编码特征从 $H^{(L)}$ 转换为 $H^{(L+1)} \in \mathbb{R}^{Q \times N \times D}$。然后 $L$ 个时空注意力块的解码器产生输出 $H^{(2L + 1)} \in \mathbb{R}^{Q \times N \times D}$。最后，全连接层输出 $Q$ 个时间步的预测 $\hat{Y} \in \mathbb{R}^{Q \times N \times C}$。&lt;/p>
&lt;p>GMAN 可以通过最小化 MAE 来优化：&lt;/p>
$$\tag{16}
\mathcal{L}(\Theta) = \frac{1}{Q} \sum^{t\_{P + Q}}\_{t = t\_P + 1} \vert Y\_t - \hat{Y}\_t \vert,
$$&lt;p>$\Theta$ 表示可学习的参数。&lt;/p>
&lt;h1 id="experiments">Experiments
&lt;/h1>&lt;h2 id="datasets">Datasets
&lt;/h2>&lt;p>我们在两个不同规模的交通预测数据集上衡量了模型的效果：（1）厦门数据集，流量预测，包含 95 个传感器从 2015 年 8 月 1 日到 12 月 31 日 5 个月的数据；（2）PeMS 数据集上速度预测，包含 325 个传感器 6 个月的数据。检测器的分布如图 7.&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Fig7.png"
loading="lazy"
alt="Figure7"
>&lt;/p>
&lt;h2 id="data-preprocessing">Data Preprocessing
&lt;/h2>&lt;p>一个时间步表示 5 min，使用 Z-Score 归一化，70% 用于训练，10% 验证，20% 测试。我们计算路网上传感器之间的距离，使用如下的路网构建方法：&lt;/p>
$$\tag{17}
\mathcal{A}\_{v\_i,v\_j} = \begin{cases}
\text{exp}(- \frac{d^2\_{v\_i,v\_j}}{\sigma^2}), &amp; \text{if} \ \text{exp}(-\frac{d^2\_{v\_i,v\_j}}{\sigma^2}) \geq \epsilon\\
0, &amp; \text{otherwise}
\end{cases}
$$&lt;p>$\epsilon$ 设定为 0.1。&lt;/p>
&lt;h2 id="experimental-settings">Experimental Settings
&lt;/h2>&lt;p>指标：MAE, RMSE, MAPE。&lt;/p>
&lt;p>超参数就不描述了。&lt;/p>
&lt;p>Baselines都是近几年的方法。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/gman-a-graph-multi-attention-network-for-traffic-prediction/Table1.png"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;p>这里值得一提的是，最后一个训练和预测时间的比较，我个人认为脱离了框架或软件，单单比较每轮训练时长是毫无意义的，因为有些静态图框架它就是很快，动态图的就是慢，而且代码质量也有区别，有的代码质量高，自然就很快，代码质量低的就很慢。拿 Graph WaveNet 举例，他们公开的代码是 pytorch 的，而且他们在 inference 的时候要对 ground truth 进行反归一化，有的代码人家就不反归一化，这也会造成 inference 的时候有差别，且有的模型是随着结点数 $N$ 的增加模型有显著的耗时增加的现象，没有考虑这些就写 computation time 的比较我觉得没有什么用，何况以 AAAI 7 页的限制来说，完全说清楚这些也毫无意义。&lt;/p></description></item><item><title>STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting</title><link>https://davidham3.github.io/blog/p/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/</link><pubDate>Fri, 12 Jul 2019 19:57:39 +0000</pubDate><guid>https://davidham3.github.io/blog/p/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/</guid><description>&lt;p>IJCAI 2019. 原文链接：&lt;a class="link" href="https://arxiv.org/abs/1905.10069.pdf" target="_blank" rel="noopener"
>STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger
Demand Forecasting&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>多步乘客需求预测对于按需车辆共享服务来说是个重要的任务。然而，预测多个时刻的乘客需求由于时空依赖的非线性和动态性很有挑战。我们提出了基于图的城市范围的旅客需求预测模型，使用一个层次图卷积同时捕获空间和时间关联性。我们的模型有三部分：1) 长期编码器对历史旅客需求编码；2) 短期编码器推导下一步预测结果来生成多步预测；3) 使用一个基于注意力的输出模块对动态的时间和各通道信息建模。实验在三个数据集上表明我们的方法比很多方法好。&lt;/p>
&lt;h1 id="1-introduction">1. Introduction
&lt;/h1>&lt;h1 id="2-notations-and-problem-statement">2. Notations and Problem Statement
&lt;/h1>&lt;p>假设一个城市分成 $N$ 个小的区域，不考虑是分成网格还是路网。我们将区域的集合表示为 $\lbrace r_1, r_2, \dots, r_i, \dots r_N \rbrace$。在每个时间步 $t$，一个二维矩阵 $\boldsymbol{D_t} \in \mathbb{R}^{N \times d_{in}}$ 表示所有区域在时间 $t$ 的旅客需求。另一个向量 $\boldsymbol{E_t} \in \mathbb{R}^{d_e}$ 表示时间步 $t$ 的时间特征，包含了几点、星期几以及节假日的信息。&lt;/p>
&lt;p>给定城市范围的历史旅客需求序列 $\lbrace \bm{D_0}, \bm{D_1}, \dots, \bm{D_t} \rbrace$ 和时间特征 $\lbrace \bm{E_0}, \bm{E_1}, \dots, \bm{E_{t+\tau}} \rbrace$，目标是学习一个预测函数 $\Gamma(\cdot)$ 来预测接下来的 $\tau$ 个时间步上城市范围的旅客需求序列。我们只使用历史 $h$ 个时间步的需求序列作为输入 $\lbrace \bm{D_{t-h+1}, \bm{D_{t-h+2}}, \dots, \bm{D_t}} \rbrace$。我们的任务描述为：&lt;/p>
$$\tag{1}
(\bm{D\_{t+1}}, \bm{D\_{t+2}}, \dots, \bm{D\_{t+\tau}}) = \Gamma(\bm{D\_{t-h+1}}, \bm{D\_{t-h+2}}, \dots, \bm{D\_t}; \bm{E\_0}, \bm{E\_1}, \dots, \bm{E\_{t+\tau}})
$$&lt;h1 id="3-methodology">3. Methodology
&lt;/h1>&lt;p>STG2Seq 的架构有三个组件：1. 长期编码器，2. 短期编码器，3.基于注意力的输出模块。长期和短期编码器由多个序列时空门控图卷积模块 (GGCM) 组成，通过在时间维度使用 GCN 可以同时捕获时间和空间相关性。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;h2 id="31-passenger-demand-on-graph">3.1 Passenger Demand on Graph
&lt;/h2>&lt;p>我们先介绍如何将城市范围的旅客需求在图上描述出来。之前的工作假设一个区域的旅客需求会被近邻的区域影响。然而，我们认为空间关系并不是仅依赖空间位置。如果遥远的区域和当前区域有相似的地方，比如具有相似的 POI，那么也可能拥有相同的旅客需求模式。因此，我们将城市看作一个图 $G = (v, \xi, A)$，$v$ 是区域的集合 $v = \lbrace r_i \mid i=1,2,\dots,N \rbrace$，$\xi$ 表示边的集合，$A$ 是邻接矩阵。我们根据区域间旅客需求模式的相似性定义图的边。&lt;/p>
$$\tag{2}
A\_{i, j} = \begin{cases}
1, \quad \text{if} \quad Similarity\_{r\_i, r\_j} > \epsilon\\
0, \quad \text{otherwise}
\end{cases}
$$&lt;p>其中 $\epsilon$ 是阈值，控制 $A$ 的稀疏程度。为了定量区域间的旅客需求模式的相似性，我们使用皮尔逊相关系数。$D_{0\text{\textasciitilde}t}(r_i)$ 表示时间从 0 到 $t$ 的区域 $r_i$ 历史旅客需求序列。$r_i$ 和 $r_j$ 之间的相似度可以定义为：&lt;/p>
$$\tag{3}
Similarity\_{r\_i, r\_j} = Pearson(D\_{0\text{\textasciitilde}t}(r\_i), D\_{0\text{\textasciitilde}t}(r\_j))
$$&lt;h2 id="32-long-term-and-short-term-encoders">3.2 Long-term and Short-term Encoders
&lt;/h2>&lt;p>很多之前的工作只考虑下一步预测，即预测下一时间步的旅客需求。在训练过程中通过减少下一时间步预测值的误差而不考虑后续时间步的误差来优化模型。因此，这些方法在多步预测的问题上会退化。仅有一些工作考虑了多步预测的问题 [Xingjian et al., 2015; Li et al., 2018]。这些工作采用了基于 RNN 的编码解码器的架构，或是它的变体，比如 ConvLSTM 这样的作为编码解码器。这些方法有两个劣势：1. 链状结构的 RNN 在编码的时候需要遍历输入的时间步。因此他们需要与输入序列等长的 RNN 单元个数（序列多长，RNN单元就有多少个）。在目标需求和前一个需求上的长距离计算会导致一些信息的遗忘。2. 在解码部分，为了预测时间步 $T$ 的需求，RNN 将隐藏状态和前一时间步 $T-1$ 作为输入。因此，前一时间步带来的误差会直接影响到预测，导致未来时间步误差的累积。&lt;/p>
&lt;p>不同于之前所有的工作，我们引入了一个依赖于同时使用长期和短期编码器的架构，不用 RNN 做多步预测。长期编码器取最近的 $h$ 个时间步的城市历史旅客需求序列 $\lbrace \bm{D_{t-h+1}}, \bm{D_{t-h+2}}, \dots, \bm{D_t} \rbrace$ 作为输入来学习历史的时空模式。这 $h$ 步需求合并后组织成三维矩阵，$h \times N \times d_{in}$。长期编码器由一些 GGCM 组成，每个 GCGGM 捕获在所有的 $N$ 个区域上捕获空间关联性，在 $k$ 个时间步上捕获时间关联性。$k$ 是超参数，我们会在 3.3 节讨论。因此，只需要 $\frac{h-1}{k-1}$ 个迭代的步数就可以捕获 $h$ 个时间步上的时间关联性。对比 RNN 结构，我们的基于 GGCM 的长期编码器显著的降低了遍历长度，进一步减少了信息的损失。长期编码器的输出 $Y_h$ 的维数是 $h \times N \times d_{out}$，是输入的编码表示。&lt;/p>
&lt;p>短期编码器用来集成已经预测的需求，用于多步预测。它使用一个长度为 $q$ 的滑动窗来捕获近期的时空关联性。当预测在 $T(T \in [t+1,t+\tau])$ 步的旅客需求时，它取最近的 $q$ 个时间步的旅客需求，即 $\lbrace \bm{D_{T-q}}, \bm{D_{T-q+1}}, \dots, \bm{D_{T-1}} \rbrace$ 作为输入。除了时间步的长度以外，短期编码器和长期编码器一样。短期编码器生成一个维数为 $q \times N \times d_{out}$ 的矩阵 $Y^T_q$ 作为近期趋势表示。和基于 RNN 的解码器不同的是，RNN的解码器只将最后一个时间步的预测结果输入回去。因此，预测误差会被长期编码器小柔，减轻基于 RNN 的解码器会导致误差累积的问题。&lt;/p>
&lt;h2 id="33-gated-graph-convolutional-module">3.3 Gated Graph Convolutional Module
&lt;/h2>&lt;p>门控图卷积模块是长期编码器和短期编码器的核心。每个 GGCM 由几个 GCN 层组成，沿着时间轴并行。为了捕获时空关联性，每个 GCN 在一定长度的时间窗内操作($k$)。它可以提取 $k$ 个时间步内所有区域的空间关联性。通过堆叠多个 GGCM，我们的模型形成了一个层次结构，可以捕获整个输入的时空关联性。图 3 展示了只使用 GCN 捕获时空关联性，为了简化我们忽略了通道维。Yu et al., 2018 的工作和我们的 GGCM 模块很像。他们的工作首先使用 CNN 捕获时间关联性，然后使用 GCN 捕获空间关联性。我们的方法对比他们的方法极大的简化了，因为我们可以同时捕获时空关联性。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/Fig4.JPG"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;p>GGCM 模块的详细设计如图 4。第 $l$ 个 GGCM 的输入是一个矩阵，维数为 $h \times N \times C^l$。在第一个 GGCM 模块，$C^l$ 是 $d_{in}$ 维的。第 $l$ 个 GGCM 的输出是 $h \times N \times C^{l+1}$。我们先拼接一个 zero padding，维数为 $(k-1) \times N \times C^l$，得到新的输入 $(h+k-1) \times N \times C^l$，确保变换不会减少序列的长度。接下来，GGCM 中的每个 GCN 取 $k$ 个时间步的数据 $k \times N \times C^l$ 作为输入来提取时空关联性，然后 reshape 成一个二维矩阵 $N \times (k \cdot C^l)$。根据 Kipf &amp;amp; Welling 的 GCN，GCN 层可以描述如下：&lt;/p>
$$\tag{4}
X^{l+1} = (\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W
$$&lt;p>$\tilde{A} = A + I_n$，$\tilde{P}_{ii} = \sum_j \tilde{A}_{ij}$，$X \in \mathbb{R}^{N \times (k \cdot C^l)}$，$W \in \mathbb{R}^{(k \cdot C^l) \times C^{l+1}}$，$X^{l+1} \in \mathbb{R}^{N \times C^{l+1}}$
。&lt;/p>
&lt;p>除此以外，我们使用了门控机制对旅客需求预测的复杂非线性建模。式 4 重新描述如下：&lt;/p>
$$\tag{5}
X^{l+1} = ((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W\_1 + X^l) \otimes \sigma((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W\_2)
$$&lt;p>$\otimes$ 是对应元素相乘，$\sigma$是 sigmoid 激活函数。因此输出是一个非线性门 $\sigma((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W_2)$ 控制的线性变换 $((\tilde{P}^{-\frac{1}{2}} \tilde{A} \tilde{P}^{-\frac{1}{2}}) X^l W_1 + X^l)$。非线性门控制线性变换的哪个部分可以通过门影响预测。此外，我们使用残差连接来避免式 5 中的网络退化。&lt;/p>
&lt;p>最后，门控机制产生的 $h$ 个输出沿时间轴合并，生成 GGCM 模块的输出 $h \times N \times C^{l+1}$。&lt;/p>
&lt;h2 id="34-attention-based-output-module">3.4 Attention-based Output Module
&lt;/h2>&lt;p>如 3.2 描述的那样，长期时空依赖和 $T$ 时间步的近期时空依赖通过两个矩阵描述 $Y_h$ 和 $Y^T_q$。我们拼接。我们拼接他们形成联合表示 $Y_{h+q} \in \mathbb{R}^{(h+q) \times N \times d_{out}}$，通过一个基于注意力机制的模块解码获得预测值。这里为了简便忽略 $T$。$Y_{h+q}$ 的三个轴分别是时间、空间、通道。&lt;/p>
&lt;p>我们先引入一个时间注意力机制来解码 $Y_{h+q}$。旅客需求是一个典型的时间序列，前一时刻的需求对后一时刻有影响。然而，之前的每一步对预测目标的影响是不同的，影响随时间变化。我们设计了一个时间注意力机制对每个历史时间步增加注意力分数衡量其影响。分数通过 $Y_{h+q} = [y_1, y_2, \dots, y_{h+q}](y_i \in \mathbb{R}^{N \times d_{out}})$ 和目标时间步的时间特征 $\bm{E}_T$ 生成，这个分数可以自适应地学习之前的时间步随时间的动态影响。我们定义时间注意力分数如下：&lt;/p>
$$\tag{6}
\bm{\alpha} = softmax(tanh(Y\_{h+q} W^Y\_3 + E\_T W^E\_4 + b\_1))
$$&lt;p>$W^Y_3 \in \mathbb{R}^{(h+q) \times (N \times d_{out}) \times 1}$，$W^E_4 \in \mathbb{R}^{d_e \times (h+q)}$，$b_1 \in \mathbb{R}^{(h+q)}$。联合表示 $Y_{h+q}$ 通过注意力分数 $\bm{\alpha}$ 转换：&lt;/p>
$$\tag{7}
Y\_{\alpha} = \sum^{h+q}\_{i=1} \alpha^i y\_i \quad \in \mathbb{R}^{N \times d\_{out}}
$$&lt;p>受到 [Chen et al., 2017] 的启发，每个通道的重要性是不同的，我们在时间注意力后面加了一个通道注意力模块来找到 $Y_\alpha = [y_1, y_2, \dots, y_{d_{out}}]$ 中最重要的那个。计算如下：&lt;/p>
$$\tag{8}
\bm\beta = softmax(tanh(Y\_\alpha W^Y\_5 + E\_T W^E\_6 + b\_2))
$$$$\tag{9}
Y\_{\beta} = \sum^{d\_{out}}\_{i=1} \beta^i y\_i \quad \mathbb{R}^N
$$&lt;p>其中，$W^Y_5 \in \mathbb{R}^{d_{out} \times N \times 1}$，$W^E_6 \in \mathbb{R}^{d_e \times d_{out}}$；$\bm\beta \in \mathbb{R}^{d_{out}}$ 是每个通道的注意力分数。当预测的维度是1时，$Y_\beta$ 就是我们预测的旅客需求 $\bm{D&amp;rsquo;_T}$。当预测维度是 2 时（预测起止需求），我们给每个通道计算注意力分数，将他们拼接起来得到最后的预测值。&lt;/p></description></item><item><title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</title><link>https://davidham3.github.io/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/</link><pubDate>Wed, 08 May 2019 16:40:48 +0000</pubDate><guid>https://davidham3.github.io/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/</guid><description>&lt;p>AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：&lt;a class="link" href="https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf" target="_blank" rel="noopener"
>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>人口流量预测在城市规划、交通管控中的很多应用中都很重要。目的是预测流入和流出流量。我们提出了 DeepSTN+，一个基于深度学习的卷积模型，预测超大城市的人口流量。首先，DeepSTN+ 使用 &lt;em>ConvPlus&lt;/em> 结构对大范围的空间依赖建模。此外，POI 分布和时间因素相融合来表达区域属性的影响，以此引入人口流动的先验知识。最后，我们提出了一个有效的融合机制来稳定训练过程，提升了结果。基于两个真实数据集的大量实验结果表明我们模型的先进性，和 state-of-the-art 比高了 8% ~ 13% 左右。&lt;/p>
&lt;h1 id="introduction">Introduction
&lt;/h1>&lt;p>如图 1 所示，人口流量预测是在给定历史流量信息的前提下，预测城市内每个区域的流入和流出流量。最近，为了解决这个问题，基于深度学习的模型被相继提出，获得了很好的效果。Deep-ST 是第一个使用卷积网络捕获空间信息的模型。ST-ResNet 用卷积模块替换了卷积。通过融合金字塔型的 ConvGRU 模型和周期表示，Periodic-CRN 设计成了捕获人口流动周期性的模型。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>这些方法仍然不够有效且不精确：&lt;/p>
&lt;ol>
&lt;li>&lt;em>不能捕获区域间的空间依赖。&lt;/em> 由于现代城市中高级的运输系统的存在，人们可以通过地铁或出租车在短时间内移动到很远的地方。因此，区域间的大范围空间依赖在人口移动中逐渐扮演重要的角色。现存的工作使用多层卷积网络来建模。然而，它们只能一步一步地捕获近邻的空间依赖，不能直接地捕获大范围的空间依赖。&lt;/li>
&lt;li>&lt;em>忽略了人口流动的区域功能的影响。&lt;/em> 人口移动是发生在物理世界中的，会直接受到区域属性的影响。举个例子，人们通常早上从家出发到公司，晚上回来。显然，区域的功能（属性）包含了关于人类移动的先验知识。然而，现存的解决方案没有考虑过区域的属性。&lt;/li>
&lt;li>&lt;em>冗余以及不稳定的神经网络结构。&lt;/em> ST-ResNet 利用了三个独立分支，每个分支都是残差卷积单元，用来处理不同的输入，在模型的结尾用一个线性操作融合三个输出。但是，最后的融合机制导致不同组件间的交互产生了缺陷，这个缺陷导致了网络内产生了无效的参数和不稳定的性质。&lt;/li>
&lt;/ol>
&lt;p>总结一下，模型应该考虑大范围的空间依赖，区域的影响，更有效的融合机制这三点因素。我们提出的 DeepSTN+ 解决了上述挑战。我们设计了一个 &lt;em>ConvPlus&lt;/em> 结构直接地捕获大范围空间依赖。&lt;em>ConvPlus&lt;/em> 放在残差单元前面作为一个全局特征提取器提取出区域间的全局特征。其次，我们设计了一个 &lt;em>SemanticPlus&lt;/em> 结构来学习人口在区域间移动的先验知识。用静态的 POI 分布作为输入，&lt;em>SemanticPlus&lt;/em> 利用时间因素给不同时间上不同的 POI 分配权重。最后，我们引入早融合和多尺度融合机制来减少训练参数，捕获不同级别特征间的复杂关系。这样，我们的系统可以对更复杂的空间关联性建模，获得更好的效果，我们的贡献有以下几点：&lt;/p>
&lt;ul>
&lt;li>我们设计了一个新的残差单元，ResPlus 单元用来替换原始的残差单元。我们指出了典型的卷积模型不能有效地捕获大范围依赖。ResPlus 包含了一个 &lt;em>ConvPlus&lt;/em> 结构，可以捕获人流间的大范围空间依赖。&lt;/li>
&lt;li>我们设计了一个 &lt;em>SemanticPlus&lt;/em> 结构来建模不同区域的影响，学习人口流动的先验知识。我们在模型头部使用早融合机制，在结尾使用多尺度融合机制，提升了模型的精度和稳定性。&lt;/li>
&lt;li>我们在两个数据集上开展了大量的实验，对比了 5 个 baselines，结果显示我们的模型在预测人口流动的错误上减少了 8% ~ 13%。&lt;/li>
&lt;/ul>
&lt;h1 id="preliminaries">Preliminaries
&lt;/h1>&lt;p>这部分，我们首先介绍人口流量预测问题，简要回顾 ST-ResNet。&lt;/p>
&lt;h2 id="problem-formulation">Problem Formulation
&lt;/h2>&lt;p>**Definition 1 (Region (Zhang et al. 2016)) 为了表示城市的区域，我们基于经纬度将城市划分成 $H \times W$ 个区域，所有的网格有相同大小且表示一个区域。&lt;/p>
&lt;p>**Definition 2 (Inflow/outflow (Zhang et al. 2016)) 为了表示城市内的人口流动，我们定义了区域 $(h, w)$ 在时段 $i$ 的流入和流出流量：&lt;/p>
&lt;p>$$
x^{h,w,in}_{i} = \sum_{T_{r_k} \in \mathbb{P}} \vert \lbrace j &amp;gt; 1 \mid g_{j-1} \not \in (h, w) \And g_j \in (h, w) \rbrace \vert,\&lt;/p>
&lt;p>x^{h,w,out}_{i} = \sum_{T_{r_k} \in \mathbb{P}} \vert \lbrace j \geq 1 \mid g_{j-1} \in (h, w) \And g_j \not \in (h, w) \rbrace \vert.
$$&lt;/p>
&lt;p>这里 $\mathbb{P}$ 表示时段 $i$ 的轨迹集合。$T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的一条轨迹，$g_j$ 是坐标；
$g_j \in (h, w)$ 表示点 $g_j$ 在网格 $(h, w)$ 内，反之亦然；$\vert \cdot \vert$ 表示集合的基数。&lt;/p>
&lt;p>&lt;strong>Crowd Flow Prediction&lt;/strong>: 给定历史观测值 $\lbrace \mathbf{X}_i \mid i=1,2,\cdots, n-1 \rbrace$，预测 $\mathbf{X}_n$。&lt;/p>
&lt;p>ST-ResNet 包含四个组件，&lt;em>closeness&lt;/em>, &lt;em>period&lt;/em>, &lt;em>trend&lt;/em> 和 外部因素单元。每个组成部分通过一个分支的残差单元或全连接层预测出一个流量地图。然后模型使用一个线性组合作为末端融合方式融合这些预测值。ST-ResNet 的外部因素包含了天气、假期事件、元数据。&lt;/p>
&lt;p>卷积神经网络的卷积核通常很小，意味着他们不能直接捕获远距离的空间依赖。然而，大范围的空间依赖在城市中很重要。另一方面，ST-ResNet 忽略了人口流动的在位置上的影响。此外，ST-ResNet 的末端融合机制导致了模型交互上的缺点以及参数的低效，还有模型的不稳定的问题。&lt;/p>
&lt;h1 id="our-model">Our Model
&lt;/h1>&lt;p>图 2 展示了我们模型的框架。主要有三个部分：流量输入、SemanticPlus 和 ResPlus 单元。流量慎入包含 &lt;em>closeness, period, terend&lt;/em>，由于数据的时间范围限制可以减少为 &lt;em>closeness, period&lt;/em>。SemanticPlus 包含 POI 分布和时间信息。ResPlus 单元可以捕获远距离空间依赖。每个区域的流入和流出流量通过每小时或者每半小时统计得到流量地图的时间序列。这些流量地图通过 Min-Max 归一化处理到 $[-1, 1]$。如图 2 所示，人口分布地图通过近期时间、近邻历史、远期历史选择后作为输入放入模型。不同类型的 POI 分布通过 Min-Max 归一化到 $[0, 1]$。如图 2 做部分所示，POI 分布地图通过时间信息赋予了不同的权重。之后，POI 信息和人流信息通过早融合后放入堆叠的 ResPlus 单元中。最后，ResPlus 单元不同级别的特征融合后进入卷积部分，然后通过 Tanh 映射到 $[-1, 1]$。下面会介绍细节。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;h2 id="resplus">ResPlus
&lt;/h2>&lt;p>很多处理人口流量预测的深度学习模型主要包含两个部分：基于 RNN 的结构，像 ConvLSTM 和 Periodic-CRN，以及基于 CNN 的结构，如 Deep-ST 和 ST-ResNet。但是，训练基于 RNN 结构的模型费时。因此我们选用基于 CNN 的结构 ST-ResNet 作为我们的基础模型。&lt;/p>
&lt;p>在这篇论文中，我们设计 ConvPlus 来捕获城市内远距离的空间依赖。如图 3，ResPlus 单元使用一个 ConvPlus 和一个典型卷积。我们尝试了 Batch Normalization 和 Dropout，为了简介没有在图里面画出来。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>典型卷积的每个通道对应一个卷积核。卷积核使用这些核来计算地图上的互相关系数，比如捕获梯度上的特征。卷积核的大小一般很小。在 ST-ResNet 和 DeepSTN+ 里面，卷积核的大小是 $3 \times 3$。但是城市中存在着远距离的依赖。人们可能坐地铁去上班。我们称这类关系叫远距离空间依赖关系。这种关系使得堆叠卷积难以有效地捕获这个关系。&lt;/p>
&lt;p>如图 3 左部分所示，在 ConvPlus 结构中，我们将典型卷积的一些通道分离来捕获每个区域的远距离空间依赖。然后用一个全连接层直接捕获每两个区域之间的远距离空间依赖，在这层前面用一个池化层来减少参数。因此，在 ConvPlus 的输出有两类通道。ConvPlus 的输出有着和普通卷积一样的输出，可以用于下一个卷积的输入。&lt;/p>
&lt;p>图 4 展示了两个不同区域的空间依赖热力图，分别是红色和黄色的星。这些目标区域不仅有区域上的依赖，还有一些和远处区域的远距离依赖。这也显示出不同的区域和地图上的其他区域有不一样的关系，这很难通过堆叠卷积有效地捕获。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig4.JPG"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;p>因为 ConvPlus 有两类不同的输出通道，我们在 ResPlus 单元中使用 ConvPlus + Conv 而不是 ConvPlus + ConvPlus。没有 SemanticPlus 的 DeepSTN+ 形式化为：&lt;/p>
$$
\widehat{\mathbf{X}} = f\_{Res}(f\_{EF}(\mathbf{X}^c + \mathbf{X}^p + \mathbf{X}^t)),
$$&lt;p>三个 $\mathbf{X}$ 表示三种类型的历史地图——&lt;em>closeness, period, trend&lt;/em>。$\widehat{\mathbf{X}}$ 表示预测出的流量地图。$+$ 表示拼接操作。$f_{EF}$ 表示用来早融合不同类型信息的卷积函数，$f_{Res}$ 表示一个堆叠的 ResPlus 单元。&lt;/p>
&lt;h2 id="semanticplus">SemanticPlus
&lt;/h2>&lt;p>POI 在人口流动上有很强烈的影响，这些影响随时间变化而变化。因此，我们继承这个先验知识到模型内。我们手机了包括类型、数量、位置的 POI 信息。然后统计每个网格内 POI 的数量，使用一个一维向量表示每种 POI 的分布。图 5 展示了北京的流量分布地图和餐饮分布地图。它们的分布很相似，并且互相关系数有 0.87，暗示了它们之间的潜在关系。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig5.JPG"
loading="lazy"
alt="Figure5"
>&lt;/p>
&lt;p>我们使用一个时间向量来表示每个人口流量地图的时间。时间向量包含两个部分：一个 one-hot 向量表示一天中的各个时间，如果时段按小时走，那长度就是 24；另一个 one-hot 向量表示是一周中的哪天，长度是 7。一个时间向量拼接了这两个向量。&lt;/p>
&lt;p>为了建模对流量地图有变化的时间影响的 POI 信息，我们将时间向量转换为 POI 的影响强度。我们使用大小为 $PN \times H \times W$ 的 $\mathbf{X}^s$ 来表示 POI 地图（$PN$ 表示 POI 的类数，$H$ 和 $W$ 是网格的行数和列数，一个向量 $\bf{I}$ 用来表示时间向量，大小为 $PN$ 的向量 $\bf{R}$ 表示 POI 的影响强度。因此，我们有带有时间权重的 POI 分布，形式化如下：&lt;/p>
$$
\mathbf{S} = \mathbf{X}^s \ast \mathbf{R} = \mathbf{X}^s \ast f\_t(\mathbf{I})
$$&lt;p>函数 $f_t()$ 将时间向量转换为表示 POI 影响强度的向量。$\ast$ 表示每个 POI 分布地图会被附上一个权重，表示 POI 的影响强度。我们假设同一类在不同的区域的 POI 有相同的时间模式。因此，一个类别的 POI 分布地图会有相同的权重。图 6 展示了娱乐和居住区的影响强度。影响强度在一周内随时间的变化而变化，每天存在着一些典型的模式。很多人早上去上班，工作结束后回家，所以每天早上和下午住宅区有明显的两个峰。对比居住区，娱乐区的影响相对稳定。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig6.JPG"
loading="lazy"
alt="Figure6"
>&lt;/p>
&lt;h2 id="fusion">Fusion
&lt;/h2>&lt;p>三组件应该用更复杂的融合方式，而不是线性组合。这些带有 POI 信息的流量信息也有复杂的交互。为了建模这种相互影响，我们使用早融合而不是末端融合使得不同的信息能更早的融合起来。早融合减少了大约三分之二的参数。此外，ST-ResNet 有些时候不能收敛。我们发现这个问题可以通过早融合减少参数来简化模型解决。考虑到不同层的特征有不同的函数，我们在模型末端设定了一个多尺度的融合机制。这里我们形式化描述整个网络：&lt;/p>
$$
\widehat{\mathbf{X}} = f\_{con}(f\_{Res}(f\_{EF}(\mathbf{X}^c + \mathbf{X}^p + \mathbf{X}^t + \mathbf{S}))),
$$&lt;p>函数 $f_{EF}$ 表示一个早融合使用的卷积操作，在早融合之前压缩了通道数。函数 $f_{con}$ 表明了最后的多尺度融合，表示卷积层后的一个拼接层。$\bf{S}$ 表示 SemanticPlus 的输出，即 带有时间权重的 POI 分布。&lt;/p>
&lt;h2 id="training">Training
&lt;/h2>&lt;p>算法 1 描述了训练过程。前 7 行是构建训练集和 POI 信息，模型通过 Adam 训练（8-12 行）&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Alg1.JPG"
loading="lazy"
alt="Alg1"
>&lt;/p>
&lt;h1 id="performance-evaluation">Performance Evaluation
&lt;/h1>&lt;p>这部分，我们在两个数据集上不同城市的不同类型的流量上做了大量的实验，为了回答三个研究问题：&lt;/p>
&lt;ul>
&lt;li>我们的提出的 DeepSTN+ 是否比现存的方法好？&lt;/li>
&lt;li>ResPlus, SemanticPlus, 早融合是怎么提升预测结果的？&lt;/li>
&lt;li>DeepSTN+ 的超参数如何影响预测结果？&lt;/li>
&lt;/ul>
&lt;h2 id="datasets">Datasets
&lt;/h2>&lt;p>表 1 包含了数据。每个数据有两个子集：流量轨迹和 POI 信息。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;p>&lt;em>&lt;strong>MobileBJ:&lt;/strong>&lt;/em> 数据是中国一个很流行的社交网络应用商提供的，时间范围是4 月 1 日到 4 月 30 日。记录了用户请求区域服务时的位置。我们用定义 2 转换成了网格流量。我们选择最后一周的数据作为测试集，前面的作为训练集。表 2 展示了这个数据集的 17 类 POI 信息。&lt;/p>
&lt;p>&lt;em>&lt;strong>BikeNYC:&lt;/strong>&lt;/em> NYC 的自行车数据，2014 年，4 月 1 日到 9 月 30 日。数据包含了旅途时长，出发和到达站的 ID，起始和结束时间。最后 14 天的数据用来测试，其他的训练。我们选了 9 类 POI 信息。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table2.JPG"
loading="lazy"
alt="Table2"
>&lt;/p>
&lt;h2 id="baselines">Baselines
&lt;/h2>&lt;ul>
&lt;li>HA&lt;/li>
&lt;li>VAR&lt;/li>
&lt;li>ARIMA&lt;/li>
&lt;li>ConvLSTM&lt;/li>
&lt;li>ST-ResNet&lt;/li>
&lt;/ul>
&lt;h2 id="metrics-and-parameters">Metrics and Parameters
&lt;/h2>&lt;ul>
&lt;li>RMSE&lt;/li>
&lt;/ul>
$$
RMSE = \sqrt{\frac{1}{T} \sum^T\_{i=1} \Vert \mathbf{X}\_i - \widehat{X}\_i \Vert^2\_2},
$$&lt;ul>
&lt;li>MAE&lt;/li>
&lt;/ul>
$$
MAE = \frac{1}{T} \sum^T\_{i=1} \vert \mathbf{X}\_i - \widehat{\mathbf{X}}\_i \vert,
$$&lt;p>RMSE 作为 loss function。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table3.JPG"
loading="lazy"
alt="Table3"
>&lt;/p>
&lt;p>表 3 展示了不同的参数设置。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table4.JPG"
loading="lazy"
alt="Table4"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table5.JPG"
loading="lazy"
alt="Table5"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig7.JPG"
loading="lazy"
alt="Figure7"
>&lt;/p></description></item><item><title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</title><link>https://davidham3.github.io/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/</link><pubDate>Fri, 19 Apr 2019 16:40:41 +0000</pubDate><guid>https://davidham3.github.io/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/</guid><description>&lt;p>TKDE 2019，网格流量预测，用一个模型同时预测每个网格的流入/流出流量和网格之间的转移流量，分别称为顶点流量和边流量，同时预测这两类流量是本文所解决的多任务预测问题。本文提出的是个框架，所以里面用什么组件应该都是可以的，文章中使用了 FCN。使用两个子模型分别处理顶点流量和边流量预测问题，使用两个子模型的输出作为隐藏状态表示，通过拼接或加和的方式融合，融合后的新表示再分别输出顶点流量和边流量。这篇文章和之前郑宇的文章一样，考虑了三种时序性质、融合了外部因素。损失函数从顶点流量预测值和真值之间的差、边流量预测值和真值之间的差、顶点流量预测值之和与边流量的预测值之差三个方面考虑。数据集是北京和纽约的出租车数据集。 &lt;a class="link" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=8606218" target="_blank" rel="noopener"
>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning&lt;/a>&lt;/p>
&lt;p>&lt;strong>Abstract&lt;/strong>——预测流量（如车流、人流、自行车流）包括结点的流入、流出流量以及不同的结点间的转移，在交通运输系统中的时空网络里扮演着重要的角色。然而，这个问题受多方面复杂因素影响，比如不同地点的空间关系、不同时段的时间关系、还有像活动和天气这样的外部因素，所以这是个有挑战性的问题。此外，一个结点的流量（结点流量）和结点之间的转移（边流量）互相影响。为了解决这个问题，我们提出了一个多任务的深度学习框架可以同时预测一个时空网络上的结点流量和边流量。基于全卷积网络，我们的方法设计了两个复杂的模型分别处理结点流量预测和边流量预测。这两个模型通过组合中间层的隐藏表示连接，而且共同训练。外部因素通过一个门控融合机制引入模型。在边流量预测模型上，我们使用了一个嵌入组件来处理顶点间的系数转移问题。我们在北京和纽约的出租车数据集上做了实验。实验结果显示比11种方法都好。&lt;/p>
&lt;h1 id="1-introduction">1 Introduction
&lt;/h1>&lt;p>时空网络（ST-networks），如运输网络和传感器网络，在世界上到处都是，每个点有个空间坐标，每个边具有动态属性。时空网络中的流量有两种表示，如图 1，顶点流量（一个结点的流入和流出流量）和边流量（结点间的转移流量）。在运输系统中，这两类流量可通过4种方式测量，1. 近邻道路的车辆数，2. 公交车的旅客数，3. 行人数，4. 以上三点。图1b 是一个示意图。取顶点 $r_1$ 为例，我们可以根据手机信令和车辆 GPS 轨迹分别计算得到流入流量是 3，流出流量是 3。$r_3$ 到 $r_1$ 的转移是 3，$r_1$ 到 $r_2$ 和 $r_4$ 的转移是 2 和 1。因此，如图1c所示，我们能拿到两种类型的流量，四个结点的流入和流出分别是 $(3,3,0,5)$ 和 $(3,2,5,1)$。所有的边转移都看作是在有向图上发生的。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>预测这类的流量对公共安全，交通管理，网络优化很重要。取人口流动做一个例子，2015 年跨年夜的上海，踩踏事故导致 36 人死亡。如果能预测每个区域之间的人流转移，这样的悲剧就可以通过应急预案避免或减轻。&lt;/p>
&lt;p>然而，同时预测所有结点和边的转移是很难的：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Scale and complexity&lt;/strong>: 一个地方的流入和流出依赖于它的邻居，有近邻的也有遥远的，因为人们会在这些区域之间转移，尤其是有活动的时候。给定一个城市，有 $N$ 个地点，$N$ 很大，那么就有 $N^2$ 种转移方式，尽管这些转移可能不会同时发生。因此，预测地点的流量，要么是流入、流出或是转移流量，我们需要考虑地点之间的依赖关系。而且，预测也考虑过去时段的流量。此外，我们不能单独地预测每个地点的流量，因为城市内的地点间是相连的，相关的，互相影响的。复杂度和尺度都是传统机器学习模型，如概率图模型在解决这个问题时面临的巨大挑战。&lt;/li>
&lt;li>&lt;strong>Model multiple correlations and external factors&lt;/strong>: 我们需要对三种关系建模来处理预测问题。第一个是不同地点流量的空间相关性，包含近邻和遥远的。第二个是一个地点不同时段的流量间的时间关系，包括时间近邻、周期和趋势性。第三，流入流出流量和转移流量高度相关，互相影响。一个区域的转入流量之和是这个区域的流入流量。精确地预测一个区域的流出流量可以让预测其他区域的转移流量更精确，反之亦然。此外，这些流量受外部因素影响，如活动、天气、事故等。如何整合这些信息还是个难题。&lt;/li>
&lt;li>&lt;strong>Dynamics and sparsity&lt;/strong>: 由于 $N^2$ 种情况，区域间随时间改变的转移流量比流入流出流量要大得多。一个地点和其他地点间的转移会在接下来的时段发生，可能是 $N^2$ 中的很小一部分（稀疏）。预测这样的稀疏转移也是个难题。&lt;/li>
&lt;/ol>
&lt;p>为了解决上述挑战，我们提出了多任务深度学习框架MDL（图4）来同时预测顶点流量和边流量。我们的贡献有三点：&lt;/p>
&lt;ul>
&lt;li>MDL 设计了一个深度神经网络来预测顶点流量（命名为 NODENET），另一个深度神经网络预测边流量（命名为 EDGENET）。通过将他们的隐藏状态拼接来连接这两个深度神经网络，并一同训练。此外，这两类流量的相关性通过损失函数中的正则项来建模。基于深度学习的模型可以处理复杂性和尺度等问题，同时多任务框架增强了每类流量的预测性能。&lt;/li>
&lt;li>NODENET 和 EDGENET 都是 three-stream 全卷积网络（3S-FCNs），closeness-stream, period-stream, trend-stream 捕获三种不同的时间相关性。每个 FCN 也同时捕获近邻和遥远的空间关系。一个门控组件用来融合时空相关性和外部因素。为了解决转移稀疏的问题，EDGENET 中我们设计了一个嵌入组件，用一个隐藏低维表示编码了稀疏高维的输入。&lt;/li>
&lt;li>我们在北京和纽约的 taxicab data 上评估了方法。结果显示我们的 MDL 超越了其他 11 种方法。&lt;/li>
&lt;/ul>
&lt;p>表 1 列出了这篇文章中出现的数学符号。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;h1 id="2-problem-formulation">2 Problem Formulation
&lt;/h1>&lt;p>&lt;em>&lt;strong>Definition 1(Node).&lt;/strong>&lt;/em> 一个空间地图基于经纬度被分成 $I \times J$ 个网格，表示为 $V = \lbrace r_1, r_2, &amp;hellip;, r_{I\times J} \rbrace$，每个元素表示一个空间节点，如图2(a)。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>令 $(\tau, x, y)$ 为时空坐标，$\tau$ 表示时间戳，$(x, y)$ 表示空间点。一个物体的移动可以记为一个按时间顺序的空间轨迹，起点和终点表示为 $s = (\tau_s, x_s, y_s)$ 和 $e = (\tau_e, x_e, y_e)$，表示出发地和目的地。$\mathbb{P}$ 表示所有的起止对。&lt;/p>
&lt;p>&lt;em>&lt;strong>Definition 2(In/out flows).&lt;/strong>&lt;/em> 给定一组起止对 $\mathbb{P}$。$\mathcal{T} = \lbrace t_1, \dots t_T\rbrace$ 表示一个时段序列。对于地图上第 $i$ 行第 $j$ 列的顶点 $r_{ij}$，时段 $t$ 流出和流入的流量分别定义为：&lt;/p>
$$\tag{1}
\mathcal{X}\_t(0, i, j) = \vert \lbrace (s,e) \in \mathbb{P} : (x\_s, y\_s) \in r\_{ij} \wedge \tau\_s \in t \rbrace \vert
$$$$\tag{2}
\mathcal{X}\_t(1, i, j) = \vert \lbrace (s,e) \in \mathbb{P} : (x\_e, y\_e) \in r\_{ij} \wedge \tau\_e \in t \rbrace \vert
$$&lt;p>其中 $\mathcal{X}_t(0, :, :)$ 和 $\mathcal{X}_t(1, :, :)$ 表示流出和流入矩阵。$(x, y) \in r_{ij}$ 表示点 $(x, y)$ 在顶点 $r_{ij}$ 上，$\tau_e \in t$ 表示时间戳 $\tau_e$ 在时段 $t$ 内。流入和流出矩阵在特定时间的矩阵如图2。&lt;/p>
&lt;p>考虑两类流量（流入和流出），一个随时间变化的空间地图一般表示一个时间有序的张量序列，每个张量对应地图在特定时间的一个快照。详细来说，每个张量包含两个矩阵：流入矩阵和流出矩阵，如图 2 所示。&lt;/p>
&lt;p>让 $V$ 表示时空网络中的顶点集，$N \triangleq \vert V \vert = I \times J$ 是顶点数。一个时间图包含 $T$ 个离散的不重叠的时段，表示为有向图 $G_{t_1}, \dots G_{t_T}$ 的时间有序序列。图 $G_t = (V, E_t)$ 捕获了时段 $t$ 时空系统上的拓扑状态。对于每个图 $G_t$ (其中 $t = t_1, \dots, t_T$) 存在一个对应的权重矩阵 $\mathbf{S}_t \in \mathbb{R}^{N \times N}$，表示时段 $t$ 的带权有向边。在我们的研究中，时段 $t$ 顶点 $r_s$ 到顶点 $r_e$ 的边的权重，是一个非负标量，表示 $r_s$ 到 $r_e$ 的 &lt;em>transition&lt;/em>，时段 $t$ 上两个顶点间没有连接的话，对应的元素在 $\mathbf{S}_t$ 中为 0。&lt;/p>
&lt;p>&lt;em>&lt;strong>Definition 3 (Transition).&lt;/strong>&lt;/em> 给定一组起止点对 $\mathbb{P}$。$\mathcal{T} = \lbrace t_1, \dots, t_T \rbrace$ 是一组时段的序列。$\mathbf{S}_t$ 是时段 $t$ 的转移矩阵，$r_s$ 到 $r_e$ 之间的转移表示为 $\mathbf{S}_t(r_s, r_e)$，定义为：&lt;/p>
$$\tag{3}
\mathbf{S}\_t(r\_s, r\_e) = \vert \lbrace (s,e) \in \mathbb{P} : (x\_s, y\_s) \in r\_s \wedge (x\_e, y\_e) \in r\_e \wedge \tau\_s \in t \wedge \tau\_e \in t \rbrace \vert
$$&lt;p>其中 $r_s, r_e \in V$ 是起始顶点和终止顶点。$(x, y) \in r$ 表示点 $(x, y)$ 在网格 $r$ 上。$\tau_s \in t$ 和 $\tau_e \in t$ 表示时间戳 $\tau_s$ 和 $\tau_e$ 都在时段 $t$ 内。我们考虑转移至发生在一个特定的时段内。因此，对于实际应用来说，我们可以预测起始和结束都发生在未来的转移。&lt;/p>
&lt;h2 id="21-converting-time-varying-graphs-into-tensors">2.1 Converting time-varying graphs into tensors
&lt;/h2>&lt;p>我们将每个时间上的图转为张量。给定时间 $t$ 有向图 $G_t = (V, E_t)$，我们先做展开，然后计算有向带权矩阵（转移矩阵 $\mathbf{S}_t$），最后给定一个张量 $\mathcal{M}_t \in \mathbf{R}^{2N \times I \times J}$。图 3 是示意图。(a)给定时间 $t$ 4 个顶点 6 条边的图。(b)首先展开成有向图。(c)对每个顶点，有一个流入的转移，还有个流出的转移，由一个向量表示（维度是8）。取 $r_1$ 为例，它的流出和流入转移向量分别为 $[0, 2, 0, 1]$ 和 $[0, 0, 3, 0]$，拼接后得到一个向量 $[0, 2, 0, 1, 0, 0, 3, 0]$，包含流出和流入的信息。(d)最后，我们将矩阵 reshape 成一个张量，每个顶点根据原来地图有一个固定的空间位置，保护了空间相关性。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;h2 id="22-flow-prediction-problem">2.2 FLow Prediction Problem
&lt;/h2>&lt;p>流量预测，简单来说，是时间序列问题，目标是给定历史 $T$ 个时段的观测值，预测 $T+1$ 时段每个区域的流量。但是我们的文章中流量有两个层次，流入和流出以及区域间的转移流量。我们的目标是同时预测这些流量。此外，我们还融入了外部因素如房价信息，天气状况，温度等等。这些外部因素可以收集并提供一些额外有用的信息。相关的符号在表 1 之中。&lt;/p>
&lt;p>&lt;em>&lt;strong>Problem 1.&lt;/strong>&lt;/em> 给定历史观测值 $\lbrace \mathcal{X}_t, \mathcal{M}_t \mid t = t_1, \dots, t_T \rbrace$，外部特征 $\mathcal{E}_T$，我们提出一个模型共同预测 $\mathcal{X}_{t_{T+1}}$ 和 $\mathcal{M}_{t_{T+1}}$。&lt;/p>
&lt;h1 id="3-multitask-deep-learning">3 Multitask Deep Learning
&lt;/h1>&lt;p>图 4 展示了我们的 MDL 框架，包含 3 个组成部分，分别用于数据转换，顶点流量建模，边流量建模。我们首先将轨迹（或订单）数据转换成两类流量，i) 顶点流量表示成有时间顺序的张量序列 $\lbrace\mathcal{X}_t \mid t = t_1, \dots, t_T \rbrace$ (1a); ii) 边流量是一个有时间顺序的图序列（转移矩阵）$\lbrace\mathbf{S}_t \mid t = t_1, \dots, t_T \rbrace$ (2a)，之后再根据 2.1 节的方法转换为张量的序列 $\lbrace\mathcal{M}_t \mid t = t_1, \dots, t_T \rbrace$ (2b)。这两类像视频一样的数据之后放到 NODENET 和 EDGENET 中。以 NODENET 为例，它选了三个不同类型的片段，放入 3S-FCN 中，对时间相关性建模。在这个模型中，每部分的 FCN 可以通过多重卷积捕获空间相关性。NODENET 和 EDGENET 中间的隐藏表示通过一个 BRIDGE 组件连接，使两个模型可以共同训练。我们使用一个嵌入层来处理转移稀疏的问题。一个门控融合组件用来整合外部信息。顶点流量和边流量用一个正则化来建模。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig4.JPG"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;h2 id="31-edgenet">3.1 EDGENET
&lt;/h2>&lt;p>根据上述的转换方法，每个时段的转移图可以转换成一个张量 $\mathcal{M}_t \in \mathbb{R}^{2N \times I \times J}$。对于每个顶点 $r_{ij}$，它最多有 $2N$ 个转移概率，包含 $N$ 个流入和 $N$ 个流出。然而，对于一个确定的时段，顶点间的转移是稀疏的。受 NLP 的嵌入方法启发，我们提出了使用空间嵌入方法，解决这样的稀疏和高维问题。详细来说，空间嵌入倾向于学习一个将 $2N$ 维映射到 $k$ 维的函数：&lt;/p>
$$\tag{4}
\mathcal{Z}\_t(:, i, j) = \mathbf{W}\_m \mathcal{M}\_t (:, i, j) + \mathbf{b}\_m, 1 \leq i \leq I, 1 \leq j \leq J
$$&lt;p>其中 $\mathbf{W}_m \in \mathbb{R}^{k \times 2N}$ 和 $\mathbf{b}_m \in \mathbb{R}^k$ 是参数。所有的结点共享参数。$\mathcal{M}_t(:, i, j) \in \mathbb{R}^{2N}$ 表示 $(i, j)$ 的向量。&lt;/p>
&lt;p>流量，比如城市中的交通流，总是受时空依赖关系影响。为了捕获不同的时间依赖（近邻、周期、趋势），Zhang et al. 提出了深度时空残差网络，沿时间轴选择不同的关键帧。受这点的启发，我们选择近邻、较近、远期关键帧来预测时段 $t$，分别表示为 $M^{dep}_t = \lbrace M^{close}_t, M^{period}_t, M^{trend}_t \rbrace$，如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Closeness&lt;/strong> dependents:
$$M^{close}\_t = \lbrace \mathcal{Z}\_{t-l\_c}, \dots, \mathcal{Z}\_{t-1} \rbrace$$&lt;/li>
&lt;li>&lt;strong>Period&lt;/strong> dependents:
$$M^{period}\_t = \lbrace \mathcal{Z}\_{t-l\_p}, \mathcal{Z}\_{t-(l\_p - 1) \cdot p}, \dots, \mathcal{Z}\_{t-p} \rbrace$$&lt;/li>
&lt;li>&lt;strong>Trend&lt;/strong> dependents:
$$M^{trend}\_t = \lbrace \mathcal{Z}\_{t-l\_q \cdot q}, \mathcal{Z}\_{t-(l\_q - 1)\cdot q}, \dots, \mathcal{Z}\_{t-q} \rbrace$$&lt;/li>
&lt;/ul>
&lt;p>其中 $p$ 和 $q$ 是周期和趋势范围。$l_c$, $l_p$ 和 $l_q$ 是三个序列的长度。&lt;/p>
&lt;p>输出（即下个时段的预测）和输入有相同的分辨率。这样的人物和图像分割问题很像，可以通过全卷积网络 (FCN) [22] 处理。&lt;/p>
&lt;p>受到这个启发，我们提出了三组件的 FCN，如图 4，来捕获时间近邻、周期和趋势依赖。每个组件都是个 FCN，包含了很多卷积（图 5）。根据卷积的性质，一个卷积层可以捕获空间近邻关系。随着卷积层数的增加，FCN 可以捕获更远的依赖，甚至是城市范围大小的空间依赖。然而，这样的深层卷积网络很难训练。因此我们使用残差连接来帮助训练。类似残差网络中的残差连接，我们使用一个包含 BN，ReLU，卷积的块。令三个近邻、周期、趋势三组件的输出分别为 $\mathcal{M}_c$, $\mathcal{M}_p$, $\mathcal{M}_q$。不同的顶点在近邻、周期、趋势上可能有不同的性质。为了解决这个问题，我们提出使用一个基于参数矩阵的融合方式（图 4 中的 PM 融合）：&lt;/p>
$$\tag{5}
\mathcal{M}\_{fcn} = \mathbf{W}\_c \odot \mathcal{M}\_c + \mathbf{W}\_p \odot \mathcal{M}\_p + \mathbf{W}\_q \odot \mathcal{M}\_q
$$&lt;p>其中 $\odot$ 是哈达玛积，$\mathbf{W}$ 是参数，调整三种时间依赖关系的影响。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig5.JPG"
loading="lazy"
alt="Figure5"
>&lt;/p>
&lt;h2 id="32-nodenet-and-bridge">3.2 NODENET and BRIDGE
&lt;/h2>&lt;p>类似 EDGENET，NODENET 也是一个 3S-GCN，我们选择近邻、较近、遥远的关键帧作为近邻、周期、趋势依赖。区别是 NODENET 没有嵌入层因为输入的通道数只有 2。这三种不同的依赖放入三个不同的 FCN 中，输出通过 PM 融合组件融合（图 4）。然后，得到 3S-FCN 的输出，表示为 $\mathcal{X}_{fcn} \in \mathbb{R}^{C_x \times I \times J}$。&lt;/p>
&lt;p>考虑顶点流量与边流量的相关性，所以从 NODENET 和 EDGENET 学习到的表示应该被连起来。为了连接 NODENET 和 EDGENET，假设 NODENET 和 EDGENET 的隐藏表示分别为 $\mathcal{X}_{fcn}$ 和 $\mathcal{M}_{fcn}$。我们提出两种融合方法：&lt;/p>
&lt;p>&lt;strong>SUM Fusion:&lt;/strong> 加和融合方法直接将两种表示相加：&lt;/p>
$$\tag{6}
\mathcal{H}(c, :, :) = \mathcal{X}\_{fcn}(c, :, :) + \mathcal{M}\_{fcn}(c, :, :), c = 0, \dots, C - 1
$$&lt;p>其中 $C$ 是 $\mathcal{X}_{fcn}$ 和 $\mathcal{M}_{fcn}$ 的通道数，$\mathcal{H} \in \mathbb{R}^{C \times I \times J}$。显然这种融合方法受限于两种表示必须有相同的维度。&lt;/p>
&lt;p>&lt;strong>CONCAT Fusion:&lt;/strong> 为了从上述的限制中解脱，我们提出了另一种融合方法。顺着通道拼接两个隐藏表示：&lt;/p>
$$\tag{7}
\mathcal{H}(c, :, :) = \mathcal{X}\_{fcn}(c, :, :), c=0, \dots, C\_x - 1
$$$$\tag{8}
\mathcal{H}(C\_x + c, :, :) = \mathcal{M}\_{fcn}(c, :, :), c=0, \dots, C\_m - 1
$$&lt;p>$C_x$ 和 $C_m$ 分别是两个隐藏表示的通道数。$\mathcal{H} \in \mathbb{R}^{(C_x + C_m) \times I \times J}$。拼接融合实际上可以通过互相强化更好地融合顶点流量和边流量。像 BRIDGE 一样我们也讨论了其他的融合方式（4.3 节）。&lt;/p>
&lt;p>在拼接融合中，我们在 NODENET 和 EDGENET 中分别加了一层卷积。卷积用来将合并的隐藏特征 $\mathcal{H}$ 映射到 不同通道大小的输出上，即 $\mathcal{X}_{res} \in \mathbb{R}^{2 \times I \times J}$ 和 $\mathcal{M}_{res} \in \mathbb{R}^{2N \times I \times J}$，如图 6。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig6.JPG"
loading="lazy"
alt="Figure6"
>&lt;/p>
&lt;h2 id="33-fusing-external-factors-using-a-gating-mechanism">3.3 Fusing External Factors Using a Gating Mechanism
&lt;/h2>&lt;p>外部因素，活动、天气会影响时空网络不同区域的流量。举个例子，一起事故可能会阻塞一个局部区域的交通，一场暴风雨可能会减少整个城市的流量。这样的外部因素就像一个开关，如果它打开了那流量会产生巨大的变化。基于这个思路，我们开发了一种基于门控机制的融合，如图 6 所示。时间 $t$ 的外部因素表示为 $\mathcal{E}_t \in \mathbb{R}^{l_e \times I \times J}$，$\mathcal{E}_t(:, i, j) \in \mathbb{R}^{l_e}$ 表示一个特定顶点的外部信息。我们可以通过下式获得 EDGENET 的门控值：&lt;/p>
$$\tag{9}
\mathbf{F}\_m(i, j) = \sigma(\mathbf{W}\_e(:, i, j) \cdot \mathcal{E}\_t(:, i, j) + \mathbf{b}\_e(i, j)), 1 \leq i \leq I, 1 \leq j \leq J
$$&lt;p>其中 $\mathbf{W}_e \in \mathbb{R}^{l_e \times I \times J}$ 和 $\mathbf{b}_e \in \mathbb{R}^{I \times J}$ 是参数。$\mathbf{F}_m \in \mathbb{R}^{I \times J}$ 是 GATING 的输出，$\mathbf{F}_m(i, j)$ 是对应时空网络中结点 $r_{ij}$ 的门控值。$\sigma(\cdot)$ 是 sigmoid 激活函数，$\cdot$ 是两向量的内积。&lt;/p>
&lt;p>然后我们使用 PRODUCT 融合方式：&lt;/p>
$$\tag{10}
\hat{\mathcal{M}}\_t(c, :, :) = \text{tanh}(\mathbf{F}\_m \odot \mathcal{M}\_{Res}(c, :, :)), c = 0, \dots, 2N - 1
$$&lt;p>类似的，NODENET 最后在时间 $t$ 的预测结果为：&lt;/p>
$$\tag{11}
\hat{\mathcal{X}}\_t(c, :, :) = \text{tanh} (\mathbf{F}\_x \odot \mathcal{X}\_{Res}(c, :, :)), c = 0, 1
$$&lt;p>其中 $\mathbf{F}_x \in \mathbb{R}^{I \times J}$ 是 GATING 的另一个输出。对于顶点流量和边流量使用不同的门控值的一个原因是外部因素对流入/流出流量和不同地点之间的转移流量的影响是不一致的。&lt;/p>
&lt;h2 id="34-losses">3.4 Losses
&lt;/h2>&lt;p>令 $\phi$ 为 EDGENET 中所有的参数，我们的目标是通过最小化目标函数学习这些参数：&lt;/p>
$$\tag{12}
\mathop{\mathrm{argmin}}\limits\_{\phi} \mathcal{J}\_{edge} = \sum\_{t \in \mathcal{T}}\sum^{2N-1}\_{c=0} \Vert Q^c\_t \odot (\hat{\mathcal{M}}\_t(c, :, :) - \mathcal{M}\_t(c, :, :)) \Vert^2\_F
$$&lt;p>其中 $Q^c_t$ 是指示矩阵，表示 $\mathcal{M}_t(c, :, :)$ 中所有非零元素。$\mathcal{T}$ 是可用的时段，$\Vert \cdot \Vert_F$ 是矩阵的 F 范数。&lt;/p>
&lt;p>类似的，$\theta$ 是 NODENET 的参数，目标函数是：&lt;/p>
$$\tag{13}
\mathop{\mathrm{argmin}}\limits\_{\theta} \mathcal{J}\_{node} = \sum\_{t \in \mathcal{T}}\sum^1\_{c=0} \Vert P^c\_t \odot (\hat{\mathcal{X}}\_t(c, :, :) - \mathcal{X}\_t(c, :, :)) \Vert^2\_F
$$&lt;p>其中 $P^c_t$ 是指示矩阵，表示 $\mathcal{X}_t(c, :, :)$ 中所有非零元素。我们知道对于一个结点来说，它的转入流量之和就是它的流入流量，转出流量之和就是流出流量。定义 2 中定义，$\hat{\mathcal{X}}_t(0, :, :)$ 和 $\hat{\mathcal{X}}_t(1, :, :)$ 分别是流出和流入矩阵。根据 2.1 节定义的方法构建转移矩阵，可知前 $N$ 个通道表示转出流量，后 $N$ 个通道表示转入流量。因此，有下面的损失函数：&lt;/p>
$$\tag{14}
\mathop{\mathrm{argmin}}\limits\_{\theta, \phi} \sum\_{t \in \mathcal{T}} \sum\_i \sum\_j (\Vert \hat{\mathcal{X}}\_t(0, i, j) - \sum^{N-1}\_{c=0} \hat{\mathcal{M}}\_t(c,i,j) \Vert^2 + \Vert \hat{\mathcal{M}}\_t(1,i,j) - \sum^{2N-1}\_{c=N} \hat{\mathcal{M}}\_t(c,i,j) \Vert^2)
$$&lt;p>或者等价的可以写成&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/EQ1.JPG"
loading="lazy"
alt="EQ15"
>&lt;/p>
&lt;p>最后，我们获得融合的损失：&lt;/p>
$$\tag{16}
\mathop{\mathrm{argmin}}\limits\_{\theta, \phi} \lambda\_{node} \mathcal{J}\_{node} + \lambda\_{edge} \mathcal{J}\_{edge} + \lambda\_{mdl} \mathcal{J}\_{mdl}
$$&lt;p>其中，$\lambda_{node}$, $\lambda_{edge}$, $\lambda_{mdl}$ 是可调节的参数。&lt;/p>
&lt;h3 id="341-optimization-algorithm">3.4.1 Optimization Algorithm
&lt;/h3>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Alg1.JPG"
loading="lazy"
alt="Alg1"
>&lt;/p>
&lt;p>算法 1 是 MDL 的训练过程。1-4 行是构建训练样例。7-8 行是用批量样本优化目标函数。&lt;/p>
&lt;h1 id="4-experiments">4 Experiments
&lt;/h1>&lt;p>两个数据集 &lt;strong>TaxiBJ&lt;/strong> 和 &lt;strong>TaxiNYC&lt;/strong>，看表 2。我们使用 RMSE 和 MAE 作为评价指标。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table2.JPG"
loading="lazy"
alt="Table2"
>&lt;/p>
&lt;h2 id="41-settings">4.1 Settings
&lt;/h2>&lt;h3 id="411-datasets">4.1.1 Datasets
&lt;/h3>&lt;p>我们使用表 3 中的两个数据集。每个数据集包含两个子集，轨迹/出行和外部因素，细节如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>TaxiBJ&lt;/strong>: 北京出租车 GPS 轨迹数据有四个时段：20130101-20131030, 20140301-20140630, 20150501-20150630, 201501101-20160410。我们用最后 4 个星期作为测试集，之前的数据作为训练集。&lt;/li>
&lt;li>&lt;strong>TaxiNYC&lt;/strong>: NYC 2011 到 2014 年的出租车订单数据。订单数据包含上车和下车的时间。上车和下车地点。最后四个星期作为测试集。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table3.JPG"
loading="lazy"
alt="Table3"
>&lt;/p>
&lt;h3 id="412-baselines">4.1.2 Baselines
&lt;/h3>&lt;p>HA, ARIMA, SARIMA, VAR, RNN, LSTM. GRU, ST-ANN, ConvLSTM, ST-ResNet, MRF.&lt;/p>
&lt;h3 id="413-preprocessing">4.1.3 Preprocessing
&lt;/h3>&lt;p>MDL 的输出，我们用 $\text{tanh}$ 作为最后的激活函数。我们用最大最小归一化。评估的时候，将预测值转换为原来的值。对于外部因素，使用 one-hot，假期和天气放入二值向量中，用最大最小归一化把温度和风速归一化。&lt;/p>
&lt;h3 id="414-hyperparameters">4.1.4 Hyperparameters
&lt;/h3>&lt;p>$\lambda_{node} = 1$ 和 $\lambda_{edge} = 1$，$\lambda_{mdl} = 0.0005$，$p$ 和 $q$ 按经验设定为一天和一周。三个依赖序列的长度分别为 $l_c \in \lbrace 1, 2, 3\rbrace$, $l_p \in \lbrace 1,2,3 \rbrace$, $l_q \in \lbrace 1,2,3 \rbrace$。卷积的数量是 5 个。训练集的 90% 用来训练，10% 来验证，用早停选最好的参数。然后使用所有的数据训练模型。网络参数通过随机初始化，Adam 优化。batch size 32。学习率 $\lbrace 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005 \rbrace$。&lt;/p>
&lt;h3 id="415-evaluation-metrics">4.1.5 Evaluation Metrics
&lt;/h3>&lt;p>RMSE 和 MAE。&lt;/p>
&lt;h2 id="42-results">4.2 Results
&lt;/h2>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table4.JPG"
loading="lazy"
alt="Table4"
>&lt;/p>
&lt;p>&lt;strong>Node Flow Prediction.&lt;/strong> 我们先比流入和流出流量的预测。表 4 展示了两个数据集上的评价指标结果。MDL 和 MRF 比其他所有的方法多要好。我们的 MDL 在 NYC 的数据集上明显比 MRF 好。BJ 的数据集上，MDL 比 MRF 差不多。原因是 NYC 数据集比 BJ 数据集大了三倍。换句话说，在大的数据集上，我们的方法比 MRF 更好。我们也注意到训练 MRF 很好使，在 BJ 数据集上训练了一个星期。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table5.JPG"
loading="lazy"
alt="Table5"
>&lt;/p>
&lt;p>&lt;strong>Results of Edge Flow Prediction.&lt;/strong> 表6 展示了边流量预测。边流量预测的实验很费时。MDL 比其他的都好。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table6.JPG"
loading="lazy"
alt="Table6"
>&lt;/p>
&lt;h2 id="43-evaluation-on-fusing-mechanisms">4.3 Evaluation on Fusing Mechanisms
&lt;/h2>&lt;p>融合 NODENET 和 EDGENET 有 CONCAT 和 SUM 两种方法。融合外部因素有 GATED 和 SIMPLE 融合，或者不使用。因此总共有 6 种方法。如表 7。使用同样的超参数设定。我们发现 CONCAT + GATING 比其他的方法好。&lt;/p>
&lt;h2 id="44-evaluation-on-model-hyper-parameters">4.4 Evaluation on Model Hyper-parameters
&lt;/h2>&lt;h3 id="441-effect-of-training-data-size">4.4.1 Effect of Training Data Size
&lt;/h3>&lt;p>我们选了 NYC 3 个月，6 个月，1 年，3 年数据。$l_c = 3$, $l_p = 1$, $l_q = 1$。图 8 是结果。我们观察到数据越多，效果越好。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig8.JPG"
loading="lazy"
alt="Figure8"
>&lt;/p>
&lt;h3 id="442-effect-of-network-depth">4.4.2 Effect of Network Depth
&lt;/h3>&lt;p>图 9 展示了网络深度在 NYC 3 个月数据集上的影响。网络越深，RMSE 会下降，因为网络越深越能捕获更大范围的空间依赖。然而，网络更深 RMSE 就会上升，这是因为网络加深后训练会变得困难。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig9.JPG"
loading="lazy"
alt="Figure9"
>&lt;/p>
&lt;h3 id="443-effect-of-multi-task-component">4.4.3 Effect of multi-task component
&lt;/h3>&lt;p>表 8 和图 10 展示了多任务组件的影响。&lt;/p>
&lt;p>我们可以看到转移流量预测任务大多数情况下可以提升，$\lambda_{node} = \lambda_{edge} = 1$，$\lambda_{mdl}=0.1$，我们的模型获得最好的效果，两种任务都获得更好的结果，证明了多任务可以互相提升。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Table8.JPG"
loading="lazy"
alt="Table8"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig10.JPG"
loading="lazy"
alt="Figure10"
>&lt;/p>
&lt;h2 id="45-flow-predictions">4.5 Flow Predictions
&lt;/h2>&lt;p>图 11 描绘了我们的 MDL 在 NYC 上预测两个节点未来一小时的数据。结点 (10, 1)，总是比 (8, 3) 高。我们的模型在预测曲线上更精确。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/Fig11.JPG"
loading="lazy"
alt="Figure11"
>&lt;/p></description></item><item><title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</title><link>https://davidham3.github.io/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/</link><pubDate>Thu, 21 Mar 2019 10:43:34 +0000</pubDate><guid>https://davidham3.github.io/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/</guid><description>&lt;p>AAAI 2019。网格流量预测，两个问题：空间依赖动态性，另一个是周期平移。原文链接：&lt;a class="link" href="http://export.arxiv.org/abs/1803.01254" target="_blank" rel="noopener"
>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>由于大规模的交通数据越来越多，而且交通预测在实际中很重要，交通预测在 AI 领域引起越来越多的关注。举个例子，一个精确的出租车需求预测可以协助出租车公司预分配出租车。交通预测的关键在于如何对复杂的空间依赖和时间动态性建模。尽管两个因素在建模的时候都会考虑，当前的方法仍会做很强的假设，即空间依赖在时间上是平稳的，时间依赖是严格周期的。然而，实际中的空间依赖可能是动态的（即随时间的变化而变化），而且时间动态性可能从一个时段到另一个时段有波动。在这篇文章中，我们有两个重要发现：（1）区域间的空间依赖是动态的；（2）时间依赖虽说有天和周的模式，但因为有动态时间平移，它不是严格周期的。为了解决这两个问题，我们提出了一个新的时空动态网络（STDN），我们用一个门控机制学习区域间的动态相似性，用一个周期性平移的注意力机制来处理长期周期时间平移现象。据我们所知，这是第一个在一个统一的框架中解决这两个问题的工作。我们的实验结果证明了提出的方法是有效的。&lt;/p>
&lt;h1 id="introduction">Introduction
&lt;/h1>&lt;p>交通预测是一个时空预测问题。精确的预测模型对很多应用都很重要。在传统交通预测问题中，给定历史数据（比如一个区域的流量，或一个交叉卡前几个月每小时的流量），预测未来一段时间的数据。这方面的研究已经有几十年了。在时间序列社区，ARIMA 和 Kalman filtering被广泛地应用到这一领域。然而这些早期方法是针对每个区域分别预测，最近的方法考虑了空间信息（比如针对近邻区域增加正则项）和外部因素（如地点信息，天气状况，地区活动）。然而，这些方法仍基于机器学习中的传统时间序列模型，不能很好的捕获复杂的非线性时空依赖）。&lt;/p>
&lt;p>最近，深度学习方法在很多任务上取得了成功。比如，一些研究将城市交通看作是热力图的图片，使用 CNN 对非线性空间关系建模。为了对非线性时间关系建模，人们提出了基于 RNN 的框架。Yao et al。 更是提出了用 CNN 和 LSTM 同时处理时间和空间依赖的框架。&lt;/p>
&lt;p>尽管考虑了同时对时空建模，现存的方法主要有两点不足。首先，区域间的空间依赖依赖于历史数据的相似性，模型学习到了一个静态的空间依赖。然而，区域间的依赖随时间是改变的。举个例子，早上，居民区和商业区之间的依赖关系强；深夜，关系就弱了。然而，这样的动态依赖在之前的研究中没有考虑。&lt;/p>
&lt;p>另一个限制是现存的研究忽略了长期周期依赖。交通数据又很强的日和周周期性，基于这种周期性的依赖关系可能用于预测。然而，一个挑战是交通数据不是严格周期的。举个例子，周末的高峰通常发生在下午的后半段，不同的日子时间不一致，从4:30pm到6:00pm变化。尽管之前的研究考虑了周期性，他们没能考虑序列性的依赖和周期性中的时间平移。&lt;/p>
&lt;p>为了解决前面提出的问题，我们提出了新的深度学习框架，时空动态网络用于交通预测。STDN 是基于时空神经网络的，使用局部 CNN 和 LSTM 分别处理时空信息。一个门控局部 CNN 使用区域间的动态相似性对空间依赖建模。一个周期平移的注意力机制用来学习长期周期依赖。通过注意力机制对长期周期信息和时间平移建模。我们的方法还用 LSTM 以层次的方式处理序列依赖。&lt;/p>
&lt;p>我们再大型的真实数据集上做了评测，纽约出租车数据和纽约的共享单车数据。和 state-of-the-art 的全面对比展示了我们模型的性能。我们的贡献如下：&lt;/p>
&lt;ul>
&lt;li>我们提出了一个流式门控机制对动态空间相似性建模。门控制信息在邻近区域传播。&lt;/li>
&lt;li>我们提出了一个周期平移注意力机制，通过同时时可用长期周期信息和时间平移。&lt;/li>
&lt;li>我们在几个真实数据集上开展了实验，效果好。&lt;/li>
&lt;/ul>
&lt;h1 id="notations-and-problem-formulation">Notations and Problem Formulation
&lt;/h1>&lt;p>我们将整个城市分为 $a \times b$ 个网格，一共 $n$ 个区域（$n = a \times b$），使用 $\lbrace 1,2,\dots,n \rbrace$ 表示他们。我们将整个时间周期分为 $m$ 个登场的连续时段。任何一个个体的移动，其本质上是整个城市交通的一部分，总是从一个区域出发，过一段时间到达目的地。我们在一个时段内给每个区域定义一个开始/结束流量作为区域出发/到达的移动发生次数。$y^s_{i,t}$ 和 $y^e_{i,t}$ 表示开区域 $i$ 在时段 $t$ 的开始/结束流量。此外，对个体旅行的聚合形成交通流，描述了区域对之间的考虑时间的移动。时段 $t$ 从区域 $i$ 开始的交通流在时段 $\tau$ 于区域 $j$ 结束，表示为 $f^{j,\tau}_{i,t}$。显然，交通流反映了区域间的连通性，也反映了个体的移动。图1（c）给出了流量和流动的展示。&lt;/p>
&lt;p>&lt;strong>Problem(Traffic Volume Prediction)&lt;/strong> 给定知道时段 $t$ 的数据，交通流预测问题目标是预测时段 $t+1$ 的起始和结束流量。&lt;/p>
&lt;h1 id="spatial-temporal-dynamic-network">Spatial-Temporal Dynamic Network*
&lt;/h1>&lt;p>这部分，我们讲一下细节。图1是我们模型的架构。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;h2 id="local-spatial-temporal-network">Local Spatial-Temporal Network
&lt;/h2>&lt;p>为了捕获时空序列依赖，在出租车需求预测上，融合局部 CNN 和 LSTM 展示出了非常好的表现。我们这里使用局部 CNN 和 LSTM 处理空间和短期时间依赖。为了手动地提升两种流量的预测（起始和结束），我们将他们集成起来。这部分称为 Local Spatial-Temporal Network (LSTN)。&lt;/p>
&lt;p>&lt;strong>Local spatial dependency&lt;/strong> 卷积神经网络用来捕获空间关系。将整个城市看作一张图片，简单地使用 CNN 不能获得最好的性能。包含了弱关系的区域会导致预测性能下降。因此，我们使用局部 CNN 对空间依赖建模。&lt;/p>
&lt;p>对于每个时段 $t$，我们将目标区域 $i$ 和它周围的邻居看作是 $S \times S$ 大小的图片，两个通道 $\mathbf{Y}_{i,t} \in \mathbb{R}^{S \times S \times 2}$。一个通道包含起始流量信息，另一个是结束流量信息。目标区域在图像的中间。局部 CNN 使用 $\mathbf{Y}_{i,t}$ 作为输入 $\mathbf{Y}^{(0)}_{i,t}$，每个卷积层的定义如下：&lt;/p>
$$\tag{1}
\mathbf{Y}^{(k)}\_{i,t} = \text{ReLU}(\mathbf{W}^{(k)} \ast \mathbf{Y}^{(k-1)}\_{i,t} + \mathbf{b}^{(k)}),
$$&lt;p>其中 $\mathbf{W}^{(k)}$ 和 $\mathbf{b}^{(k)}$ 是参数。堆叠 $K$ 层卷积后，用一个全连接来推测区域 $i$ 的空间表示，记为 $\mathbf{y}_{i,t}$。&lt;/p>
&lt;p>&lt;strong>Short-term Temporal Dependency&lt;/strong> 我们使用 LSTM 捕获空间序列依赖。我们使用原始版本的 LSTM：&lt;/p>
$$\tag{2}
\mathbf{h}\_{i,t} = \text{LSTM}([\mathbf{y}\_{i,t};\mathbf{e}\_{i,t}], \mathbf{h}\_{i,t-1}),
$$&lt;p>其中，$\mathbf{h}_{i,t}$ 是区域 $i$ 在时段 $t$ 的输出表示。$\mathbf{e}_{i,t}$ 表示外部因素。因此，$\mathbf{h}_{i,t}$ 包含空间和短期时间信息。&lt;/p>
&lt;h2 id="spatial-dynamic-similarity-flow-gating-mechanism">Spatial Dynamic Similarity: Flow Gating Mechanism
&lt;/h2>&lt;p>局部 CNN 用于捕获空间依赖。CNN 通过局部连接和权重共享处理局部结构相似性。在局部 CNN 中，局部空间依赖依靠历史交通流量的相似度。然而，流量的空间依赖是平稳的，不能完全地反映目标区域和其邻居间的关系。一个直接的表示区域间关系的方式是交通流。如果两个区域间有很多流量，那么他们之间的关系强烈（也就是他们更相似）。交通流可以用于控制流量信息在区域间的转移。因此，我们设计了一个 Flow Gating Mechanism (FGM)，以层次的方式对动态空间依赖建模。&lt;/p>
&lt;p>类似局部 CNN，我们构建了局部空间流量图来保护流量的空间依赖。一个时段和一个区域相关的流量分两种，流入和流出，两个流量矩阵可以如上构建，每个元素表示对应区域的流入流出流量。图1(c) 给了一个流出矩阵。&lt;/p>
&lt;p>给定一个区域 $i$，我们获得过去 $l$ 个时段的相关的流量（即从 $t-l+1$ 到 $t$）。需要的流量矩阵拼接起来，表示为 $\mathbf{F}_{i,t} \in \mathbb{R}^{S \times S \times 2l}$，$2l$ 是流量矩阵的数量。因为堆叠的流量矩阵包含了过去与区域 $i$ 相关的矩阵，我们使用 CNN 对区域间的空间流量关系建模，将 $\mathbf{F}_{i,t}$ 作为输入 $\mathbf{F}^{(0)}_{i,t}$。对于每层 $k$，公式如下：&lt;/p>
$$\tag{3}
\mathbf{F}^{(k)}\_{i,t} = \text{ReLU}(\mathbf{W}^{(k)}\_f \ast \mathbf{F}^{(k-1)}\_{i,t} + \mathbf{b}^{(k)}\_f),
$$&lt;p>其中 $\mathbf{W}^{(k)}_f$ 和 $\mathbf{b}^{(k)}_f$ 是参数。&lt;/p>
&lt;p>每层，我们使用流量信息对区域间的动态相似性进行捕获，通过一个流量门限制空间信息。特别地，空间表示 $\mathbf{Y}^{i,k}_t$ 作为每层的输出，受流量门调整。我们重写式1为：&lt;/p>
$$\tag{4}
\mathbf{Y}^{(k)}\_{i,t} = \text{ReLU}(\mathbf{W}^{(k)} \ast \mathbf{Y}^{(k-1)}\_{i,t} + \mathbf{b}^{(k)}) \otimes (\mathbf{F}^{i,k-1}\_t),
$$&lt;p>$\otimes$ 是element-wise product。&lt;/p>
&lt;p>$K$ 个门控卷积层后，我们用一个全连接得到流量门控空间表示 $\mathbf{y}_{i,t}$。&lt;/p>
&lt;p>我们将式2中的空间表示 $\mathbf{y}_{i,t}$ 替换为 $\hat{\mathbf{y}}_{i,t}$。&lt;/p>
&lt;h2 id="temporal-dynamic-similarity-periodically-shifted-attention-mechanism">Temporal Dynamic Similarity: Periodically Shifted Attention Mechanism
&lt;/h2>&lt;p>在上面的局部时空网络中，只有前几个时段用于预测。然而，这会忽略长期依赖（周期），但周期在时空预测问题中又很重要。这部分我们考虑长期依赖。&lt;/p>
&lt;p>训练 LSTM 来处理长期信息不是一个简单的任务，因为序列长度的增加导致梯度消失，因此会减弱周期性的影响。为了解决这个问题，预测目标的相对时段（即昨天的这个时候，前天这个时候）应该被建模。然而，单纯地融入相对时段是不充分的，会忽略周期的平移，即交通数据不是严格周期的。举个例子，周末的高峰通常发生在下午的后半段，不同的日子时间不一致，从4:30pm到6:00pm变化。周期的平移在交通序列中很普遍，因为事故或堵塞的发生。图 2a 和 2b 分别是不同的天和周的时间平移的例子。这两个时间序列是从 NYC 的出租车数据中算的从 Javits Center出发的流量。显然，交通序列是周期性的，但是这些序列的峰值（通过红圈标记）在不同的日子里时间不一样。此外，对比两张图，周期性不是严格按日或按周的。因此，我们设计了一个 Periodically Shifted Attention Mechanism (PSAM) 来解决问题。详细的方法如下。&lt;/p>
&lt;p>我们专注于解决日周期的平移问题。如图 1(a) 所示，从前 $P$ 天获得的相对时段用来处理周期依赖。对于每天，为了解决时间平移问题，我们从每天中额外的选择 $Q$ 个时段。举个例子，如果预测的时间是9:00-9:30pm，我们选之前的一个小时和之后的一个小时，即8:00-19:30pm，$\vert Q \vert = 5$。这些时段 $q \in Q$ 用来解决潜在的时间平移问题。此外，我们使用对每天 $p \in P$ 保护每天的序列信息，公式如下：&lt;/p>
$$\tag{5}
\mathbf{h}^{p,q}\_{i,t} = \text{LSTM}([\mathbf{y}^{p,q}\_{i,t}; \mathbf{e}^{p,q}\_{i,t}], \mathbf{h}^{p,q-1}\_{i,t}),
$$&lt;p>其中，$\mathbf{h}^{p,q}_{i,t}$ 是对于区域 $i$ 的预测时间 $t$，时段 $q$ 在前一天 $p$ 的表示。&lt;/p>
&lt;p>我们用了一个注意力机制捕获时间平移并且获得了前几天的每一天的一个表示。前几天每一天的表示 $\mathbf{h}^p_{i,t}$ 是时段 $q$ 每一个选中时间的带权加和，定义为：&lt;/p>
$$\tag{6}
\mathbf{h}^p\_{i,t} = \sum\_{q \in Q} \alpha^{p,q}\_{i,t} \mathbf{h}^{p,q}\_{i,t},
$$&lt;p>权重 $\alpha^{p,q}_{i,t}$ 衡量了在 $p \in P$ 这天时段 $q$ 的重要性。重要值 $\alpha^{p,q}_{i,t}$ 通过对比从短期记忆（式2）得到的时空表示和前一个隐藏状态 $\mathbf{h}^{p,q}_{i,t}$ 得到。权重定义为：&lt;/p>
$$\tag{7}
\alpha^{p,q}\_{i,t} = \frac{\text{exp}(\text{score}(\mathbf{h}^{p,q}\_{i,t}, \mathbf{h}\_{i,t}))} {\sum\_{q \in Q} \text{exp}(\text{score} (\mathbf{h}^{p,q}\_{i,t}, \mathbf{h}\_{i,t})}
$$&lt;p>类似 (Luong, Pham and Manning 2015)，注意力分数的定义可以看作是基于内容的函数：&lt;/p>
$$\tag{8}
\text{score}(\mathbf{h}^{p,q}\_{i,t}, \mathbf{h}\_{i,t}) = \mathbf{v}^\text{T} \text{tanh} (\mathbf{W\_H} \mathbf{h}^{p,q}\_{i,t} + \mathbf{W\_X} \mathbf{h}\_{i,t} + \mathbf{b\_X}),
$$&lt;p>其中，$\mathbf{W_H}, \mathbf{W_X}, \mathbf{b_X}, \mathbf{v}$ 是参数，$\mathbf{v}^\text{T}$ 是转置。对于前面的每一天 $p$，我们得到一个周期表示 $\mathbf{h}^p_{i,t}$。然后我们使用另一个 LSTM 用这些周期表示作为输入，保存序列信息，即&lt;/p>
$$\tag{9}
\hat{\mathbf{h}}^p\_{i,t} = \text{LSTM}(\mathbf{h}^p\_{i,t}, \hat{\mathbf{h}}^{p-1}\_{i,t}).
$$&lt;p>我们将最后一个时段的输出 $\hat{\mathbf{h}}^P_{i,t}$ 看作是时间动态相似度的表示（即长期周期信息）。&lt;/p>
&lt;h2 id="joint-training">Joint Training
&lt;/h2>&lt;p>我们拼接把短期表示 $\mathbf{h}_{i,t}$ 和 长期表示 $\hat{\mathbf{h}}^P_{i,t}$ 拼接得到 $\mathbf{h}^c_{i,t}$，对于预测区域和时间来说既保留了短期依赖又保留了长期依赖。我们将 $\mathbf{h}^c_{i,t}$ 输入到全连接中，获得每个区域 $i$ 流入和流出流量的最终预测值，分别表示为 $y^i_{s,t+1}$ 和 $y^i_{e,t+1}$。最终预测函数定义为：&lt;/p>
$$\tag{10}
[y^i\_{s,t+1}, y^i\_{e,t+1}] = \text{tanh}(\mathbf{W}\_{fa} \mathbf{h}^c\_{i,t} + \mathbf{b}\_{fa}),
$$&lt;p>因为我们做了归一化，所以输出的范围在 $(-1, 1)$，输出值会映射回需求值。&lt;/p>
&lt;p>我们同时预测出发和到达流量，损失函数定义为：&lt;/p>
$$\tag{11}
\mathcal{L} = \sum^n\_{i=1} \lambda (y^s\_{i,t+1} - \hat{y}^s\_{i, t+1})^2 + (1 - \lambda) (y^e\_{i,t+1} - \hat{y}^e\_{i, t+1})^2,
$$&lt;p>$\lambda$ 用来平衡流入和流出的影响。区域 $i$ 在时间 $t+1$ 实际的流入和流出流量表示为 $\hat{y}^s_{i, t+1}, \hat{y}^e_{i, t+1}$。&lt;/p>
&lt;h1 id="experiment">Experiment
&lt;/h1>&lt;h2 id="experiment-settings">Experiment Settings
&lt;/h2>&lt;p>&lt;strong>Datasets&lt;/strong> 我们在两个 NYC 的大型数据集上评价了模型。每个数据集包含旅行记录，详情如下：&lt;/p>
&lt;ul>
&lt;li>NYC-Taxi：2015 年 22349490 个出租车的旅行记录，从 2015年1月1日到2015年3月1日。实验中，我们使用1月1日到2月10日作为训练，剩下20天测试。&lt;/li>
&lt;li>NYC-Bike：2016 年 NYC 自行车轨迹数据，7月1日到8月29日，包含了 2605648 条记录。前 40 天用来训练，后 20 天做测试。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Preprocessing&lt;/strong> 我们将整个城市分成 $10 \times 20$ 个区域。每个区域大小是 $1km \times 1km$。时段长度设为 30min。使用最大最小归一化 volume 和 flow 到 $[0, 1]$。预测后，使用逆变换后的值评价。我们使用滑动窗采样。测试模型的时候，滤掉 volumn 小于 10 的样本，这是工业界和学界常用的技巧 (Yao et al. 2018)。因为真实数据集中，关注较小的交通数据没有太大的意义。我们选择 80% 的数据训练，20% 验证。&lt;/p>
&lt;p>&lt;strong>Evaluation Metric &amp;amp; Baselines&lt;/strong> 两个指标：MAPE, RMSE。baselines：HA, ARIMA, Ridge, Lin-UOTD (Tong el al. 2017), XGBoost, MLP, ConvLSTM, DeepSD, ST-ResNet, DMVST-Net。&lt;/p>
&lt;p>&lt;strong>Hyperparameter Settings&lt;/strong> 我们基于验证集设定超参数。对于空间信息，64 个卷积核，$3 \times 3$ 大小。每个邻居的大小设定为 $7 \times 7$。层数 $K = 3$，对于 flow 考虑的时间跨度 $l = 2$。时间信息，短期 LSTM 长度为 7，长期周期信息 $\vert P \vert = 3$，周期平移注意力机制 $\vert Q \vert = 3$，LSTM 中隐藏表示的维度是 128。STDN 通过 Adam 优化，batch size 64，学习率 0.001。LSTM 中的 dropout 0.5。$\lambda$ 取 0.5。&lt;/p>
&lt;h2 id="results">Results
&lt;/h2>&lt;p>&lt;strong>PerformanceComparison&lt;/strong> 表 1 展示了我们的方法对比其他方法在两个数据集上的结果。我们跑每个 baseline 10次，取了平均和标准差。此外，我们也做了 t 检验。我们的方法在两个数据集上指标都很好。&lt;/p></description></item><item><title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</title><link>https://davidham3.github.io/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/</link><pubDate>Fri, 08 Mar 2019 10:26:16 +0000</pubDate><guid>https://davidham3.github.io/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/</guid><description>&lt;p>AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：&lt;a class="link" href="https://arxiv.org/abs/1610.00081" target="_blank" rel="noopener"
>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>对于交通管理和公共安全来说，预测人流很重要，但这个问题也很有挑战性，因为收到很多复杂的因素影响，如区域内的交通、事件、天气。我们提出了一个基于深度学习的模型 ST-ResNet，对城市内的每个区域的人流的进出一起预测。我们基于时空数据独一的属性，设计了一个端到端的结构。我们使用残差神经网络框架对时间近邻、周期、趋势属性建模。对每个属性，我们设计了残差卷积的一个分支，每个分支对人流的空间属性建模。ST-ResNet 基于数据动态地聚合三个残差神经网络的输出，给不同的分支和区域分配权重。聚合结果还融合了外部因素，像天气或日期。实验在北京和纽约两个数据集上开展。&lt;/p>
&lt;h1 id="introduction">Introduction
&lt;/h1>&lt;p>对于交通管理和公共安全来说，预测人流很重要（Zheng et al. 2014）。举个例子，2015年新年夜，上海有大量人群涌入一个区域，导致 36 人死亡。2016年六月中旬，数百名 Pokemon Go 玩家冲入纽约中央公园，为了抓一只特别稀有的怪，导致严重的踩踏事故。如果可以预测一个区域的人流，这样的悲剧可以通过应急措施避免，像提前做交通管控，发布预警，疏散人群等。&lt;/p>
&lt;p>我们在这篇文章中预测两类人流（Zhang et al. 2016)：如图 1（a）所示，流入和流出。流入是在给定时间段，从其他区域进入到一个区域的交通运载量。流出表示给定时段内，从一个区域向其他区域的交通运载量。两个流量都是区域间的人口流动。了解这个对风险评估和交通管理有很大帮助。流入/流出可以通过行人数量、邻近道路车辆数、公共运输系统的人数、或是所有的都加起来。图 1（b）展示了一个例子。我们可以使用手机信号测量行人数，$r_2$ 的流入和流出分别为 3 和 1。类似地，使用车辆 GPS 轨迹，分别是 0 和 3。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>然而，同时预测城市每个区域人口的流入和流出是很有难度的，有 3 个复杂的因素：&lt;/p>
&lt;ol>
&lt;li>空间依赖。区域 $r_2$ 的流入（图1（a））受邻近区域（像 $r_1$）和遥远区域流出的影响。$r_2$ 的流出也受其他区域（$r_3$）流入的影响。$r_2$ 的流入也影响其自身。&lt;/li>
&lt;li>时间依赖。一个区域的人流受到近期和远期时间影响。举个例子，早上8点发生的交通拥堵可能会影响到 9 点。此外，早高峰的交通状况可能在接连的几天都是相似的，每 24 小时一次。而且随着冬天的到来，早高峰时间可能越来越晚。温度下降，日初变晚会使人们起床时间变晚。&lt;/li>
&lt;li>外部影响。一些像天气和事件的外部因素可能会显著地改变城市内不同区域的人口流动。&lt;/li>
&lt;/ol>
&lt;p>为了解决这些问题，我们提出了一个深度深空残差网络 (ST-ResNet) 对每个区域的流入和流出同时预测。我们的贡献有 4 点：&lt;/p>
&lt;ul>
&lt;li>ST-ResNet 使用基于卷积的残差神经网络对城市内两个邻近的和遥远的区域的空间依赖建模，同时还确信了模型的预测精度不会因为模型的深度增加而降低。&lt;/li>
&lt;li>我们将人口流动的时间属性分为三种，时间近邻、周期、趋势。ST-ResNet 使用三个残差网络对这些属性建模。&lt;/li>
&lt;li>ST-ResNet 动态地聚合三个上述网络的输出，给不同的分支和区域分配权重。聚合还融合了外部因素。&lt;/li>
&lt;li>我们使用北京出租车的轨迹数据和气象数据，纽约自行车轨迹数据。结果表示我们的方法比 6 个 baseline 都好。&lt;/li>
&lt;/ul>
&lt;h1 id="preliminaries">Preliminaries
&lt;/h1>&lt;p>简要回顾人流预测问题（Zhang el al. 2016; Hoang, Zheng, and Singh 2016），介绍残差学习（He et al. 2016）。&lt;/p>
&lt;h2 id="formulation-of-crowd-flows-problem">Formulation of Crowd Flows Problem
&lt;/h2>&lt;p>&lt;strong>Definition 1(Region (Zhang et al. 2016))&lt;/strong> 根据不同粒度级和语义，一个地点的定义有很多。我们根据经纬度将城市划分成 $I \times J$ 个网格，一个网格表示一个区域，如图 2(a)。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>**Definition 2(Inflow/outflow (Zhang et al. 2016)) $\mathbb{P}$ 是第 t 时段的轨迹集合。对于第 $i$ 行第 $j$ 列的网格，时段 $t$ 流入和流出的人流分别定义为：&lt;/p>
$$
x^{in,i,j}\_t = \sum\_{T\_r \in \mathbb{P}} \vert \lbrace k > 1 \mid g\_{k-1} \not \in (i, j) \wedge g\_k \in (i,j) \rbrace \vert
\\
x^{out,i,j}\_t = \sum\_{T\_r \in \mathbb{P}} \vert \lbrace k \geq 1 \mid g\_k \in (i,j) \wedge g\_{k+1} \not \in (i,j) \rbrace \vert
$$&lt;p>其中 $T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的轨迹，$g_k$ 是地理坐标；$g_k \in (i,j)$ 表示点 $g_k$ 落在 $(i, j)$ 内；$\vert · \vert$ 表示集合基数。&lt;/p>
&lt;p>时段 $t$ ，所有区域的流入和流出可以表示成 $\mathbf{X}_t \in \mathbb{R}^{2 \times I \times J}$，$(\mathbf{X}_t)_{0,i,j}=x^{in,i,j}_t, (\mathbf{X}_t)_{1,i,j} = x^{out,i,j}_t$。流入矩阵如图2(b)。&lt;/p>
&lt;p>空间区域可以表达成一个 $I \times J$ 的区域，有两类流动，所以观测值可以表示为 $\mathbf{X} \in \mathbb{R}^{2 \times I \times J}$。&lt;/p>
&lt;p>&lt;strong>Problem 1&lt;/strong> 给定历史观测值 $\lbrace \mathbf{X}_t \mid t = 0,\dots,n-1 \rbrace$，预测 $\mathbf{X}_n$。&lt;/p>
&lt;h2 id="deep-residual-learning">Deep Residual Learning
&lt;/h2>$$\tag{1}
\mathbf{X}^{(l+1)} = \mathbf{X}^{(l)} + \mathcal{F}(\mathbf{X}^{(l)})
$$&lt;h1 id="deep-spatio-temporal-residual-networks">Deep Spatio-Temporal Residual Networks
&lt;/h1>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>图 3 展示了 ST-ResNet的架构，4 个部分分别对时间近邻、周期、远期、外部因素建模。如图 3 所示，首先将流入和流出作为两个通道放到矩阵中，使用定义 1 和 2 引入的方法。我们将时间轴分为三个部分，表示近期时间、邻近历史、远期历史。三个时段的两通道的流动矩阵分别输入上述模型，对三种时间属性建模。这三个组件结构相同，都是残差网络。这样的结构捕获邻近和遥远区域间的空间依赖。外部组件中，我们手动的从数据集中提取了特征，如天气、事件等，放入两层全连接神经网络中。前三个组件的输出基于参数矩阵融合为 $\mathbf{X}_{Res}$，参数矩阵给不同的区域不同的组件分配权重。$\mathbf{X}_{Res}$ 然后与外部组件 $\mathbf{X}_{Ext}$ 集成。最后，聚合结果通过 Tanh 映射到 $[-1, 1]$，在反向传播会比 logistic function 收敛的更快 (LeCun et al. 2012)。&lt;/p>
&lt;h2 id="structures-of-the-first-three-components">Structures of the First Three Components
&lt;/h2>&lt;p>如图 4。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig4.JPG"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;p>&lt;em>&lt;strong>Convolution&lt;/strong>&lt;/em> 一个城市通常很大，包含很多距离不同的区域。直观上来说，邻近区域的人流会影响其他区域，可以通过 CNN 有效地处理，CNN 也被证明在层级地捕获空间信息方面很强 (LeCun et al. 1998)。而且，如果两个遥远地方通过地铁或高速公路连接，那么这两个区域间就有依赖关系。为了捕获任何区域的空间依赖，我们需要设计一个很多层的 CNN 模型，因为一个卷积层只考虑空间近邻，受限于它卷积核的大小。同样的问题在视频序列生成任务中也有，当输入和输出有同样的分辨率的时候(Mathieu, Couprie, and LeCun 2015)。为了避免下采样导致的分辨率损失引入了几种方法，同时还保持遥远的依赖关系(Long, Shelhamer, and Darrell 2015)。与传统的 CNN 不同的是，我们没有使用下采样，而是只使用卷积 (Jain et al. 2007)。如图 4(a)，图中有 3 个多级的 feature map，通过一些卷积操作相连。一个高层次的结点依赖于 9 个中间层次的结点，这些又依赖于低层次的所有结点。这意味着一个卷积可以很自然地捕获空间近邻依赖，堆叠卷积可以更多地捕获遥远的空间依赖。&lt;/p>
&lt;p>图 3 的近邻组件使用了一些 2 通道流动矩阵对近邻时间依赖建模。令最近的部分为 $[\mathbf{X}_{t-l_c}, \mathbf{X}_{t-(l_c-1)}, \dots, \mathbf{X}_{t-1}]$，也称为近邻依赖序列。我们将他们沿第一个轴（时间）拼接，得到一个张量 $\mathbf{X}^{(0)}_c \in \mathbb{R}^{2l_c \times I \times J}$，然后使用卷积（图 3 中的 Conv1）：&lt;/p>
$$\tag{2}
\mathbf{X}^{(1)}\_c = f(W^{(1)}\_c \ast \mathbf{X}^{(0)}\_c + b^{(1)}\_c)
$$&lt;p>其中 $\ast$ 表示卷积；$f$ 是激活函数；$W^{(1)}_c, b^{(1)}_c$ 是参数。&lt;/p>
&lt;p>&lt;em>&lt;strong>Residual Unit.&lt;/strong>&lt;/em> 尽管有 ReLU 职业那个的激活函数和正则化技巧，深度卷积网络在训练上还是很难。但我们仍然需要深度神经网络捕获非常大范围的依赖。对于典型的流量数据，假设输入大小是 $32 \times 32$，卷积核大小是 $3 \times 3$，如果我们想对城市范围的依赖建模，至少需要连续 15 个卷积层。为了解决这个问题，我们使用残差学习(He et al. 2015)，在训练超过 1000 层的网络时很有效。&lt;/p>
&lt;p>在我们的 ST-ResNet(如图 3)，我们在 Conv1 上堆叠 $L$ 个残差单元如下：&lt;/p>
$$\tag{3}
\mathbf{X}^{(l+1)}\_c = \mathbf{X}^{(l)}\_c + \mathcal{F}(\mathbf{X}^{(l)}\_c; \theta^{(l)}\_c), l = 1, \dots, L
$$&lt;p>$\mathcal{F}$ 是残差函数，即 ReLU + Convolution，如图 4(b)。我们还在 ReLU 之前加了 &lt;em>Batch Normalization&lt;/em>。在第 $L$ 个残差单元前，我们使用了一个卷积层，图 3 中的 Conv2。2 个卷积和 $L$ 个残差单元，图 3 中的近邻组件的输出是 $\mathbf{X}^{(l+2)}_c$。&lt;/p>
&lt;p>同样的，使用上面的操作，我们可以构建 &lt;em>周期&lt;/em> 和 &lt;em>趋势&lt;/em> 组件，如图 3。假设时段 $p$ 有 $l_p$ 个时间间隔。那么 &lt;em>时段&lt;/em> 依赖序列是 $[\mathbf{X}_{t-l_p \cdot p}, \mathbf{X}_{t-(l_p - 1) \cdot p}, \dots, \mathbf{X}_{t-p}]$。使用式 2 和 式 3 那样的卷积和 $L$ 个残差单元，&lt;em>周期&lt;/em> 组件的输出是 $\mathbf{X}^{(L + 2)}_p$。同时，&lt;em>趋势&lt;/em> 组件的输出是 $\mathbf{X}^{(L+2)}_q$，输入是 $[\mathbf{X}_{t-l_q \cdot q}, \mathbf{X}_{t-(l_q - 1) \cdot q}, \dots, \mathbf{X}_{t-q}]$，$l_q$ 是&lt;em>趋势&lt;/em>依赖序列的长度，$q$ 是趋势跨度。需要注意的是 $p$ 和 $q$ 是两个不同类型的周期。在实际的实现中，$p$ 等于一天，描述的是日周期，$q$ 是一周，表示周级别的趋势。&lt;/p>
&lt;h2 id="the-structure-of-the-external-component">The Structure of the External Component
&lt;/h2>&lt;p>交通流会被很多复杂的外部因素所影响，如天气或事件。图 5(a) 表示假期（春节）时的人流和平时的人流很不一样。图 5(b) 表示相比上周的同一天，突然而来的大雨会减少此时办公区域的人流。令 $E_t$ 为特征向量，表示预测的时段 $t$ 的外部因素。我们的实现中，我们主要考虑天气、假期事件、元数据（工作日、周末）。详细情况见表 1。为了预测时段 $t$ 的交通流，假期事件和元数据可以直接获得。然而，未来时段 $t$ 的天气预报不知道。可以使用时段 $t$ 的天气预报，或是 $t-1$ 时段的天气来近似。我们在 $E_t$ 上堆叠两个全连接层，第一层可以看作是每个子因素的嵌入层。第二层用来从低维映射到和 $\mathbf{X}_t$ 一样的高维上。图 3 中外部组件的输出表示为 $\mathbf{X}_{Ext}$，参数是$\theta_{Ext}$。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig5.JPG"
loading="lazy"
alt="Figure5"
>&lt;/p>
&lt;h2 id="fusion">Fusion
&lt;/h2>&lt;p>我们先用一个参数矩阵融合前三个组件，然后融合外部组件。&lt;/p>
&lt;p>图6(a)和(d)展示了表1展示的北京轨迹数据的比例曲线，x轴是两个时段的时间差，y轴是任意两个有相同时间差的流入的平均比例。两个不同区域的曲线在时间序列上表现出了时间联系，也就是近期的流入比远期的流入更相关，表现出了事件近邻性。两条曲线有两个不同的形状，表现出不同区域可能有不同性质的近邻性。图6(b)和(e)描绘了7天所有时段的流入。我们可以观察到两个区域明显的日周期性。在办公区域，工作日的峰值比周末的高很多。住宅区在工作日和周末有相似的峰值。图6(c)和(f)描述了2015年3月到2015年6月一个特定时段(9:00pm-9:30pm)的流入。随着时间的推移，办公区域的流入逐渐减少，住宅区逐渐增加。不同的区域表现出了不同的趋势。总的来说，两个区域的流入受到近邻、周期、趋势三部分影响，但是影响程度是不同的。我们也发现其他区域也有同样的性质。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig6.JPG"
loading="lazy"
alt="Figure6"
>&lt;/p>
&lt;p>综上，不同区域受近邻、周期、趋势的影响，但是影响程度不同。受这些观察的启发，我们提出了一个基于矩阵参数的融合方法。&lt;/p>
&lt;p>&lt;em>&lt;strong>Parametric-matrix-based fusion.&lt;/strong>&lt;/em> 我们融合图 3 中前三个组件：&lt;/p>
$$\tag{4}
\mathbf{X}\_{Res} = \mathbf{W}\_c \odot \mathbf{X}^{(L+2)}\_c + \mathbf{W}\_p \odot \mathbf{X}^{(L+2)}\_p + \mathbf{W}\_q \odot \mathbf{X}^{(L+2)}\_q
$$&lt;p>$\odot$ 是哈达玛乘积，$\mathbf{W}$ 是参数，分别调整三个组件的影响程度。&lt;/p>
&lt;p>&lt;em>&lt;strong>Fusing the external component.&lt;/strong>&lt;/em> 我们直接地将前三个组件的输出和外部组件融合，如图3。最后，时段 $t$ 的预测值，表示为 $\hat{\mathbf{X}}_t$ 定义为：&lt;/p>
$$\tag{5}
\hat{\mathbf{X}}\_t = \mathrm{tanh}(\mathbf{X}\_{Res} + \mathbf{X}\_{Ext})
$$&lt;p>我们的 ST-ResNet 可以从三个流动与朕和外部因素特征通过最下滑 MSE 来训练：&lt;/p>
$$\tag{6}
\mathcal{L}(\theta) = \Vert \mathbf{X}\_t - \hat{\mathbf{X}}\_t \Vert^2\_2
$$&lt;h2 id="algorithm-and-optimization">Algorithm and Optimization
&lt;/h2>&lt;p>算法1描述了 ST-ResNet 的训练过程。首先从原始序列构造训练实例。然后通过反向传播，用 Adam 算法训练。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Alg1.JPG"
loading="lazy"
alt="Algorithm1"
>&lt;/p>
&lt;h1 id="experiments">Experiments
&lt;/h1>&lt;h2 id="settings">Settings
&lt;/h2>&lt;p>&lt;strong>Datasets.&lt;/strong> 我们使用表 1 中展示的两个数据集。每个数据集都包含两个子集，轨迹和天气。&lt;/p>
&lt;ul>
&lt;li>TaxiBJ: 轨迹数据是出租车 GPS 数据和北京的气象数据，2013年7月1日到10月30日，2014年5月1日到6月30日，2015年5月1日到6月30日，2015年11月1日到2016年4月1日。使用定义2，我们获得两类人流。我们选择最后四周作为测试集，之前的都为训练集。&lt;/li>
&lt;li>BikeNYC: 轨迹数据是2014年NYC Bike系统中取的，从4月1日到9月30日。旅行数据包含：持续时间、起点终点站点ID，起始终止时间。在数据中，最后10天选做测试集，其他选做训练集。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;p>&lt;strong>Baselines.&lt;/strong> 我们对比了6个baselines：HA, ARIMA, SARIMA, VAR, ST-ANN, DeepST.&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table2.JPG"
loading="lazy"
alt="Table2"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table3.JPG"
loading="lazy"
alt="Table3"
>&lt;/p></description></item><item><title>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</title><link>https://davidham3.github.io/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/</link><pubDate>Thu, 07 Mar 2019 09:03:16 +0000</pubDate><guid>https://davidham3.github.io/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/</guid><description>&lt;p>T-GCN，arxiv上面的一篇文章，用 GCN 对空间建模，GRU 对时间建模，很简单的模型。没有对比近几年的图卷积在时空数据挖掘中的模型。原文地址：&lt;a class="link" href="https://arxiv.org/abs/1811.05320" target="_blank" rel="noopener"
>T-GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>精确和实时的交通预测在智能交通系统中扮演着重要的角色，对城市交通规划、交通管理、交通控制起着重要的作用。然而，交通预测由于其受限于城市路网且随时间动态变化，即有着空间依赖与时间依赖，早已成为一个公开的科学研究问题。为了同时捕获空间和时间依赖，我们提出了一个新的神经网络方法，时间图卷积网络模型 （T-GCN），将图卷积和门控循环单元融合起来。GCN 用来学习复杂的拓扑结构来捕获空间依赖，门控循环单元学习交通数据的动态变化来捕获时间依赖。实验表明我们的 T-GCN 模型比之前的方法要好。我们的 tf 实现：&lt;a class="link" href="https://github.com/lehaifeng/T-GCN" target="_blank" rel="noopener"
>代码仓库地址&lt;/a>。&lt;/p>
&lt;h1 id="1-introduction">1 Introduction
&lt;/h1>&lt;p>随着智能交通系统的发展，交通预测受到了越来越多的关注。交通预测是高级交通管理系统中的关键部分，是实现交通规划、交通管理、交通控制的重要部分。交通预测是分析城市路网上交通状况、包括流量、车速、密度，挖掘交通模式，对路网上交通进行预测的一个过程。交通预测不仅能给管理者提供科学依据来预测交通拥挤并提前限制出行，还可以给旅客提供适当的出行路线并提高交通效率。然而，交通由于其空间和时间的依赖至今还是一个有难度的挑战：&lt;/p>
&lt;p>（1）空间依赖。流量的改变主要受路网的拓扑结构控制。上游道路的交通状态通过转移影响下游的道路，下游的交通状态会通过反馈影响上游的状态。如图 1 所示，由于邻近道路的强烈影响，短期相似性从状态 1 （上游与中游相似）转移到 状态 2（上游与下游相似）。&lt;/p>
&lt;p>（2）时间依赖。流量随时间动态改变，主要会出现周期性和趋势。如图 2（a）所示，路 1 的流量在一周内展示出了周期性变化。图 2（b）中，一天的流量也发生变换；举个例子，流量会被其前一时刻或更前的时刻的交通状况所影响。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig1.JPG"
loading="lazy"
alt="Figure1"
>
&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig2.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>有很多交通预测方法，一些考虑时间依赖，包括 ARIMA，Kalman filtering model, SVR, knn, Beyesian model, partial neural network model.上述方法考虑交通状况在时间上的动态变化，忽略了空间依赖，导致不能精确预测。为了更好地刻画空间特征，一些研究引入了卷积神经网络对空间建模；然而，卷积适用于欧氏空间的数据，如图像、网格等。这样的模型不能在城市路网这样有着复杂拓扑结构的环境下工作，所以他们不能描述空间依赖。&lt;/p>
&lt;p>为了解决这个问题，我们提出了新的交通预测方法，时间图卷积网络 （T-GCN），用于对基于城市路网的交通预测任务。我们的贡献有三点：&lt;/p>
&lt;p>（1） 我们提出的模型结合了 GCN 和 GRU，图卷积捕获路网的拓扑结构做空间建模，GRU 捕获路网上交通数据的时间依赖。T-GCN 模型可以用于其他时空预测任务上。&lt;/p>
&lt;p>（2） T-GCN 的预测结果比其他的方法好，表明我们的 T-GCN 模型不仅可以做短期预测，也可以做长期预测。&lt;/p>
&lt;p>（3）我们使用深圳市罗湖区的出租车速度数据和洛杉矶线圈数据。结果表明我们的预测误差比所有的 baseline 小了 1.5%到57.8%，表明 T-GCN 在交通预测上的优越性。&lt;/p>
&lt;h1 id="2-related-work">2 Related work
&lt;/h1>&lt;p>智能交通系统交通预测是现在的一个重要研究问题。现存的方法分两类：模型驱动的方法和数据驱动的方法。首先，模型驱动的方法主要解释交通流量、速度、密度的瞬时性和平稳性。这样的方法需要基于先验知识的系统建模。代表方法包括排队论模型，细胞传递模型，交通速度模型，microscopic fundamental diagram model 等等。实际中，交通数据受多种因素影响，很难获得一个精准的交通模型。现存的模型不能精确地描述复杂的现实环境中的交通数据的变化。此外，这些模型的构建需要很强的计算能力，而且很容易收到交通扰乱和采样点空间等问题的影响。&lt;/p>
&lt;p>数据驱动的方法基于数据的规律性，从统计学推测变化局势，然后用于预测。这类方法不分析物理性质和交通系统的动态行为，有很高的灵活性。早期的方法包括历史均值模型，使用历史周期的交通流量均值作为预测值。这个方法不需要假设，计算简单而且还快，但是不能有效地拟合时间特征，预测的精准度低。随着研究的深入，很多高精度的方法涌现出来，主要分为参数模型和非参数模型。&lt;/p>
&lt;p>参数模型提前假设回归函数，参数通过对原始数据处理得到，基于回归函数对交通流预测。时间序列模型，线性回归模型，Kalman filtering model 是常用的方法。时间序列模型将观测到的时间序列拟合进一个模型，然后用来预测。早在 1976 年，Box and Jenkins 提出了 ARIMA，Hamed 等人使用 ARIMA 预测城市内的交通流量。为了提高模型的精度，不同的变体相继被提出，Kohonen ARIMA，subset ARIMA，seasonal ARIMA 等等。Lippi 等人对比支持向量回归和 seasonal ARIM，发现 SARIMA 模型在交通拥堵上的预测有更好的结果。线性回归模型基于历史数据构建模型来预测。2004 年，Sun 等人使用 local linear model 解决了区间预测，在真实数据集上获得了较好的效果。Kalman filtering model 基于前一时刻和当前时刻的交通状态预测未来的状态。1984 年，Okutani 等人使用 Kalman filtering 理论建立了交通流状态预测模型。后续，一些研究使用 Kalman filtering 模型解决交通预测任务。&lt;/p>
&lt;p>传统的参数模型算法简单，计算方便。然而，这些方法依赖平稳假设，不能反映交通数据的非线性和不确定性，也不能克服交通事件这种随机性事件。非参数模型很好地解决这些问题，只需要足够的历史信息能自动地从中学到统计规律即可。常见的非参数模型包括：k近邻，支持向量回归，Fuzzy Logic 模型等。&lt;/p>
&lt;p>近些年，随着深度学习的快速发展，深度神经网络可以捕获交通数据的动态特征，获得很好的效果。根据是否考虑空间依赖，模型可以划分成两类。一些方法只考虑时间依赖，如 Park 等人使用 FNN 预测交通流。Huang 等人使用深度置信网络 DBN 和回归模型在多个数据集上证明可以捕获交通数据中的随机特征，提升预测精度。此外，RNN 及其变体 LSTM, GRU 可以有效地使用自循环机制，他们可以很好地学习到时间依赖并获得更好的预测结果。&lt;/p>
&lt;p>这些模型考虑时间特征但是忽略空间依赖，所以交通数据的变化不受城市路网的限制，因此他们不能精确的预测路上的交通状态。解决交通预测问题的关键是充分利用空间和时间依赖。为了更好的刻画空间特征，很多研究已经在这个基础上进行了提升。Lv 等人提出了一个 SAE 模型从交通数据中捕获时空特征，实现短期交通流的预测。Zhang 等人提出了一个叫 ST-ResNet 的模型，基于人口流动的时间近邻、周期和趋势这些特征设计了残差卷积网络，然后三个网络和外部因素动态地聚合起来，预测城市内每个区域人口的流入和流出。Wu 等人设计了一个特征融合架构通过融合 CNN 和 LSTM 进行短期预测。一个一维的 CNN 用于捕获空间依赖，两个 LSTM 用来挖掘交通流的短期变化和周期性。Cao 等人提出一个叫 ITRCN 的端到端模型，将交互的网络交通转换为图像，使用 CNN 捕获交通的交互式功能，用 GRU 提取时间特征，预测误差比 GRU 和 CNN 分别高了 14.3% 和 13.0%。Ke 等人提出一个新的深度学习方法叫融合卷积长短时记忆网络（FCL-Net），考虑空间依赖、时间依赖，以及异质依赖，用于短期乘客需求预测。Yu 等人用深度卷积神经网络捕获空间依赖，用 LSTM 捕获时间动态性，在北京交通网络数据上展示出了 SRCN 的优越性。&lt;/p>
&lt;p>尽管上述方法引入了 CNN 对空间依赖建模，在交通预测任务上有很大的进步，但 CNN 本质上只适用于欧氏空间，在有着复杂拓扑结构的交通网络上不能刻画空间依赖。因此，这类方法有缺陷。近些年，图卷积网络的发展，可以用来捕获图网络的结构特征，提供更好的解决方案。Li 等人提出了 DCRNN 模型，通过图上的随机游走捕获空间特征，通过编码解码结构捕获时间特征。&lt;/p>
&lt;p>基于这个背景，我们提出了新的神经网络方法捕获复杂的时空特征，可以用于基于城市路网的交通预测任务上。&lt;/p>
&lt;h1 id="3-methodology">3 Methodology
&lt;/h1>&lt;h2 id="31-problem-definition">3.1 Problem Definition
&lt;/h2>&lt;p>目标是基于历史信息预测未来。我们的方法中，交通信息是一个通用的概念，可以是速度、流量、密度。我们在实验的时候将交通信息看作是速度。&lt;/p>
&lt;p>定义1：路网 $G$。我们用图 $G = (V, E)$ 描述路网的拓扑结构，每条路是一个顶点，$V$ 顶点集，$V = \lbrace v_1, v_2, \dots, v_N \rbrace$，$N$ 是顶点数，$E$ 是边集。邻接矩阵 $A$ 表示路的关系，$A \in R^{N \times N}$。邻接矩阵只有 0 和 1。如果路之间有连接就为 1， 否则为 0。&lt;/p>
&lt;p>定义2：特征矩阵 $X^{N \times P}$。我们将交通信息看作是顶点的特征。$P$ 表示特征数，$X_t \in R^{N \times i}$ 用来表示时刻 $i$ 每条路上的速度。&lt;/p>
&lt;p>时空交通预测的问题可以看作学习一个映射函数：&lt;/p>
$$\tag{1}
[X\_{t+1}, \dots, X\_{t+T}] = f(G; (X\_{t-n}, \dots, X\_{t-1}, X\_t))
$$&lt;p>$n$ 是历史时间序列的长度，$T$ 是需要预测的长度。&lt;/p>
&lt;h2 id="32-overview">3.2 Overview
&lt;/h2>&lt;p>T-GCN 模型有两个部分：GCN 和 GRU。图 3 所示，我们使用历史 $n$ 个时刻的时间序列数据作为输入，图卷积网络捕获路网拓扑结构获取空间依赖。然后将带有空间特征的时间序列放入 GRU 中，通过信息在单元间的传递捕获动态变化，获得时间特征。最后，将结果送入全连接层。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;h2 id="33-methodology">3.3 Methodology
&lt;/h2>&lt;h3 id="331-spatial-dependence-modeling">3.3.1 Spatial Dependence Modeling
&lt;/h3>&lt;p>获取复杂的空间依赖在交通预测中是一个关键问题。传统的 CNN 只能用于欧氏空间。城市路网不是网格，CNN 不能反映复杂的拓扑结构。GCN 可以处理图结构，已经广泛应用到文档分类、半监督学习、图像分类中。GCN 在傅里叶域中构建滤波器，作用在顶点及其一阶邻居上，捕获顶点间的空间特征，可以通过堆叠构建 GCN 模型。如图 4 所示，假设顶点 1 是中心道路，GCN 模型可以获取中心道路和它周围道路的拓扑关系，将这个结构和道路属性编码，获得空间依赖。总之，我们用 GCN 模型从交通数据中学习空间特征。两层 GCN 表示为：&lt;/p>
$$\tag{2}
f(X, A) = \sigma(\hat{A} Relu(\hat{A} X W\_0) W\_1)
$$&lt;p>$\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$ 表示预处理，$\tilde{A} = A + I_N$ 表示加了自连接的邻接矩阵。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig4.JPG"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;h3 id="332-temporal-dependence-modeling">3.3.2 Temporal Dependence Modeling
&lt;/h3>&lt;p>因为 GRU 比 LSTM 参数少，训练快，我们使用 GRU 获取交通数据的时间依赖。如图 5 所示，$h_{t-1}$ 表示时刻 $t-1$ 的隐藏状态；$x_t$ 表示时刻 $t$ 的交通信息；$r_t$ 表示重置门，用来控制忽略前一时刻信息的程度；$u_t$ 是更新门，用来控制将信息从上一时刻拿到这个时刻的程度；$c_t$ 是时刻 $t$ 的记忆内容；$h_t$ 是时刻 $t$ 的输出状态。GRU 通过将时刻 $t-1$ 的隐藏状态和当前时刻的交通信息作为输入，获取时刻 $t$ 的交通状态。在捕获当前时刻的交通信息的时候，模型仍保留着历史信息，且有能力捕获时间依赖。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig5.JPG"
loading="lazy"
alt="Figure5"
>&lt;/p>
&lt;h3 id="333-temporal-graph-convolutional-network">3.3.3 Temporal Graph Convolutional Network
&lt;/h3>&lt;p>为了同时从交通数据中捕获时空依赖，我们提出了时间图卷极网络（T-GCN）。如图6所示，左侧是时空交通预测的过程，右侧是一个 T-GCN 细胞的结构，$h_{t-1}$ 表示 $t-1$ 时刻的输出，GC 是图卷积过程，$u_t, r_t$ 是时刻 $t$ 的更新门和重置门，$h_t$ 表示时刻 $t$ 的输出。计算过程如下。$f(A, X_t)$ 表示图卷积过程，如式 2 定义。$W$ 和 $b$ 表示训练过程的权重与偏置。&lt;/p>
$$\tag{3}
u\_t = \sigma(W\_u[f(A, X\_t), h\_{t-1}] + b\_u)
$$$$\tag{4}
r\_t = \sigma(W\_r[f(A, X\_t), h\_{t-1}] + b\_r)
$$$$\tag{5}
c\_t = tanh(W\_c[f(A, X\_t), (r\_t \ast h\_{t-1})] + b\_c)
$$$$\tag{6}
h\_t = u\_t \ast h\_{t-1} + (1 - u\_t) \ast c\_t
$$&lt;p>总之，T-GCN 能处理复杂的空间依赖和时间动态性。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig6.JPG"
loading="lazy"
alt="Figure6"
>&lt;/p>
&lt;h3 id="334-loss-function">3.3.4 Loss Function
&lt;/h3>&lt;p>损失函数如式 7。第一项用来减小速度的误差。第二项 $L_{reg}$ 是一个 $L2$ 正则项，避免过拟合，$\lambda$ 是超参。&lt;/p>
$$\tag{7}
loss = \Vert Y\_t - \hat{Y}\_t \Vert + \lambda L\_{reg}
$$&lt;h1 id="4-experiments">4 Experiments
&lt;/h1>&lt;h2 id="41-data-description">4.1 Data Description
&lt;/h2>&lt;p>两个数据集，深圳出租车和洛杉矶线圈。两个数据集都和车速有关。&lt;/p>
&lt;p>（1）SZ-taxi。数据是2015年1月1日到1月31日的深圳出租车轨迹数据。我们选了罗湖区 156 个主要路段作为研究区域。实验数据主要有两部分。一个是 156 * 156 的邻接矩阵，另一个是特征矩阵，描述了速度随时间的变化。我们将速度以 15 分钟为单位聚合。&lt;/p>
&lt;p>（2）Los-loop。数据集是洛杉矶县高速公路线圈的实时数据。我们选了 207 个监测器，数据是 2012年5月1日到5月7日的数据。我们以5分钟为单位聚合车速。数据也是一个邻接矩阵和一个特征矩阵。我们用线性插值填补了缺失值。&lt;/p>
&lt;p>我们将输入数据归一化到 $[0, 1]$。此外，80% 的数据用来训练，20% 用来测试。我们预测未来15、30、45、60分钟的车速。&lt;/p>
&lt;h2 id="42-evaluation-metrics">4.2 Evaluation Metrics
&lt;/h2>&lt;p>（1）RMSE:&lt;/p>
$$\tag{8}
RMSE = \sqrt{\frac{1}{n} \sum^n\_{i=1} (Y\_t - \hat{Y}\_t)^2}
$$&lt;p>（2）MAE:&lt;/p>
$$\tag{9}
MAE = \frac{1}{n} \sum^n\_{i=1} \vert Y\_t - \hat{Y}\_t \vert
$$&lt;p>（3）Accuracy:&lt;/p>
$$\tag{10}
Accuracy = 1 - \frac{\Vert Y - \hat{Y} \Vert}{\Vert Y \Vert\_F}
$$&lt;p>（4）Coefficient of Determination (R2):&lt;/p>
$$\tag{11}
R^2 = 1 - \frac{\sum\_{i=1} (Y\_t - \hat{Y}\_t)^2}{\sum\_{i=1}(Y\_t - \bar{Y})^2}
$$&lt;p>（5）Explained Variance Score(Var):&lt;/p>
$$
var = 1 - \frac{Var\lbrace Y - \hat{Y}\rbrace}{Var\lbrace Y\rbrace}
$$&lt;p>RMSE 和 MAE 用来评估预测误差：越小越好。精度衡量预测的精度：越大越好。$R^2$ 和 Var 计算相关系数，评估预测结果表达真实数据的能力，越大越好。&lt;/p>
&lt;h2 id="43-model-parameters-designing">4.3 Model Parameters Designing
&lt;/h2>&lt;p>(1) Hyperparameter&lt;/p>
&lt;p>学习率、batch size、训练论述，隐藏层数。我们设定的是学习率0.001，batch size 64，轮数 3000 轮。&lt;/p>
&lt;p>隐层单元数对 T-GCN 来说是个重要的参数，因为不同的单元数可能会影响预测精度。我们通过实验选取了最优的隐藏单元数。&lt;/p>
&lt;p>看不下去了。。。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Fig7.JPG"
loading="lazy"
alt="Figure7"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p></description></item><item><title>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</title><link>https://davidham3.github.io/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/</link><pubDate>Thu, 28 Feb 2019 21:12:58 +0000</pubDate><guid>https://davidham3.github.io/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/</guid><description>&lt;p>AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：&lt;a class="link" href="http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf" target="_blank" rel="noopener"
>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>区域级别的预测是网约车服务的关键任务。精确地对网约车需求预测可以指导车辆调度、提高车辆利用率，减少用户的等待时间，减轻交通拥堵。这个任务的关键在于区域间复杂的时空依赖关系。现存的方法主要关注临近区域的欧式关系建模，但是在距离较远的区域间组成的非欧式关系对精确预测也很关键。我们提出了 &lt;em>spatiotemporal multi-graph convolution network&lt;/em> (ST-MGCN)。我们首先将非欧的关系对编码到多个图中，然后使用 multi-graph convolution 对他们建模。为了在时间建模上利用全局的背景信息，我们提出了 &lt;em>contextual gated recurrent neural network&lt;/em>，用一个注意背景的门机制对不同的历史观测值重新分配权重。在两个数据集上比当前的 state-of-the-art 强 10%。&lt;/p>
&lt;h1 id="introduction">Introduction
&lt;/h1>&lt;p>我们研究的问题是区域级别网约车需求预测，是智能运输系统的重要部分。目标是通过历史观测值，预测一个城市里面各区域未来的需求。任务的挑战是复杂的时空关系。一方面，不同区域有着复杂的依赖关系。举个例子，一个区域的需求通常受其空间上临近的区域所影响，同时与有着相同背景的较远的区域有联系。另一方面，非线性的依赖关系也存在于不同的时间观测值之间。预测一个时刻通常和多个历史的观测值相关，比如一小时前、一天前、甚至一周前。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>最近在深度学习的进步使得对基于区域级别的时空关系预测有了很好的结果。使用卷积神经网络和循环神经网络，得到了很多非常好的效果(Shi et al. 2015; Yu et al. 2017; Shi et al. 2017; Zhang, Zheng, and Qi 2017; Zhang et al. 2018a; Ma et al. 2017; Yao et al. 2018b; 2018a)。尽管有了很好的效果，但是我们认为在对时空关系建模上有两点被忽略了。其一，这些方法主要对不同区域的欧式关系建模，但是我们发现非欧关系很重要。图 1 是一个例子，对于区域 1，以及邻居区域 2，可能和很远的区域 3 有相似的功能，也就是他们都靠近学校和医院。此外，区域 1 还可能被区域 4 影响，区域 4 是通过高速公路直接与区域 1 相连的。其二：这些方法中，在使用 RNN 对时间关系建模时，每个区域是独立处理的，或者只基于局部信息。然而，我们认为全局和背景信息也很重要。举个例子，网约车需求的一个全局性的增长/减小通常表明一些可能会影响未来需求的活动发生了。&lt;/p>
&lt;p>我们提出了 ST-MGCN 解决这些问题。在 ST-MGCN 中，我们提出了将区域间非欧关系编码进多个图的方法。不同于 Yao et al. 2018b 给每个区域使用图嵌入作为额外的不变特征，我们用图卷积对区域间的关系对直接建模。图卷积在预测的时候可以聚合邻居特征，传统的图嵌入难以做到这一点。此外，在对时间关系建模时，为了聚合全局的背景信息，我们提出了 contextual gated recurrent neural network (CGRNN)。通过一个基于全局信息计算的门机制增强 RNN，对不同时间步的观测值重新赋权重。我们在两个大型的真实数据集上做了测试，ST-MGCN 比 baselines 好了一大截。我们主要的贡献是：&lt;/p>
&lt;ul>
&lt;li>识别了网约车需求预测中的非欧关系，将他们编码进多个图。利用多图卷积对这些关系建模。&lt;/li>
&lt;li>对时间依赖，提出了 Contextual Gated RNN (CGRNN) 来集成全局背景信息。&lt;/li>
&lt;li>在两个大型真实数据集上做了实验，提出的方法比 state-of-the-art 在相对误差上小了 10%.&lt;/li>
&lt;/ul>
&lt;h1 id="related-work">Related work
&lt;/h1>&lt;h2 id="spatiotemporal-prediction-in-urban-computing">Spatiotemporal prediction in urban computing
&lt;/h2>&lt;p>时空预测是数据驱动的城市管理的基础问题。有很多关于这方面的工作，自行车流量预测(Zhang, Zheng, and Qi 2017)，出租车需求(Ke et al. 2017b; Yao et al. 2018b)，到达时间(Li et al. 2018b)，降雨量(Shi et al. 2015; 2017)，对矩形区域的聚合值进行预测，区域关系通过地理距离建模。具体来讲，城市数据的空间结构通过矩阵形式表示，每个元素表示一个矩形区域。在之前的工作中，区域和他们的关系对一般表示成欧式结构，使得卷积神经网络可以有效地利用这个结构来预测。&lt;/p>
&lt;p>非欧结构的数据也存在于城市计算。通常，基于站点或点的预测任务，像流量预测(Li et al. 2018c; Yu, Yin, and Zhu 2018; Yao et al. 2018a)，基于点的出租车需求预测(Tong et al. 2017)以及基于站点的自行车流量预测(Chai, Wang, and Yang 2018)是很自然的非欧结构，数据不再是矩阵形式，卷积神经网络也不那么有效了。人工定制的特征工程或图卷积网络是处理非欧结构数据目前最好的方法。不同于之前的工作，ST-MGCN 将区域间的关系对编码进语义图中。尽管 ST-MGCN 是对基于区域的预测设计的，但是区域关系的非规整性使得它实际是对非欧数据进行预测。&lt;/p>
&lt;p>在 (Yao et al. 2018b)，作者提出 DMVST-Net，将区域间关系编码进图中来预测出租车需求。DMVST-Net 主要使用图嵌入作为额外特征来预测，没有使用相关区域的需求值（目标值）。在 (Yao et al. 2018a) 的工作中，作者通过注意力机制对周期性的平移问题建模提升了性能。但是，这些方法都没有直接对区域间的非欧关系建模。我们的工作中，ST-MGCN 使用提出的多图卷积从相关区域聚合特征，从不同角度的相关区域的预测值中做预测。&lt;/p>
&lt;p>最近在对帕金森的神经图像分析 (Zhang et al. 2018b) 的研究中，图卷积在空间特征提取上很有效。他们使用 GCN 从最相似的区域中学习特征，提出了多视图结构融合了不同的 MRI。然而，上述工作没有考虑时间依赖。ST-GCN 用于基于骨骼的动作识别(Li et al. 2018a; Yan, Xiong, and Lin 2018)。ST-GCN 的变换是一个空间依赖和局部时间循环的组合。然而，我们认为这些模型，在时间依赖建模上，背景信息或全局信息被忽略了。&lt;/p>
&lt;h2 id="graph-convolution-network">Graph convolution network
&lt;/h2>&lt;p>图卷积网络定义在图 $\mathcal{G} = (V, \boldsymbol{A})$ 上，$V$ 是顶点集，$\boldsymbol{A} \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ 是邻接矩阵，元素表示顶点间是否相连。GCN 可以用不同的感受野从不同的非欧结构中提取局部特征(Hammond et al. 2011)。令 $\boldsymbol{L} = \boldsymbol{I} - \boldsymbol{D}^{-1/2} \boldsymbol{A} \boldsymbol{D}^{-1/2}$ 表示图拉普拉斯矩阵，$\boldsymbol{D}$ 是度矩阵，图卷积操作 (Defferrard, Bresson, and Vandergheynst 2016) 定义为：&lt;/p>
$$
\boldsymbol{X}\_{l+1} = \sigma (\sum^{K-1}\_{k=0} \alpha\_k \boldsymbol{L}^k \boldsymbol{X}\_l),
$$&lt;p>$\boldsymbol{X}_l$ 表示第 $l$ 层的特征，$\alpha_k$ 表示可学习的参数，$\boldsymbol{L}^k$ 是图拉普拉斯矩阵的 $k$ 次幂，$\sigma$ 是激活函数。&lt;/p>
&lt;h2 id="channel-wise-attention">Channel-wise attention
&lt;/h2>&lt;p>Channel-wise attention (Hu, Shen, and Sun 2018; Chen et al. 2017) 在 cv 的论文中提出。本质是给每个通道学习一个权重，为了找到最重要的帧，然后基于他们更高的权重。$\boldsymbol{X} \in \mathbb{R}^{W \times H \times C}$ 表示输入，$W$ 和 $H$ 是输入图像的维度，$C$ 表示通道数，channel-wise attention 计算方式如下：&lt;/p>
$$\tag{1}
z\_c = F\_{pool}(\boldsymbol{X}\_{:,:,c}) = \frac{1}{WH} \sum^W\_{i=0} \sum^H\_{j=0} X\_{i,j,c} \quad \text{for} c=1,2,\dots,C \\
\boldsymbol{s} = \sigma(\boldsymbol{W}\_2 \delta (\boldsymbol{W}\_1 \boldsymbol{z})) \\
\tilde{\boldsymbol{X}}\_{:,:,c} = \boldsymbol{X}\_{:,:,c} \circ s\_c \quad \text{for} c=1,2,\dots,C
$$&lt;p>$F_{pool}$ 是全局池化操作，把每个通道聚合成一个标量 $\boldsymbol{z}_c$，$c$ 是通道的下标。用一个注意力机制对聚合的向量 $\boldsymbol{z}$ 使用非线性变换生成自适应的通道权重 $\boldsymbol{s}$，$\boldsymbol{W}_1, \boldsymbol{W}_2$ 是对应的权重，$\delta, \sigma$ 是 ReLU 和 sigmoid 激活函数。$\boldsymbol{s}$ 通过矩阵乘法乘到输入上。最后，输入通道基于学习到的权重得到了缩放。我们使用这个方法，针对一系列的图生成了时间依赖的注意力分数。&lt;/p>
&lt;h1 id="methodology">Methodology
&lt;/h1>&lt;h2 id="region-level-ride-hailing-demand-forecasting">Region-level ride-hailing demand forecasting
&lt;/h2>&lt;p>我们将城市分为相同大小的网格，每个格子定义为一个区域 $v \in V$，$V$ 表示城市内所有不相交的区域。$\boldsymbol{X}^{(t)}$ 表示第 $t$ 个时段所有区域的订单。&lt;em>区域级别的网约车需求预测&lt;/em> 问题定义为：给定一个定长的输入，对单个时间步进行时空预测，也就是学习一个函数 $f: \mathbb{R}^{\vert V \vert \times T} \rightarrow \mathbb{R}^{\vert V \vert}$，将所有区域的历史需求映射到下一个时间步上。&lt;/p>
$$
[\boldsymbol{X}^{(t-T+1)}, \dots, \boldsymbol{X}^{(t)}]
$$&lt;p>&lt;strong>Framework overview&lt;/strong> ST-MGCN 的系统架构如图2。我们从不同的角度表示区域间的关系，顶点表示区域，边对区域间的关系编码。首先，我们使用提出的 CGRNN，考虑全局背景信息对不同时间的观测值进行聚合。然后，使用多图卷积捕获区域间不同类型的关系。最后，使用全连接神经网络将特征映射到预测上。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;h2 id="spatial-dependency-modeling">Spatial dependency modeling
&lt;/h2>&lt;p>我们用图将区域间关系建模成三种类型，（1）邻居图 $\mathcal{G}_N = (V, \boldsymbol{A}_N)$，编码了空间相近程度，（2）功能相似度图 $\mathcal{G}_F = (V, \boldsymbol{A}_F)$，编码了区域的 POI 的相似度，（3）连接图 $\mathcal{G}_T = (V, \boldsymbol{A}_T)$，编码了距离较远的区域的连通性。我们的方法可以轻易地扩展到其他的图上。&lt;/p>
&lt;p>&lt;strong>Neighborhood&lt;/strong> 区域的邻居基于空间近邻程度定义。我们将 $3 \times 3$ 区域中的最中间的那个区域与他邻接的 8 个区域相连。&lt;/p>
$$\tag{3}
A\_{N, ij} = \begin{cases}
1, \quad v\_i \quad \text{and} \quad v\_j \quad \text{are} \quad \text{adjacent}\\
0, \quad \text{otherwise}
\end{cases}
$$&lt;p>&lt;strong>Functional similarity&lt;/strong> 对一个区域做预测的时候，很自然的会想到和这个区域在功能上相似的区域会有帮助。区域功能可以由 POI 刻画，两个顶点间的边定义为 POI 的相似度：&lt;/p>
$$\tag{3}
A\_{S,i,j} = \text{sim}(P\_{v\_i}, P\_{v\_j}) \in [0, 1]
$$&lt;p>其中 $P_{v_i}, P_{v_j}$ 是区域 $v_i$ 和 $v_j$ 的 POI 向量，维度等于 POI 种类的个数，每个分量表示这个区域内这个 POI 类型的数量。&lt;/p>
&lt;p>&lt;strong>Transportation connectivity&lt;/strong> 运输系统也是一个重要因素。一般来说，这些空间距离上相距较远但是可以很方便到达的区域可以关联起来。这种连接包含高速公路、公路、地铁这样的公共运输。我们定义：如果两个区域间通过这些路直接相连，那么他们之间有边：&lt;/p>
$$\tag{4}
A\_{C,i,j} = max(0, \text{conn}(v\_i, v\_j) - A\_{N,i,j}) \in \lbrace 0, 1\rbrace
$$&lt;p>$\text{conn}(u, v)$ 表示 $v_i$ 和 $v_j$ 之间的连通性。邻居的边在这个图中移除掉了，减少冗余的关系，所以这个图最后是一个稀疏图。&lt;/p>
&lt;p>&lt;strong>Multi-graph convolution for spatial dependency modeling&lt;/strong> 有了这些图，我们提出了多图卷积对空间关系建模：&lt;/p>
$$\tag{5}
\boldsymbol{X}\_{l+1} = \sigma(\bigsqcup\_{\mathbf{A} \in \mathbb{A}} f(\mathbf{A; \theta\_i}) \boldsymbol{X}\_l \mathbf{W}\_l)
$$&lt;p>其中 $\boldsymbol{X}_l \in \mathbb{R}^{\vert V \vert \times P_l}, \boldsymbol{X}_{l+1} \in \mathbb{R}^{\vert V \vert \times P_{l+1}}$ 是第 $l$ 和 $l+1$ 层的特征向量，$\sigma$ 是激活函数，$\bigsqcup$ 表示聚合函数，如 sum, max, average etc. $\mathbb{A}$ 表示图的集合，$f(\mathbf{A}; \theta_i) \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ 表示参数为 $\theta_i$ 的基于图 $\mathbf{A} \in \mathbb{A}$ 的不同样本组成的矩阵的聚合值，$\mathbf{W}_l \in \mathbb{R}^{P_l \times P_{l+1}}$ 表示特征变换矩阵，举个例子，如果 $f(\mathbf{A}, \theta_i)$ 是拉普拉斯矩阵 $\mathbf{L}$ 的多项式，那么这就是多图上的 ChebNet。如果是 $\mathbf{I}$，那就是全连接神经网络。&lt;/p>
&lt;p>我们实现的是 $K$ 阶 拉普拉斯 $\mathbf{L}$ 多项式，图 3 是一个中心区域通过图卷积层变换后的例子。假设邻接矩阵中的值不是 0 就是 1，$L^k_{ij} \not = 0$ 表示 $v_i$ 在 $k$ 步内可达 $v_j$。根据卷积操作，$k$ 是空间特征提取时的感受野范围。使用图 1 的道路连通性图 $\mathcal{G}_C = (V, \boldsymbol{A}_C)$ 来说明。在邻接矩阵 $\boldsymbol{A}_C$ 中，我们有：&lt;/p>
$$
A\_{C,1,4} = 1; A\_{C,1,6} = 0; A\_{C,4,6} = 1,
$$&lt;p>在 1 度拉普拉斯矩阵中对应的分量是：&lt;/p>
$$
L^1\_{C,1,4} \not = 0; L^1\_{C,1,6} = 0; L^1\_{C,4,6} \not = 0
$$&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>如果拉普拉斯矩阵的最大度数 $K$ 设为 $1$，那么区域 1 变换的特征向量，即 $\boldsymbol{X}_{l+1, 1,:}$ 不会包含区域 6: $\boldsymbol{X}_{l,6,:}$，因为 $L^1_{C,1,6}=0$。当 $K$ 增大到 2 的时候，对应的元素 $L^2_{C,1,6}$ 变成非零，$\boldsymbol{X}_{l+1,1,:}$ 就可以利用 $\boldsymbol{X}_{l,6,:}$ 的信息了。&lt;/p>
&lt;p>基于多图卷积的空间依赖建模不限于上述三种图，可以轻易地扩展到其他的图上，适用于其他的时空预测问题上。多图卷积对区域间的关系进行特征提取。感受野小的时候，专注于近邻的区域。增大拉普拉斯阶数，或者堆叠卷积层可以增加感受野的范围，鼓励模型捕获全局依赖关系。&lt;/p>
&lt;p>图嵌入是另一种对区域间关系建模的方法。在 DMVST-Net (Yao et al. 2018b)，作者使用图嵌入表示区域间关系，然后将嵌入作为额外特征加到每个区域上。我们认为 ST-MGCN 中的空间依赖建模方法比之前的方法好，因为：ST-MGCN 将区域间关系编码到图中，通过图卷积从相关区域聚合需求值。但是在 DMVST-Net 中区域关系是嵌入到一个基于区域的不随时间变化的特征中，作为的模型的输入，&lt;/p>
&lt;p>尽管 DMVST-Net 也捕获了拓扑结构信息，但是它很难从相关的区域中通过区域关系聚合需求值。而且不变的特征对模型训练的贡献有限。&lt;/p>
&lt;h2 id="temporal-correlation-modeling">Temporal correlation modeling
&lt;/h2>&lt;p>我们提出 Contextual Gated Recurrent Neural Network (CGRNN) 对不同时间步上的样本建模。CGRNN 通过使用一个上下文注意的门机制增强 RNN 将背景信息集成到时间建模中，结构如图 4。假设我们有 $T$ 个观测样本，$\boldsymbol{X}^{(t)} \in \mathbb{R}^{\vert V \vert \times P}$ 表示第 $t$ 个样本，$P$ 是特征数，如果特征只包含订单数，那就是 1。上下文门控机制如下：&lt;/p>
$$tag{6}
\hat{\boldsymbol{X}}^{(t)} = [\boldsymbol{X}^{(t)}, F^{K'}\_\mathcal{G}(\boldsymbol{X}^{(t)})] \quad \text{for} \quad t = 1,2,\dots,T
$$&lt;p>首先，上下文门控机制通过将临近区域的历史信息和当前区域拼接，得到了区域的描述信息。从相邻区域来的信息看作是环境信息，通过图卷积 $F^{K&amp;rsquo;}_\mathcal{G}$ 使用最大阶数为 $K&amp;rsquo;$ 的拉普拉斯矩阵提取。上下文门控机制用来用图卷积操作集成临近区域的信息，然后使用一个池化：&lt;/p>
$$\tag{7}
z^{(t)} = F\_{pool}(\hat{\boldsymbol{X}}^{(t)}) = \frac{1}{\vert V \vert} \sum^{\vert V \vert}\_{i=1} \hat{X}^{(t)}\_{i,:} \quad \text{for} \quad t=1,2,\dots,T
$$&lt;p>然后，我们在所有的区域上使用全局平均池化 $F_{pool}$ 生成每个时间步观测值的平均值。&lt;/p>
$$tag{8}
\boldsymbol{s} = \sigma(\boldsymbol{W}\_2 \delta(\boldsymbol{W}\_1) \boldsymbol{z})
$$&lt;p>然后使用一个注意力机制，$\boldsymbol{W}_1, \boldsymbol{W}_2$ 是参数，$\delta, \sigma$ 分别是 ReLU 和 sigmoid 激活。&lt;/p>
$$\tag{9}
\tilde{\boldsymbol{X}^{(t)}} = \boldsymbol{X}^{(t)} \circ s^{(t)} \quad \text{for} \quad t=1,2,\dots,T
$$&lt;p>最后，$\boldsymbol{s}$ 用来对每个时间样本进行缩放：&lt;/p>
$$tag{10}
\boldsymbol{H}\_{i,:} = \text{RNN}(\tilde{\boldsymbol{X}}^{(1)}\_{i,:}, \dots, \tilde{\boldsymbol{X}}^{(T)}\_{i,:}; \boldsymbol{W}\_3) \quad \text{for} \quad i=1,\dots,\vert V \vert
$$&lt;p>在上下文门控之后，使用一个共享的 RNN 对所有的区域进行计算，将每个区域聚合成单独的向量 $\boldsymbol{H}_{i,:}$。使用共享 RNN 的原因是我们想找到一个对所有区域通用的聚合规则，这个规则鼓励模型泛化且减少模型的复杂度。&lt;/p>
&lt;h1 id="experiments">Experiments
&lt;/h1>&lt;p>&lt;strong>Dataset&lt;/strong> 北京和上海。时间是从2017年5月1日到2017年12月31日。5月1日到7月31日训练、8月1日到9月30日验证，剩下的测试。POI 数据是2017年的，包含13个类别。每个区域和一个 POI 向量相关，分量是这个 POI 类型在这个区域的个数。用来评估运输可达性的路网使用的是 OpenStreetMap (Haklay and Weber 2008)。&lt;/p>
&lt;h2 id="experimental-settings">Experimental Settings
&lt;/h2>&lt;p>学习任务是：$f: \mathbb{R}^{\vert V \vert \times T} \rightarrow \mathbb{R}^{\vert V \vert}$。实验中，我们将区域以 $1km \times 1km$ 的大小划分成网格。北京和上海分别 1296 和 896 个区域。就像 Zhang, Zheng, and Qi 2017 做的那样，网络的输入包含 5 个历史观测值，三个最近邻的部分，1个周期部分，一个最新的趋势部分。在构建运输可达性网络的时候，我们考虑了高速公路、公路、地铁。两个区域间只要有这样的路直接相连就认为是连通的。&lt;/p>
&lt;p>$f(\mathbf{A}; \theta_i)$ 选择的是 $K = 2$ 时的切比雪夫多项式，$\bigsqcup$ 是 sum 函数。隐藏层为3，每层 64 个隐藏单元，L2 正则，weight decay 是 $1e-4$。CGRNN 中的图卷积 $K&amp;rsquo;$ 是 1。&lt;/p>
&lt;p>我们使用 ReLU 作为图卷积的激活函数。ST-MGCN 的学习率是 $2e-3$，使用验证集上的早停。所有的算法都用 tf 实现，adam 优化 RMSE。ST-MGCN 训练时用了 10G 内存，9G GPU 显存。在 Tesla P40 单卡上训练了一个半小时。&lt;/p>
&lt;p>&lt;strong>Methods for evaluation&lt;/strong> HA, LASSO, Ridge, Auto-regressive model(VAR, STAR), Gradient boosted machine (GBM), ST-ResNet (Zhang, Zheng and Qi 2017), DMVST-Net (Yao et al. 2018b), DCRNN, ST-GCN。&lt;/p>
&lt;h2 id="performance-comparison">Performance comparison
&lt;/h2>&lt;p>我们在验证集上用网格搜索调整了所有模型的参数，在测试集上跑了多次得到的最后的结果。我们使用 RMSE 和 MAPE 作为评价指标。表 1 展示了不同方法在 10 次以上的预测中的对比结果。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;p>我们在两个数据集上观测到了几个现象：（1）基于深度学习的方法能够对非线性的时空依赖关系建模，比其他的方法好；（2）ST-MGCN 在两个数据集上比其他的方法都好，比第二好的高出 10%；（3）对比其他的深度学习方法，ST-MGCN 的方差更小。&lt;/p>
&lt;h2 id="effect-of-spatial-dependency-modeling">Effect of spatial dependency modeling
&lt;/h2>&lt;p>为了研究空间和时间依赖建模的效果，我们通过减少模型中的组成部分评估了 ST-MGCN 的几个变体，包括：（1）邻居图，（2）功能相似性图，（3）运输连通性图。结果如表 2 所示。移除任何一个图都会造成性能损失，证明了每种关系的重要性。这些图编码了重要的先验知识，也就是区域间的相关性。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table2.JPG"
loading="lazy"
alt="Table2"
>&lt;/p>
&lt;p>为了评估集成多个区域关系的效果，我们扩展了基于单个图的模型，包括 DCRNN 和 STGCN，分别记为 DCRNN+ 和 ST-GCN+。结果如图 3，两个算法都得到了提升。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table3.JPG"
loading="lazy"
alt="Table3"
>&lt;/p>
&lt;h2 id="effect-of-temporal-dependency-modeling">Effect of temporal dependency modeling
&lt;/h2>&lt;p>我们使用不同的方法对时间建模，评估 ST-GCN 对时间关系建模的效果。（1）平均池化：通过平均池化对历史观测值进行聚合，（2）RNN：使用 RNN 对历史观测值聚合，（3）CG：使用上下文门对不同的历史观测值赋权，不适用 RNN，（4）GRNN：不用图卷积的 CGRNN。结果如表 4。我们观察到了以下现象：&lt;/p>
&lt;ul>
&lt;li>平均池化会盲目地平均不同的样本，导致性能下降，能做上下文依赖非线性时间聚合的 RNN 能显著地提升性能。&lt;/li>
&lt;li>CGRNN 增强了 RNN。移除 RNN 和 图卷积都导致性能下降，证明了每个部件的有效性。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table4.JPG"
loading="lazy"
alt="Table4"
>&lt;/p>
&lt;h2 id="effect-of-model-parameters">Effect of model parameters
&lt;/h2>&lt;p>我们调整了两个最重要的参数来看不同参数对模型的影响，$K$ 和图卷积层数。图 5 展示了测试集上的结果。可以观察到随着层数的增加，错误先降后增。但是随着 $K$ 的增加，错误是先减小，后不变。越大的 $K$ 或层数使得模型能捕获全局关联性，代价是模型的复杂度会增加，更易过拟合。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig5.JPG"
loading="lazy"
alt="Figure5"
>&lt;/p>
&lt;h1 id="conclusion-and-future-work">Conclusion and Future work
&lt;/h1>&lt;p>我们研究的是网约车需求预测，要找寻这个问题唯一的时空依赖关系。我们提出的深度学习模型使用多个图对区域间的非欧关系建模，使用多图卷积明显的捕获了这个关系。然后用上下文门控机制增强了 RNN，在时间建模上集成了全局背景信息。在两个大型真实数据集上评估了模型，比 state-of-the-art好。未来的工作是：（1）在其他的时空预测任务上评估模型；（2）将提出的模型扩展到多步预测上。&lt;/p></description></item><item><title>Multistep Speed Prediction on Traffic Networks: A Graph Convolutional Sequence-to-Sequence Learning Approach with Attention Mechanism</title><link>https://davidham3.github.io/blog/p/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/</link><pubDate>Mon, 21 Jan 2019 15:17:52 +0000</pubDate><guid>https://davidham3.github.io/blog/p/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/</guid><description>&lt;p>AGC-Seq2Seq，投的是TRC。清华大学和高德地图合作的一项研究。作者采用了 GCN + Seq2Seq + Attention 的混合模型，将路网中的边构建成图中的结点，在 GCN 上做了改进，将邻接矩阵扩展到 k 阶并与一个权重矩阵相乘，类似 HA-GCN(2016)，实现了邻居信息聚合时权重的自由调整，可以处理有向图。时间关系上使用 Seq2Seq + Attention 建模，完成了北京市二环线的多步的车速预测，对比的方法中没有近几年出现的时空预测模型。&lt;/p>
&lt;h1 id="摘要">摘要
&lt;/h1>&lt;p>为了在多步交通预测的任务中，捕获复杂的非平稳的时间动态性和空间依赖关系，我们提出了一个叫注意力图卷积序列到序列模型（AGC-Seq2Seq）。空间和时间用图卷积和序列到序列模型分开建模。注意力机制用来解决序列到序列模型在多步预测上的困难，同时来捕获交通流的异质性。&lt;/p>
&lt;h1 id="2-literature-review">2. LITERATURE REVIEW
&lt;/h1>&lt;p>如 Li et al. 2017 所述，统计模型、shallow machine learning models 和 深度学习模型是三个主要的方法。&lt;/p>
&lt;p>统计模型基于过去的时间序列观测值对未来进行预测。ARIMA 模型，Kalman filter，还有它们衍生出的算法。然而，简单的时间序列模型通常依赖平稳假设，这与城市交通的动态性不符。特别是对于多步时间预测，后面的预测值是基于前面的预测值的，因此，预测的误差会逐渐的传播。使用简单的时间序列预测模型很难满足高精度的预测需求。&lt;/p>
&lt;p>同时，机器学习方法在交通预测研究中表现的很好。神经网络模型，贝叶斯网络，支持向量机模型，K 近邻摩西那个，随机森林模型在交通流预测中表现的很好。然而，机器学习算法的表现依赖于手工选取特征，而且选取特征的方法是不存在的，因为关键特征一般因问题而异。因此，使用元素级别的机器学习方法在复杂的预测任务上不会产生好的效果。&lt;/p>
&lt;p>最近，深度学习算法成功的应用在计算机科学中，同时，它在运输学科也吸引了很多人的注意。Huang et al. 2014 使用深度置信网络用于无监督学习，证明了在交通流预测上的有效性。Lv et al. 2015 使用一个堆叠的自编码器模型学习交通流特征。Ma et al 2015 使用 LSTM 有效地捕获了交通流的动态性。Polson and Sokolov 2017 融合了 $L_1$ 正则和 $\text{tanh}$ 激活的多层网络来检测交通流的极端的非线性。然而，这些方法主要聚焦于对单个序列建模，不能反映交通网络的空间关系。&lt;/p>
&lt;p>卷积神经网络提供了一个有效的架构来提取大尺度、高维的数据集中有效的统计模式。在学习局部平稳结构中，CNN 的能力在图像和视频识别任务中获得了很大的突破。在运输领域，也有学者使用 CNN 捕获交通网络上的空间关系。Ma et al. (2017) 提出了一个预测车速的深度卷积神经网络，将交通的时空动态性转换成图像。Wang et al. (2017) 将高速公路处理成一个 band image，提出了误差回传的循环卷积神经网络结构用于连续的交通速度预测。Ke et al. (2017) 将城市区域划分成均匀的网格，通过将卷积和 LSTM 层合并来预测每个网格内的乘客需求。上述的研究将交通网络转换为网格是因为 CNN 受限于处理欧氏空间的数据。然而，在交通预测上，路网上的时间序列是分布在一个拓扑图上连续的序列，是一种非欧式结构数据的典型 (Narang et al., 2013)；原本的 CNN 结构是不能使用的。为了解决这个问题，基于谱图理论的图卷积网络 (GCN) 可以用于在非欧式空间上使用卷积 (Kipf and Welling, 2016)。几个刚刚发表的研究在交通预测上使用了图卷积模型。基于谱的图卷积和时间上的卷积相结合 (Yu et al., 2017)，还有图卷积与循环神经网络 (RNN) 的结合 (Li et al., 2017) 来用于预测交通状态。之后，Cui et al. (2018) 使用高阶图卷积来学习路网上不同路段间的交互关系。上述研究没有在路网上直接定义图卷积，而是通过高斯核根据任意两个监测器间的距离构建了监测器之间的网络。此外，交通状况的时间关联也没有考虑。&lt;/p>
&lt;p>总结一下，城市路网上交通状况的变化展示出了时空的依赖性。我们提出了一个定制版的深度学习框架，在 Seq2Seq 框架中继承了注意力机制和图卷积模型，同时捕获复杂的非平稳的空间动态性和多步交通预测的空间依赖性。&lt;/p>
&lt;h1 id="3-agc-seq2seq-deep-learning-framework">3. AGC-SEQ2SEQ DEEP LEARNING FRAMEWORK
&lt;/h1>&lt;h2 id="31-preliminaries">3.1 Preliminaries
&lt;/h2>&lt;p>&lt;em>(1) Road network topology&lt;/em>&lt;/p>
&lt;p>路网根据驾驶方向构建成有向图 $\mathcal{G}(\mathcal{N}, \mathcal{L})$ ，顶点集 $\mathcal{N}$ 表示路口 (监测器或选择的高速公路的划分点)，边集 $\mathcal{L}$ 表示路段，如图1所示。$\boldsymbol{A}$ 是边集的邻接矩阵，$\boldsymbol{A}(i, j)$ 表示边 $i$ 和 $j$ 是否相连，即&lt;/p>
$$
\boldsymbol{A}(i, j) = \begin{cases}
1, &amp;\text{if } \quad l\_i \quad \text{and} \quad l\_j \quad \text{are} \quad \text{connected} \quad \text{along} \quad \text{driving} \quad \text{direction}\\
0, &amp;\text{if } \quad \text{otherwise}
\end{cases}
$$&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig1.jpg"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>&lt;em>(2) Traffic speed&lt;/em>&lt;/p>
&lt;p>路段 $l_i (\forall l_i \in \mathcal{L})$ 的第 $t$ 个时段（比如 5 分钟）定义为路段上这个时间段浮动车的平均速度，表示为 $v^i_t$。路网在第 $t$ 个时段的速度定义为向量 $\boldsymbol{V}_t \in \mathbb{R}^{\vert \mathcal{L} \vert}$（$\vert \mathcal{L} \vert$ 是边集 $\mathcal{L}$ 的基数），第 $i$ 个元素是 $(\boldsymbol{V}_t)_i = v^i_t$。&lt;/p>
&lt;p>作为典型的时间序列预测问题，最近邻的 $m$ 步观测值可以对多步预测提供有价值的信息。除了实时的车速信息，一些外部变量，如时间、工作日还是周末，历史的统计信息也对预测有帮助。&lt;/p>
&lt;p>&lt;em>(3) Time-of-day and weekday-or-weekend&lt;/em>&lt;/p>
&lt;p>因为路段的车速是聚合 5 分钟得到的平均值，时间会被转化为一个有序的实数，比如 00:00-00:05 转化为 $N_t = 1$，7:00-7:05 转化为 $N_t = 85(7 * 12 + 1)$，工作日或周末表示为 $p_t$，区分工作日和周末的不同特性。&lt;/p>
&lt;p>&lt;em>(4) Historical statistic information&lt;/em>&lt;/p>
&lt;p>交通状态的每日趋势可以通过引入历史的统计数据捕获。历史的平均车速，中值车速，最大车速，最小车速，路段 $l_i$ 的 $t$ 时段的标准差，分别定义为训练集中的平均值、中位数、最大、最小、标准差，表示为 $v^i_{t,average}, v^i_{t,median}, v^i_{t,max}, v^i_{t,min}, d^i_t$。&lt;/p>
&lt;p>&lt;em>(5) Problem formulation&lt;/em>&lt;/p>
&lt;p>车速预测是用之前观测到的速度预测一个确定时段每个路段上的车速。多步速度预测问题定义为：&lt;/p>
$$\tag{1}
\hat{V}\_{t+n} = \mathop{\arg\max}\limits\_{V\_{t+n}} \text{Pr}(V\_{t+n} \mid V\_t, V\_{t-1}, \dots, V\_{t-m};\mathcal{G})
$$&lt;p>其中 $\hat{V}_{t+n}(n=1,2,3,\dots)$ 表示第 $n$ 步的预测速度，$\lbrace V_t, V_{t-1}, \dots, V_{t-m} \mid m=1,2,\dots \rbrace$ 是之前观测到的值。$\text{Pr}(·\mid·)$ 是条件概率。&lt;/p>
&lt;h2 id="32-graph-convolution-on-traffic-networks">3.2 Graph Convolution on Traffic Networks
&lt;/h2>&lt;p>图卷积通过谱域，将传统的卷积从网格上扩展到了图上。为了引入一般的 $K$ 阶图卷积，我们首先给每个路段 $l_i \in \mathcal{L}$ 定义了 $K$ 阶邻居 $\mathcal{H}_i(K) = \lbrace l_j \in \mathcal{L} \mid d(l_i, l_j) \leq K \rbrace$，其中 $d(l_i, l_j)$ 表示所有从 $l_i$ 到 $l_j$ 的路径中最短路径的长度。&lt;/p>
&lt;p>邻接矩阵就是一阶邻居，$K$ 次幂就是 $K$ 阶邻居。为了模仿拉普拉斯矩阵，我们在对角线上加了1，定义为：&lt;/p>
$$\tag{2}
\boldsymbol{A}^K\_{GC} = \text{Ci}(\boldsymbol{A}^K + \boldsymbol{I})
$$&lt;p>其中 $\text{Ci}(·)$ 是clip function，将非0元素变成1；因此 $\boldsymbol{A}^K_{GC}(i, j) = 1 \quad for \quad l_j \in \mathcal{H}_i(K) \quad or \quad i = j$；否则 $\boldsymbol{A}^K_{GC}(i, j) = 0$。单位阵 $\boldsymbol{I}$ 增加了自连接，卷积的时候可以考虑到自身。&lt;/p>
&lt;p>基于上述的邻居矩阵，一个简单版本的图卷积(e.g., Cui et al., 2018)可以定义为：&lt;/p>
$$\tag{3}
\boldsymbol{V}\_t(K) = (\boldsymbol{W}\_{GC} \odot \boldsymbol{A}^K\_{GC})\cdot \boldsymbol{V}\_t
$$&lt;p>其中 $\boldsymbol{W}_{GC}$ 是一个和 $\boldsymbol{A}$ 一样大小的可训练的矩阵。$\odot$ 表示哈达玛积。通过哈达玛乘积，$(\boldsymbol{W}_{GC} \odot \boldsymbol{A}^K_{GC})$ 可以得到一个在 $K$ 阶邻居上有参数，其他地方为0的新矩阵。因此，$(\boldsymbol{W}_{GC} \odot \boldsymbol{A}^K_{GC})\cdot \boldsymbol{V}_t$ 可以理解成是一个对 $\boldsymbol{V}_t$ 的空间离散的卷积。结果就是，$\boldsymbol{V}_t(K)$ 是时间 $t$ 的融合空间的速度向量。它的第 $i$ 个元素 $v^i_t(K)$ 表示路段 $l_i \in \mathcal{L}$ 在时间 $t$ 的空间融合速度，这个速度集成了其邻居路段 $\mathcal{H}_i(K)$ 的信息。&lt;/p>
&lt;p>此外，式3可以分解成一个一维卷积。&lt;/p>
$$\tag{4}
v^i\_t(K) = (\boldsymbol{W}\_{GC}[i] \odot \boldsymbol{A}^K\_{GC}[i])^T \cdot \boldsymbol{V}\_t
$$&lt;p>$\boldsymbol{W}_{GC}[i]$ 和 $\boldsymbol{A}^K_{GC}[i]$ 分别是 $\boldsymbol{W}_{GC}$ 和 $\boldsymbol{A}^K_{GC}$ 的第 $i$ 行。图2是路网上 $\boldsymbol{A}^K_{GC}[i]$ 的一个例子，路段 $i$ 在红线，邻居是蓝线。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig2.jpg"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;h2 id="33-attention-graph-convolutional-sequence-to-sequence-model-agc-seq2seq">3.3 Attention Graph Convolutional Sequence-to-Sequence Model (AGC-Seq2Seq)
&lt;/h2>&lt;p>我们提出了 AGC-Seq2Seq 模型将时空变量和外部信息集成至深度学习架构中，用来做多步车辆速度预测。&lt;/p>
&lt;p>为了捕获时间序列特征和获得多步输出，我们使用 Seq2Seq 作为整个方法的基础结构，由两个参数独立的 RNN 模块组成(Sutskever et al., 2014; Cho et al., 2014)。为了克服 RNN 输出的长度不可变，Seq2Seq 模型将输入进编码器的时间序列编码，解码器从 &lt;em>context vector&lt;/em> 中解码出预测值。我们提出的 AGC-Seq2Seq 模型如图3所示。首先用图卷积来捕获空间特征，然后将时空变量 $v^i_{t-j}(K)$ 和外部信息 $\boldsymbol{E}_{t-j}$（包括时间和工作日或周末信息）融合构成输入向量，然后放入 Seq2Seq的编码模型中。上述过程如下：&lt;/p>
$$\tag{5}
v^i\_{t-j}(K) = (\boldsymbol{W}\_{GC}[i] \odot \boldsymbol{A}^K\_{GC}[i])^T \cdot \boldsymbol{V}\_{t-j}, \quad 0 \leq j \leq m
$$$$\tag{6}
\boldsymbol{E}\_{t-j} = [N\_{t-j};p\_{t-j}]
$$$$\tag{7}
\boldsymbol{X}^i\_{t-j} = [v^i\_{t-j}(K);\boldsymbol{E}\_{t-j}]
$$&lt;p>其中 $N_{t-j}$ 和 $p_{t-j}$ 如3.1节定义，$[·;·]$ 操作是将两个张量拼接。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig3.jpg"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>编码部分如式8-9，在时间步 $t-j, j\in \lbrace 0, \dots, m \rbrace$，前一个隐藏状态 $\boldsymbol{h}_{t-j-1}$ 传入到当前时间戳和 $\boldsymbol{X}_{t-j}$ 计算得到 $\boldsymbol{h}_{t-j}$。因此，背景向量 $\boldsymbol{C}$ 存储了包括隐藏状态 $(\boldsymbol{h}_{t-m}, \boldsymbol{h}_{t-m+1}, \boldsymbol{h}_{t-1})$ 和输入向量 $(\boldsymbol{X}_{t-m}, \boldsymbol{X}_{t-m+1}, \boldsymbol{X}_t)$ 的信息。&lt;/p>
$$\tag{8}
\boldsymbol{h}\_{t-j} = \begin{cases}
\text{Cell}\_{encoder}(\boldsymbol{h}\_0, \boldsymbol{X}\_{t-j}), \quad &amp;j = m\\
\text{Cell}\_{encoder}(\boldsymbol{h}\_{t-j-1}, \boldsymbol{X}\_{t-j}), \quad &amp;j \in \lbrace 0, \dots, m-1 \rbrace
\end{cases}
$$$$\tag{9}
\boldsymbol{C} = \boldsymbol{h}\_t
$$&lt;p>其中 $\boldsymbol{h}_0$ 是初始隐藏状态，通常是 0 向量；$\text{Cell}_{encoder}(·)$ 是编码器的计算函数，由使用的 RNN 结构决定。&lt;/p>
&lt;p>在解码器的部分，关键是利用背景向量 $\boldsymbol{C}$ 作为初始的隐藏向量，一步一步地解码。时间 $t+j, j \in \lbrace 1, \dots, n \rbrace$ 步，隐藏状态 $\boldsymbol{h}_{t+j}$ 不仅包括输入信息，还考虑之前的输出状态 $(\boldsymbol{h}_{t+1}, \boldsymbol{h}_{t+2}, \dots, \boldsymbol{h}_{t+j-1})$。&lt;/p>
&lt;p>解码器的输入依赖于训练方法。&lt;em>Teacher forcing&lt;/em> 在 NLP 中是一个流行的训练策略。在 teacher-forcing 训练策略中，真值在训练的时候输入到解码器，测试的时候将预测值输入进解码器。这种方法不适合时间序列预测主要是因为在训练和测试的时候，输入到解码器的分布不一致。Li et al. (2017) 使用 &lt;em>scheduled sampling&lt;/em> 缓解了这个问题，通过设定概率 $\epsilon$，随机的将真值或预测值放入到解码器中。但这会增加模型的复杂度，给计算造成负担。&lt;/p>
&lt;p>为了解决这个问题，我们提出了一个新的训练策略，将历史的统计信息和时间信息作为输入。在时间序列预测问题中，历史信息可以通过训练和测试阶段获得；这样解码器在训练和测试的时候，其输入的分布就可以相互同步，解决 &lt;em>teacher forcing&lt;/em> 的问题。此外，因为历史统计信息在多步预测中很重要，增加这个可以提高模型的预测精度。下面的等式用来计算 $t+j,j \in \lbrace 1, \dots, n \rbrace$ 这个时间步解码器的隐藏状态。&lt;/p>
$$\tag{10}
\boldsymbol{v}^i\_{t+j}(H) = [N\_{t+j}; v^i\_{t+j, average};v^i\_{t+j, median}; v^i\_{t+j, max}; v^i\_{t+j, min}; d^i\_{t+j}]
$$$$\tag{11}
\boldsymbol{h}\_{t+j} = \begin{cases}
\text{Cell}\_{decoder}(\boldsymbol{C}, \boldsymbol{v}^i\_{t+j}(H)), \quad &amp;j = 1\\
\text{Cell}\_{decoder}(\boldsymbol{h}\_{t+j-1}, \boldsymbol{v}^i\_{t+j}(H)), \quad &amp;j \in \lbrace 2, \dots, n \rbrace
\end{cases}
$$&lt;p>其中 $\text{Cell}_{decoder}$ 是解码器的计算公式，与编码器类似。&lt;/p>
&lt;p>我们使用 GRU (Chung et al., 2014) 作为编码和解码的结构，如图4。实验效果比标准的 LSTM 好很多。编码器和解码器的计算过程如式12-17所示：&lt;/p>
$$\tag{12}
z\_t = \sigma(\boldsymbol{W}\_z \cdot [\boldsymbol{h}\_{t-1}; x\_t] + b\_z)
$$$$\tag{13}
r\_t = \sigma(\boldsymbol{W}\_r \cdot [\boldsymbol{h}\_{t-1}; x\_t] + b\_r)
$$$$\tag{14}
c\_t = \text{tanh}(\boldsymbol{W}\_c \cdot [r\_t \odot \boldsymbol{h}\_{t-1}; x\_t] + b\_c)
$$$$\tag{15}
\boldsymbol{h}\_t = (1 - z\_t) \odot \boldsymbol{h}\_{t-1} + z\_t \odot c\_t
$$$$\tag{16}
\sigma(x) = \frac{1}{1 + e^{-x}}
$$$$\tag{17}
\text{tanh}(x) = \frac{e^x - e^{-x}}{e^x+e^{-x}}
$$&lt;p>在上式中，$z_t$ 和 $r_t$ 分别是更新门和重置门。$c_t$ 是候选输出，$\sigma(\cdot)$ 和 $\text{tanh}(\cdot)$ 是两个激活函数。$W_z$，$W_r$ 和 $W_c$ 是权重矩阵，$b_z$，$b_r$ 和 $b_c$ 是偏置。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig4.jpg"
loading="lazy"
alt="Figure4"
>&lt;/p>
&lt;p>为了捕获交通模式的外部信息，我们还集成了注意力机制 (Bahdanau et al., 2014; Luong et al., 2015)。注意力机制的关键在于在每个时间步增加捕获了源信息的相关性的注意力向量来帮助交通速度。在时间步 $t+j, j \in \lbrace 1, \dots, n \rbrace$，注意力函数定义为式 18-20，将 query $\boldsymbol{h}_{t+j}$ 和 一组 key $(\boldsymbol{h}_{t-m}, \dots, \boldsymbol{t-1}, \boldsymbol{h}_t)$ 映射起来组成注意力向量 $\boldsymbol{S}_{t+j}$。如下式 18-20，$\boldsymbol{S}_{t+j}$ 通过计算这些 key 的带权和得到，权重通过计算得到：&lt;/p>
$$\tag{18}
u^{t-i}\_{t+j} = \boldsymbol{q}^T \text{tanh} (\boldsymbol{h}\_{t+j} \boldsymbol{W}\_f \boldsymbol{h}\_{t-j}), \quad i = 0,1,\dots,m
$$$$\tag{19}
a^{t-i}\_{t+j} = \text{softmax}(u^{t-i}\_{t+j}) = \frac{\text{exp}(u^{t-i}\_{t+j})}{\sum^m\_{r=1} \text{exp} (u^{t-r}\_{t+j})}, \quad i=0,1,\dots,m
$$$$\tag{20}
\boldsymbol{S}\_{t+j} = \sum^m\_{i=1} a^{t-i}\_{t+j} \boldsymbol{h}\_{t-i}
$$&lt;p>其中，式 18 计算出的 $u^{t-i}_{t+j}$ 可以用来衡量 $\boldsymbol{h}_{t+j}$ 和 $\boldsymbol{h}_{t-i}$ 之间的相似性，我们使用 &lt;em>Luong Attention form&lt;/em> (Luong et al., 2015) 作为注意力的计算公式，$\boldsymbol{W}_f$ 和 $\boldsymbol{q}^T$ 是参数，用来调节结果的维数；$a^{t-i}_{t+j}$ 是 $u^{t-i}_{t+j}$ 归一化的结果，用作对应编码器隐藏状态 $\boldsymbol{h}_{t-i}$ 的权重来计算 $\boldsymbol{S}_{t+j}$。&lt;/p>
&lt;p>如图3所示，注意力隐藏状态 $\tilde{\boldsymbol{h}}_{t+j}$ 由注意力向量 $\boldsymbol{S}_{t+j}$ 和原始隐藏状态 $\boldsymbol{h}_{t+j}$ 通过一个简单拼接组成，如式 21 所示。式 22 表示从隐藏状态到输出的线性变换。参数 $\boldsymbol{W}_v$ 和 $b_v$ 的维度与输出一致。&lt;/p>
$$\tag{21}
\tilde{\boldsymbol{h}}\_{t+j} = \text{tanh} (\boldsymbol{W}\_h \cdot [\boldsymbol{S}\_{t+k};\boldsymbol{h}\_{t+j}])
$$$$\tag{22}
\hat{v}\_{t+j} = \boldsymbol{W}\_v \tilde{h}\_{t+j} + b\_v
$$&lt;p>为了减少多步预测中的误差，我们定义了所有要预测的时间步上的平均绝对误差：&lt;/p>
$$\tag{23}
loss = \frac{1}{n} \sum^n\_{j=1} \vert \hat{v}^i\_{t+j} - v^i\_{t+j} \vert
$$&lt;p>所有的参数通过随机梯度下降训练。&lt;/p>
&lt;h1 id="4-numerical-examples">4 NUMERICAL EXAMPLES
&lt;/h1>&lt;h2 id="41-dataset">4.1 Dataset
&lt;/h2>&lt;p>数据集是从 A-map 的用户收集的，是中国的一个手机导航应用提供的 (Sohu, 2018)。研究范围选择在了北京 2 环，是北京最堵的地方。如图5(a)所示，我们将 33km 长的二环以 200m 一段分成 163 个路段。此外，我们通过用户的轨迹点计算每个路段上 5 分钟的平均速度。2环上工作和和周末的车速如图5(b)(c)所示，x 轴是经度，y 轴是纬度，z 轴是时间和速度的颜色表。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig5_a.jpg"
loading="lazy"
alt="“Figure5 a”"
>
&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig5_bc.jpg"
loading="lazy"
alt="“Figure5 bc”"
>&lt;/p>
&lt;p>数据范围是2016年10月1日到2016年11月30日。10月1日到11月20日做训练，11月21日到27日做测试。预测的范围是 06:00 到 22:00，因此，每条路段每天包含 192 个数据点。图6展示了划分的数据集。在数据清理后，缺失值通过线性插值的方法填补。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Fig6.jpg"
loading="lazy"
alt="Figure6"
>&lt;/p>
&lt;h2 id="42-model-comparisons">4.2 Model comparisons
&lt;/h2>&lt;p>在每个部分，提出的模型对比的是其他的 benchmark 模型，包括传统的时间序列分析方法（如 HA 和 ARIMA），还有一些先进的机器学习方法（ANN, KNN, SVR, XGBOOST），深度学习模型（LSTM, GCN, Seq2Seq-Att）。&lt;/p>
&lt;ul>
&lt;li>HA：历史均值模型通过训练集的统计值预测测试集的未来车速。举个例子，路段 $l_i \in \mathcal{L}$ 在 8:00-8:05 的平均车速通过训练集同时段同路段的历史速度均值估计。&lt;/li>
&lt;li>ARIMA：$(p, d, q)$ 模型 (Box and Pierce, 1970)，差分的阶数设定为 $d = 1$，自回归部分的阶数和移动平均部分的阶数 $(p, q)$ 通过计算对应的 Akaike information criterion 决定，$p \in [0, 2], q \in [7, 12]$。&lt;/li>
&lt;li>ANN：我们用了三层神经网络，sigmoid 激活，隐藏单元数是特征数的 2 倍。因为 ANN 不能区分时间步上的变量，所以它不能捕获时间依赖。&lt;/li>
&lt;li>KNN：k 近邻，获取训练集中特征空间最相近的 k 个观测值。预测值通过对应的特征向量进行线性组合得到。超参数 $K$ 通过 5 到 25 折的交叉验证选定。&lt;/li>
&lt;li>SVR：支持向量回归 (Suykens and Vandewalle, 1999)，通过核函数将特征向量映射到高维空间得到拟合曲线。核函数和超参数通过交叉验证选定。&lt;/li>
&lt;li>XGBOOST：(Chen and Guestrin, 2016) 在很多机器学习任务上表现出了很好的效果；基于树结构可以扩展成端到端的系统。所有的特征 reshape 后输入到 XGBOOST 来训练。&lt;/li>
&lt;li>LSTM：(Hochreiter and Schmidhuber, 1997)，每个路段的所有特征都 reshape 成一个矩阵，一个轴是时间，另一个轴是特征。LSTM 考虑时间依赖，但是没有捕获空间依赖。&lt;/li>
&lt;li>GCN：GCN 中所有的路段的特征 reshape 成一个矩阵，一个轴是路段，另一个轴是特征。GCN 通过拉普拉斯矩阵将卷积泛化到非欧空间；因此，只考虑了空间关联，没有捕获时间依赖。&lt;/li>
&lt;li>Seq2Seq-Att: 和 AGC-Seq2Seq 的区别是图卷积层。&lt;/li>
&lt;/ul>
&lt;p>为了保证共鸣，之前提到的预测模型都有和 AGC-Seq2Seq 同样的输入特征（特征类型和窗口长度），尽管传统的时间序列模型利用了训练集的全部速度记录。窗口长度为 12，也就是用过去一小时预测未来。19 维特征如表 1 所示。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Table1.jpg"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;p>所有的符号如 3.1 节定义，$n$ 是定值。我们通过三个错误指标评价模型，MAPE, MAE, RMSE, $\text{MAPE} = \frac{1}{Q} \sum^Q_{i=1} \frac{\vert v_i - \hat{v}_i \vert}{v_i}$, $\text{MAE} = \frac{1}{Q} \sum^Q_{i=1} \vert v_i - \hat{v}_i \vert$, $\text{RMSE} = \sqrt{\frac{1}{Q} \sum^Q_{i=1} (v_i - \hat{v}_i)^2}$，其中 $v_i$ 和 $\hat{v}^i$ 分别是真值和预测值；$Q$ 是测试集大小。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Table2_a.jpg"
loading="lazy"
alt="“Table2 a”"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Table2_b.jpg"
loading="lazy"
alt="“Table2 b”"
>&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/multistep-speed-prediction-on-traffic-networks-a-graph-convolutional-sequence-to-sequence-learning-approach-with-attention-mechanism/Table2_c.jpg"
loading="lazy"
alt="“Table2 c”"
>&lt;/p></description></item><item><title>Dynamic Bike Reposition: A Spatio-Temporal Reinforcement Learning Approach</title><link>https://davidham3.github.io/blog/p/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/</link><pubDate>Mon, 08 Oct 2018 21:28:18 +0000</pubDate><guid>https://davidham3.github.io/blog/p/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/</guid><description>&lt;p>KDD 2018.强化学习处理共享单车调度问题。&lt;/p>
&lt;h1 id="abstract">ABSTRACT
&lt;/h1>&lt;p>共享单车系统在很多城市都开始使用了，尽管拥挤和空的站点都会导致客户的流失。当前，运营者试图在系统运行中不断地在站点间调度车辆。然而，如何在一个长时间的范围内有效地调度自行车使得乘客的流失最少还没有得到解决。我们提出了一个基于时空强化学习方法的自行车调度模型解决这个问题。首先，一个互相依赖且内部平衡的聚类算法用来对站点聚类。类簇有两点属性，每个类簇类内平衡而且类间独立。因为在很大的系统中有很多三轮车调整自行车，聚类对于减少问题的复杂度来说很重要。其次，我们给每个类簇分配了多辆三轮车，对类内自行车进行调度。我们设计了一个时空强化学习模型对每个类簇进行策略的学习，目标是在长时间范围内降低用户的流失。为了学习每个模型，我们设计了一个深度神经网络来估计它的最优长期价值函数，最优策略可以从这个函数中轻松地推导出来。除了将模型定义成多智能体的方式，我们还通过两个时空剪枝规则减少了训练的复杂度。其三，我们基于两个预测其设计了一个系统模拟器来预测训练和评估调度模型。在Citi Bike的真实数据集上的实验验证了我们的模型的有效性。&lt;/p>
&lt;h1 id="1-introduction">1 INTRODUCTION
&lt;/h1>&lt;p>共享单车系统给公民提供了便利的出行方式。用户可以在一个随机的站点租或返还自行车，通过刷卡，生成一条单车使用记录。然而，因为在一个城市内的单车使用是非常不平衡的，系统中经常出现没有车的空站点以及缺少可用停车位的拥挤站点，导致乘客的流失。当前，系统运营者使用 &lt;em>dynamic bike reposition&lt;/em> 来处理这个问题，也就是，在系统运行中使用三轮车不断的在站点间调整车辆。然而，如何在长时间范围内调整车辆使得顾客流失最少还是一个问题。实时监测并不是一个好的方案，因为在观测到不平衡后对车辆重新分配太晚了。仅仅基于单车使用预测来调度只会导致一个贪心且短视的策略，在长时间来看不会是最优的。我们总结了解决这个问题的三个挑战。&lt;/p>
&lt;p>&lt;em>&lt;strong>A bike-sharing system is complex and dynamic.&lt;/strong>&lt;/em> 系统中经常有几十辆三轮车在几百个站点间调度车辆。在这么一个大的系统内协同调度很复杂，更不用说系统是在运行中保持动态的情况了。难以预测系统的动态性有三点原因：1) 图1. A 展示出了一个月每个小时的租车需求。可以看到，每天的租用模式变化得很剧烈，受多个复杂的因素影响，比如天气、事件以及站点间的相关性。2) 很多移动看起来是随机的。图1. B的第一张图表示出了历史通勤，也就是2016年4月到10月每个工作日的早上这段期间，平均至少发生一次的移动，只占了18%。我们用图1. C的例子解释了这种现象：从A到B，站点间的移动有12种可能，用户一般会根据哪个站点有可用的车辆或车位，选择随机的一条路线，使12条路线中的一条变成可能的频繁移动路线。3) 影响车辆使用的外部因素非常不平衡，比如，晴天时长要比雨天时长多很多。因此，在每个条件下训练一个学习器不能保证在次要条件下的准确性。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>&lt;em>&lt;strong>A single bike reposition has long-term effect.&lt;/strong>&lt;/em> 一个简单的调度是好是坏不是那么简单就能判断的。我们将用图2的两个例子详细描述一下，红圈表示没有可用车位的站点，绿圈表示一个空的站点；带有一个数字和一个时间标记的实线箭头表示在那个时段会有多少辆车从起点租用并返还到目的地；虚线箭头表示了一个三轮车的调度是如何进行的；$t_0 &amp;lt; t_1 &amp;lt; t_2$。首先，一个简单的调度会影响系统内的车辆使用很长的一段时间。如图2. A) 所示，如果一个三轮车到了空站点 $s_1$，在 $t_0$ 时段放了5辆车，在 $s_1$ 的可用车辆就变成了$5$，在 $t_1$ 时段 $s_1$ 可以服务 $5$ 位即将到来的租车者；这5个租车者骑车到 $s_2$ 在 $t_1 &amp;lt; t_2$ 还车，4位到来的租车者在 $t_2$ 时段 $s_2$ 车站想租车的也可以使用那些还回来的车。因此，一个调度可以服务的额外用户的数量很难估计。其次，当前的调度会影响以下情况。如图2. B) 所示，如果一个三轮车到站点 $s_1$ 在 $t_0$ 时段带走了 9 辆自行车，那里的可用车位就变成了 9，因此9个用户就可以在 $t_1$ 时段把他们的自行车还到 $s_1$。然而，因为 $s_1$ 离 $s_3$ 太远，在完成picking up之后，这辆三轮车不能在 $t_2$ 时段之前将5辆自行车运送到空站点 $s_3$，来服务5位即将到来的租客。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>&lt;em>&lt;strong>Uncertainties in partical reposition.&lt;/strong>&lt;/em> 在实际的调度过程中有很多不确定因素。尽管我们可以预测系统的动态，我们不能保证预测与实际完全一样，因为模型会有错误以及随机噪声。此外，完成一次调度的时间也是不同的，比如，从 $s_1$ 运送车辆到 $s_2$ 今天可能需要10分钟，明天可能就要15分钟，尽管方法可能一样。这可能是由于变化的外部因素导致，比如，恶劣的天气状况以及交通的拥挤程度，或是随机噪声。因为动态调度是在系统运行的时候工作的，时间很重要，这也可以从上面两个例子看出来。这些不确定因素，还有长期影响，使得优化模型非常复杂，甚至是无法工作。&lt;/p>
&lt;p>我们提出了一个基于时空强化学习的动态调度模型来解决这三个挑战。我们的贡献可以归纳为4点：&lt;/p>
&lt;ol>
&lt;li>我们提出了一个两步聚类算法，称为 Inter-Independent Inner-Balance算法，简称 IIIB。这个算法首先在系统中迭代地将独立的站点聚类生成小的功能区域，保证每个区域更稳定的租车需求以及车辆移动模式。其次，这个算法根据区域间的移动，将这些区域聚类成组，保证每个类簇是类内平衡且类间独立的。将整个系统分为各个类簇，极大地减少了问题的复杂程度。&lt;/li>
&lt;li>我们基于两个预测器生成了一个系统模拟器。一个是O-Model，通过一个基于相似度的KNN模型预测每个区域的租车需求，考虑复杂的影响因素，解决了不平衡样本的问题。另一个模型是I-Model，通过一个基于车辆移动的推断方法，预测每个区域的还车需求。&lt;/li>
&lt;li>我们提出了一个时空强化学习模型，STRL，为每个类簇学习一个最优的类内调度策略。STRL的状态通过捕获系统动态性以及实时的不确定性仔细地设计出来。因为状态以及行动空间很大，我们设计了一个深度神经网络为每个STRL估计最优的长期价值函数，通过这个可以推断出它的最优调度策略。除了将模型定义成多智能体的方式，我们还通过两个时空剪枝规则减少了训练的复杂度。&lt;/li>
&lt;li>我们在Citi Biki 2016年4月到10月的数据集上证明了我们的模型比baselines更有效。&lt;/li>
&lt;/ol>
&lt;h1 id="2-overview">2 OVERVIEW
&lt;/h1>&lt;p>这部分定义了符号以及相关术语&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;h2 id="21-preliminary">2.1 Preliminary
&lt;/h2>&lt;p>&lt;em>Definition 1&lt;/em> Transition. 一个移动 $f_{ij} = (s_i, s_j, \tau_i, \tau_j)$ 是一辆自行车的使用记录，描述了一辆自行车从地点 $S_i$ 在时刻 $\tau_i$ 被租用以及在地点 $s_j$ 时刻 $\tau_j$ 返还。&lt;/p>
&lt;p>&lt;em>Definition 2&lt;/em> Demand. 时段 $t$ 的地点 $s_i$ 的租用需求 $o_{i,t}$ 是想在 $s_i$ 时段 $t$ 内租用自行车的顾客的个数，包括成功以及失败的。时段 $t$ 内地点 $s_i$ 的返还需求 $r_{i,t}$的定义类似。&lt;/p>
&lt;p>&lt;em>Definition 3&lt;/em> Episode. 一个时段 $E$ 是一天的一个长时段，在这个时段中，我们想最小化总的客户流失。我们在3.1.2中详细地定义了我们问题中的 Episodes，保证了一些约束，而不是随机选取的。&lt;/p>
&lt;h2 id="22-framework">2.2 Framework
&lt;/h2>&lt;p>如图3所示，我们的模型包括了一个离线学习过程以及一个在线调度过程。这个学习过程有三个部分，分别是IIIB聚类算法，系统模拟器生成过程以及每个类簇的STRL模型。&lt;/p>
&lt;p>&lt;em>&lt;strong>IIIB Clustering Algorithm.&lt;/strong>&lt;/em> 为了解决第一个问题，也就是一个系统很大且很复杂，我们提出了一个两步IIIB聚类算法。首先对那些相近且有相似移动模式的站点聚类，在系统中生成小的功能区域。然后基于他们区域间的迁移规律，将区域聚类成组。给每个类簇分配多辆三轮车完成类簇内区域间的调度，而不是类间的自行车调度。&lt;/p>
&lt;p>&lt;em>&lt;strong>Simulator Generation.&lt;/strong>&lt;/em> 为了训练和评估调度模型，我们基于两个预测器生成了一个系统模拟器，也就是分别预测每个区域的租车需求和还车需求的O-Model和I-Model。对于一个指定的时段，比如周六早上7点到7点半，我们先根据历史的天气统计结果生成一个可能的天气状况，比如晴天，然后O-Model预测每个区域周六早上7点到7点半晴天的租车需求。基于这些预测，每个区域的租车需求由泊松过程模拟。每次一辆自行车被租用，I-Model就会估计它的目的地区域以及到达时间，并且追踪它。每个区域的还车事件通过连续地检查自行车是否到达那里来生成。&lt;/p>
&lt;p>&lt;em>&lt;strong>STRL Model.&lt;/strong>&lt;/em> 我们提出了一个STRL模型，对每个类簇学习一个最优的类内调度方案。我们这个基于强化学习的模型是多智能体形式。每次一个三轮车完成它最后的调度，它会不等待其他调度的完成，紧接着开始一个由方案生成的新的调度。新的调度基于当前状态生成，这个调度会很仔细地定义，来捕获系统动态性和实时的不确定性。一个状态包含多个因素，如，每个区域当前自行车和车库的可用性；实时预测的租车和还车需求；三轮车的状态，包含它自身的以及其他的；当前的时间，等等。我们设计了一个深度神经网络为每个STRL估计最优的长期价值函数，通过这个我们能推导出最优的调度策略。网络在系统模拟器迭代地训练出来，在图3中用灰色高亮了出来。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/dynamic-bike-reposition-a-spatio-temporal-reinforcement-learning-approach/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>&lt;em>&lt;strong>Online Reposition.&lt;/strong>&lt;/em> 在学习过程之后，我们在每个类簇上会获得一个神经网络。在在线过程中，当一个三轮车需要一个新的调度时，我们先确定它在哪个类簇中，通过O模型和I模型生成它的当前状态。然后，对应的网络给当前状态中每个可能的调度估计最优的长期价值。选择最大价值的调度并返回。&lt;/p>
&lt;h1 id="3-methodology">3 METHODOLOGY
&lt;/h1>&lt;h2 id="31-iiib-clustering-algorithm">3.1 IIIB Clustering Algorithm
&lt;/h2>&lt;h3 id="311-region-generation">3.1.1 Region Generation
&lt;/h3>&lt;p>如图1. C)所示的例子，站点间的随机迁移使得车站间的单车调度不是那么有意义，因为我们只需要保证在 $s_1$ 或 $s_2$ 或 $s_3$ 有可用的自行车，在 $s_4$ 或 $s_5$ 或 $s_6$ 或 $s_7$ 有可用的车位。考虑每个站点的车辆和车位的可用性，从 $A$ 到 $B$ 的用户可以选择在哪里租车并且还车。受到这个现象的启发，我们对这个区域周围的几个车站聚类，对目标区域周围的车站进行聚类，生成两个小的区域，也就是 $s_1$，$s_2$ 和 $s_3$ 形成了一个区域，$s_4$，$s_5$，$s_6$ 和 $s_7$ 形成了另一个区域。然后，我们只需要保证每个区域车辆和车位的可用性即可。我们认为一个区域的租车需求比一个单独的车站更稳定，更规律；而且，两个区域间的迁移比两个站点间的迁移更频繁。&lt;/p>
&lt;p>为了正式地阐述这个想法，我们基于两个约束在一个系统中生成了一些区域。1) 一个区域的站点应该和其他的站点相近，保证这个区域内顾客的方便。2) 一个区域内的站点应该有相似的OD区域，使得区域间的迁移更专一且更频繁。生成这些的区域的方法是一个迭代的方法，称为二部聚类算法[2]，这个算法会基于车站的位置和迁移模式进行聚类。&lt;/p>
&lt;p>基于获得的这些区域，我们分析了 Citi Bike 中历史的车辆使用数据，证实了上述的两个优势。如图1. A)底部所示，一个区域的租车需求更稳定，更规律，因此更容易地精确预测。随机迁移的问题也可用得到解决。图1. B)右图展示了2016年4月到10月工作日的早上区域间的通勤，占了56%。可以看到，得到的区域间迁移模式更简单，使得还车需求预测更简单且更精确。这里获得的区域可用看作是城市中小的功能区，比如居民区周围的车站很可能组成一个区域，而在工作区周围的可能形成另一个。我们对这些区域聚类成组，而不是在整个系统中的这些屈居间直接调度，而且因为两个原因，我们只在类簇内开展调度。1) 聚类可用进一步减少问题的复杂度。2) 司机一般只对城市内的一个区域比较熟悉。&lt;/p>
&lt;h3 id="312-iiib-clustering-insight">3.1.2 IIIB Clustering Insight
&lt;/h3>&lt;p>获得到的类簇应该有两个性质，每个类簇的内部平衡以及类簇间的相互依赖。&lt;/p>
&lt;p>&lt;em>&lt;strong>Inner-Balance.&lt;/strong>&lt;/em>&lt;/p></description></item><item><title>Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</title><link>https://davidham3.github.io/blog/p/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/</link><pubDate>Thu, 27 Sep 2018 15:11:55 +0000</pubDate><guid>https://davidham3.github.io/blog/p/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/</guid><description>&lt;p>NIPS 2015. 将 FC-LSTM 中的全连接换成了卷积，也就是将普通的权重与矩阵相乘，换成了卷积核对输入和隐藏状态的卷积，为了能捕获空间信息，将输入变成了4维的矩阵，后两维表示空间信息。两个数据集：Moving-MNIST 和 雷达云图数据集。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1506.04214" target="_blank" rel="noopener"
>Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>降雨量预测的目标是预测未来一个局部区域再相对短的一个时间段的降雨密度。之前几乎没有研究从机器学习角度研究这个重要而且很有挑战的问题。在这篇论文中，我们将降雨量预测问题定义成一个时空序列预测问题，输入和预测都是时空序列。通过扩展 &lt;em>fully connected LSTM&lt;/em> (FC-LSTM)，在输入到隐藏与隐藏到隐藏的变换都加入卷积结构，我们提出了 &lt;em>convolutional LSTM&lt;/em> (ConvLSTM)，用它做了一个端到端的模型来预测降雨量。实验表明我们的 ConvLSTM 网络比 FC-LSTM 以及最先进的 ROVER 算法在降水量预测上能更好地捕获时空关系。&lt;/p>
&lt;h1 id="1-introduction">1. Introduction
&lt;/h1>&lt;h1 id="2-preliminaries">2. Preliminaries
&lt;/h1>&lt;h2 id="21-forumulation-of-precipitation-nowcasting-problem">2.1 Forumulation of Precipitation Nowcasting Problem
&lt;/h2>&lt;p>降水量预测的目标是使用之前的雷达声波序列预测一个区域（如香港、纽约、东京）未来定长（时间）的雷达图。在实际应用中，雷达图通常从气候雷达每6到10分钟获得一次，然后预测未来1到6小时，也就是说，预测6到60帧。从机器学习的角度来看，这个问题可以看作是时空序列预测问题。&lt;/p>
&lt;p>假设我们在一个空间区域观测了一个动态系统，由一个 $M \times N$ 的网格组成，$M$ 行 $N$ 列。在网格的每个单元格内部随着时间的变化，有 $P$ 个测量值。因此，观测值在任意时刻可以表示成一个张量 $\mathcal{X} \in \mathbf{R}^{P \times M \times N}$，其中 $\mathbf{R}$ 表示观测到的特征的定义域。如果我们周期性的记录观测值，我们可以得到一个序列 $\hat{\mathcal{X}_1}, \hat{\mathcal{X}_2}, &amp;hellip;, \hat{\mathcal{X}_t}$。这个时空序列预测问题是给定前 $J$ 个观测值，预测未来长度为 $K$ 的序列：&lt;/p>
$$\tag{1}
\tilde{\mathcal{X}}\_{t+1}, ..., \tilde{\mathcal{X}}\_{t+K} = \mathop{\arg \max}\_{\mathcal{X}\_{t+1}, ...\mathcal{X}\_{t+K}} p(\mathcal{X}\_{t+1}, ..., \mathcal{X}\_{t+K} \mid \hat{\mathcal{X}}\_{t-J+1}, \hat{\mathcal{X}}\_{t-J+2}, ..., \hat{\mathcal{X}}\_t)
$$&lt;p>对于降雨量预测，每个时间戳的观测值是一个2D雷达地图。如果我们将地图分到平铺且不重合的部分，将每个部分内的像素看作是它的观测值（图1），预测问题就会自然地变成一个时空序列预测问题。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/Fig1.JPG"
loading="lazy"
alt="Figure1"
>&lt;/p>
&lt;p>我们注意到我们的时空序列预测问题与一步时间序列预测问题不同，因为我们问题的预测目标是一个包含时间和空间结构的序列。尽管长度为$K$的序列中的自由变量的数量可以达到$O(M^KN^KP^K)$，实际上我们可以挖掘可能的预测值的空间结构，减小维度，使问题变得容易处理。&lt;/p>
&lt;h2 id="22-long-short-term-memory-for-sequence-modeling">2.2 Long Short-Term Memory for Sequence Modeling
&lt;/h2>&lt;p>这篇论文，我们使用 FC-LSTM 的公式[11]&lt;/p>
$$\tag{2}
\begin{aligned}
i\_t &amp;= \sigma ( W\_{xi} x\_t + W\_{hi} h\_{t-1} + W\_{ci} \circ c\_{t-1} + b\_i) \\
f\_t &amp;= \sigma ( W\_{xf} x\_t + W\_{hf} h\_{t-1} + W\_{cf} \circ c\_{t-1} + b\_f) \\
c\_t &amp;= f\_t \circ c\_{t-1} + i\_t \circ \mathrm{tanh}(W\_{xc} x\_t + W\_{hc} h\_{t-1} + b\_c) \\
o\_t &amp;= \sigma ( W\_{xo} x\_t + W\_{ho} h\_{t-1} + W\_{co} \circ c\_t + b\_o ) \\
h\_t &amp;= o\_t \circ \mathrm{tanh}(c\_t)
\end{aligned}
$$&lt;p>多个 LSTM 可以堆叠，对复杂的结构在时间上拼接。&lt;/p>
&lt;h1 id="3-the-model">3 The Model
&lt;/h1>&lt;p>尽管 FC-LSTM 层已经在时间关系上表现的很有效了，但是在空间数据上有很多的冗余。为了解决这个问题，我们提出了 FC-LSTM 的扩展，在输入到隐藏，以及隐藏到隐藏的变换上有了卷积的结构。通过堆叠多个 ConvLSTM 层，形成一个 encoding-forecasting 结构，我们可以构建一个不仅可以处理降雨量预测问题，还可以处理更一般的时空序列预测问题的模型。&lt;/p>
&lt;h2 id="31-convolutional-lstm">3.1 Convolutional LSTM
&lt;/h2>&lt;p>FC-LSTM 的主要问题是处理时空数据的时候，它的全连接层没有对空间信息进行编码。为了解决这个问题，我们的设计中的一个特征就是，所有的输入 $\mathcal{X}_1, &amp;hellip;, \mathcal{X}_t$，细胞状态 $\mathcal{C}_1, &amp;hellip;, \mathcal{C}_t$，隐藏状态 $\mathcal{H}_1, &amp;hellip; \mathcal{H}_t$，还有门 $i_t, f_t, o_t$ 都是三维的张量，而且后两维都是空间维（行和列）。为了更好的理解输入和状态，我们可以把它们想象成在空间网格站立的向量。ConvLSTM 通过输入和局部邻居的上一个状态决定了一个特定细胞的未来状态。通过在输入到隐藏，隐藏到隐藏中使用一个卷积操作器就可以轻松的实现（图2）。ConvLSTM的重要的公式如（3）所示（下面的公式），$\ast$表示卷积操作，$\circ$表示Hadamard积：&lt;/p>
$$\tag{3}
\begin{aligned}
i\_t &amp;= \sigma( W\_{xi} \ast \mathcal{X}\_t + W\_{hi} \ast \mathcal{H}\_{t-1} + W\_{ci} \circ \mathcal{C}\_{t-1} + b\_i )\\
f\_t &amp;= \sigma( W\_{xf} \ast \mathcal{X}\_t + W\_{hf} \ast \mathcal{H}\_{t-1} + W\_{cf} \circ \mathcal{C}\_{t-1} + b\_f )\\
\mathcal{C}\_t &amp;= f\_t \circ \mathcal{C}\_{t-1} + i\_t \circ \mathrm{tanh}(W\_{xc} \ast \mathcal{X}\_t + W\_{hc} \ast \mathcal{H}\_{t-1} + b\_c)\\
o\_t &amp;= \sigma( W\_{xo} \ast \mathcal{X}\_t + W\_{ho} \ast \mathcal{H}\_{t-1} + W\_{co} \circ \mathcal{C}\_t + b\_o )\\
\mathcal{H}\_t &amp;= o\_t \circ \mathrm{tanh}(\mathcal{C}\_t)
\end{aligned}
$$&lt;p>&lt;img src="https://davidham3.github.io/blog/images/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/Fig2.JPG"
loading="lazy"
alt="Figure2"
>&lt;/p>
&lt;p>如果我们将状态看作是移动物体的隐藏表示，带有一个更大的变换卷积核的 ConvLSTM 应该能捕获更快的移动，而小的核能捕获慢的移动。同时，如果我们用[16]的角度来看，由式2表示的传统的 FC-LSTM 的输入、细胞输出以及隐藏状态可以看作是一个后两维都是1的三维张量。这样的话，FC-LSTM实际上是所有特征都站立在一个单独细胞上 ConvLSTM 的一个特例。&lt;/p>
&lt;p>为了确保状态和输入有相同个数的行和列，需要在卷积操作之前加入 padding 操作。这里隐藏状态在边界点的 padding 可以看作是使用 &lt;em>state of the outside world&lt;/em> 来计算。通常，在第一个输入来之前，我们将 LSTM 的所有状态初始化为0，对应未来的 “total ignorance”。相似地，如果我们在隐藏状态上用 zero-padding，我们实际上将 &lt;em>state of the outside world&lt;/em> 设定为0，而且假设没有关于外部的先验知识。通过在状态上加 padding，我们可以不同地对待边界点，很多时候这都是有用的。举个例子，假设我们的系统正在观测一个被墙环绕的移动的球。尽管我们不能看到这些墙，但是我们可以通过观察球的一次次反弹推测它们的存在，如果边界点像内部的点一样有相同的状态变化动态性，那这就几乎不可能了。&lt;/p>
&lt;h2 id="32-encoding-forecasting-structure">3.2 Encoding-Forecasting Structure
&lt;/h2>&lt;p>就像 FC-LSTM，ConvLSTM 可以使用块对复杂的结构建模。对于我们的时空序列预测问题，我们使用图3这样的结构，由两个网络组成，一个编码网络，一个预测网络。就像[21]，预测网络的初始状态和细胞输出从编码网络的最后一个状态复制过来。两个网络都通过堆叠多个 ConvLSTM 层构成。因为我们的预测目标与输入的维度相同，我们将预测网络所有的状态拼接，放到一个 $1 \times 1$ 的卷积层中，生成最后的预测结果。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting/Fig3.JPG"
loading="lazy"
alt="Figure3"
>&lt;/p>
&lt;p>我们使用像[23]一样的观点解释这个结构。编码 LSTM 将整个输入序列压缩到一个隐藏状态的张量中，预测 LSTM 解压了这个状态，给出了最后的预测：&lt;/p>
$$\tag{4}
\begin{aligned}
\tilde{\mathcal{X}\_{t+1}}, ..., \tilde{\mathcal{X}\_{t+K}} &amp;= \mathop{\arg \max}\_{\mathcal{X}\_{t+1}, ..., \mathcal{X}\_{t+K}} p(\mathcal{X}\_{t+1}, ..., \mathcal{X}\_{t+K} \mid \hat{\mathcal{X}}\_{t-J+1}, \hat{\mathcal{X}}\_{t-J+2}, ..., \hat{\mathcal{X}}\_t) \\
&amp;\approx \mathop{\arg \max}\_{\mathcal{X}\_{t+1}, ..., \mathcal{X}\_{t+K}} p(\mathcal{X}\_{t+1}, ..., \mathcal{X}\_{t+K} \mid f\_{encoding} (\hat{\mathcal{X}}\_{t-J+1}, \hat{\mathcal{X}}\_{t-J+2}, ..., \hat{\mathcal{X}}\_t)) \\
&amp;\approx g\_{forecasting}(f\_{encoding}(\hat{\mathcal{X}}\_{t-J+1}, \hat{\mathcal{X}}\_{t-J+2}, ..., \hat{\mathcal{X}}\_t))
\end{aligned}
$$&lt;p>这个结构与[21]中的 LSTM 未来预测模型相似，除了我们的输入和输出元素都是三维的张量，保留了所有的空间信息。因为网络堆叠了多个 ConvLSTM 层，它由很强的表示能力可以在复杂的动态系统中给出预测，如降雨量预测问题。&lt;/p>
&lt;h1 id="4-experiments">4. Experiments
&lt;/h1>&lt;p>我们将我们的模型 ConvLSTM 与 FC-LSTM 在一个人工生成的 Moving-MNIST 数据集上做了对比，对我们的模型进行一个初步的了解。我们使用了不同的层数以及不同的卷积核大小，也研究了一些 &amp;ldquo;out-of-domain&amp;rdquo; 的情况，如[21]。为了验证我们的模型在更有挑战的降雨量预测问题上的有效性，我们构建了一个新的雷达声波图，在几个降雨量预测的指标上，比较了我们的模型和当前最先进的 ROVER 算法。结果显示这两个数据集上：&lt;/p>
&lt;ol>
&lt;li>ConvLSTM 比 FC-LSTM 在处理时空关系时更好&lt;/li>
&lt;li>隐藏状态到隐藏状态的卷积核的尺寸大于1对于捕获时空运动模式来说很重要&lt;/li>
&lt;li>深、且参数少的模型能生成更好的结果&lt;/li>
&lt;li>ConvLSTM 比 ROVER 在降雨量预测上表现的更好。&lt;/li>
&lt;/ol></description></item><item><title>GeoMAN: Multi-level Attention Networks for Geo-sensory Time Series Prediction</title><link>https://davidham3.github.io/blog/p/geoman-multi-level-attention-networks-for-geo-sensory-time-series-prediction/</link><pubDate>Mon, 09 Jul 2018 17:03:00 +0000</pubDate><guid>https://davidham3.github.io/blog/p/geoman-multi-level-attention-networks-for-geo-sensory-time-series-prediction/</guid><description>&lt;p>IJCAI 2018，看了一部分，还没看完。原文链接：&lt;a class="link" href="https://www.ijcai.org/proceedings/2018/476" target="_blank" rel="noopener"
>GeoMAN: Multi-level Attention Networks for Geo-sensory Time Series Prediction&lt;/a>&lt;/p>
&lt;h1 id="abstract">Abstract
&lt;/h1>&lt;p>大量的监测器被部署在各个地方，连续协同地监测周围的环境，如空气质量。这些检测器生成很多时空序列数据，之间有着空间相关性。预测这些时空数据很有挑战，因为预测受很多因素影响，比如动态的时空关联和其他因素。我们在这篇论文中使用多级基于注意力机制的 RNN 模型，结合空间、气象和检测器数据来预测未来的监测数值。我们的模型由两部分组成：&lt;/p>
&lt;ol>
&lt;li>多级注意力机制对时空依赖关系建模&lt;/li>
&lt;li>一个通用的融合模块对多领域的外部信息进行融合&lt;/li>
&lt;/ol>
&lt;p>实验用了两个真实的数据集，空气质量数据和水质监测数据，结果显示我们的模型比9个baselines都要好。&lt;/p>
&lt;h1 id="1-introduction">1 Introduction
&lt;/h1>&lt;p>现实世界中有大量的检测器，如空气监测站。每个监测站都有一个地理位置，不断地生成时间序列数据。一组检测器不断的监测一个区域的环境，数据间有空间依赖关系。我们成这样的监测数据为 &lt;em>geosensory time series&lt;/em>。此外，一个检测器生成多种 geo-sensory 时间序列是很常见的，因为这个检测器同时监测不同的目标。举个例子，图1a，路上的循环检测器实时记录车辆通行情况，也记录他们的速度。图1b 展示了检测器每五分钟生成的关于水质的三个不同的气候指标。除了监测，对于 geo-sensory 时间序列预测还有一个重要的需求就是交通预测。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/geoman-multi-level-attention-networks-for-geo-sensory-time-series-prediction/Fig1.PNG"
loading="lazy"
alt="Fig1"
>&lt;/p>
&lt;p>然而，预测 geo-sensory 时间序列很有挑战性，主要受两个因素影响：&lt;/p>
&lt;ol>
&lt;li>动态时空关系
·检测器间复杂的关系。图1c展示了不同检测器的时间序列间的空间关系是高度动态的，随着时间不断改变。除此以外，geo-sensory时间序列根据地区有非线性的变化。当对动态关系建模时，传统方法（如概率图模型）的计算量会很大，因为他们有很多参数。
·检测器内部的动态关系。首先，一个geo-sensory时间序列通常由一种周期模式（如，图1c中的$S_1$），这种模式一直变化，并且地理上也有改变。其次，检测器记录经常有很大的振动，很快地减少前一个数值的影响。因此，如何选择一个时间间隔来预测也是一个问题。&lt;/li>
&lt;li>外部因素。
检测器数据也被周围的环境影响，比如气象（例如强风），几点（比如早晚高峰）还有土地使用情况等。&lt;/li>
&lt;/ol>
&lt;p>为了解决这些挑战，我们提出了一个多级注意力网络（GeoMAN）来预测一个检测器未来几个小时的数值。我们的贡献有三点：&lt;/p>
&lt;ol>
&lt;li>&lt;em>多级注意力机制&lt;/em>。我们研发了一个多级注意力机制对动态时空关系建模。具体来说，第一级，我们提出了一个新的注意力机制，由局部空间注意力和全局空间注意力组成，用来捕获不同检测器时间序列间的复杂空间关系。第二级，时间注意力对一个时间序列中的动态时间关系进行建模。&lt;/li>
&lt;li>&lt;em>外部因素融合模型&lt;/em>。我们设计了一个通用融合模型融合不同领域的外部因素。学习到的隐含表示会输入至多级注意力网络中来提升这些外部因素的重要性。&lt;/li>
&lt;li>&lt;em>真实的评价&lt;/em>。我们基于两个真实的数据集评估我们的方法。大量的实验证明了我们的方法相比于baseline的优越性。&lt;/li>
&lt;/ol>
&lt;h1 id="2-preliminary">2 Preliminary
&lt;/h1>&lt;h2 id="21-notations">2.1 Notations
&lt;/h2>&lt;p>假设，有 $N_g$ 个检测器，每个都生成 $N_l$ 种时间序列。我们指定其中的一个为 &lt;em>target series&lt;/em> 来预测，其它序列作为特征。时间窗为 $T$，我们使用 $\mathbf{Y} = (\mathbf{y}^1, \mathbf{y}^2, &amp;hellip;, \mathbf{y}^{N_g}) \in \mathbb{R}^{N_g \times T}$ 来表示所有目标序列在过去 $T$ 个小时的监测值，其中 $\mathbf{y}^i \in \mathbb{R}^T$ 属于监测器 $i$。我们使用 $\mathbf{X}^i = (\mathbf{x}^{i, 1}, \mathbf{x}^{i, 2}, &amp;hellip;, \mathbf{x}^{i, N_l})^{\rm T} = (\mathbf{x}^i_1, \mathbf{x}^i_2, &amp;hellip;, \mathbf{x}^i_T) \in \mathbb{R}^{N_l \times T}$ 作为检测器 $i$ 的局部特征，其中 $\mathbf{x}^{i,k} \in \mathbb{R}^T$ 是这个检测器的第 $k$ 个时间序列，$\mathbf{x}^i_t = (x^{i,1}_t, x^{i,2}_t, &amp;hellip;, x^{i,N_l}_t)^{\rm T} \in \mathbb{R}^{N_l}$ 表示检测器 $i$ 在时间 $t$ 的所有时间序列的值。除了检测器 $i$ 的局部特征，由于不同检测器间的空间关系，其他的检测器会共享大量对于预测有用的信息。为了这个目的，我们将每个检测器的局部特征融合到集合 $\mathcal{X}^i = \lbrace \mathbf{X}^1, \mathbf{X}^2, &amp;hellip;, \mathbf{X}^{N_g}\rbrace$ 中作为检测器 $i$ 的全局特征。&lt;/p>
&lt;h2 id="22-problem-statement">2.2 Problem Statement
&lt;/h2>&lt;p>给定每个检测器之前的值和外部因素，预测检测器 $i$ 在未来 $\tau$ 个小时的值，表示为 $\hat{\mathbf{y}}^i = (\hat{y}^i_{T+1}, \hat{y}^i_{T+2}, &amp;hellip;, \hat{y}^i_{T+\tau})^{\rm T} \in \mathbb{R}^{\tau}$.&lt;/p>
&lt;h1 id="3-multi-level-attention-networks">3 Multi-level Attention Networks
&lt;/h1>&lt;p>&lt;img src="https://davidham3.github.io/blog/images/geoman-multi-level-attention-networks-for-geo-sensory-time-series-prediction/Fig2.PNG"
loading="lazy"
alt="Fig2"
>&lt;/p>
&lt;p>图 2 展示了我们方法的框架。基于编码解码架构[Cho et al., 2014b]，我们用两个分开的 LSTM，一个对输入序列编码，也就是对历史的 geo-sensory 时间序列，另一个来预测输出的序列 $\hat{y}^i$。更具体的讲，我们的模型 GeoMAN 有两个主要部分：&lt;/p>
&lt;ol>
&lt;li>多级注意力机制。包含一个带有两类空间注意力机制的编码器和一个带有时间注意力的解码器。在编码器，我们开发了两种不同的注意力机制，局部空间注意力和全局空间注意力，如图 2 所示，这两种注意力机制通过前几步编码器的隐藏状态、前几步检测器的值和空间信息（检测器网络），可以在每个时间步上捕获检测器间的复杂关系。在解码器，我们使用了一个时间注意力机制来自适应地选择之前的时间段来做预测。&lt;/li>
&lt;li>外部因素融合。这个模块用来处理外部因素的影响，输出会作为解码器的一部分输入。这里，我们使用 $h_t \in \mathbb{R}^m$ 和 $s_t \in \mathbb{R}^m$ 来表示编码器在时间 $t$ 的隐藏状态和细胞状态。$d_t \in \mathbb{R}^n$ 和 $s&amp;rsquo; \in \mathbb{R}^n$ 表示解码器的隐藏状态和细胞状态。&lt;/li>
&lt;/ol>
&lt;h2 id="31-spatial-attention">3.1 Spatial Attention
&lt;/h2>&lt;h3 id="local-spatial-attention">Local Spatial Attention
&lt;/h3>&lt;p>我们先介绍空间局部注意力机制。对应一个监测器，在它的局部时间序列上有复杂的关联性。举个例子，一个空气质量检测站会记录不同的时间序列如 PM2.5，NO 和 SO2。事实上，PM2.5 的浓度通常被其他时间序列影响，包括其他的空气污染物和局部空气质量 [Wang et al., 2005]。为了解决这个问题，给定第 $i$ 个检测器第 $k$ 个局部特征向量 $\mathbf{x}^{i,k}$，我们使用注意力机制自适应地捕获目标序列和每个局部特征间的动态关系：&lt;/p>
$$\tag{1}
e^k\_t = \mathbf{v}^T\_l \text{tanh} (\mathbf{W}\_l [\mathbf{h}\_{t-1};\mathbf{s}\_{t-1}] + \mathbf{U}\_l \mathbf{x}^{i,k} + \mathbf{b}\_l)
$$$$\tag{2}
\alpha^k\_t = \frac{\text{exp}(e^k\_t)}{\sum^{N\_l}\_{j=1}\text{exp}(e^j\_t)}.
$$&lt;p>其中 $[\cdot;\cdot]$ 是拼接操作（论文这里写的是 concentration，我怎么觉得是concatenation呢。。。）。$\mathbf{v}_l, \mathbf{b}_l \in \mathbb{R}^T, \mathbf{W}_l \in \mathbb{R}^{T \times 2m}, \mathbf{U}_l \in \mathbb{R}^{T \times T}$ 是参数。局部特征的注意力权重通过编码器中输入的局部特征和历史状态共同决定。这个注意力分数语义上表示每个局部特征的重要性，局部空间注意力在时间步 $t$ 的输出向量通过下式计算：&lt;/p>
$$\tag{3}
\tilde{\mathbf{x}}^{local}\_t = (\alpha^1\_t x^{i,1}\_t, \alpha^2\_t x^{i,2}\_t, \dots, \alpha^{N\_l}\_t x^{i,N\_l}\_t)^{\rm T}.
$$&lt;h3 id="global-spatial-attention">Global Spatial Attention
&lt;/h3>&lt;p>对于一个监测器记录的目标时间序列，其他监测器是时间序列对其有直接影响。然而，影响权重是高度动态地，随时间变化。因为可能有很多不相关的序列，直接使用各种时间序列作为编码器的输入来捕获不同监测器之间的关系会导致很高的计算开销并且降低模型的能力。而且这样的影响权重受其他监测器的局部条件影响。举个例子，当强风从一个遥远地地方吹过来，这个区域的空气质量回比之前受影响的多。受这个现象的启发，我们开发了一个新的注意力机制捕获不同监测器间的动态关系。给定第 $i$ 个监测器作为我们的预测目标，另一个监测器 $l$，我们计算他们之间的注意力分数如下：&lt;/p>
$$
g^l\_t = \mathbf{v}^{\rm T}\_g \text{tanh} (\mathbf{W}\_g [\mathbf{h}\_{t-1}; \mathbf{s}\_{t-1}] + \mathbf{U}\_g \mathbf{y}^l + \mathbf{W}'\_g \mathbf{X}^l \mathbf{u}\_g + \mathbf{b}\_g),
$$&lt;p>其中 $\mathbf{v}_g, \mathbf{u}_g, \mathbf{b}_g \in \mathbb{R}^T, \mathbf{W}_g \in \mathbb{R}^{T \times 2m}, \mathbf{U}_g \in \mathbb{R}^{T \times T}, \mathbf{W}&amp;rsquo;_g \in \mathbb{R}^{T \times N_l}$ 是参数。通过考虑目标序列和其他检测器的局部特征，这个注意力机制可以自适应地选择相关的监测器来做预测。同时，通过考虑编码器内前一隐藏状态和细胞状态，历史信息会跨时间流动。&lt;/p>
&lt;p>注意，空间因素也会对不同监测器之间的关系做出贡献。一般来说，geo-sensors 通过一个明确的或隐含的网络连接起来。这里，我们使用一个矩阵 $\mathbf{P} \in \mathbb{R}^{N_g \times N_g}$ 来衡量地理空间相似度（如地理距离的倒数），$P_{i,j}$ 表示监测器 $i$ 和 $j$ 之间的相似度。不同于注意力权重，地理相似度可以看作是先验知识。特别的说，如果 $N_g$ 很大，一个方法是使用最近邻或最相近的一组而不是所有的监测器。之后，我们使用一个 softmax 函数，确定所有的注意力权重之和为1，两个方法共同考虑地理相似度如下：&lt;/p>
$$\tag{4}
\beta^l\_t = \frac{\text{exp}((1-\lambda)g^l\_t + \lambda P\_{i,l})}{\sum^{N\_g}\_{j=1} \text{exp}((1-\lambda)g^j\_t + \lambda P\_{i,j})},
$$&lt;p>其中，$\lambda$ 是一个可调的超惨。如果 $\lambda$ 大，这项会强制注意力权重等于地理相似度。全局注意力的输出向量计算如下：&lt;/p>
$$\tag{5}
\tilde{\mathbf{x}}^{global}\_t = (\beta^1\_t y^1\_t, \beta^2\_t y^2\_t, \dots, \beta^{N\_g}\_t y^{N\_g}\_t)^{\rm T}.
$$&lt;h2 id="32-temporal-attention">3.2 Temporal Attention
&lt;/h2>&lt;p>因为编码解码结构会随着长度增长会很快的降低性能，一个重要的扩展是增加时间注意力机制，可以自适应地选择编码器相关的隐藏状态来生成输出序列，即模型对目标序列中不同时间间隔的动态时间关系建模。特别来说，为了计算每个输出时间 $t&amp;rsquo;$ 对编码器每个隐藏状态的的注意力向量，我们定义：&lt;/p>
$$\tag{6}
u^o\_{t'} = \mathbf{v}^{\rm T}\_d \text{tanh} (\mathbf{W}'\_d [\mathbf{d}\_{t'-1}; \mathbf{s}'\_{t'-1}] + \mathbf{W}\_d \mathbf{h}\_o + \mathbf{b}\_d),
$$$$\tag{7}
\gamma^o\_{t'} = \frac{\text{exp} (u^o\_{t'})}{\sum^T\_{o=1} \gamma^o\_{t'} \mathbf{h}\_o},
$$$$\tag{8}
\mathbf{c}\_{t'} = \sum^T\_{o=1} \gamma^o\_{t'} \mathbf{h}\_o,
$$&lt;h2 id="33-external-factor-fusion">3.3 External Factor Fusion
&lt;/h2>&lt;p>Geo-sensory 时间序列和空间因素有强烈的相关性，如 POI 和监测器网络。这些因素一起表示一个区域的功能。而且还有很多时间因素影响监测器的数值，如气象或时间。受之前工作的启发 [Liang et al., 2017; Wang et al., 2018] 专注时空应用中的外部因素的影响，我们设计了一个简单有效的组件来处理这些因素。&lt;/p>
&lt;p>如图 2 所示，我们先将包含时间、气象特征的时间因素和表示目标监测器的监测器ID融合。因为未来的天气条件未知，我们使用天气预报来提升性能。这些因素的大部分都是离散特征，不能直接放到神经网络里面，我们通过将离散特征分开放入不同的嵌入层，将离散特征转换为低维向量。根据空间因素，我们使用不同 POI 类型的密度作为特征。因为监测器的属性依赖实际情况，我们只使用网络的结构特征，如邻居数和交集等。最后，我们将获得的嵌入向量和空间特征拼接作为这个模块的输出，表示为 $\mathbf{ex}_{t&amp;rsquo;} \in \mathbb{R}^{N_e}$，其中 $t&amp;rsquo;$ 是解码器中未来的时间步。&lt;/p>
&lt;h2 id="34-encoder-decoder--model-training">3.4 Encoder-decoder &amp;amp; Model Training
&lt;/h2>&lt;p>编码器中，我们简单地从局部空间注意力和全局空间注意力聚合输出：&lt;/p>
$$\tag{9}
\tilde{\mathbf{x}}\_t = [\tilde{\mathbf{x}}^{local}\_t; \tilde{\mathbf{x}}^{global}\_t],
$$&lt;p>其中 $\tilde{\mathbf{x}}_t \in \mathbb{R}^{N_l + N_g}$。我们将拼接 $\tilde{\mathbf{x}}_t$ 作为编码器的新输入，使用 $\mathbf{h}_t = f_e(\mathbf{h}_{t-1}, \tilde{\mathbf{x}}_t)$ 更新时间 $t$ 的隐藏状态，$f_e$ 是一个 LSTM 单元。&lt;/p>
&lt;p>解码器中，一旦我们获得了时间 $t&amp;rsquo;$ 的上下文向量 $\mathbf{c}_{t&amp;rsquo;}$ 的带权和，我们将他与外部因素融合模块的输出 $\mathbf{ex}_{t&amp;rsquo;}$ 还有解码器的最后一个输出 $\hat{y}^i_{t&amp;rsquo;-1}$ 融合，用 $\mathbf{d}_{t&amp;rsquo;} = f_d (\mathbf{d}_{t&amp;rsquo;-1}, [\hat{y}^i_{t&amp;rsquo;-1}; \mathbf{ex}_{t&amp;rsquo;}; \mathbf{c}_{t&amp;rsquo;}])$ 更新解码器的隐藏状态，$f_d$ 是解码器中使用的 LSTM 单元。然后，我们讲上下文向量 $\mathbf{c}_{t&amp;rsquo;}$ 和隐藏状态 $\mathbf{d}_{t&amp;rsquo;}$ 拼接，得到新的隐藏状态，然后做最后的预测：&lt;/p>
$$\tag{10}
\hat{y}^i\_{t'} = \mathbf{v}^{\rm T}\_y (\mathbf{W}\_m [\mathbf{c}\_{t'}; \mathbf{b}\_{t'}] + \mathbf{b}\_m) + b\_y,
$$&lt;p>其中，$\mathbf{W}_m \in \mathbb{R}^{n \times (m + n))}$ 和 $\mathbf{b}_m \in \mathbb{R}^n$ 将 $[\mathbf{c}_{t&amp;rsquo;}; \mathbf{d}_{t&amp;rsquo;}] \in \mathbb{R}^{m + n}$ 映射到解码器隐藏状态的空间。最后，我们用一个线性变换生成最终结果。&lt;/p>
&lt;p>因为我们的方法是平滑且可微的，可以通过反向传播训练。在训练时，我们使用 Adam，最小化 MSE。&lt;/p>
$$\tag{11}
\mathcal{L}(\theta) = \Vert \hat{\mathbf{y}}^i - \mathbf{y}^i \Vert^2\_2,
$$&lt;h1 id="4-experiments">4 Experiments
&lt;/h1>&lt;h2 id="41-settings">4.1 Settings
&lt;/h2>&lt;h3 id="datasets">Datasets
&lt;/h3>&lt;p>我们在两个数据集中开展了实验，每个数据集包含三个子集：气象数据、POI、监测器网络数据。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>水质数据集：中国东南的一个城市的供水系统中的监测器提供了长达三年的每5分钟一个记录的数据，包含了残余氯(RC)、浑浊度和PH值等。我们将 RC 作为目标时间序列，因为它在环境科学中作为常用的水质指标。一共有 14 个监测器，监测 10 个指标，它们之间通过管道网络相连。我们使用 Liu et al., 2016a 提出的指标作为这个数据集的相似度矩阵。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>空气质量：从一个公开数据集抓取的，这个数据集包含不同污染物的浓度，还有气象数据，北京地区一共 35 个监测器。主要污染物是 PM2.5，因此我们将它作为目标。我们只使用空间距离的倒数表示两个监测器之间的相似度。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/geoman-multi-level-attention-networks-for-geo-sensory-time-series-prediction/Table1.JPG"
loading="lazy"
alt="Table1"
>&lt;/p>
&lt;p>对于水质数据集，我们将数据分成了不重叠的训练集、验证集和测试集，去年的前一半作为验证机，去年的后半段作为测试集。可惜的是，我们在第二个数据集上没能获得很多的数据，因此我们使用了8：1：1的比例划分。&lt;/p>
&lt;h3 id="evaluation-metrics">Evaluation Metrics
&lt;/h3>&lt;p>我们使用多个标准评价模型，RMSE 和 MAE。&lt;/p>
&lt;h3 id="hyperparameters">Hyperparameters
&lt;/h3>&lt;p>我们令 $\tau = 6$，做短期预测。在训练阶段，batch size 256，学习率 0.001。外部因素融合模块，我使用 $\mathbb{R}^6$ 嵌入监测器 ID，时间特征 $\mathbb{R}^10$。我们的模型一共 4 个超参数，$\lambda$ 根据经验设置，从 0.1 到 0.5。对于窗口长度 $T$，我们设为 $T \in \lbrace 6, 12, 24, 36, 48 \rbrace$。为了简单，我们将编码器和解码器采用同样的隐藏维数，网格搜索 $\lbrace 32, 64, 128, 256\rbrace$。我们堆叠 LSTM 来提高性能，层数记为 $q$。验证集上得到的最好参数是 $q = 2, m = n = 64, \lambda = 2$。&lt;/p>
&lt;h2 id="42-baselines">4.2 Baselines
&lt;/h2>&lt;p>ARIMA, VAR, GBRT, FFA, stMTMVL, stDNN, LSTM, Seq2seq, DA-RNN。&lt;/p>
&lt;p>对于 ARIMA，我们用前六个小时的数据作为输入。stMTMVL 和 FFA，我们使用和作者一样的设置。和 GeoMAN 类似，我们使用前 $T \in \lbrace 6, 12, 24, 36, 48\rbrace$ 个小时的数据作为其他模型的输入。最后，我们测试了不同的超参数，得到了每个模型的最好效果。&lt;/p>
&lt;h2 id="43-model-comparsion">4.3 Model Comparsion
&lt;/h2>&lt;p>我们在两个数据集上比较了模型和 baselines。为了公平，我们在表 2 展示了每个方法的最好性能。&lt;/p>
&lt;p>我们的方法在水质预测上得到了最好的性能。比 state-of-the-art 的 DA-RNN 在两个指标上分别提升了 14.2% 和 13.5%。因为 RC 浓度有一个确定的周期模式，stDNN 和 基于 RNN 的模型比 stMTMVL 和 FFA 获得了更好的效果，因为他们能捕获更长的时间依赖。对比 LSTM 智能预测一个未来的时间步，GeoMAN 和 Seq2seq 由于解码器的存在有很大的提升。GBRT 比大部分方法也要好，体现了集成学习的优势。&lt;/p>
&lt;p>对比数据相对稳定的水质数据集，PM2.5 的浓度有些时候震荡得很厉害，使得很难预测。表 2 展示了北京的空气质量数据集上一个全面的对比。可以看到我们的模型有最好的效果。我们主要讨论下 MAE。我们的方法比这些方法的 MAE 相对低 7.2% 和 63.5%，展示出了比其他方法更好的泛化效果。另一个有趣的现象是 stMTMVL 在水质预测上表现很好，在空气质量上&lt;/p></description></item><item><title>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic</title><link>https://davidham3.github.io/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/</link><pubDate>Thu, 10 May 2018 15:35:47 +0000</pubDate><guid>https://davidham3.github.io/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/</guid><description>&lt;p>IJCAI 2018，大体思路：使用Kipf &amp;amp; Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1709.04875v4" target="_blank" rel="noopener"
>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting&lt;/a>&lt;/p>
&lt;h1 id="摘要">摘要
&lt;/h1>&lt;p>实时精确的交通预测对城市交通管控和引导很重要。由于交通流的强非线性以及复杂性，传统方法并不能满足中长期预测的要求，而且传统方法经常忽略对时空数据的依赖。在这篇文章中，我们提出了一个新的深度学习框架，时空图卷积(Spatio-Temporal Graph Convolutional Networks)，来解决交通领域的时间序列预测问题。我们在图上将问题形式化，并且建立了完全卷积的结构，并不是直接应用传统的卷积以及循环神经单元，这可以让训练速度更快，参数更少。实验结果显示通过在多尺度的交通网络上建模，STGCN模型可以有效地捕获到很全面的时空相关性并且在各种真实数据集上表现的要比很多state-of-the-art算法好。&lt;/p>
&lt;h1 id="引言">引言
&lt;/h1>&lt;p>交通运输在每个人的生活中都扮演着重要的角色。根据2015年的调查，美国的司机们平均每天要在车上呆48分钟。这种情况下，精确的实时交通状况预测对于路上的用户，private sector和政府来说变得至关重要。广泛使用的交通服务，如交通流控制、路线规划和导航，也依赖于高质量的交通状况预测。总的来说，多尺度的交通预测的研究很有前景而且是城市交通流控制和引导的基础，也是智能交通系统的一个主要功能。&lt;/p>
&lt;p>在交通研究中，交通流的基本变量，也就是速度、流量和密度，通常作为监控当前交通状态以及未来预测的指示指标。根据预测的长度，交通预测大体分为两个尺度：短期(5~30min)，中和长期预测(超过30min)。大多数流行的统计方法(比如，线性回归)可以在短期预测上表现的很好。然而，由于交通流的不确定性和复杂性，这些方法在相对长期的预测上不是那么的有效。&lt;/p>
&lt;p>之前在中长期交通预测上的研究可以大体的分为两类：动态建模和数据驱动的方法。动态建模使用了数学工具（比如微分方程）和物理知识通过计算模拟来形式化交通问题[Vlahogiani, 2015]。为了达到一个稳定的状态，模拟进程不仅需要复杂的系统编程，还需要消耗大量的计算资源。模型中不切实际的假设和化简也会降低预测的精度。因此，随着交通数据收集和存储技术的快速发展，一大群研究者正在将他们的目光投向数据驱动的方法。
典型的统计学和机器学习模型是数据驱动方法的两种体现。在时间序列分析上，自回归移动平均模型（ARIMA）和它的变形是众多统一的方法中基于传统统计学的方法[Ahmed and Cook, 1979; Williams and Hoel, 2003; Lippi $et al.$, 2013]。然而，这种类型的模型受限于时间序列的平稳分布，而且不能考虑时空相关性。因此，这些方法限制了高度非线性的交通流的表示能力。最近，传统的统计方法在交通预测上已经受到了机器学习方法的冲击。这些模型可以获得更高的精度，对更复杂的数据建模，比如k近邻（KNN），支持向量机（SVM）和神经网络（NN）。&lt;/p>
&lt;p>&lt;strong>深度学习方法&lt;/strong> 最近，深度学习已经被广泛且成功地应用于各式各样的交通任务中，在最近的工作中已经取得了很显著的成果，比如，深度置信网络（DBN）[Jia &lt;em>et al.&lt;/em>, 2016; Huang &lt;em>et al.&lt;/em>, 2014]和层叠自编码器(stacked autoencoder)(SAE)[Lv &lt;em>et al.&lt;/em>, 2015; Chen &lt;em>et al.&lt;/em>, 2016]。然而，这些全连接神经网络很难从输入中提取空间和时间特征。而且，空间属性的严格限制甚至完全缺失，这些网络的表示能力被限制的很严重。&lt;/p>
&lt;p>为了充分利用空间特征，一些研究者使用了卷积神经网络来捕获交通网络中的临近信息，同时也在时间轴上部署了循环神经网络。通过组合长短期记忆网络[Hochreiter and Schmidhuber, 1997]和1维卷积，Wu和Tan[2016]首先提出一个特征层面融合的架构CLTFP来预测短期交通状况。尽管它采取了一个很简单的策略，CLTFP仍然是第一个尝试对时间和空间规律性对齐的方法。后来，Shi &lt;em>et al.&lt;/em>[2015]提出了卷积LSTM，这是一个带有嵌入卷积层的全连接LSTM的扩展。然而，常规的卷积操作限制了模型只能处理常规的网格结构（如图像或视频），而不是其他的大部分领域（比如Graph）。与此同时，循环神经网络对于序列的学习需要迭代训练，这会导致误差的积累。更进一步地说，循环神经网络（包括基于LSTM的RNN）的难以训练和计算量大是众所周知的。&lt;/p>
&lt;p>为了克服这些问题，我们引入了一些策略来有效的对交通流的时间动态和空间依赖进行建模。为了完全利用空间信息，我们通过一个广义图对交通网络建模，而不是将交通流看成各个离散的部分（比如网格或碎块）。为了处理循环神经网络的缺陷，我们在时间轴上部署了一个全卷积结构来阻止累积效应（cumulative effects）并且加速模型的训练过程。综上所述，我们提出了一个新的神经网络架构，时空图卷积网络，来预测交通情况。这个架构由多个时空图卷积块组成，这些都是图卷积层和卷积序列学习层（convolutional sequence learning layers）的组合，用来对时间和空间依赖关系进行建模。&lt;/p>
&lt;p>我们的主要贡献可以归纳为以下三点：&lt;/p>
&lt;ol>
&lt;li>我们研究了在交通领域时间与空间依赖结合的好处。为了充分利用我们的知识，这是在交通研究中第一次应用纯卷积层来同时从图结构的时间序列中提取时空信息。&lt;/li>
&lt;li>我们提出了一个新的由时空块组成的神经网络结构。由于这个架构中是纯卷积操作，它比基于RNN的模型的训练速度快10倍以上，而且需要的参数更少。这个架构可以让我们更有效地处理更大的路网，这部分将在第四部分展示。&lt;/li>
&lt;li>我们在两个真实交通数据集上验证了提出来的网络。这个实验显示出我们的框架比已经存在的在多长度预测和网络尺度上的模型表现的更好。&lt;/li>
&lt;/ol>
&lt;h1 id="准备工作">准备工作
&lt;/h1>&lt;h2 id="路网上的交通预测">路网上的交通预测
&lt;/h2>&lt;p>交通预测是一个典型的时间序列预测问题，也就是预测在给定前M个观测样本接下来H个时间戳后最可能的交通流指标（比如速度或交通流），&lt;/p>
&lt;p>$$&lt;/p>
&lt;pre>&lt;code>\tag{1} \hat{v}\_{t+1}, ..., \hat{v}\_{t+H} = \mathop{\arg\min}\_{v\_{t+1},...,v\_{t+H}}logP(v\_{t+1},...,v\_{t+H}\vert v\_{t-M+1},...v\_t)
&lt;/code>&lt;/pre>
&lt;p>$$&lt;/p>
&lt;p>这里$v_t \in \mathbb{R}^n$是$n$个路段在时间戳$t$观察到的一个向量，每个元素记录了一条路段的历史观测数据。&lt;/p>
&lt;p>在我们的工作中，我们在一个图上定义了一个交通网络，并专注于结构化的交通时间序列。观测到的样本$v_t$间不是相互独立的，而是在图中两两相互连接的。因此，数据点$v_t$可以被视为定义在权重为$w_{ij}$，如图1展示的无向图（或有向图）$\mathcal{G}$上的一个信号。在第$t$个时间戳，在图$\mathcal{G_t}=(\mathcal{V_t}, \mathcal{\varepsilon}, W)$, $\mathcal{V_t}$是当顶点的有限集，对应在交通网络中$n$个监测站；$\epsilon$是边集，表示观测站之间的连通性；$W \in \mathbb{R^{n \times n}}$表示$\mathcal{G_t}$的邻接矩阵。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig1.PNG"
loading="lazy"
alt="Fig1"
>&lt;/p>
&lt;h2 id="图上的卷积">图上的卷积
&lt;/h2>&lt;p>传统网格上的标准卷积很明显是不能应用在广义图上的。现在有两个基本的方法正在探索如何泛化结构化数据上的CNN。一个是扩展卷积的空间定义[Niepert &lt;em>et al.&lt;/em>, 2016]，另一个是使用图傅里叶变换在谱域中进行操作[Bruna &lt;em>et al.&lt;/em>, 2013]。前一个方法重新将顶点安排至确定的表格形式内，然后就可以使用传统的卷积方法了。后者引入了谱框架，在谱域中应用图卷积，经常被称为谱图卷积。一些后续的研究通过将时间复杂度从$O(n^2)$降至线性[Defferrard &lt;em>et al.&lt;/em>, 2016;Kipf and Welling, 2016]使谱图卷积的效果更好。
我们基于谱图卷积的定义引入图卷积操作“$\ast_{\mathcal{G}}$”的符号，也就是一个核$\Theta$和信号$x \in \mathbb{R}^n$的乘法，&lt;/p>
$$\tag{2} \Theta \ast\_{\mathcal{G}}x=\Theta(L)x=\Theta(U \Lambda U^T)x=U\Theta(\Lambda)U^Tx$$&lt;p>这里图的傅里叶基$U \in \mathbb{R}^{n \times n}$是归一化的拉普拉斯矩阵$L=I_n-D^{-1/2}WD^{-1/2}= U \Lambda U^T \in \mathbb{R}^{n \times n}$的特征向量组成的矩阵，其中$I_n$是单位阵，$D \in \mathbb{R}^{n \times n}$是对角的度矩阵$D_{ii}=\sum_j{W_{ij}}$；$\Lambda \in \mathbb{R}^{n \times n}$是$L$的特征值组成的矩阵，卷积核$\Theta(\Lambda)$是一个对角矩阵。通过这个定义，一个图信号$x$是被一个核$\Theta$通过$\Theta$和图傅里叶变换$U^Tx$[Shuman &lt;em>et al.&lt;/em>, 2013]过滤的。&lt;/p>
&lt;h1 id="提出的模型">提出的模型
&lt;/h1>&lt;h2 id="网络架构">网络架构
&lt;/h2>&lt;p>在这部分，我们详细说明了时空图卷积网络的框架。如图二所示，STGCN有多个时空卷积块组成，每一个都是像一个“三明治”结构的组成，有两个门序列卷积层和一个空间图卷积层在中间。每个模块的细节如下。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig2.PNG"
loading="lazy"
alt="Fig2"
>&lt;/p>
&lt;p>图二：时空图卷积网络的架构图。STGCN的架构有两个时空卷积块和一个全连接的在末尾的输出层组成。每个ST-Conv块包含了两个时间门卷积层，中间有一个空间图卷积层。每个块中都使用了残差连接和bottleneck策略。输入$v_{t-M+1},&amp;hellip;v_t$被ST-Conv块均匀的（uniformly）处理，来获取时空依赖关系。全部特征由一个输出层来整合，生成最后的预测$\hat{v}$。&lt;/p>
&lt;h2 id="提取空间特征的图卷积神经网络">提取空间特征的图卷积神经网络
&lt;/h2>&lt;p>交通网络大体上是一个图结构。由数学上的图来构成路网是很自然也很合理的。然而，之前的研究忽视了交通网络的空间属性：因为交通网络被分成了块或网格状，所以网络的全局性和连通性被过分的关注了。即使是在网格上的二维卷积，由于数据建模的折中，也只能捕捉到大体的空间局部性。根据以上情况，在我们的模型中，图卷积被直接的应用在了图结构数据上为了在空间中抽取很有意义的模式和特征。集是在图卷积中由式2可以看出核$\Theta$的计算的时间复杂度由于傅里叶基的乘法可以达到$O(n^2)$，两个近似的策略可以解决这个问题。&lt;/p>
&lt;p>&lt;strong>切比雪夫多项式趋近&lt;/strong>&lt;/p>
&lt;p>为了局部化过滤器并且减少参数，核$\Theta$可以被一个关于$\Lambda$的多项式限制起来，也就是$\Theta(\Lambda)=\sum_{k=0}^{K-1} \theta_k \Lambda^k$，其中$\theta \in \mathbb{R}^K$是一个多项式系数的向量。$K$是图卷积核的大小，它决定了卷积从中心节点开始的最大半径。一般来说，切比雪夫多项式$T_k(x)$被用于近似核，作为$K-1$阶展开的一部分，也就是$\Theta(\Lambda) \approx \sum_{k=0}^{K-1} \theta_k T_k(\widetilde{\Lambda})$，其中$\widetilde{\Lambda}=2\Lambda/\lambda_{max}-I_n$（$\lambda_{max}$表示$L$的最大特征值）[Hammond &lt;em>et al.&lt;/em>, 2011]。图卷积因此可以被写成&lt;/p>
$$
\tag{3} \Theta \ast\_{\mathcal{G}} x = \Theta(L)x \approx \sum\_{k=0}^{K-1}\theta\_k T\_k(\widetilde{L})x
$$&lt;p>其中$T_k(\widetilde{L}) \in \mathbb{R}^{n \times n}$是k阶切比雪夫多项式对缩放后（scaled）的拉普拉斯矩阵$\widetilde{L}=2L/\lambda_{max}-I_n$。通过递归地使用趋近后的切比雪夫多项式计算K阶卷积操作，式2的复杂度可以被降低至$O(K\vert \varepsilon \vert)$，如式3所示[Defferrard &lt;em>et al.&lt;/em>, 2016]。&lt;/p>
&lt;p>&lt;strong>1阶近似&lt;/strong>&lt;/p>
&lt;p>一个针对层的线性公式可以由堆叠多个使用拉普拉斯矩阵的一阶近似的局部图卷积层[Kipf and Welling, 2016]。结果就是，这样可以构建出一个深的网络，这个网络可以深入地恢复空间信息并且不需要指定多项式中的参数。由于在神经网络中要缩放和归一化，我们可以进一步假设$\lambda_{max} \approx 2$。因此，式3可以简写为&lt;/p>
$$
\begin{aligned}
\Theta \ast\_{\mathcal{G}}x \approx &amp; \theta\_0x+\theta\_1(\frac{2}{\lambda\_{max}}L-I\_n)x\\
\approx &amp; \theta\_0 x- \theta\_1(D^{-\frac{1}{2}} W D^{-\frac{1}{2}}) x
\end{aligned}
$$&lt;p>其中，$\theta_0$，$\theta_1$是核的两个共享参数。为了约束参数并为稳定数值计算，$\theta_0$和$\theta_1$用一个参数$\theta$来替换，$\theta=\theta_0=-\theta_1$；$W$和$D$是通过$\widetilde{W}=W+I_n$和$\widetilde{D}_{ii}=\sum_j\widetilde{W}_{ij}$重新归一化得到的。之后，图卷积就可以表达为&lt;/p>
$$
\begin{aligned}
\Theta \ast\_{\mathcal{G}} x = &amp; \theta(I\_n + D^{-\frac{1}{2}} W D^{\frac{1}{2}})x\\
= &amp; \theta (\widetilde{D}^{-\frac{1}{2}} \widetilde{W} \widetilde{D}^{-\frac{1}{2}})x
\end{aligned}
$$&lt;p>竖直地堆叠一阶近似的图卷积可以获得和平行的K阶卷积相同的效果，所有的卷积可以从一个顶点的$K-1$阶邻居中获取到信息。在这里，$K$是连续卷积操作的次数或是模型中的卷积层数。进一步说，针对层的线性结构是节省参数的，并且对大型的图来说是效率很高的，因为多项式趋近的阶数为1。&lt;/p>
&lt;p>&lt;strong>图卷积的泛化&lt;/strong>&lt;/p>
&lt;p>图卷积操作$\ast_{\mathcal{G}}$也可以被扩展到多维张量上。对于一个有着$C_i$个通道的信号$X \in \mathbb{R}^{n \times C_i}$，图卷积操作可以扩展为&lt;/p>
$$
y\_j = \sum\_{i=1}^{C\_i} \Theta\_{i,j}(L) x\_i \in \mathbb{R}^n, 1 \leq j \leq C\_o
$$&lt;p>其中，$C_i \times C_o$个向量是切比雪夫系数$\Theta_{i,j} \in \mathbb{R}^K$（$C_i$，$C_o$分别是feature map的输入和输出大小）。针对二维变量的图卷积表示为$\Theta \ast_{\mathcal{G}} X$，其中$\Theta \in \mathbb{R}^{K \times C_i \times C_o}$。需要注意的是，输入的交通预测是由$M$帧路网组成的，如图1所示。每帧$v_t$可以被视为一个矩阵，它的第$i$列是图$\mathcal{G_t}$中第$i$个顶点的一个为$C_i$维的值，也就是$X \in \mathbb{R}^{n \times C_i}$（在这个例子中，$C_i=1$）。对于$M$中的每个时间步$t$，相同的核与相同的图卷积操作是在$X_t \in \mathbb{R}^{n \times C_i}$中并行进行的。因此，图卷积操作也可以泛化至三维，记为$\Theta \ast_{\mathcal{G}} \mathcal{X}$，其中$\mathcal{X} \in \mathbb{R}^{M \times n \times C_i}$&lt;/p>
&lt;h2 id="抽取时间特征的门控卷积神经网络">抽取时间特征的门控卷积神经网络
&lt;/h2>&lt;p>尽管基于RNN的模型可以广泛的应用于时间序列分析，用于交通预测的循环神经网络仍然会遇到费时的迭代，复杂的门控机制，对动态变化的响应慢。相反，CNN训练快，结构简单，而且不依赖于前一步。受到[Gehring &lt;em>et al.&lt;/em>, 2017]的启发，我们在时间轴上部署了整块的卷积结构，用来捕获交通流的动态时间特征。这个特殊的设计可以让并行而且可控的训练过程通过多层卷积结构形成层次表示。&lt;/p>
&lt;p>如图2右侧所示，时间卷积层包含了一个一维卷积，核的宽度为$K_t$，之后接了一个门控线性单元(GLU)作为激活。对于图$\mathcal{G}$中的每个顶点，时间卷积对输入元素的$K_t$个邻居进行操作，导致每次将序列长度缩短$K_t-1$。因此，每个顶点的时间卷积的输入可以被看做是一个长度为$M$的序列，有着$C_i$个通道，记作$Y \in \mathbb{R}^{M \times C_i}$。卷积核$\Gamma \in \mathbf{R}^{K_t \times C_i \times 2C_o}$是被设计为映射$Y$到一个单个的输出$[P Q] \in \mathbb{R}^{(M-K_t+1) \times (2C_o)}$($P$, $Q$是通道数的一半)。作为结果，时间门控卷积可以定义为：&lt;/p>
$$
\Gamma \ast\_ \tau Y = P \otimes \sigma (Q) \in \mathbb{R}^{(M-K\_t+1) \times C\_o}
$$&lt;p>其中，$P$, $Q$分别是GLU的输入门，$\otimes$表示哈达玛积，sigmoid门$\sigma(Q)$控制当前状态的哪个输入$P$对于发现时间序列中的组成结构和动态方差是相关的。非线性门通过堆叠时间层对挖掘输入也有贡献。除此以外，在堆叠时间卷积层时，实现了残差连接。相似地，通过在每个节点$\mathcal{Y_i} \in \mathbb{R}^{M \times C_i}$(比如监测站)上都使用同样的卷积核$\Gamma$，时间卷积就可以泛化至3D变量上，记作$\Gamma \ast_\tau \mathcal{Y}$，其中$\mathcal{Y} \in \mathbb{R}^{M \times n \times C_i}$。&lt;/p>
&lt;p>&lt;strong>这里我之前认为残差是用了 padding 的，其实不是，看了作者的代码后发现作者是用了一半数量的卷积核完成卷积，这样就和 P 的维度一致了，然后直接和 P 相加，然后与 sigmoid 激活后的值进行点对点的相乘。&lt;/strong>&lt;/p>
&lt;h2 id="时空卷积块">时空卷积块
&lt;/h2>&lt;p>为了同时从空间和时间领域融合特征，时空卷积块(ST-Conv block)的构建是为了同时处理图结构的时间序列的。如图2（中）所示，bottleneck策略的应用形成了三明治的结构，其中含有两个时间门控卷积层，分别在上下两层，一个空间图卷积层填充中间的部分。空间卷积层导致的通道数$C$的减小促使了参数的减少，并且减少了训练的时间开销。除此以外，每个时空块都使用了层归一化来抑制过拟合。&lt;/p>
&lt;p>ST-Conv块的输入和输出都是3D张量。对于块$l$的输入$v^l \in \mathbb{R}^{M \times n \times C^l}$，输出$v^{l+1} \in \mathbb{R}^{(M-2(K_t-1)) \times n \times C^{l+1}}$通过以下式子计算得到：&lt;/p>
$$
v^{l+1} = \Gamma^l\_1 \ast\_\tau \rm ReLU(\Theta^l \ast\_{\mathcal{G}}(\Gamma^l\_0 \ast\_\tau v^l))
$$&lt;p>其中$\Gamma^l_0$，$\Gamma^l_1$是块$l$的上下两个时间层；$\Theta^l$是图卷积谱核；$\rm ReLU(·)$表示ReLU激活函数。我们在堆叠两个ST-Conv块后，加了一个额外的时间卷积和全连接层作为最后的输出层（图2左侧）。时间卷积层将最后一个ST-Conv块的输出映射到一个最终的单步预测上。之后，我们可以从模型获得一个最后的输出$Z \in \mathbb{R}^{n \times c}$，通过一个跨$c$个通道的线性变换$\hat{v} = Zw+b$来预测$n$个节点的速度，其中$w \in \mathbb{R}^c$是权重向量,$b$是偏置。对交通预测的STGCN的损失函数可以写成：&lt;/p>
$$
L(\hat{v}; W\_\theta) = \sum\_t \Vert \hat{v}(v\_{t-M+1, ..., v\_t, W\_\theta}) - v\_{t+1} \Vert^2
$$&lt;p>其中，$W_\theta$是模型中所有的训练参数; $v_{t+1}$是ground truth，$\hat{v}(·)$表示模型的预测。&lt;/p>
&lt;p>我们来总结一下我们的STGCN的主要特征：&lt;/p>
&lt;ol>
&lt;li>STGCN是处理结构化的时间序列的通用框架，不仅可以解决交通网络建模，还可以应用到其他的时空序列学习的挑战中，比如社交网络和推荐系统。&lt;/li>
&lt;li>时空块融合了图卷积和门控时间卷积，可以同时抽取有用的空间信息，捕获本质上的时间特征。&lt;/li>
&lt;li>模型完全由卷积层组成，因此可以在输入序列上并行运算，空间域中参数少易于训练。更重要的是，这个经济的架构可以使模型更高效的处理大规模的网络。&lt;/li>
&lt;/ol>
&lt;h1 id="实验">实验
&lt;/h1>&lt;h2 id="数据集描述">数据集描述
&lt;/h2>&lt;p>我们在两个真实的数据集上验证了模型，分别是&lt;strong>BJER4&lt;/strong>和&lt;strong>PeMSD7&lt;/strong>，由北京市交委和加利福尼亚运输部提供。每个数据集包含了交通观测数据的关键属性和对应时间的地图信息。&lt;/p>
&lt;p>&lt;strong>BJER4&lt;/strong>是通过double-loop detector获取的东四环周边的数据。我们的实验中有12条道路。交通数据每五分钟聚合一次。时间是从2014年的7月1日到8月31日，不含周末。我们选取了第一个月的车速速度记录作为训练集，剩下的分别做验证和测试。&lt;/p>
&lt;p>&lt;strong>PeMSD7&lt;/strong>是Caltrans Performance Measurement System(PeMS)通过超过39000个监测站实时获取的数据，这些监测站分布在加州高速公路系统主要的都市部分[Chen &lt;em>et al&lt;/em>., 2001]。数据是30秒的数据样本聚合成5分钟一次的数据。我们在加州的District 7随机选取了一个小的和一个大的范围作为数据源，分别有228和1026个监测站，分别命名为PeMSD7(S)和PeMSD7(L)（如图3左侧所示）。PeMSD7数据集的时间范围是2012年五月和六月的周末。我们使用同样的原则对数据进行了训练集和测试集的划分。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig3.PNG"
loading="lazy"
alt="Fig1"
>&lt;/p>
&lt;h2 id="数据预处理">数据预处理
&lt;/h2>&lt;p>两个数据集的间隔设定为5分钟。因此，路网中的每个顶点每天就有288个数据点。数据清理后使用了线性插值的方法来填补缺失值。通过核对相关性，每条路的方向和OD(origin-destination)点，环路系统可以被数值化成一个有向图。&lt;/p>
&lt;p>在PeMSD7，路网的邻接矩阵通过交通网络中的监测站的距离来计算。带权邻接矩阵$W$通过以下公式计算：&lt;/p>
$$
w\_{ij} = \begin{cases}
\exp{(-\frac{d^2\_{ij}}{\sigma^2})}&amp;,i \neq j \ \rm and \exp{(-\frac{d^2\_{ij}}{\sigma^2}) \geq \epsilon} \\
0&amp;, \rm otherwise
\end{cases}
$$&lt;p>其中$w_{ij}$是边的权重，通过$d_{ij}$得到，也就是$i$和$j$之间的距离。$\sigma^2$和$\epsilon$是来控制矩阵$W$的分布和稀疏性的阈值，我们用了10和0.5。$W$的可视化在图3的右侧。&lt;/p>
&lt;h1 id="代码">代码
&lt;/h1>&lt;p>&lt;a class="link" href="https://github.com/VeritasYin/STGCN_IJCAI-18" target="_blank" rel="noopener"
>作者代码&lt;/a>，这个是作者提供的代码。&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/Davidham3/STGCN" target="_blank" rel="noopener"
>仓库地址&lt;/a>，我按照论文结合作者的代码进行了复现与修正。&lt;/p></description></item><item><title>Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition</title><link>https://davidham3.github.io/blog/p/spatial-temporal-graph-convolutional-networks-for-skeleton-based-action-recognition/</link><pubDate>Wed, 18 Apr 2018 10:43:36 +0000</pubDate><guid>https://davidham3.github.io/blog/p/spatial-temporal-graph-convolutional-networks-for-skeleton-based-action-recognition/</guid><description>&lt;p>AAAI 2018，以人体关节为图的顶点，构建空间上的图，然后通过时间上的关系，连接连续帧上相同的关节，构成一个三维的时空图。针对每个顶点，对其邻居进行子集划分，每个子集乘以对应的权重向量，得到时空图上的卷积定义。实现时使用Kipf &amp;amp; Welling 2017的方法实现。原文链接：&lt;a class="link" href="https://arxiv.org/abs/1801.07455" target="_blank" rel="noopener"
>Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition&lt;/a>&lt;/p>
&lt;h1 id="摘要">摘要
&lt;/h1>&lt;p>人体骨骼的动态传递了用于人体动作识别的很多信息。传统方法需要手工和遍历规则，导致表现力的限制和泛化的困难。我们提出了动态骨骼识别的新模型，STGCN，可以从数据中自动学习时空模式。这套理论有很强的表达能力与泛化能力。在两个大型数据集Kinetics和NTU-RGBD上比主流方法表现的更好。&lt;/p>
&lt;h1 id="1-引言">1 引言
&lt;/h1>&lt;p>动作识别在视频理解中很有用。一般，从多个角度识别人体动作，如外表、景深、光源、骨骼。对骨骼建模受到的关注较外表和光源较少，我们系统的研究了这个模态，目的是研发出一个有效的对动态骨骼建模的方法，服务于动作识别。&lt;/p>
&lt;p>动态骨骼模态很自然地表示成人体关节的时间序列，以2D或3D坐标的形式。人体动作可以通过分析移动规律来识别。早期的工作只用每帧的关节坐标生成特征向量，然后使用空间分析（Wang et al., 2012; Fernando et al., 2015）。这些方法能力受限的原因是他们没有挖掘关节之间的空间信息，但是这些信息对于理解人体动作来说很关键。最近，新的方法尝试利用关节间的自然连接关系(Shahroudy et al., 2016; Du, Wang, and Wang 2015)。这些方法都有提升，表明了连接的重要性。然而，很多显存的方法依赖手工的部分或是分析空间模式的规则。结果导致针对特定问题设计的模型不能泛化。&lt;/p>
&lt;p>为了跨越这些限制，我们需要一个新的方法能自动捕获关节的空间配置与时间动态性中嵌入的模式。这就是深度神经网络的优势了。由于骨骼是图结构，不是2D或3D网格，因此传统的CNN不行，最近GCN已经成功的应用在了一些应用上，如图像分类(Bruna et al., 2014)，文档分类(Defferrard, Bresson, and Vandergheynst 2016)，还有半监督学习(Kipf and Welling 2017)。然而，这些工作都假设一个固定的图作为输入。GCN的应用在大尺度的数据集上对动态图建模，如人体骨骼序列还没有被挖掘过。&lt;/p>
&lt;p>![Fig1]](/blog/images/spatial-temporal-graph-convolutional-networks-for-skeleton-based-action-recognition/Fig1.JPG)
我们将图网络扩展到一个时空图模型来对骨骼序列进行表示后识别动作。图1所示，这个模型基于一个骨骼图序列，每个顶点表示人体的一个关节。有两种类型的边，空间边，连接关节，时间边连接连续时间的同一关节。构建在上面的时空卷积可以同时集成时间和空间上的信息。&lt;/p>
&lt;p>ST-GCN的层次本质消除了手工和遍历部分。不仅有更强的表达能力和更好的表现，也更简单的泛化到其他环境中。在基础的GCN公式基础上，受到图像模型的启发，我们还提出了设计图卷积核新的策略。&lt;/p>
&lt;p>我们的工作有三点贡献：&lt;/p>
&lt;ol>
&lt;li>提出了ST-GCN，对动态骨骼建模的基于图结构的模型，第一个应用基于图的神经网络到这个任务上。&lt;/li>
&lt;li>设计ST-GCN的卷积核时提出了几个原则使得在骨骼建模时满足特定的需求。&lt;/li>
&lt;li>在两个大尺度数据集上，我们提出的模型效果比之前的手工和遍历规则的方法强。
代码和模型：https://github.com/yysijie/st-gcn&lt;/li>
&lt;/ol>
&lt;h1 id="2-相关工作">2 相关工作
&lt;/h1>&lt;p>两类方法&lt;/p>
&lt;ol>
&lt;li>谱方法，谱分析中考虑图卷积的局部形式(Henaff, Bruna, and LeCun 2015; Duvenaud et al., 2015; Li et al., 2016; Kipf and Welling., 2017)&lt;/li>
&lt;li>空间方法，卷积核直接在顶点和他们的邻居上做卷积(Bruna et al., 2014; Niepert, Ahmed, and Kutzkov 2016)。我们的工作follow了第二种方法。我们在空间领域构建CNN滤波器，通过限制滤波器到每个顶点的一阶邻居上。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>骨骼动作识别&lt;/strong> 方法可分为手工方法和深度学习方法。第一类是手工设计特征捕获关节移动的动态性。可以是关节轨迹的协方差矩阵(Hussein et al., 2013)，关节的相对位置(Wang et al., 2012)，身体部分的旋转和变换(Vemulapalli, Arrate, and Chellappa 2014)。深度学习的工作使用RNN(Shahroudy et al., 2016; Zhu et al. 2016; Liu et al. 2016; Zhang, Liu and Xiao 2017)和时间CNN(Li et al. 2017; Ke et al. 2017; Kim and Reiter 2017)用端到端的方式学习动作识别模型。这些方法中很多强调了将关节与身体部分建模的重要性。但这些都需要领域知识。我们的ST-GCN是第一个将图卷积用在骨骼动作识别上的。不同于之前的方法，我们的方法可以利用图卷积的局部性和时间动态性学习身体部分的信息。通过消除手工部分标注的需要，模型更容易去设计，而且能学到更好的动作表示。&lt;/p>
&lt;h1 id="3-spatial-temporal-graph-convnet">3 Spatial Temporal Graph ConvNet
&lt;/h1>&lt;p>人们在活动的时候，关节只在一个范围内活动，这个部分称为body parts。已有的方法已经证明了将body parts融入到模型中是很有效的(Shahroudy et al., 2016; Liu et al., 2016; Zhang, Liu and Xiao 2017)。我们认为提升很有可能是因为parts将关节轨迹限制在了局部区域中。像物体识别这样的任务，层次表示和局部性通常是卷积神经网络潜在就可以获得的(Krizhevsky, Sutskever, and Hinton 2012)，而不是手动分配的。这使得我们在基于骨骼的动作识别中引入CNN的性质。结果就是ST-GCN模型的尝试。&lt;/p>
&lt;h2 id="31-pipeline-overview">3.1 Pipeline Overview
&lt;/h2>&lt;p>骨骼数据通过动作捕捉设备和动作估计算法即可从视频中获得。通常数据是一系列的帧，每帧有一组关节坐标。给定身体关节2D或3D的坐标序列，我们构建了一个时空图，关节作图的顶点，身体结构或时间作边。ST-GCN的输入因此就是关节坐标向量。可以认为这是基于图片的CNN的近似，后者的输入是2D网格中的像素向量。多层时空图卷积操作加到输入上会生成更高等级的特征。然后使用softmax做费雷。整个模型以端到端的方式进行训练。&lt;/p>
&lt;h2 id="32-骨骼图构建">3.2 骨骼图构建
&lt;/h2>&lt;p>骨骼序列通常表示成每帧都是人体关节的2D或3D坐标。之前使用卷积来做骨骼动作识别的工作(Kim and Reiter 2017)拼接了在每帧拼接了所有关节的坐标向量来生成一个特征向量。我们的工作中，我们利用时空图来生成骨骼序列的层次表示。特别地，我们构建了无向时空图$G = (V, E)$，$N$个关节，$T$帧描述身体内和帧与帧之间的连接。&lt;/p>
&lt;p>顶点集$V = \lbrace v_{ti} \mid t = 1, &amp;hellip;, T, i = 1, &amp;hellip;, N \rbrace$包含了骨骼序列中所有的关节。ST-GCN的输入，每个顶点的特征向量$F(v_{ti})$由第$t$帧的第$i$个关节的坐标向量组成，还有estimation confidence。构建时空图分为两步，第一步，一帧内的关节通过人体结构连接，如图1所示。然后每个关节在连续的帧之间连接起来。这里不需要人工干预。举个例子，Kinetics数据集，我们使用OpenPose toolbox(Cao et al., 2017b)2D动作估计生成了18个关节，而NTU-RGB+D(Shahroudy et al., 2016)数据集上使用3D关节追踪产生了25个关节。ST-GCN可以在这两种情况下工作，并且提供一致的优越性能。图1就是时空图的例子。
严格来说，边集$E$由两个子集组成，第一个子集描述了每帧骨骼内的连接，表示为$E_S = \lbrace v_{ti}v_{tj} \mid (i, j) \in H \rbrace$，$H$是自然连接的关节的结合。第二个子集是连续帧的相同关节$E_F = \lbrace v_{ti} v_{(t+1)i} \rbrace$，因此$E_F$中所有的边对于关节$i$来说表示的是它随时间变化的轨迹。&lt;/p>
&lt;p>&lt;img src="https://davidham3.github.io/blog/images/spatial-temporal-graph-convolutional-networks-for-skeleton-based-action-recognition/Fig2.JPG"
loading="lazy"
alt="Fig2"
>&lt;/p>
&lt;h2 id="33-空间图卷积神经网络">3.3 空间图卷积神经网络
&lt;/h2>&lt;p>时间$\tau$上，$N$个关节顶点$V_t$，骨骼边集$E_S(\tau) = \lbrace v_{ti} v_{tj} \mid t = \tau, (i, j) \in H \rbrace$。图像上的2D卷积的输入和输出都上2D网格，stride设为1时，加上适当的padding，输出的size就可以不变。给定一个$K \times K$的卷积操作，输入特征$f_{in}$的channels数是$c$。在空间位置$\mathbf{x}$的单个通道的输出值可以写成：&lt;/p>
$$\tag{1}
f\_{out}(\mathbf{x}) = \sum^K\_{h=1} \sum^K\_{w=1} f\_{in}(\mathbf{p}(\mathbf{x}, h, w)) \cdot \mathbf{w}(h, w)
$$&lt;p>&lt;strong>采样函数&lt;/strong>$\mathbf{p} : Z^2 \times Z^2 \rightarrow Z^2$对$\mathbf{x}$的邻居遍历。在图像卷积中，也可表示成$\mathbf{p}(\mathbf{x}, h, w) = \mathbf{x} + \mathbf{p}&amp;rsquo;(h, w)$。&lt;/p>
&lt;p>&lt;strong>权重函数&lt;/strong>$\mathbf{w}: Z^2 \rightarrow \mathbb{R}^c$提供了一个$c$维的权重向量，与采出的$c$维输入特征向量做内积。需要注意的是权重函数与输入位置$\mathbf{x}$无关。因此滤波器权重在输入图像上是共享的。图像领域标准的卷积通过对$\mathbf{p}(x)$中的举行进行编码得到。更多解释和应用可以看(Dai et al., 2017)。&lt;/p>
&lt;p>图上的卷积是对上式的扩展，输入是空间图$V_t$。feature map $f^t_{in}: V_t \rightarrow R^c$在图上的每个顶点有一个向量。下一步扩展是重新定义采样函数$\mathbf{p}$，权重函数是$\mathbf{w}$。&lt;/p>
&lt;p>&lt;strong>采样函数.&lt;/strong> 图像中，采样函数$\mathbf{p}(h, w)$定义为中心位置$\mathbf{x}$的邻居像素。图中，我们可以定义相似的采样函数在顶点$v_{ti}$的邻居集合上$B(v_{ti}) = \lbrace v_{tj} \mid d(v_{tj}, v_{ti} \leq D \rbrace)$。这里$d(v_{tj}, t_{ti})$表示从$v_{tj}$到$v_{ti}$的任意一条路径中最短的。因此采样函数$\mathbf{p}: B(v_{ti}) \rightarrow V$可以写成：
&lt;/p>
$$\tag{2}
\mathbf{p}(v\_{ti}, v\_{tj}) = v\_{tj}.
$$&lt;p>
我们令$D = 1$，也就是关节的一阶邻居。更高阶的邻居会在未来的工作中实现。&lt;/p>
&lt;p>&lt;strong>权重函数.&lt;/strong> 对比采样函数，权重函数在定义时更巧妙。在2D卷积，网格型自然就围在了中心位置周围。所以像素与其邻居有个固定的顺序。权重函数根据空间顺序通过对维度为$(c, K, K)$的tensor添加索引来实现。对于像我们构造的这种图，没有这种暗含的关系。解决方法由(Niepert, Ahmed, and Kuzkov 2016)提出，顺序是通过根节点周围的邻居节点的标记顺序确定。我们根据这个思路构建我们的权重函数。不再给每个顶点一个标签，我们通过将顶点$v_{ti}$的邻居集合$B(v_{ti})$划分为$K$个子集来简化过程，其中每个子集都有一个数值型标签。因此我们可以得到一个映射$l_{ti}:B(v_{ti}) \rightarrow \lbrace 0,&amp;hellip;,K-1 \rbrace$，这个映射将顶点映射到它的邻居子集的标签上。权重函数$\mathbf{w}(v_{ti}, v_{tj}):B(v_{ti}) \rightarrow R^c$可以通过对维度为$(c, K)$的tensor标记索引或
&lt;/p>
$$\tag{3}
\mathbf{w}(v\_{ti}, v\_{tj}) = \mathbf{w}'(l\_{ti}(v\_{tj})).
$$&lt;p>
我们会在3.4节讨论分区策略。&lt;/p>
&lt;p>&lt;strong>空间图卷积.&lt;/strong> 我们可以将式1重写为：
&lt;/p>
$$\tag{4}
f\_{out}(v\_{ti}) = \sum\_{v\_{tj} \in B(v\_{ti})} \frac{1}{Z\_{ti}(v\_{tj})} f\_{in}(\mathbf{p}(v\_{ti}, v\_{tj})) \cdot \mathbf{w}(v\_{ti}, v\_{tj}),
$$&lt;p>
其中归一化项$Z_{ti}(v_{tj}) = \vert \lbrace v_{tk} \mid l_{ti}(v_{tk}) = l_{ti}(t_{tj}) \rbrace \vert$等于对应子集的基数。这项被加入是来平衡不同子集对输出的贡献。
替换式2和式3，我们可以得到
&lt;/p>
$$\tag{5}
f\_{out}(v\_{ti}) = \sum\_{v\_{tj} \in B(v\_{ti})} \frac{1}{Z\_{ti}(v\_{tj})} f\_{in}(v\_{tj}) \cdot \mathbf{w}(l\_{ti}(v\_{tj})).
$$&lt;p>
这个公式与标准2D卷积相似如果我们将图片看作2D网格。比如，$3 \times 3$卷积核的中心像素周围有9个像素。邻居集合应被分为9个子集，每个子集有一个像素。&lt;/p>
&lt;p>&lt;strong>时空建模.&lt;/strong> 通过对空间图CNN的构建，我们现在可以对骨骼序列的时空动态性进行建模。回想图的构建，图的时间方面是通过在连续帧上连接相同的关节进行构建的。这可以让我们定义一个很简单的策略来扩展空间图CNN到时空领域。我们扩展邻居的概念到包含空间连接的关节：
&lt;/p>
$$\tag{6}
B(v\_{ti}) = \lbrace v\_{qj} \mid d(v\_{tj}, v\_{ti}) \leq K, \vert q - t \vert \leq \lfloor \Gamma / 2 \rfloor \rbrace.
$$&lt;p>
参数$\Gamma$控制被包含到邻居图的时间范围，因此被称为空间核的大小。我们需要采样函数来完成时空图上的卷积操作，与只有空间卷积一样，我们还需要权重函数，具体来说就是映射$l_{ST}$。因为空间轴是有序的，我们直接修改根节点为$v_{ti}$的时空邻居的标签映射$l_{ST}$为：
&lt;/p>
$$\tag{7}
l\_{ST}(v\_{qj}) = l\_{ti}(v\_{tj}) + (q - t + \lfloor \Gamma / 2 \rfloor) \times K,
$$&lt;p>
其中$l_{ti}(v_{tj})$是$v_{ti}$的单帧的标签映射。这样，我们就有了一个定义在时空图上的卷积操作。&lt;/p>
&lt;h2 id="34-分区策略">3.4 分区策略
&lt;/h2>&lt;p>设计一个实现标记映射的分区策略很重要。我们探索了几种分区策略。简单来说，我们只讨论单帧情况下，因为使用式7就可以很自然的扩展到时空领域。&lt;/p>
&lt;p>&lt;strong>Uni-labeling.&lt;/strong> 最简单的分区策略，所有的邻居都是一个集合。每个邻居顶点的特征向量会和同一个权重向量做内积。事实上，这个策略和Kipf and Welling 2017提出的传播规则很像。但是有个很明显的缺陷，在单帧的时候使用这种分区策略就是将邻居的特征向量取平均后和权重向量做内积。在骨骼序列分析中不能达到最优，因为丢失了局部性质。$K = 1$，$l_{ti}(v_{tj}) = 0, \forall{i, j} \in V$。&lt;/p>
&lt;p>&lt;strong>Distance partitioning.&lt;/strong> 另一个自然的分区策略是根据顶点到根节点$v_{ti}$的距离$d(\cdot, v_{ti})$来划分。我们设置$D = 1$，邻居集合会被分成两个子集，$d = 0$表示根节点子集，其他的顶点是在$d = 1$的子集中。因此我们有两个不同的权重向量，他们能对局部性质进行建模，比如关节间的相对变换。$K = 2$，$l_{ti}(v_{tj}) = d(v_{tj}, v_{ti})$&lt;/p>
&lt;p>&lt;strong>Spatial configuration partitioning.&lt;/strong> 因为骨骼是空间局部化的，我们仍然可以利用这个特殊的空间配置来分区。我们将邻居集合分为三部分：1. 根节点自己；2. 中心组：相比根节点更接近骨骼重心的邻居顶点；3. 其他的顶点。其中，中心定义为一帧中骨骼所有的关节的坐标的平均值。这是受到人体的运动大体分为同心运动和偏心运动两类。
&lt;/p>
$$\tag{8}
l\_{ti}(v\_tj) = \begin{cases}
0 &amp; if r\_j = r\_i \\
1 &amp; if r\_j &lt; r\_i \\
2 &amp; if r\_j > r\_i \end{cases}
$$&lt;p>
其中，$r_i$是训练集中所有帧的重心到关节$i$的平均距离。
分区策略如图3所示。我们通过实验检验提出的分区策略在骨骼动作识别上的表现。分区策略越高级，效果应该是越好的。
&lt;img src="https://davidham3.github.io/blog/images/spatial-temporal-graph-convolutional-networks-for-skeleton-based-action-recognition/Fig3.JPG"
loading="lazy"
alt="Fig3"
>&lt;/p>
&lt;h2 id="35-learnable-edge-importance-weighting">3.5 Learnable edge importance weighting
&lt;/h2>&lt;p>尽管人在做动作时关节是以组的形式移动的，但一个关节可以出现在身体的多个部分。然而，这些表现在建模时应该有不同的重要性。我们在每个时空图卷积层上添加了一个可学习的mask$M$。这个mask会基于$E_S$中每个空间图边上可学习的重要性权重来调整一个顶点的特征对它的邻居顶点的贡献。通过实验我们发现增加这个mask可以提升ST-GCN的性能。使用注意力映射应该也是可行的，这个留到以后再做。&lt;/p>
&lt;h2 id="36-implementation-st-gcn">3.6 Implementation ST-GCN
&lt;/h2>&lt;p>实现这个图卷积不像实现2D或3D卷积那样简单。我们提供了实现ST-GCN的具体细节。
我们采用了Kipf &amp;amp; Welling 2017的相似的实现方式。单帧内身体内关节的连接表示为一个邻接矩阵$\rm{A}$，单位阵$\rm{I}$表示自连接。在单帧情况下，ST-GCN使用第一种分区策略时可以实现为：
&lt;/p>
$$\tag{9}
\rm
f\_{out} = \Lambda^{-\frac{1}{2}}(A + I) \Lambda^{-\frac{1}{2}} f\_{in}W,
$$&lt;p>
其中，$\Lambda^{ii} = \sum_j (A^{ij} + I^{ij})$。多个输出的权重向量叠在一起形成了权重矩阵$\mathrm{W}$。实际上，在时空情况下，我们可以将输入的feature map表示为维度为$(C, V, T)$的tensor。图卷积通过一个$1 \times \Gamma$实现一个标准的2D卷积，将结果与归一化的邻接矩阵$\rm \Lambda^{-\frac{1}{2}}(A + I)\Lambda^{-\frac{1}{2}}$在第二个维度上相乘。&lt;/p>
&lt;p>对于多个子集的分区策略，我们可以再次利用这种实现。但注意现在邻接矩阵已经分解成了几个矩阵$A_j$，其中$\rm A + I = \sum_j A_j$。举个例子，在距离分区策略中，$\rm A_0 = I$，$\rm A_1 = A$。式9变形为
&lt;/p>
$$\tag{10}
\rm f\_{out} = \sum\_j \Lambda^{-\frac{1}{2}}\_j A\_j \Lambda^{\frac{1}{2}}\_j f\_{in} W\_j
$$&lt;p>
其中，$\rm \Lambda^{ii}_j = \sum_k (A^{ik}_j) + \alpha$。这里我们设$\alpha = 0.001$避免$\rm A_j$中有空行。&lt;/p>
&lt;p>实现可学习的边重要性权重很简单。对于每个邻接矩阵，我们添加一个可学习的权重矩阵$M$，替换式9中的$\rm A + I$和式10中的$\rm A_j$中的$A_j$为$\rm (A + I) \otimes M$和$\rm A_j \otimes M$。这里$\otimes$表示两个矩阵间的element-wise product。mask$M$初始化为一个全一的矩阵。&lt;/p></description></item></channel></rss>