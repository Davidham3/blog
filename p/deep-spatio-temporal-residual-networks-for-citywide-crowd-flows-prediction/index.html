<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：[Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction](https://arxiv.org/abs/1610.00081)"><title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</title><link rel=canonical href=https://davidham3.github.io/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/><link rel=stylesheet href=/blog/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction"><meta property='og:description' content="AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：[Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction](https://arxiv.org/abs/1610.00081)"><meta property='og:url' content='https://davidham3.github.io/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='Spatial-temporal'><meta property='article:tag' content='graph convolutional network'><meta property='article:tag' content='Graph'><meta property='article:tag' content='Time Series'><meta property='article:published_time' content='2019-03-08T10:26:16+00:00'><meta property='article:modified_time' content='2019-03-08T10:26:16+00:00'><meta name=twitter:title content="Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction"><meta name=twitter:description content="AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：[Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction](https://arxiv.org/abs/1610.00081)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a95981f1fc190aef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#formulation-of-crowd-flows-problem>Formulation of Crowd Flows Problem</a></li><li><a href=#deep-residual-learning>Deep Residual Learning</a></li></ol><ol><li><a href=#structures-of-the-first-three-components>Structures of the First Three Components</a></li><li><a href=#the-structure-of-the-external-component>The Structure of the External Component</a></li><li><a href=#fusion>Fusion</a></li><li><a href=#algorithm-and-optimization>Algorithm and Optimization</a></li></ol><ol><li><a href=#settings>Settings</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>论文阅读笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</a></h2><h3 class=article-subtitle>AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：[Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction](https://arxiv.org/abs/1610.00081)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 08, 2019</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 10 分钟</time></div></footer></div></header><section class=article-content><p>AAAI 2017, ST-ResNet，网格流量预测，用三个相同结构的残差卷积神经网络对近邻时间、周期、趋势（远期）分别建模。与 RNN 相比，RNN 无法处理序列长度过大的序列。三组件的输出结果进行集成，然后和外部因素集成，得到预测结果。原文地址：<a class=link href=https://arxiv.org/abs/1610.00081 target=_blank rel=noopener>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</a></p><h1 id=abstract>Abstract</h1><p>对于交通管理和公共安全来说，预测人流很重要，但这个问题也很有挑战性，因为收到很多复杂的因素影响，如区域内的交通、事件、天气。我们提出了一个基于深度学习的模型 ST-ResNet，对城市内的每个区域的人流的进出一起预测。我们基于时空数据独一的属性，设计了一个端到端的结构。我们使用残差神经网络框架对时间近邻、周期、趋势属性建模。对每个属性，我们设计了残差卷积的一个分支，每个分支对人流的空间属性建模。ST-ResNet 基于数据动态地聚合三个残差神经网络的输出，给不同的分支和区域分配权重。聚合结果还融合了外部因素，像天气或日期。实验在北京和纽约两个数据集上开展。</p><h1 id=introduction>Introduction</h1><p>对于交通管理和公共安全来说，预测人流很重要（Zheng et al. 2014）。举个例子，2015年新年夜，上海有大量人群涌入一个区域，导致 36 人死亡。2016年六月中旬，数百名 Pokemon Go 玩家冲入纽约中央公园，为了抓一只特别稀有的怪，导致严重的踩踏事故。如果可以预测一个区域的人流，这样的悲剧可以通过应急措施避免，像提前做交通管控，发布预警，疏散人群等。</p><p>我们在这篇文章中预测两类人流（Zhang et al. 2016)：如图 1（a）所示，流入和流出。流入是在给定时间段，从其他区域进入到一个区域的交通运载量。流出表示给定时段内，从一个区域向其他区域的交通运载量。两个流量都是区域间的人口流动。了解这个对风险评估和交通管理有很大帮助。流入/流出可以通过行人数量、邻近道路车辆数、公共运输系统的人数、或是所有的都加起来。图 1（b）展示了一个例子。我们可以使用手机信号测量行人数，$r_2$ 的流入和流出分别为 3 和 1。类似地，使用车辆 GPS 轨迹，分别是 0 和 3。</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig1.JPG loading=lazy alt=Figure1></p><p>然而，同时预测城市每个区域人口的流入和流出是很有难度的，有 3 个复杂的因素：</p><ol><li>空间依赖。区域 $r_2$ 的流入（图1（a））受邻近区域（像 $r_1$）和遥远区域流出的影响。$r_2$ 的流出也受其他区域（$r_3$）流入的影响。$r_2$ 的流入也影响其自身。</li><li>时间依赖。一个区域的人流受到近期和远期时间影响。举个例子，早上8点发生的交通拥堵可能会影响到 9 点。此外，早高峰的交通状况可能在接连的几天都是相似的，每 24 小时一次。而且随着冬天的到来，早高峰时间可能越来越晚。温度下降，日初变晚会使人们起床时间变晚。</li><li>外部影响。一些像天气和事件的外部因素可能会显著地改变城市内不同区域的人口流动。</li></ol><p>为了解决这些问题，我们提出了一个深度深空残差网络 (ST-ResNet) 对每个区域的流入和流出同时预测。我们的贡献有 4 点：</p><ul><li>ST-ResNet 使用基于卷积的残差神经网络对城市内两个邻近的和遥远的区域的空间依赖建模，同时还确信了模型的预测精度不会因为模型的深度增加而降低。</li><li>我们将人口流动的时间属性分为三种，时间近邻、周期、趋势。ST-ResNet 使用三个残差网络对这些属性建模。</li><li>ST-ResNet 动态地聚合三个上述网络的输出，给不同的分支和区域分配权重。聚合还融合了外部因素。</li><li>我们使用北京出租车的轨迹数据和气象数据，纽约自行车轨迹数据。结果表示我们的方法比 6 个 baseline 都好。</li></ul><h1 id=preliminaries>Preliminaries</h1><p>简要回顾人流预测问题（Zhang el al. 2016; Hoang, Zheng, and Singh 2016），介绍残差学习（He et al. 2016）。</p><h2 id=formulation-of-crowd-flows-problem>Formulation of Crowd Flows Problem</h2><p><strong>Definition 1(Region (Zhang et al. 2016))</strong> 根据不同粒度级和语义，一个地点的定义有很多。我们根据经纬度将城市划分成 $I \times J$ 个网格，一个网格表示一个区域，如图 2(a)。</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig2.JPG loading=lazy alt=Figure2></p><p>**Definition 2(Inflow/outflow (Zhang et al. 2016)) $\mathbb{P}$ 是第 t 时段的轨迹集合。对于第 $i$ 行第 $j$ 列的网格，时段 $t$ 流入和流出的人流分别定义为：</p>$$
x^{in,i,j}\_t = \sum\_{T\_r \in \mathbb{P}} \vert \lbrace k > 1 \mid g\_{k-1} \not \in (i, j) \wedge g\_k \in (i,j) \rbrace \vert
\\
x^{out,i,j}\_t = \sum\_{T\_r \in \mathbb{P}} \vert \lbrace k \geq 1 \mid g\_k \in (i,j) \wedge g\_{k+1} \not \in (i,j) \rbrace \vert
$$<p>其中 $T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的轨迹，$g_k$ 是地理坐标；$g_k \in (i,j)$ 表示点 $g_k$ 落在 $(i, j)$ 内；$\vert · \vert$ 表示集合基数。</p><p>时段 $t$ ，所有区域的流入和流出可以表示成 $\mathbf{X}_t \in \mathbb{R}^{2 \times I \times J}$，$(\mathbf{X}_t)_{0,i,j}=x^{in,i,j}_t, (\mathbf{X}_t)_{1,i,j} = x^{out,i,j}_t$。流入矩阵如图2(b)。</p><p>空间区域可以表达成一个 $I \times J$ 的区域，有两类流动，所以观测值可以表示为 $\mathbf{X} \in \mathbb{R}^{2 \times I \times J}$。</p><p><strong>Problem 1</strong> 给定历史观测值 $\lbrace \mathbf{X}_t \mid t = 0,\dots,n-1 \rbrace$，预测 $\mathbf{X}_n$。</p><h2 id=deep-residual-learning>Deep Residual Learning</h2>$$\tag{1}
\mathbf{X}^{(l+1)} = \mathbf{X}^{(l)} + \mathcal{F}(\mathbf{X}^{(l)})
$$<h1 id=deep-spatio-temporal-residual-networks>Deep Spatio-Temporal Residual Networks</h1><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig3.JPG loading=lazy alt=Figure3></p><p>图 3 展示了 ST-ResNet的架构，4 个部分分别对时间近邻、周期、远期、外部因素建模。如图 3 所示，首先将流入和流出作为两个通道放到矩阵中，使用定义 1 和 2 引入的方法。我们将时间轴分为三个部分，表示近期时间、邻近历史、远期历史。三个时段的两通道的流动矩阵分别输入上述模型，对三种时间属性建模。这三个组件结构相同，都是残差网络。这样的结构捕获邻近和遥远区域间的空间依赖。外部组件中，我们手动的从数据集中提取了特征，如天气、事件等，放入两层全连接神经网络中。前三个组件的输出基于参数矩阵融合为 $\mathbf{X}_{Res}$，参数矩阵给不同的区域不同的组件分配权重。$\mathbf{X}_{Res}$ 然后与外部组件 $\mathbf{X}_{Ext}$ 集成。最后，聚合结果通过 Tanh 映射到 $[-1, 1]$，在反向传播会比 logistic function 收敛的更快 (LeCun et al. 2012)。</p><h2 id=structures-of-the-first-three-components>Structures of the First Three Components</h2><p>如图 4。</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig4.JPG loading=lazy alt=Figure4></p><p><em><strong>Convolution</strong></em> 一个城市通常很大，包含很多距离不同的区域。直观上来说，邻近区域的人流会影响其他区域，可以通过 CNN 有效地处理，CNN 也被证明在层级地捕获空间信息方面很强 (LeCun et al. 1998)。而且，如果两个遥远地方通过地铁或高速公路连接，那么这两个区域间就有依赖关系。为了捕获任何区域的空间依赖，我们需要设计一个很多层的 CNN 模型，因为一个卷积层只考虑空间近邻，受限于它卷积核的大小。同样的问题在视频序列生成任务中也有，当输入和输出有同样的分辨率的时候(Mathieu, Couprie, and LeCun 2015)。为了避免下采样导致的分辨率损失引入了几种方法，同时还保持遥远的依赖关系(Long, Shelhamer, and Darrell 2015)。与传统的 CNN 不同的是，我们没有使用下采样，而是只使用卷积 (Jain et al. 2007)。如图 4(a)，图中有 3 个多级的 feature map，通过一些卷积操作相连。一个高层次的结点依赖于 9 个中间层次的结点，这些又依赖于低层次的所有结点。这意味着一个卷积可以很自然地捕获空间近邻依赖，堆叠卷积可以更多地捕获遥远的空间依赖。</p><p>图 3 的近邻组件使用了一些 2 通道流动矩阵对近邻时间依赖建模。令最近的部分为 $[\mathbf{X}_{t-l_c}, \mathbf{X}_{t-(l_c-1)}, \dots, \mathbf{X}_{t-1}]$，也称为近邻依赖序列。我们将他们沿第一个轴（时间）拼接，得到一个张量 $\mathbf{X}^{(0)}_c \in \mathbb{R}^{2l_c \times I \times J}$，然后使用卷积（图 3 中的 Conv1）：</p>$$\tag{2}
\mathbf{X}^{(1)}\_c = f(W^{(1)}\_c \ast \mathbf{X}^{(0)}\_c + b^{(1)}\_c)
$$<p>其中 $\ast$ 表示卷积；$f$ 是激活函数；$W^{(1)}_c, b^{(1)}_c$ 是参数。</p><p><em><strong>Residual Unit.</strong></em> 尽管有 ReLU 职业那个的激活函数和正则化技巧，深度卷积网络在训练上还是很难。但我们仍然需要深度神经网络捕获非常大范围的依赖。对于典型的流量数据，假设输入大小是 $32 \times 32$，卷积核大小是 $3 \times 3$，如果我们想对城市范围的依赖建模，至少需要连续 15 个卷积层。为了解决这个问题，我们使用残差学习(He et al. 2015)，在训练超过 1000 层的网络时很有效。</p><p>在我们的 ST-ResNet(如图 3)，我们在 Conv1 上堆叠 $L$ 个残差单元如下：</p>$$\tag{3}
\mathbf{X}^{(l+1)}\_c = \mathbf{X}^{(l)}\_c + \mathcal{F}(\mathbf{X}^{(l)}\_c; \theta^{(l)}\_c), l = 1, \dots, L
$$<p>$\mathcal{F}$ 是残差函数，即 ReLU + Convolution，如图 4(b)。我们还在 ReLU 之前加了 <em>Batch Normalization</em>。在第 $L$ 个残差单元前，我们使用了一个卷积层，图 3 中的 Conv2。2 个卷积和 $L$ 个残差单元，图 3 中的近邻组件的输出是 $\mathbf{X}^{(l+2)}_c$。</p><p>同样的，使用上面的操作，我们可以构建 <em>周期</em> 和 <em>趋势</em> 组件，如图 3。假设时段 $p$ 有 $l_p$ 个时间间隔。那么 <em>时段</em> 依赖序列是 $[\mathbf{X}_{t-l_p \cdot p}, \mathbf{X}_{t-(l_p - 1) \cdot p}, \dots, \mathbf{X}_{t-p}]$。使用式 2 和 式 3 那样的卷积和 $L$ 个残差单元，<em>周期</em> 组件的输出是 $\mathbf{X}^{(L + 2)}_p$。同时，<em>趋势</em> 组件的输出是 $\mathbf{X}^{(L+2)}_q$，输入是 $[\mathbf{X}_{t-l_q \cdot q}, \mathbf{X}_{t-(l_q - 1) \cdot q}, \dots, \mathbf{X}_{t-q}]$，$l_q$ 是<em>趋势</em>依赖序列的长度，$q$ 是趋势跨度。需要注意的是 $p$ 和 $q$ 是两个不同类型的周期。在实际的实现中，$p$ 等于一天，描述的是日周期，$q$ 是一周，表示周级别的趋势。</p><h2 id=the-structure-of-the-external-component>The Structure of the External Component</h2><p>交通流会被很多复杂的外部因素所影响，如天气或事件。图 5(a) 表示假期（春节）时的人流和平时的人流很不一样。图 5(b) 表示相比上周的同一天，突然而来的大雨会减少此时办公区域的人流。令 $E_t$ 为特征向量，表示预测的时段 $t$ 的外部因素。我们的实现中，我们主要考虑天气、假期事件、元数据（工作日、周末）。详细情况见表 1。为了预测时段 $t$ 的交通流，假期事件和元数据可以直接获得。然而，未来时段 $t$ 的天气预报不知道。可以使用时段 $t$ 的天气预报，或是 $t-1$ 时段的天气来近似。我们在 $E_t$ 上堆叠两个全连接层，第一层可以看作是每个子因素的嵌入层。第二层用来从低维映射到和 $\mathbf{X}_t$ 一样的高维上。图 3 中外部组件的输出表示为 $\mathbf{X}_{Ext}$，参数是$\theta_{Ext}$。</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig5.JPG loading=lazy alt=Figure5></p><h2 id=fusion>Fusion</h2><p>我们先用一个参数矩阵融合前三个组件，然后融合外部组件。</p><p>图6(a)和(d)展示了表1展示的北京轨迹数据的比例曲线，x轴是两个时段的时间差，y轴是任意两个有相同时间差的流入的平均比例。两个不同区域的曲线在时间序列上表现出了时间联系，也就是近期的流入比远期的流入更相关，表现出了事件近邻性。两条曲线有两个不同的形状，表现出不同区域可能有不同性质的近邻性。图6(b)和(e)描绘了7天所有时段的流入。我们可以观察到两个区域明显的日周期性。在办公区域，工作日的峰值比周末的高很多。住宅区在工作日和周末有相似的峰值。图6(c)和(f)描述了2015年3月到2015年6月一个特定时段(9:00pm-9:30pm)的流入。随着时间的推移，办公区域的流入逐渐减少，住宅区逐渐增加。不同的区域表现出了不同的趋势。总的来说，两个区域的流入受到近邻、周期、趋势三部分影响，但是影响程度是不同的。我们也发现其他区域也有同样的性质。</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Fig6.JPG loading=lazy alt=Figure6></p><p>综上，不同区域受近邻、周期、趋势的影响，但是影响程度不同。受这些观察的启发，我们提出了一个基于矩阵参数的融合方法。</p><p><em><strong>Parametric-matrix-based fusion.</strong></em> 我们融合图 3 中前三个组件：</p>$$\tag{4}
\mathbf{X}\_{Res} = \mathbf{W}\_c \odot \mathbf{X}^{(L+2)}\_c + \mathbf{W}\_p \odot \mathbf{X}^{(L+2)}\_p + \mathbf{W}\_q \odot \mathbf{X}^{(L+2)}\_q
$$<p>$\odot$ 是哈达玛乘积，$\mathbf{W}$ 是参数，分别调整三个组件的影响程度。</p><p><em><strong>Fusing the external component.</strong></em> 我们直接地将前三个组件的输出和外部组件融合，如图3。最后，时段 $t$ 的预测值，表示为 $\hat{\mathbf{X}}_t$ 定义为：</p>$$\tag{5}
\hat{\mathbf{X}}\_t = \mathrm{tanh}(\mathbf{X}\_{Res} + \mathbf{X}\_{Ext})
$$<p>我们的 ST-ResNet 可以从三个流动与朕和外部因素特征通过最下滑 MSE 来训练：</p>$$\tag{6}
\mathcal{L}(\theta) = \Vert \mathbf{X}\_t - \hat{\mathbf{X}}\_t \Vert^2\_2
$$<h2 id=algorithm-and-optimization>Algorithm and Optimization</h2><p>算法1描述了 ST-ResNet 的训练过程。首先从原始序列构造训练实例。然后通过反向传播，用 Adam 算法训练。</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Alg1.JPG loading=lazy alt=Algorithm1></p><h1 id=experiments>Experiments</h1><h2 id=settings>Settings</h2><p><strong>Datasets.</strong> 我们使用表 1 中展示的两个数据集。每个数据集都包含两个子集，轨迹和天气。</p><ul><li>TaxiBJ: 轨迹数据是出租车 GPS 数据和北京的气象数据，2013年7月1日到10月30日，2014年5月1日到6月30日，2015年5月1日到6月30日，2015年11月1日到2016年4月1日。使用定义2，我们获得两类人流。我们选择最后四周作为测试集，之前的都为训练集。</li><li>BikeNYC: 轨迹数据是2014年NYC Bike系统中取的，从4月1日到9月30日。旅行数据包含：持续时间、起点终点站点ID，起始终止时间。在数据中，最后10天选做测试集，其他选做训练集。</li></ul><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table1.JPG loading=lazy alt=Table1></p><p><strong>Baselines.</strong> 我们对比了6个baselines：HA, ARIMA, SARIMA, VAR, ST-ANN, DeepST.</p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table2.JPG loading=lazy alt=Table2></p><p><img src=/blog/images/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/Table3.JPG loading=lazy alt=Table3></p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/spatial-temporal/>Spatial-Temporal</a>
<a href=/blog/tags/graph-convolutional-network/>Graph Convolutional Network</a>
<a href=/blog/tags/graph/>Graph</a>
<a href=/blog/tags/time-series/>Time Series</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/><div class=article-details><h2 class=article-title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</h2></div></a></article><article><a href=/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/><div class=article-details><h2 class=article-title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</h2></div></a></article><article><a href=/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/><div class=article-details><h2 class=article-title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/><div class=article-details><h2 class=article-title>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/><div class=article-details><h2 class=article-title>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>