<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="这是一篇讲事件序列度量学习的文章，提出的模型叫MeLES，Metric Learning for Event Sequences。[Event sequence metric learning](https://arxiv.org/abs/2002.08232)"><title>Event sequence metric learning</title><link rel=canonical href=https://davidham3.github.io/blog/p/event-sequence-metric-learning/><link rel=stylesheet href=/blog/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="Event sequence metric learning"><meta property='og:description' content="这是一篇讲事件序列度量学习的文章，提出的模型叫MeLES，Metric Learning for Event Sequences。[Event sequence metric learning](https://arxiv.org/abs/2002.08232)"><meta property='og:url' content='https://davidham3.github.io/blog/p/event-sequence-metric-learning/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='event sequence'><meta property='article:published_time' content='2022-04-26T14:38:05+00:00'><meta property='article:modified_time' content='2022-04-26T14:38:05+00:00'><meta name=twitter:title content="Event sequence metric learning"><meta name=twitter:description content="这是一篇讲事件序列度量学习的文章，提出的模型叫MeLES，Metric Learning for Event Sequences。[Event sequence metric learning](https://arxiv.org/abs/2002.08232)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a95981f1fc190aef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#21-样本构成>2.1 样本构成</a></li><li><a href=#22-序列表示>2.2 序列表示</a></li><li><a href=#23-损失>2.3 损失</a></li><li><a href=#24-负样本采样策略>2.4 负样本采样策略</a></li></ol><ol><li><a href=#31-baselines>3.1 Baselines</a></li><li><a href=#32-参数选择>3.2 参数选择</a></li><li><a href=#33-嵌入可视化>3.3 嵌入可视化</a></li><li><a href=#34-结果>3.4 结果</a><ol><li><a href=#341-关于半监督的实验>3.4.1 关于半监督的实验</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/event-sequence-metric-learning/>Event sequence metric learning</a></h2><h3 class=article-subtitle>这是一篇讲事件序列度量学习的文章，提出的模型叫MeLES，Metric Learning for Event Sequences。[Event sequence metric learning](https://arxiv.org/abs/2002.08232)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Apr 26, 2022</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 5 分钟</time></div></footer></div></header><section class=article-content><p>这是一篇讲事件序列度量学习的文章，提出的模型叫MeLES，Metric Learning for Event Sequences。<a class=link href=https://arxiv.org/abs/2002.08232 target=_blank rel=noopener>Event sequence metric learning</a></p><p>事件序列主要是指连续时间下的离散事件。比如用户的信用卡交易、在网站上的点击行为等等。</p><h1 id=1-模型架构>1. 模型架构</h1><p><img src=/blog/images/event-sequence-metric-learning/Fig1.jpg loading=lazy alt=Figure1></p><h1 id=2-原理>2. 原理</h1><h2 id=21-样本构成>2.1 样本构成</h2><p>每 $N$ 个序列构成一个batch，对这个batch内的序列进行切分，有三种切分方式：</p><ol><li>保持事件顺序，随机不放回采样</li><li>随机切分序列，子序列之间不重叠</li><li>随机切分序列，子序列之间重叠</li></ol><p>不管怎么切，都能把一个序列切成多个子序列，这里将每个序列切成 $K$ 个子序列，那么一个batch就可以得到 $N \times K$ 个子序列。</p><p>在这些子序列中，来自同一个序列的两个子序列组成的pair，为正样本，来自不同序列的两个子序列组成的pair为负样本。这样，对于每个子序列，就有 $K - 1$ 个正样本，$(N - 1) \times K$ 个负样本。</p><h2 id=22-序列表示>2.2 序列表示</h2><p>然后使用RNN或者是transformer对子序列进行编码，编码后可以得到一个向量，这个向量就是这个子序列的嵌入表示。拿到这个表示，就可以计算损失了。</p><h2 id=23-损失>2.3 损失</h2><p>计算损失的时候，最简单的想法肯定就是类似交叉熵一样的损失，正样本的损失加上负样本的损失即可。</p><p>但是之前的研究认为，有些嵌入表示，他们的距离过于远，这种样本对模型训练没什么用，因此本文给了两个损失函数来剔除这种情况。一个叫contrastive loss，一个叫margin loss，原理都是一样的。</p><p><img src=/blog/images/event-sequence-metric-learning/loss.jpg loading=lazy alt=loss></p><p>对于contrastive loss来说，正样本的损失正常计算，而负样本的损失，如果pair中的两个表示的距离大于 $m$ ，就不要了。</p><p>对于margin loss是同样的原理，$b + m$ 和 $b - m$ 构成了损失函数的边界，正样本的距离要大于 $b - m$ 才有意义，而负样本的距离要小于 $b + m$ 才有意义。而且，当 $b &lt; m$ 的时候，这个损失就会变得和上面的contrastive loss一样，只考虑负样本的margin，因为只要距离是欧式距离，在任何情况下 $max(0, D^i_W - b + m) = D^i_W - b + m > 0$。</p><h2 id=24-负样本采样策略>2.4 负样本采样策略</h2><p>然后，除了上述的损失函数可以控制两个距离过远的负样本不计算损失，还可以做负样本采样，也就是刚才说的 $(N - 1) \times K$ 个负样本，只取出一部分用来训练。这里有4种方式：</p><ol><li>随机采样</li><li>难例挖掘，对每个整理生成$k$个难例作为负样本</li><li>负样本采样的时候考虑距离因素</li><li>第四个没看明白他在说啥，倒是给了个参考文献：Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. FaceNet: A<br>unified embedding for face recognition and clustering. 2015 IEEE Conference on<br>Computer Vision and Pattern Recognition (CVPR) (2015), 815–823.</li></ol><p>不管是上述哪种负采样方案，除了第一种，都是要算距离的，也就是算两个embedding之间的距离。而且是要算batch内任意两个embedding之间的距离，或者说是算 $(N - 1) \times K$ 个距离。如果用欧氏距离计算嵌入 $A$ 和 $B$ 之间的距离，那么 $D(A, B) = \sqrt{\sum_i (A_i - B_i)^2} = \sqrt{\sum_i A^2_i + \sum_i B^2_i - 2 \sum_i A_i B_i}$，这里为了计算简便，只要让 $\Vert A \Vert = \Vert B \Vert = 1$ 就好了，那就能转换成 $D(A, B) = \sqrt{2 - 2(A \cdot B)}$。所以，为了达成上面的目标，让 $A$ 和 $B$ 的模等于1，只要对这些嵌入表示做标准化，就可以实现了。论文里面说，做了这个操作之后，负样本采样的计算复杂度是 $O(n^2h)$，这个我还没想明白，后面再说吧。</p><h1 id=3-实验>3. 实验</h1><p>两个数据集都是银行交易数据，主要是通过交易事件序列预测用户的年龄与性别。</p><h2 id=31-baselines>3.1 Baselines</h2><ol><li><p>手工特征+GBM，手工构建了近1k个特征，然后用LightGBM。</p></li><li><p>Contrastive Predictive Coding(CPC)，一个自监督学习方法，Aäron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation<br>Learning with Contrastive Predictive Coding. CoRR abs/1807.03748 (2018).<br>arXiv:1807.03748 <a class=link href=http://arxiv.org/abs/1807.03748 target=_blank rel=noopener>http://arxiv.org/abs/1807.03748</a></p></li><li><p>除了上面两个方法，作者还试了编码器网络+分类网络直接用于监督学习任务，这里就没有预训练了。</p></li></ol><h2 id=32-参数选择>3.2 参数选择</h2><p><img src=/blog/images/event-sequence-metric-learning/Table4_to_7.jpg loading=lazy alt=result></p><p>上面4个表的结论：</p><ol><li>不同编码器效果不同</li><li>在训练集上表现最好的损失函数在测试集上不一定是最好的</li><li>随机slice比随机采样更好</li><li>难例挖掘带来的提升是显著的（但是论文前边根本没仔细介绍难例挖掘好吧。。。）</li></ol><p><img src=/blog/images/event-sequence-metric-learning/Fig2.jpg loading=lazy alt=Figure2></p><p>图2是说嵌入在800维的时候效果最好，用bias-variance来解释。维数少的时候高bias，信息丢失，维数高的时候高variance，噪声多了。</p><p><img src=/blog/images/event-sequence-metric-learning/Fig3.jpg loading=lazy alt=Figure3></p><p>图3一样，256到2048比较平缓，下游任务的效果没有明显增强。</p><p>作者说嵌入维数的增加，训练时间和显存消耗都是线性增加的。</p><h2 id=33-嵌入可视化>3.3 嵌入可视化</h2><p>tSNE，染色是用数据集中的target value染色的。学习完全是自监督的。交易序列表示的是用户的行为，因此模型可以捕获行为模式，产出的embedding如果相近，则说明用户的行为模式相似。</p><p><img src=/blog/images/event-sequence-metric-learning/Fig4.jpg loading=lazy alt=Figure4></p><h2 id=34-结果>3.4 结果</h2><p><img src=/blog/images/event-sequence-metric-learning/Table8.jpg loading=lazy alt=Table8></p><p>对比手工构建的特征，模型效果强劲。fine-tuned的表示效果最好。另外可以看到的是，使用手工特征+事件序列嵌入表示的模型效果比纯手工特征效果更好。</p><h3 id=341-关于半监督的实验>3.4.1 关于半监督的实验</h3><p>只取了一部分标签做实验，就像监督学习一样用手工特征的lightgbm和CPC。对于嵌入生成方法（MeLES和CPC），分别使用lightgbm和fine-tuned模型来评估效果。同时还比了监督模型在这些label上的效果。</p><p><img src=/blog/images/event-sequence-metric-learning/Fig5.jpg loading=lazy alt=Figure5></p><p><img src=/blog/images/event-sequence-metric-learning/Fig6.jpg loading=lazy alt=Figure6></p><p><img src=/blog/images/event-sequence-metric-learning/Fig78.jpg loading=lazy alt=Figure7_and_Figure8></p><p>结论就是标签少的时候，效果很好。</p><h1 id=4-结论>4. 结论</h1><p>提出了MeLES，效果很好，而且还可以在半监督中做预训练。好处是基本不用怎么对数据做处理就可以拿到嵌入表示，获得好的效果。而且在新的事件加入的时候，甚至是可以增量更新已经计算的嵌入表示。另一方面是嵌入表示无法还原原始的事件序列，可以起到数据加密的作用。</p><p>这里提到的增量更新其实就是，RNN的计算只要上一个时间步的信息就好了，不需要从头再训练一次，因此如果有新的事件到来，从最后一次的状态开始算就好了，这就叫增量更新。</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/event-sequence/>Event Sequence</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/modeling-the-intensity-function-of-point-process-via-recurrent-neural-networks/><div class=article-details><h2 class=article-title>Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks</h2></div></a></article><article><a href=/blog/p/fully-neural-network-based-model-for-general-temporal-point-processes/><div class=article-details><h2 class=article-title>Fully Neural Network based Model for General Temporal Point Processes</h2></div></a></article><article><a href=/blog/p/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/><div class=article-details><h2 class=article-title>Recurrent Marked Temporal Point Processes: Embedding Event History to Vector</h2></div></a></article><article><a href=/blog/p/time-dependent-representation-for-neural-event-sequence-prediction/><div class=article-details><h2 class=article-title>Time-dependent representation for neural event sequence prediction</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>