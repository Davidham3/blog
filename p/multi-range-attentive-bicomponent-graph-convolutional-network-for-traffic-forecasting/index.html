<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="AAAI 2020，原文链接：[https://arxiv.org/abs/1911.12093](https://arxiv.org/abs/1911.12093)。"><title>Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</title>
<link rel=canonical href=https://davidham3.github.io/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting"><meta property='og:description' content="AAAI 2020，原文链接：[https://arxiv.org/abs/1911.12093](https://arxiv.org/abs/1911.12093)。"><meta property='og:url' content='https://davidham3.github.io/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='Graph'><meta property='article:tag' content='Attention'><meta property='article:tag' content='Spatial-temporal'><meta property='article:tag' content='Time Series'><meta property='article:published_time' content='2020-01-03T20:18:29+00:00'><meta property='article:modified_time' content='2020-01-03T20:18:29+00:00'><meta name=twitter:title content="Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting"><meta name=twitter:description content="AAAI 2020，原文链接：[https://arxiv.org/abs/1911.12093](https://arxiv.org/abs/1911.12093)。"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a92d3b55c5d43e55.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#problem-definition>Problem Definition</a></li><li><a href=#graph-convolution>Graph Convolution</a></li></ol><ol><li><a href=#model-overview>Model Overview</a></li><li><a href=#bicomponent-graph-convolution>Bicomponent Graph Convolution</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>论文阅读笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/>Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</a></h2><h3 class=article-subtitle>AAAI 2020，原文链接：[https://arxiv.org/abs/1911.12093](https://arxiv.org/abs/1911.12093)。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jan 03, 2020</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><p>AAAI 2020，原文链接：<a class=link href=https://arxiv.org/abs/1911.12093 target=_blank rel=noopener>https://arxiv.org/abs/1911.12093</a>。</p><h1 id=abstract>Abstract</h1><p>交通预测在运输和公共安全中扮演重要角色，由于复杂的时空依赖和路网和交通状况带来的不确定性使这个问题很有挑战。最新的研究专注于使用图卷积网络 GCNs 对一个固定权重的图进行建模，即对空间依赖建模。然而，边，即两个结点之间的关系更加复杂且两者相互影响。我们提出了 Multi-Range Attentive Bicomponent GCN (MRA-BGCN)，一种新的用于交通预测的深度学习框架。我们先根据路网上结点的距离构建结点图，在根据不同的边的交互模式构造边图。然后，我们使用 bicomponent 图卷积实现结点和边的交互。这个多范围注意力机制用来聚合不同邻居范围的信息，自动地学习不同范围的重要性。大量的实验在两个真实数据集，METR-LA 和 PEMS-BAY 上开展，显示出我们的模型效果很好。</p><h1 id=introduction>Introduction</h1><p><img src=/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig1.png loading=lazy alt=Figure1></p><p>讲了好多历史。。。然后是论点部分：</p><p>我们认为 DCRNN 和 STGCN 虽说集成了 GCN，但是有两个点忽略了：</p><p>首先，这些方法主要关注通过在一个固定权重的图上部署 GCN 对空间依赖建模。然而，边更复杂。图 1a 中，传感器 1 和 3，还有 2 和 3，通过路网连接。显然，这些关联随当前的交通状况改变，他们之间也互相交互。图 1b 所示，现存的方法根据路网距离构建一个固定的带权图，使用 GCN 实现这些结点的交互，但是结点间的关联性在邻接矩阵中通过固定的值表示，这就忽略了边的复杂性和交互性。</p><p>其次，这些方法经常使用一个给定范围内聚合的信息，比如 $k$ 阶邻居，忽略多个范围的信息。然而，不同范围的信息表现出不同的交通属性。小的范围表现出局部依赖，大范围倾向于表现全局的交通模式。此外，不同范围的信息也不是永远都具有相同的分量。举个例子，一次交通事故，一个结点主要受它最近的邻居的影响，这样模型就应该更关注它，而不是给其他的 $k$ 阶邻居相同的关注。</p><p>为了解决上述两点问题，我们提出了 MRA-BGCN，不仅考虑结点关联，也把边作为实体，考虑他们之间的关系，如图 1c，我们还利用了不同的范围信息。我们的贡献：</p><ul><li>提出 MRA-BGCN，引入 bicomponent 图卷积，对结点和边直接建模。结点图根据路网距离构建，边图根据边的交互模式、stream connectivity 和 竞争关系构建。</li><li>我们针对 bicomponent 图卷积提出多范围注意力机制，可以聚合不同范围邻居的信息，学习不同范围的重要性。</li><li>我们开展了大量的实验，实验效果很好。</li></ul><h1 id=preliminaries>Preliminaries</h1><h2 id=problem-definition>Problem Definition</h2><p>给定历史的数据，预测未来的数据。$N$ 个结点组成的图 $G = (V, E, \bm{A})$。时间 $t$ 路网上的交通数据表示为图信号 $\bm{X}^{(t)} \in \mathbb{R}^{N \times P}$，$P$ 是特征数。交通预测是过去的数据预测未来：</p>$$
[\bm{X}^{(t-T'+1):t},G] \xrightarrow{f} [\bm{X}^{(t+1)}:(t+T)],
$$<p>$\bm{X}^{(t-T&rsquo;+1):t} \in \mathbb{R}^{N \times P \times T&rsquo;}$，$\bm{X}^{(t+1):(t+T)} \in \mathbb{R}^{N \times P \times T}$。</p><h2 id=graph-convolution>Graph Convolution</h2><p>不介绍了。</p><h1 id=methodology>Methodology</h1><h2 id=model-overview>Model Overview</h2><p><img src=/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig2.png loading=lazy alt=Figure2></p><p>图 2 展示了 MRA-BGCN 的架构，包含两个部分：（1）双组件图卷积模块；（2）多范围注意力层。双组件图卷积模块包含多个结点图卷积层和边图卷积层，直接对结点和边的交互建模。多范围注意力层聚合不同范围的邻居信息，学习不同范围的重要性。此外，我们融合 MRA-BGCN 和 RNN 对时间依赖建模完成交通预测。</p><h2 id=bicomponent-graph-convolution>Bicomponent Graph Convolution</h2><p><img src=/blog/images/multi-range-attentive-bicomponent-graph-convolutional-network-for-traffic-forecasting/Fig3.png loading=lazy alt=Figure3></p><p>图卷积可以有效聚合结点之间的交互关系，然而，交通预测中边更复杂（这句话说三遍了）。因此我们提出双组件图卷积，直接对结点和边的交互建模。</p><p>Chen 等人提出边的邻近的 line graph 来建模边的关系。$G = (V, E, \bm{A})$ 表示结点有向图，$G_L = (V_L, E_L, \bm{A}_L)$ 是对应的 line graph，$G_L$ 的结点 $V_L$ 是 $E$ 中有序的边。$\bm{A}_L$ 是无权的邻接矩阵，编码了结点图中的边邻接关系，有关系就等于1。</p><p>尽管 line graph 可以考虑边的邻接，它仍然是一个无权图且只认为两条边中的一条边的汇点和另一条边的源点相同时，这两条才相关。然而，对于刻画交通预测中各种各样边的交互关系来说这不够高效。如图 3 所示，我们定义两类边的交互模式来构建边图 $G_e = (V_e, E_e, \bm{A}_e)$。$V_e$ 中的每个节点表示 $E$ 中的边。</p><p><strong>Stream connectivity</strong> 在交通网络中，路网可能受它上下游的路段影响。如图 3a 所示，$(i \rightarrow j)$ 是 $(j \rightarrow k)$ 的上游的边，因此他们是相互关联的。直观上来看，如果结点 $j$ 有很多数量的邻居，那么 $(i \rightarrow j)$ 和 $(j \rightarrow k)$ 之间的关系是弱的，因为它还要受其他邻居的影响。我们使用高斯核计算边的权重用来表示 $\bm{A}_e$ 中的 stream connectivity：</p>$$\tag{2}
\bm{A}\_{e, (i \rightarrow j), (j \rightarrow k)} = \bm{A}\_{e, (j \rightarrow k), (i \rightarrow j)} = \text{exp}(- \frac{(\text{deg}^-(j) + \text{deg}^+(j) - 2)^2}{\sigma^2})
$$<p>$\text{deg}^-(j)$ 和 $\text{deg}^+(j)$ 分别表示结点 $j$ 的入度和出度，$\sigma$ 是结点度的标准差。</p><p><strong>Competitive relationship</strong> 路网</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/graph/>Graph</a>
<a href=/blog/tags/attention/>Attention</a>
<a href=/blog/tags/spatial-temporal/>Spatial-Temporal</a>
<a href=/blog/tags/time-series/>Time Series</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Jan 03, 2020 20:18 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/gman-a-graph-multi-attention-network-for-traffic-prediction/><div class=article-details><h2 class=article-title>GMAN: A Graph Multi-Attention Network for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/><div class=article-details><h2 class=article-title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</h2></div></a></article><article><a href=/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/><div class=article-details><h2 class=article-title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</h2></div></a></article><article><a href=/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/><div class=article-details><h2 class=article-title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/><div class=article-details><h2 class=article-title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>