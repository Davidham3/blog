<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="ECCV 2016ï¼Œå®æ—¶é£æ ¼è¿ç§»ä¸è¶…åˆ†è¾¨ç‡åŒ–çš„æ„ŸçŸ¥æŸå¤±ï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯åœ¨cs231né‡Œé¢çœ‹åˆ°çš„ï¼Œæ­£å¥½æœ€è¿‘åœ¨ç ”ç©¶é£æ ¼è¿ç§»ã€‚ä¸€ä½œæ˜¯Justin Johnsonï¼Œ2017æ˜¥çš„cs231nçš„ä¸»è®²ä¹‹ä¸€ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦å†…å®¹æ˜¯å¯¹Gatysç­‰äººçš„é£æ ¼è¿ç§»åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¤§å¹…æå‡äº†æ€§èƒ½ã€‚ä¸»è¦åŸç†å°±æ˜¯ï¼Œä¹‹å‰Gatysç­‰äººçš„è®ºæ–‡æ˜¯åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„VGG19ï¼Œæ±‚losså¹¶åˆ©ç”¨VGGçš„ç»“æ„åå‘æ±‚å¯¼æ›´æ–°å›¾ç‰‡ã€‚ç”±äºVGGç»“æ„å¤æ‚ï¼Œè¿™æ ·åå‘æ›´æ–°é€Ÿåº¦å¾ˆæ…¢ï¼Œæ”¹è¿›æ–¹æ³•æ˜¯å†å¦å¤–è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå°†å†…å®¹å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ‰”åˆ°VGGä¸­åšä¸¤ä¸ªlossï¼Œç„¶ååå‘ä¼ æ’­æ›´æ–°å½“å‰è¿™ä¸ªç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè¿™æ ·è®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå°±å¯èƒ½å°†ä»»æ„çš„å†…å®¹å›¾ç‰‡æ‰”è¿›å»ï¼Œè¾“å‡ºä¸ºé£æ ¼è¿ç§»åçš„å›¾ç‰‡ï¼Œè¿™ä¹Ÿå°±è§£å†³äº†é€Ÿåº¦çš„é—®é¢˜ã€‚è¿™ä¹Ÿå°±æ˜¯å°†Feed-forward image transformationä¸style transferç»“åˆåœ¨ä¸€èµ·ã€‚åŸæ–‡é“¾æ¥ï¼š[Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155)"><title>Perceptual Losses for Real-Time Style Transfer and Super-Resolution</title><link rel=canonical href=https://davidham3.github.io/blog/p/perceptual-losses-for-real-time-style-transfer-and-super-resolution/><link rel=stylesheet href=/blog/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="Perceptual Losses for Real-Time Style Transfer and Super-Resolution"><meta property='og:description' content="ECCV 2016ï¼Œå®æ—¶é£æ ¼è¿ç§»ä¸è¶…åˆ†è¾¨ç‡åŒ–çš„æ„ŸçŸ¥æŸå¤±ï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯åœ¨cs231né‡Œé¢çœ‹åˆ°çš„ï¼Œæ­£å¥½æœ€è¿‘åœ¨ç ”ç©¶é£æ ¼è¿ç§»ã€‚ä¸€ä½œæ˜¯Justin Johnsonï¼Œ2017æ˜¥çš„cs231nçš„ä¸»è®²ä¹‹ä¸€ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦å†…å®¹æ˜¯å¯¹Gatysç­‰äººçš„é£æ ¼è¿ç§»åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¤§å¹…æå‡äº†æ€§èƒ½ã€‚ä¸»è¦åŸç†å°±æ˜¯ï¼Œä¹‹å‰Gatysç­‰äººçš„è®ºæ–‡æ˜¯åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„VGG19ï¼Œæ±‚losså¹¶åˆ©ç”¨VGGçš„ç»“æ„åå‘æ±‚å¯¼æ›´æ–°å›¾ç‰‡ã€‚ç”±äºVGGç»“æ„å¤æ‚ï¼Œè¿™æ ·åå‘æ›´æ–°é€Ÿåº¦å¾ˆæ…¢ï¼Œæ”¹è¿›æ–¹æ³•æ˜¯å†å¦å¤–è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå°†å†…å®¹å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ‰”åˆ°VGGä¸­åšä¸¤ä¸ªlossï¼Œç„¶ååå‘ä¼ æ’­æ›´æ–°å½“å‰è¿™ä¸ªç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè¿™æ ·è®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå°±å¯èƒ½å°†ä»»æ„çš„å†…å®¹å›¾ç‰‡æ‰”è¿›å»ï¼Œè¾“å‡ºä¸ºé£æ ¼è¿ç§»åçš„å›¾ç‰‡ï¼Œè¿™ä¹Ÿå°±è§£å†³äº†é€Ÿåº¦çš„é—®é¢˜ã€‚è¿™ä¹Ÿå°±æ˜¯å°†Feed-forward image transformationä¸style transferç»“åˆåœ¨ä¸€èµ·ã€‚åŸæ–‡é“¾æ¥ï¼š[Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155)"><meta property='og:url' content='https://davidham3.github.io/blog/p/perceptual-losses-for-real-time-style-transfer-and-super-resolution/'><meta property='og:site_name' content='Davidhamçš„åšå®¢'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='machine learning'><meta property='article:tag' content='computer vision'><meta property='article:tag' content='image style transfer'><meta property='article:tag' content='super resolution'><meta property='article:tag' content='å·²å¤ç°'><meta property='article:published_time' content='2018-03-01T19:01:46+00:00'><meta property='article:modified_time' content='2018-03-01T19:01:46+00:00'><meta name=twitter:title content="Perceptual Losses for Real-Time Style Transfer and Super-Resolution"><meta name=twitter:description content="ECCV 2016ï¼Œå®æ—¶é£æ ¼è¿ç§»ä¸è¶…åˆ†è¾¨ç‡åŒ–çš„æ„ŸçŸ¥æŸå¤±ï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯åœ¨cs231né‡Œé¢çœ‹åˆ°çš„ï¼Œæ­£å¥½æœ€è¿‘åœ¨ç ”ç©¶é£æ ¼è¿ç§»ã€‚ä¸€ä½œæ˜¯Justin Johnsonï¼Œ2017æ˜¥çš„cs231nçš„ä¸»è®²ä¹‹ä¸€ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦å†…å®¹æ˜¯å¯¹Gatysç­‰äººçš„é£æ ¼è¿ç§»åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¤§å¹…æå‡äº†æ€§èƒ½ã€‚ä¸»è¦åŸç†å°±æ˜¯ï¼Œä¹‹å‰Gatysç­‰äººçš„è®ºæ–‡æ˜¯åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„VGG19ï¼Œæ±‚losså¹¶åˆ©ç”¨VGGçš„ç»“æ„åå‘æ±‚å¯¼æ›´æ–°å›¾ç‰‡ã€‚ç”±äºVGGç»“æ„å¤æ‚ï¼Œè¿™æ ·åå‘æ›´æ–°é€Ÿåº¦å¾ˆæ…¢ï¼Œæ”¹è¿›æ–¹æ³•æ˜¯å†å¦å¤–è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå°†å†…å®¹å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ‰”åˆ°VGGä¸­åšä¸¤ä¸ªlossï¼Œç„¶ååå‘ä¼ æ’­æ›´æ–°å½“å‰è¿™ä¸ªç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè¿™æ ·è®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå°±å¯èƒ½å°†ä»»æ„çš„å†…å®¹å›¾ç‰‡æ‰”è¿›å»ï¼Œè¾“å‡ºä¸ºé£æ ¼è¿ç§»åçš„å›¾ç‰‡ï¼Œè¿™ä¹Ÿå°±è§£å†³äº†é€Ÿåº¦çš„é—®é¢˜ã€‚è¿™ä¹Ÿå°±æ˜¯å°†Feed-forward image transformationä¸style transferç»“åˆåœ¨ä¸€èµ·ã€‚åŸæ–‡é“¾æ¥ï¼š[Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=åˆ‡æ¢èœå•>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a95981f1fc190aef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸš€</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidhamçš„åšå®¢</a></h1><h2 class=site-description>éšä¾¿å†™å†™</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>æš—è‰²æ¨¡å¼</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">ç›®å½•</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#architecture>Architecture</a></li><li><a href=#inputs-and-outputs>Inputs and Outputs</a></li><li><a href=#downsampling-and-upsampling>Downsampling and Upsampling</a></li></ol><ol><li><a href=#featue-reconstruction-loss>Featue Reconstruction Loss</a></li><li><a href=#style-reconstruction-loss>Style Reconstruction Loss</a></li></ol><ol><li><a href=#style-transfer>Style Transfer</a></li><li><a href=#single-image-super_resolution>Single-Image Super_Resolution</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>è®ºæ–‡é˜…è¯»ç¬”è®°</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/perceptual-losses-for-real-time-style-transfer-and-super-resolution/>Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a></h2><h3 class=article-subtitle>ECCV 2016ï¼Œå®æ—¶é£æ ¼è¿ç§»ä¸è¶…åˆ†è¾¨ç‡åŒ–çš„æ„ŸçŸ¥æŸå¤±ï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯åœ¨cs231né‡Œé¢çœ‹åˆ°çš„ï¼Œæ­£å¥½æœ€è¿‘åœ¨ç ”ç©¶é£æ ¼è¿ç§»ã€‚ä¸€ä½œæ˜¯Justin Johnsonï¼Œ2017æ˜¥çš„cs231nçš„ä¸»è®²ä¹‹ä¸€ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦å†…å®¹æ˜¯å¯¹Gatysç­‰äººçš„é£æ ¼è¿ç§»åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¤§å¹…æå‡äº†æ€§èƒ½ã€‚ä¸»è¦åŸç†å°±æ˜¯ï¼Œä¹‹å‰Gatysç­‰äººçš„è®ºæ–‡æ˜¯åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„VGG19ï¼Œæ±‚losså¹¶åˆ©ç”¨VGGçš„ç»“æ„åå‘æ±‚å¯¼æ›´æ–°å›¾ç‰‡ã€‚ç”±äºVGGç»“æ„å¤æ‚ï¼Œè¿™æ ·åå‘æ›´æ–°é€Ÿåº¦å¾ˆæ…¢ï¼Œæ”¹è¿›æ–¹æ³•æ˜¯å†å¦å¤–è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå°†å†…å®¹å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ‰”åˆ°VGGä¸­åšä¸¤ä¸ªlossï¼Œç„¶ååå‘ä¼ æ’­æ›´æ–°å½“å‰è¿™ä¸ªç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè¿™æ ·è®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå°±å¯èƒ½å°†ä»»æ„çš„å†…å®¹å›¾ç‰‡æ‰”è¿›å»ï¼Œè¾“å‡ºä¸ºé£æ ¼è¿ç§»åçš„å›¾ç‰‡ï¼Œè¿™ä¹Ÿå°±è§£å†³äº†é€Ÿåº¦çš„é—®é¢˜ã€‚è¿™ä¹Ÿå°±æ˜¯å°†Feed-forward image transformationä¸style transferç»“åˆåœ¨ä¸€èµ·ã€‚åŸæ–‡é“¾æ¥ï¼š[Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 01, 2018</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>é˜…è¯»æ—¶é•¿: 5 åˆ†é’Ÿ</time></div></footer></div></header><section class=article-content><p>ECCV 2016ï¼Œå®æ—¶é£æ ¼è¿ç§»ä¸è¶…åˆ†è¾¨ç‡åŒ–çš„æ„ŸçŸ¥æŸå¤±ï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯åœ¨cs231né‡Œé¢çœ‹åˆ°çš„ï¼Œæ­£å¥½æœ€è¿‘åœ¨ç ”ç©¶é£æ ¼è¿ç§»ã€‚ä¸€ä½œæ˜¯Justin Johnsonï¼Œ2017æ˜¥çš„cs231nçš„ä¸»è®²ä¹‹ä¸€ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦å†…å®¹æ˜¯å¯¹Gatysç­‰äººçš„é£æ ¼è¿ç§»åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¤§å¹…æå‡äº†æ€§èƒ½ã€‚
ä¸»è¦åŸç†å°±æ˜¯ï¼Œä¹‹å‰Gatysç­‰äººçš„è®ºæ–‡æ˜¯åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„VGG19ï¼Œæ±‚losså¹¶åˆ©ç”¨VGGçš„ç»“æ„åå‘æ±‚å¯¼æ›´æ–°å›¾ç‰‡ã€‚ç”±äºVGGç»“æ„å¤æ‚ï¼Œè¿™æ ·åå‘æ›´æ–°é€Ÿåº¦å¾ˆæ…¢ï¼Œæ”¹è¿›æ–¹æ³•æ˜¯å†å¦å¤–è®¾è®¡ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå°†å†…å®¹å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ‰”åˆ°VGGä¸­åšä¸¤ä¸ªlossï¼Œç„¶ååå‘ä¼ æ’­æ›´æ–°å½“å‰è¿™ä¸ªç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè¿™æ ·è®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå°±å¯èƒ½å°†ä»»æ„çš„å†…å®¹å›¾ç‰‡æ‰”è¿›å»ï¼Œè¾“å‡ºä¸ºé£æ ¼è¿ç§»åçš„å›¾ç‰‡ï¼Œè¿™ä¹Ÿå°±è§£å†³äº†é€Ÿåº¦çš„é—®é¢˜ã€‚è¿™ä¹Ÿå°±æ˜¯å°†Feed-forward image transformationä¸style transferç»“åˆåœ¨ä¸€èµ·ã€‚åŸæ–‡é“¾æ¥ï¼š<a class=link href=https://arxiv.org/abs/1603.08155 target=_blank rel=noopener>Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a></p><h1 id=image-transformation-network>Image Transformation Network</h1><h2 id=architecture>Architecture</h2><p>We do not use any pooling layers, instead using strided and fractionally strided convolutions for in-network downsampling and upsampling. Our network body consists of five residual blocks using the architecture of http://torch. ch/blog/2016/02/04/resnets.html. All non-residual convolutional layers are followed by spatial batch normalization and ReLU nonlinearities with the exception of the output layer, which instead uses a scaled tanh to ensure that the output image has pixels in the range [0, 255]. Other than the first and last layers with use $9 \times 9$ kernels, all convolutional layers use $3 \times 3$ kernels. The exact architectures of all our networks can be found in the supplementary material.</p><h2 id=inputs-and-outputs>Inputs and Outputs</h2><p>For style transfer the input and output are both color images of shape #3 \times 256 \times 256#.
For super-resolution with an upsampling factor of $f$, the output is a high-resolution patch of shape $3 \times 288/f \times 288/f$. Since the image transformation networks are fully-convolutional, at test-time they can be applied to images of any resolution.</p><h2 id=downsampling-and-upsampling>Downsampling and Upsampling</h2><p>For super-resolution with an upsampling factor of $f$, we use several residual blocks followed by $log_2f$ convolutional layers with stride $1/2$. This is different from [1] who use bicubic interpolation to upsample the low-resolution input before passing it to the network.</p><p>Our style transfer networks use the architecture shown in Table 1 and our super-resolution networks use the architecture shown in Table 2. In these tables &ldquo;$C \times H \times W$ conv&rdquo; denotes a convolutional layer with $C$ filters size $H \times W$ which is immeidately followed by spatial batch normalization [1] and a ReLU nonlinearity.
Our residual blocks each contain two $3 \times 3$ convolutional layers with the same number of filters on both layer. We use the residual block design of Gross and Wilber [2] (shown in Figure 1), which differs from that of He <em>et al</em> [3] in that the ReLU nonlinearity following the addition is removed; this modified design was found in [2] to perform slightly better for image classification.
For style transfer, we found that standard zero-padded convolutions resulted in severe artifacts around the borders of the generated image. We therefore remove padding from the convolutions in residual blocks. A $3 \times 3$ convolution with no padding reduces the size of a feature map by 1 pixel on each side, so in this case the identity connection of the residual block performs a center crop on the input feature map. We also add spatial reflection padding to the beginning of the network so that the input and output of the network have the same size.</p><h1 id=perceptual-loss-functions>Perceptual Loss Functions</h1><p>We define two <em>perceptual loss functions</em> that measure high-level perceptual and semantic differences between images. They make use of a loss <em>network</em> $\phi$ pretrained for image classification, meaning that these perceptual loss functions are themselves deep convolutional neural networks. In all our experiments $\phi$ is the 16-layer VGG network pretrained on the ImageNet dataset.</p><h2 id=featue-reconstruction-loss>Featue Reconstruction Loss</h2><p>Rather than encouraging the pixels of the output image $\hat{y} = f_W(x)$ to exactly match the pixels of the target image $y$, we instead encourage them to have similar feature representations as computed by the loss network $\phi$. Let $\phi_j(x)$ be the activations of the <em>j</em>th layer of the network $\phi$ when processing the image $x$; if $j$ is a convolutional layer then $\phi_j(x)$ will be a feature map of shape $C_j \times H_j \times W_j$. The <em>feature reconstruction loss</em> is the (squared, normalized) Euclidean distance between feature representations:</p>$$\ell\_{feat}^{\phi,j}(\hat{y}, y)=\frac{1}{C\_jH\_jW\_j}\Vert \phi\_j(\hat{y})-\phi\_j(y)\Vert\_2^2$$<p>As demonstrated in [6] and reproduced in Figure 3, finding an image $\hat{y}$ that minimizes the feature reconstruction loss for early layers tends to produce images that are visually indistinguishable from $y$.</p><h2 id=style-reconstruction-loss>Style Reconstruction Loss</h2><p>The feature reconstruction loss penalizes the output image $\hat{y}$ when it deviates in content from the target $y$. We also wish to penalize differences in style: colors, textures, common patterns, etc. To achieve this effect, Gatys <em>et al</em> propose the following <em>style reconstruction loss</em>.
As above, let $\phi_j(x)$ be the activations at the $j$th layer of the network $\phi$ for the input $x$, which is a feature map of shape $C_j \times H_j \times W_j$. Define the <em>Gram matrix</em> $G^\phi_j(x)$ to be the $C_j \times C_j$ matrix whose elements are given by</p>$$G^\phi\_j(x)\_{c,c'}=\frac{1}{C\_jH\_jW\_j}\sum^{H\_j}\_{h=1}\sum\_{w=1}^{W\_j}\phi\_j(x)\_{h,w,c}\phi\_j(x)\_{h,w,c'}$$<h1 id=experiments>Experiments</h1><h2 id=style-transfer>Style Transfer</h2><h2 id=single-image-super_resolution>Single-Image Super_Resolution</h2><p>This is an inherently ill-posed problem, since for each low-resolution image there exist multiple high-resolution images that could have generated it. The ambiguity becomes more extreme as the super-resolution factor grows; for larger factors ($\times 4$, $\times 8$), fine details of the high-resolution image may have little or no evidence in its low-resolution version.
To overcome this problem, we train super-resolution networks not with the per-pixel loss typically used [1] but instead with a feature reconstruction loss to allow transer of semantic knowledge from the pretrained loss network to the super-resolution network. We focus on $\times 4$ and $\times 8$ super-resolution since larger factors require more semantic reasoning about the input.
The traditional metrics used to evaluate super-resolution are PSNR and SSIM, both of which have been found to correlate poorly with human assessment of visual quality. PSNR and SSIM rely only on low-level differences between pixels and operate under the assumption of additive Gasussian noise, which may be invalid for super-resolution. In addition, PSNR is equivalent to the per-pixel loss $\mathcal{l_{pixle}}$, so as measured by PSNR a model trained to minimize feature reconstruction loss should always outperform a model trained to minimize feature reconstruction loss. We therefore emphasize that the goal of these experiments is not to achieve state-of-the art PSNR or SSIM results, but instead to showcase the qualitative difference between models trained with per-pixel and feature reconstruction losses.</p><h1 id=code>code</h1><p>æˆ‘ç”¨gluonå®ç°äº†ä¸€ä¸ª2xçš„è¶…åˆ†è¾¨ç‡ç½‘ç»œï¼Œè®­ç»ƒåæ„Ÿè§‰æ•ˆæœä¸€èˆ¬ï¼Œåªæœ‰ä¸€æ¬¡lossé™åˆ°äº†40é™„è¿‘ï¼Œé‚£æ¬¡æ•ˆæœæŒºå¥½ï¼Œä½†æ˜¯é¢œè‰²å¹¶ä¸æ˜¯å¾ˆå¥½
ä»¥ä¸‹æ˜¯ä»£ç ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mxnet</span> <span class=k>as</span> <span class=nn>mx</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mxnet</span> <span class=kn>import</span> <span class=n>nd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mxnet</span> <span class=kn>import</span> <span class=n>autograd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mxnet</span> <span class=kn>import</span> <span class=n>gluon</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mxnet.gluon</span> <span class=kn>import</span> <span class=n>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mxnet</span> <span class=kn>import</span> <span class=n>init</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mxnet.gluon.model_zoo</span> <span class=kn>import</span> <span class=n>vision</span> <span class=k>as</span> <span class=n>models</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=c1># get_ipython().run_line_magic(&#39;matplotlib&#39;, &#39;inline&#39;)</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=cl><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data_filenames</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;trainx_</span><span class=si>%s</span><span class=s1>.params&#39;</span><span class=o>%</span><span class=p>(</span><span class=n>i</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>7</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=n>target_filenames</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;trainy_</span><span class=si>%s</span><span class=s1>.params&#39;</span><span class=o>%</span><span class=p>(</span><span class=n>i</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>7</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=n>load_params</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=n>epochs</span> <span class=o>=</span> <span class=mi>500</span>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>ratio</span> <span class=o>=</span> <span class=mf>0.1</span>
</span></span><span class=line><span class=cl><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>1e-5</span>
</span></span><span class=line><span class=cl><span class=n>start_index</span><span class=p>,</span> <span class=n>end_index</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>7</span>
</span></span><span class=line><span class=cl><span class=n>num_samples</span> <span class=o>=</span> <span class=n>end_index</span> <span class=o>-</span> <span class=n>start_index</span>
</span></span><span class=line><span class=cl><span class=n>ctx</span> <span class=o>=</span> <span class=p>[</span><span class=n>mx</span><span class=o>.</span><span class=n>gpu</span><span class=p>(</span><span class=n>i</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>load_params</span> <span class=o>==</span> <span class=kc>False</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;training.log&#39;</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>residual_unit</span><span class=p>(</span><span class=n>gluon</span><span class=o>.</span><span class=n>HybridBlock</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>channels</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>residual_unit</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2D</span><span class=p>(</span><span class=n>channels</span> <span class=o>=</span> <span class=n>channels</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>use_bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm</span><span class=p>(</span><span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>act1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Activation</span><span class=p>(</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2D</span><span class=p>(</span><span class=n>channels</span> <span class=o>=</span> <span class=n>channels</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>use_bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm</span><span class=p>(</span><span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>act2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Activation</span><span class=p>(</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2D</span><span class=p>(</span><span class=n>channels</span> <span class=o>=</span> <span class=n>channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>use_bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>act3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Activation</span><span class=p>(</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>hybrid_forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>F</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>t</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>act1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>t</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>act2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>t</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>x2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>act3</span><span class=p>(</span><span class=n>t</span> <span class=o>+</span> <span class=n>x2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>plsr_network</span><span class=p>(</span><span class=n>gluon</span><span class=o>.</span><span class=n>HybridBlock</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>plsr_network</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>name_scope</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2D</span><span class=p>(</span><span class=n>channels</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>9</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>use_bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>residual_sequential</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>HybridSequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>residual_sequential</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>residual_unit</span><span class=p>(</span><span class=mi>64</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>deconv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2DTranspose</span><span class=p>(</span><span class=n>channels</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>output_padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>use_bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2D</span><span class=p>(</span><span class=n>channels</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>9</span><span class=p>,</span> <span class=n>strides</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>use_bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>HybridSequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>net</span><span class=o>.</span><span class=n>add</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>conv1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>residual_sequential</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>deconv1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>conv2</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>hybrid_forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>F</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>net</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>out</span> <span class=o>=</span> <span class=n>i</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>tv_loss</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>data1</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>nd</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>x</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>1</span><span class=p>:,</span> <span class=p>:]</span> <span class=o>-</span> <span class=n>x</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]))</span>
</span></span><span class=line><span class=cl>    <span class=n>data2</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>nd</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>x</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=mi>1</span><span class=p>:]</span> <span class=o>-</span> <span class=n>x</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>data1</span> <span class=o>+</span> <span class=n>data2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_vgg_loss_net</span><span class=p>(</span><span class=n>pretrained_net</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>HybridSequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>9</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>net</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>pretrained_net</span><span class=o>.</span><span class=n>features</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>net</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_loss</span><span class=p>(</span><span class=n>vgg_loss_net</span><span class=p>,</span> <span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>,</span> <span class=n>ratio</span> <span class=o>=</span> <span class=mf>0.1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>nd</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>nd</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>vgg_loss_net</span><span class=p>(</span><span class=n>output</span><span class=p>)</span> <span class=o>-</span> <span class=n>target</span><span class=p>))</span> <span class=o>+</span> <span class=n>ratio</span> <span class=o>*</span> <span class=n>tv_loss</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rgb_mean</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>])</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>rgb_std</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_samples</span><span class=o>*</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>72</span><span class=p>,</span> <span class=mi>72</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>target</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=n>shape</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_samples</span><span class=o>*</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>72</span><span class=p>,</span> <span class=mi>72</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>total_size</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>data_filenames</span><span class=p>,</span> <span class=n>target_filenames</span><span class=p>))[:</span><span class=n>num_samples</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>nd</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>i</span><span class=p>)[</span><span class=mi>0</span><span class=p>],</span> <span class=n>nd</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>j</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>total_size</span> <span class=o>+=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=n>index</span><span class=o>*</span><span class=mi>1000</span><span class=p>:</span> <span class=p>(</span><span class=n>index</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=mi>1000</span><span class=p>],</span> <span class=n>target</span><span class=p>[</span><span class=n>index</span><span class=o>*</span><span class=mi>1000</span><span class=p>:</span> <span class=p>(</span><span class=n>index</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=mi>1000</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>data</span><span class=p>[:</span><span class=n>total_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>target</span> <span class=o>=</span> <span class=n>target</span><span class=p>[:</span><span class=n>total_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[:]</span> <span class=o>-=</span> <span class=n>data</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plsr</span> <span class=o>=</span> <span class=n>plsr_network</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>load_params</span> <span class=o>==</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>plsr</span><span class=o>.</span><span class=n>load_params</span><span class=p>(</span><span class=s1>&#39;plsr.params&#39;</span><span class=p>,</span> <span class=n>ctx</span> <span class=o>=</span> <span class=n>ctx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>plsr</span><span class=o>.</span><span class=n>initialize</span><span class=p>(</span><span class=n>ctx</span> <span class=o>=</span> <span class=n>ctx</span><span class=p>,</span> <span class=n>init</span><span class=o>=</span><span class=n>init</span><span class=o>.</span><span class=n>Xavier</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plsr</span><span class=o>.</span><span class=n>hybridize</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>pretrained_net</span> <span class=o>=</span> <span class=n>models</span><span class=o>.</span><span class=n>vgg16</span><span class=p>(</span><span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>vgg_loss_net</span> <span class=o>=</span> <span class=n>get_vgg_loss_net</span><span class=p>(</span><span class=n>pretrained_net</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>vgg_loss_net</span><span class=o>.</span><span class=n>collect_params</span><span class=p>()</span><span class=o>.</span><span class=n>reset_ctx</span><span class=p>(</span><span class=n>ctx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>gluon</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>Trainer</span><span class=p>(</span><span class=n>plsr</span><span class=o>.</span><span class=n>collect_params</span><span class=p>(),</span> <span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=p>{</span><span class=s1>&#39;learning_rate&#39;</span><span class=p>:</span> <span class=n>learning_rate</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                                <span class=s1>&#39;beta1&#39;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                                <span class=s1>&#39;beta2&#39;</span><span class=p>:</span> <span class=mf>0.99</span><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=n>dataloader</span> <span class=o>=</span> <span class=n>gluon</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>gluon</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>ArrayDataset</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>),</span> <span class=n>batch_size</span> <span class=o>=</span> <span class=n>batch_size</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>training_loss</span> <span class=o>=</span> <span class=mf>0.</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>data_list</span> <span class=o>=</span> <span class=n>gluon</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>split_and_load</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>ctx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>target_list</span> <span class=o>=</span> <span class=n>gluon</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>split_and_load</span><span class=p>(</span><span class=n>target</span><span class=p>,</span> <span class=n>ctx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>autograd</span><span class=o>.</span><span class=n>record</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>data_list</span><span class=p>,</span> <span class=n>target_list</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>                <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>get_loss</span><span class=p>(</span><span class=n>vgg_loss_net</span><span class=p>,</span>                                       <span class=p>(</span><span class=n>plsr</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>-</span><span class=n>rgb_mean</span><span class=o>.</span><span class=n>copyto</span><span class=p>(</span><span class=n>data</span><span class=o>.</span><span class=n>context</span><span class=p>))</span><span class=o>/</span><span class=n>rgb_std</span><span class=o>.</span><span class=n>copyto</span><span class=p>(</span><span class=n>data</span><span class=o>.</span><span class=n>context</span><span class=p>),</span>                                       <span class=n>target</span><span class=p>,</span> <span class=n>ratio</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>loss</span> <span class=ow>in</span> <span class=n>losses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>trainer</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>training_loss</span> <span class=o>+=</span> <span class=nb>sum</span><span class=p>([</span><span class=n>l</span><span class=o>.</span><span class=n>asscalar</span><span class=p>()</span> <span class=k>for</span> <span class=n>l</span> <span class=ow>in</span> <span class=n>losses</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>epoch</span><span class=p>,</span> <span class=n>training_loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;training.log&#39;</span><span class=p>,</span> <span class=s1>&#39;a&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>training_loss</span><span class=p>)</span><span class=o>+</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plsr</span><span class=o>.</span><span class=n>save_params</span><span class=p>(</span><span class=s1>&#39;plsr.params&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>åœ¨å®ç°çš„æ—¶å€™ï¼Œè¶…åˆ†è¾¨ç‡åéœ€è¦ä¸€ä¸ªåå¤„ç†â€”â€”ç›´æ–¹å›¾åŒ¹é…ï¼Œè¿™é‡Œå‚è€ƒçš„æ˜¯<a class=link href=https://github.com/mapbox/rio-hist/blob/master/rio_hist/match.py target=_blank rel=noopener>rio-hist</a>ã€‚
å®éªŒæ•°æ®æœ€å¼€å§‹ç”¨çš„æ˜¯Microsoftçš„coco2017ï¼Œå°†æ¯å¼ å›¾éšæœºæˆªå–$144 \times 144$åƒç´ çš„å¤§å°ï¼Œç„¶åä½¿ç”¨å®½åº¦ä¸º1çš„é«˜æ–¯æ ¸è¿›è¡Œæ¨¡ç³Šå¤„ç†åï¼Œdownsamplingäº†ä¸€ä¸‹ï¼Œå¾—åˆ°äº†$72 \times 72$çš„å›¾ç‰‡ï¼Œä½œä¸ºç½‘ç»œçš„è¾“å…¥ã€‚åæ¥å‘ç°æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œå°±æ‰“ç®—å‘waifu2xä¸€æ ·ï¼Œåªè®­ç»ƒåŠ¨æ¼«å›¾ç‰‡ï¼Œä¸Škonachanä¸Šçˆ¬äº†ä¸€ä¸‡å¼ å›¾ï¼ŒåšåŒæ ·çš„å¤„ç†ã€‚æ­¤æ—¶çš„lossé™åˆ°äº†31.
<img src=/blog/images/perceptual-losses-for-real-time-style-transfer-and-super-resolution/400_0.1_31.png loading=lazy alt=Fig1>
è¿™æ˜¯è®­ç»ƒçš„æœ€å¥½çš„ä¸€æ¬¡ï¼Œæœ€å·¦ä¾§æ˜¯è¾“å…¥çš„æ¨¡ç³Šå›¾ç‰‡ï¼Œç¬¬äºŒåˆ—æ˜¯ç½‘ç»œçš„è¾“å‡ºï¼Œç¬¬ä¸‰åˆ—æ˜¯åšäº†ç›´æ–¹å›¾åŒ¹é…å¾—åˆ°çš„å›¾ç‰‡ï¼Œç¬¬å››åˆ—æ˜¯ground truthã€‚å¯ä»¥çœ‹åˆ°æœ‰å¾ˆå¤šå°ç‚¹ç‚¹ï¼Œæˆ‘åˆ†ææ˜¯tv losså æ¯”å¤ªå°çš„åŸå› ï¼Œå½“å‰tv lossä¹˜ä»¥äº†0.1ã€‚äºæ˜¯å°†tv lossä¹˜ä»¥0.5ååˆè®­ç»ƒäº†ä¸€æ¬¡ï¼Œlossé™åˆ°äº†58ï¼Œç»“æœå¦‚ä¸‹ï¼š
<img src=/blog/images/perceptual-losses-for-real-time-style-transfer-and-super-resolution/400_0.5_58.png loading=lazy alt=Fig2>
æ„Ÿè§‰æ²¡æ³•çœ‹äº†ã€‚ã€‚ã€‚</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/machine-learning/>Machine Learning</a>
<a href=/blog/tags/computer-vision/>Computer Vision</a>
<a href=/blog/tags/image-style-transfer/>Image Style Transfer</a>
<a href=/blog/tags/super-resolution/>Super Resolution</a>
<a href=/blog/tags/%E5%B7%B2%E5%A4%8D%E7%8E%B0/>å·²å¤ç°</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>ç›¸å…³æ–‡ç« </h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/image-style-transfer-using-convolutional-neural-networks/><div class=article-details><h2 class=article-title>Image Style Transfer Using Convolutional Neural Networks</h2></div></a></article><article><a href=/blog/p/spatial-temporal-graph-convolutional-networks-for-skeleton-based-action-recognition/><div class=article-details><h2 class=article-title>Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition</h2></div></a></article><article><a href=/blog/p/identity-mappings-in-deep-residual-networks/><div class=article-details><h2 class=article-title>Identity Mappings in Deep Residual Networks</h2></div></a></article><article><a href=/blog/p/image-super-resolution-using-deep-convolutional-networks/><div class=article-details><h2 class=article-title>Image Super-Resolution Using Deep Convolutional Networks</h2></div></a></article><article><a href=/blog/p/layer-normalization/><div class=article-details><h2 class=article-title>Layer Normalization</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Davidhamçš„åšå®¢</section><section class=powerby>ä½¿ç”¨ <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> æ„å»º<br>ä¸»é¢˜ <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> ç”± <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> è®¾è®¡</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>