<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：[DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis](https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf)"><title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</title><link rel=canonical href=https://davidham3.github.io/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/><link rel=stylesheet href=/blog/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis"><meta property='og:description' content="AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：[DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis](https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf)"><meta property='og:url' content='https://davidham3.github.io/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='Spatial-temporal'><meta property='article:tag' content='graph convolutional network'><meta property='article:tag' content='Graph'><meta property='article:tag' content='Time Series'><meta property='article:published_time' content='2019-05-08T16:40:48+00:00'><meta property='article:modified_time' content='2019-05-08T16:40:48+00:00'><meta name=twitter:title content="DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis"><meta name=twitter:description content="AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：[DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis](https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a95981f1fc190aef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#problem-formulation>Problem Formulation</a></li></ol><ol><li><a href=#resplus>ResPlus</a></li><li><a href=#semanticplus>SemanticPlus</a></li><li><a href=#fusion>Fusion</a></li><li><a href=#training>Training</a></li></ol><ol><li><a href=#datasets>Datasets</a></li><li><a href=#baselines>Baselines</a></li><li><a href=#metrics-and-parameters>Metrics and Parameters</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>论文阅读笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</a></h2><h3 class=article-subtitle>AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：[DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis](https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 08, 2019</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 9 分钟</time></div></footer></div></header><section class=article-content><p>AAAI 2019，网格流量预测，对比ST-ResNet，抛出三个问题，卷积捕获的空间范围小、人口流动和区域的功能相关、之前的融合机制不好。改了一下残差卷积，给 POI 信息增加了时间维度，多组件的信息提前融合，减少了参数，稳定模型训练。原文链接：<a class=link href=https://github.com/FIBLAB/DeepSTN/blob/master/docs/5624_AAAI19_DeepSTN%2B_Camera_Ready.pdf target=_blank rel=noopener>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</a></p><h1 id=abstract>Abstract</h1><p>人口流量预测在城市规划、交通管控中的很多应用中都很重要。目的是预测流入和流出流量。我们提出了 DeepSTN+，一个基于深度学习的卷积模型，预测超大城市的人口流量。首先，DeepSTN+ 使用 <em>ConvPlus</em> 结构对大范围的空间依赖建模。此外，POI 分布和时间因素相融合来表达区域属性的影响，以此引入人口流动的先验知识。最后，我们提出了一个有效的融合机制来稳定训练过程，提升了结果。基于两个真实数据集的大量实验结果表明我们模型的先进性，和 state-of-the-art 比高了 8% ~ 13% 左右。</p><h1 id=introduction>Introduction</h1><p>如图 1 所示，人口流量预测是在给定历史流量信息的前提下，预测城市内每个区域的流入和流出流量。最近，为了解决这个问题，基于深度学习的模型被相继提出，获得了很好的效果。Deep-ST 是第一个使用卷积网络捕获空间信息的模型。ST-ResNet 用卷积模块替换了卷积。通过融合金字塔型的 ConvGRU 模型和周期表示，Periodic-CRN 设计成了捕获人口流动周期性的模型。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig1.JPG loading=lazy alt=Figure1></p><p>这些方法仍然不够有效且不精确：</p><ol><li><em>不能捕获区域间的空间依赖。</em> 由于现代城市中高级的运输系统的存在，人们可以通过地铁或出租车在短时间内移动到很远的地方。因此，区域间的大范围空间依赖在人口移动中逐渐扮演重要的角色。现存的工作使用多层卷积网络来建模。然而，它们只能一步一步地捕获近邻的空间依赖，不能直接地捕获大范围的空间依赖。</li><li><em>忽略了人口流动的区域功能的影响。</em> 人口移动是发生在物理世界中的，会直接受到区域属性的影响。举个例子，人们通常早上从家出发到公司，晚上回来。显然，区域的功能（属性）包含了关于人类移动的先验知识。然而，现存的解决方案没有考虑过区域的属性。</li><li><em>冗余以及不稳定的神经网络结构。</em> ST-ResNet 利用了三个独立分支，每个分支都是残差卷积单元，用来处理不同的输入，在模型的结尾用一个线性操作融合三个输出。但是，最后的融合机制导致不同组件间的交互产生了缺陷，这个缺陷导致了网络内产生了无效的参数和不稳定的性质。</li></ol><p>总结一下，模型应该考虑大范围的空间依赖，区域的影响，更有效的融合机制这三点因素。我们提出的 DeepSTN+ 解决了上述挑战。我们设计了一个 <em>ConvPlus</em> 结构直接地捕获大范围空间依赖。<em>ConvPlus</em> 放在残差单元前面作为一个全局特征提取器提取出区域间的全局特征。其次，我们设计了一个 <em>SemanticPlus</em> 结构来学习人口在区域间移动的先验知识。用静态的 POI 分布作为输入，<em>SemanticPlus</em> 利用时间因素给不同时间上不同的 POI 分配权重。最后，我们引入早融合和多尺度融合机制来减少训练参数，捕获不同级别特征间的复杂关系。这样，我们的系统可以对更复杂的空间关联性建模，获得更好的效果，我们的贡献有以下几点：</p><ul><li>我们设计了一个新的残差单元，ResPlus 单元用来替换原始的残差单元。我们指出了典型的卷积模型不能有效地捕获大范围依赖。ResPlus 包含了一个 <em>ConvPlus</em> 结构，可以捕获人流间的大范围空间依赖。</li><li>我们设计了一个 <em>SemanticPlus</em> 结构来建模不同区域的影响，学习人口流动的先验知识。我们在模型头部使用早融合机制，在结尾使用多尺度融合机制，提升了模型的精度和稳定性。</li><li>我们在两个数据集上开展了大量的实验，对比了 5 个 baselines，结果显示我们的模型在预测人口流动的错误上减少了 8% ~ 13%。</li></ul><h1 id=preliminaries>Preliminaries</h1><p>这部分，我们首先介绍人口流量预测问题，简要回顾 ST-ResNet。</p><h2 id=problem-formulation>Problem Formulation</h2><p>**Definition 1 (Region (Zhang et al. 2016)) 为了表示城市的区域，我们基于经纬度将城市划分成 $H \times W$ 个区域，所有的网格有相同大小且表示一个区域。</p><p>**Definition 2 (Inflow/outflow (Zhang et al. 2016)) 为了表示城市内的人口流动，我们定义了区域 $(h, w)$ 在时段 $i$ 的流入和流出流量：</p><p>$$
x^{h,w,in}_{i} = \sum_{T_{r_k} \in \mathbb{P}} \vert \lbrace j > 1 \mid g_{j-1} \not \in (h, w) \And g_j \in (h, w) \rbrace \vert,\</p><p>x^{h,w,out}_{i} = \sum_{T_{r_k} \in \mathbb{P}} \vert \lbrace j \geq 1 \mid g_{j-1} \in (h, w) \And g_j \not \in (h, w) \rbrace \vert.
$$</p><p>这里 $\mathbb{P}$ 表示时段 $i$ 的轨迹集合。$T_r: g_1 \rightarrow g_2 \rightarrow \cdots \rightarrow g_{\vert T_r \vert}$ 是 $\mathbb{P}$ 中的一条轨迹，$g_j$ 是坐标；
$g_j \in (h, w)$ 表示点 $g_j$ 在网格 $(h, w)$ 内，反之亦然；$\vert \cdot \vert$ 表示集合的基数。</p><p><strong>Crowd Flow Prediction</strong>: 给定历史观测值 $\lbrace \mathbf{X}_i \mid i=1,2,\cdots, n-1 \rbrace$，预测 $\mathbf{X}_n$。</p><p>ST-ResNet 包含四个组件，<em>closeness</em>, <em>period</em>, <em>trend</em> 和 外部因素单元。每个组成部分通过一个分支的残差单元或全连接层预测出一个流量地图。然后模型使用一个线性组合作为末端融合方式融合这些预测值。ST-ResNet 的外部因素包含了天气、假期事件、元数据。</p><p>卷积神经网络的卷积核通常很小，意味着他们不能直接捕获远距离的空间依赖。然而，大范围的空间依赖在城市中很重要。另一方面，ST-ResNet 忽略了人口流动的在位置上的影响。此外，ST-ResNet 的末端融合机制导致了模型交互上的缺点以及参数的低效，还有模型的不稳定的问题。</p><h1 id=our-model>Our Model</h1><p>图 2 展示了我们模型的框架。主要有三个部分：流量输入、SemanticPlus 和 ResPlus 单元。流量慎入包含 <em>closeness, period, terend</em>，由于数据的时间范围限制可以减少为 <em>closeness, period</em>。SemanticPlus 包含 POI 分布和时间信息。ResPlus 单元可以捕获远距离空间依赖。每个区域的流入和流出流量通过每小时或者每半小时统计得到流量地图的时间序列。这些流量地图通过 Min-Max 归一化处理到 $[-1, 1]$。如图 2 所示，人口分布地图通过近期时间、近邻历史、远期历史选择后作为输入放入模型。不同类型的 POI 分布通过 Min-Max 归一化到 $[0, 1]$。如图 2 做部分所示，POI 分布地图通过时间信息赋予了不同的权重。之后，POI 信息和人流信息通过早融合后放入堆叠的 ResPlus 单元中。最后，ResPlus 单元不同级别的特征融合后进入卷积部分，然后通过 Tanh 映射到 $[-1, 1]$。下面会介绍细节。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig2.JPG loading=lazy alt=Figure2></p><h2 id=resplus>ResPlus</h2><p>很多处理人口流量预测的深度学习模型主要包含两个部分：基于 RNN 的结构，像 ConvLSTM 和 Periodic-CRN，以及基于 CNN 的结构，如 Deep-ST 和 ST-ResNet。但是，训练基于 RNN 结构的模型费时。因此我们选用基于 CNN 的结构 ST-ResNet 作为我们的基础模型。</p><p>在这篇论文中，我们设计 ConvPlus 来捕获城市内远距离的空间依赖。如图 3，ResPlus 单元使用一个 ConvPlus 和一个典型卷积。我们尝试了 Batch Normalization 和 Dropout，为了简介没有在图里面画出来。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig3.JPG loading=lazy alt=Figure3></p><p>典型卷积的每个通道对应一个卷积核。卷积核使用这些核来计算地图上的互相关系数，比如捕获梯度上的特征。卷积核的大小一般很小。在 ST-ResNet 和 DeepSTN+ 里面，卷积核的大小是 $3 \times 3$。但是城市中存在着远距离的依赖。人们可能坐地铁去上班。我们称这类关系叫远距离空间依赖关系。这种关系使得堆叠卷积难以有效地捕获这个关系。</p><p>如图 3 左部分所示，在 ConvPlus 结构中，我们将典型卷积的一些通道分离来捕获每个区域的远距离空间依赖。然后用一个全连接层直接捕获每两个区域之间的远距离空间依赖，在这层前面用一个池化层来减少参数。因此，在 ConvPlus 的输出有两类通道。ConvPlus 的输出有着和普通卷积一样的输出，可以用于下一个卷积的输入。</p><p>图 4 展示了两个不同区域的空间依赖热力图，分别是红色和黄色的星。这些目标区域不仅有区域上的依赖，还有一些和远处区域的远距离依赖。这也显示出不同的区域和地图上的其他区域有不一样的关系，这很难通过堆叠卷积有效地捕获。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig4.JPG loading=lazy alt=Figure4></p><p>因为 ConvPlus 有两类不同的输出通道，我们在 ResPlus 单元中使用 ConvPlus + Conv 而不是 ConvPlus + ConvPlus。没有 SemanticPlus 的 DeepSTN+ 形式化为：</p>$$
\widehat{\mathbf{X}} = f\_{Res}(f\_{EF}(\mathbf{X}^c + \mathbf{X}^p + \mathbf{X}^t)),
$$<p>三个 $\mathbf{X}$ 表示三种类型的历史地图——<em>closeness, period, trend</em>。$\widehat{\mathbf{X}}$ 表示预测出的流量地图。$+$ 表示拼接操作。$f_{EF}$ 表示用来早融合不同类型信息的卷积函数，$f_{Res}$ 表示一个堆叠的 ResPlus 单元。</p><h2 id=semanticplus>SemanticPlus</h2><p>POI 在人口流动上有很强烈的影响，这些影响随时间变化而变化。因此，我们继承这个先验知识到模型内。我们手机了包括类型、数量、位置的 POI 信息。然后统计每个网格内 POI 的数量，使用一个一维向量表示每种 POI 的分布。图 5 展示了北京的流量分布地图和餐饮分布地图。它们的分布很相似，并且互相关系数有 0.87，暗示了它们之间的潜在关系。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig5.JPG loading=lazy alt=Figure5></p><p>我们使用一个时间向量来表示每个人口流量地图的时间。时间向量包含两个部分：一个 one-hot 向量表示一天中的各个时间，如果时段按小时走，那长度就是 24；另一个 one-hot 向量表示是一周中的哪天，长度是 7。一个时间向量拼接了这两个向量。</p><p>为了建模对流量地图有变化的时间影响的 POI 信息，我们将时间向量转换为 POI 的影响强度。我们使用大小为 $PN \times H \times W$ 的 $\mathbf{X}^s$ 来表示 POI 地图（$PN$ 表示 POI 的类数，$H$ 和 $W$ 是网格的行数和列数，一个向量 $\bf{I}$ 用来表示时间向量，大小为 $PN$ 的向量 $\bf{R}$ 表示 POI 的影响强度。因此，我们有带有时间权重的 POI 分布，形式化如下：</p>$$
\mathbf{S} = \mathbf{X}^s \ast \mathbf{R} = \mathbf{X}^s \ast f\_t(\mathbf{I})
$$<p>函数 $f_t()$ 将时间向量转换为表示 POI 影响强度的向量。$\ast$ 表示每个 POI 分布地图会被附上一个权重，表示 POI 的影响强度。我们假设同一类在不同的区域的 POI 有相同的时间模式。因此，一个类别的 POI 分布地图会有相同的权重。图 6 展示了娱乐和居住区的影响强度。影响强度在一周内随时间的变化而变化，每天存在着一些典型的模式。很多人早上去上班，工作结束后回家，所以每天早上和下午住宅区有明显的两个峰。对比居住区，娱乐区的影响相对稳定。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig6.JPG loading=lazy alt=Figure6></p><h2 id=fusion>Fusion</h2><p>三组件应该用更复杂的融合方式，而不是线性组合。这些带有 POI 信息的流量信息也有复杂的交互。为了建模这种相互影响，我们使用早融合而不是末端融合使得不同的信息能更早的融合起来。早融合减少了大约三分之二的参数。此外，ST-ResNet 有些时候不能收敛。我们发现这个问题可以通过早融合减少参数来简化模型解决。考虑到不同层的特征有不同的函数，我们在模型末端设定了一个多尺度的融合机制。这里我们形式化描述整个网络：</p>$$
\widehat{\mathbf{X}} = f\_{con}(f\_{Res}(f\_{EF}(\mathbf{X}^c + \mathbf{X}^p + \mathbf{X}^t + \mathbf{S}))),
$$<p>函数 $f_{EF}$ 表示一个早融合使用的卷积操作，在早融合之前压缩了通道数。函数 $f_{con}$ 表明了最后的多尺度融合，表示卷积层后的一个拼接层。$\bf{S}$ 表示 SemanticPlus 的输出，即 带有时间权重的 POI 分布。</p><h2 id=training>Training</h2><p>算法 1 描述了训练过程。前 7 行是构建训练集和 POI 信息，模型通过 Adam 训练（8-12 行）</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Alg1.JPG loading=lazy alt=Alg1></p><h1 id=performance-evaluation>Performance Evaluation</h1><p>这部分，我们在两个数据集上不同城市的不同类型的流量上做了大量的实验，为了回答三个研究问题：</p><ul><li>我们的提出的 DeepSTN+ 是否比现存的方法好？</li><li>ResPlus, SemanticPlus, 早融合是怎么提升预测结果的？</li><li>DeepSTN+ 的超参数如何影响预测结果？</li></ul><h2 id=datasets>Datasets</h2><p>表 1 包含了数据。每个数据有两个子集：流量轨迹和 POI 信息。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table1.JPG loading=lazy alt=Table1></p><p><em><strong>MobileBJ:</strong></em> 数据是中国一个很流行的社交网络应用商提供的，时间范围是4 月 1 日到 4 月 30 日。记录了用户请求区域服务时的位置。我们用定义 2 转换成了网格流量。我们选择最后一周的数据作为测试集，前面的作为训练集。表 2 展示了这个数据集的 17 类 POI 信息。</p><p><em><strong>BikeNYC:</strong></em> NYC 的自行车数据，2014 年，4 月 1 日到 9 月 30 日。数据包含了旅途时长，出发和到达站的 ID，起始和结束时间。最后 14 天的数据用来测试，其他的训练。我们选了 9 类 POI 信息。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table2.JPG loading=lazy alt=Table2></p><h2 id=baselines>Baselines</h2><ul><li>HA</li><li>VAR</li><li>ARIMA</li><li>ConvLSTM</li><li>ST-ResNet</li></ul><h2 id=metrics-and-parameters>Metrics and Parameters</h2><ul><li>RMSE</li></ul>$$
RMSE = \sqrt{\frac{1}{T} \sum^T\_{i=1} \Vert \mathbf{X}\_i - \widehat{X}\_i \Vert^2\_2},
$$<ul><li>MAE</li></ul>$$
MAE = \frac{1}{T} \sum^T\_{i=1} \vert \mathbf{X}\_i - \widehat{\mathbf{X}}\_i \vert,
$$<p>RMSE 作为 loss function。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table3.JPG loading=lazy alt=Table3></p><p>表 3 展示了不同的参数设置。</p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table4.JPG loading=lazy alt=Table4></p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Table5.JPG loading=lazy alt=Table5></p><p><img src=/blog/images/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/Fig7.JPG loading=lazy alt=Figure7></p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/spatial-temporal/>Spatial-Temporal</a>
<a href=/blog/tags/graph-convolutional-network/>Graph Convolutional Network</a>
<a href=/blog/tags/graph/>Graph</a>
<a href=/blog/tags/time-series/>Time Series</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/><div class=article-details><h2 class=article-title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</h2></div></a></article><article><a href=/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/><div class=article-details><h2 class=article-title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/><div class=article-details><h2 class=article-title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</h2></div></a></article><article><a href=/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/><div class=article-details><h2 class=article-title>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/><div class=article-details><h2 class=article-title>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>