<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="[Individual Mobility Prediction via Attentive Marked Temporal Point Processes](https://arxiv.org/pdf/2109.02715.pdf)。代码：[https://github.com/Kaimaoge/AMTPP\\_for\\_Mobility](https://github.com/Kaimaoge/AMTPP_for_Mobility)。结合深度学习的TPP，用注意力机制增强对事件的表示，使用混合ALL分布对事件间的时间间隔建模，通过学习OD转移概率矩阵给定O预测D。"><title>Individual Mobility Prediction via Attentive Marked Temporal Point Processes</title>
<link rel=canonical href=https://davidham3.github.io/blog/p/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Individual Mobility Prediction via Attentive Marked Temporal Point Processes"><meta property='og:description' content="[Individual Mobility Prediction via Attentive Marked Temporal Point Processes](https://arxiv.org/pdf/2109.02715.pdf)。代码：[https://github.com/Kaimaoge/AMTPP\\_for\\_Mobility](https://github.com/Kaimaoge/AMTPP_for_Mobility)。结合深度学习的TPP，用注意力机制增强对事件的表示，使用混合ALL分布对事件间的时间间隔建模，通过学习OD转移概率矩阵给定O预测D。"><meta property='og:url' content='https://davidham3.github.io/blog/p/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='point process'><meta property='article:published_time' content='2022-05-20T15:35:04+00:00'><meta property='article:modified_time' content='2022-05-20T15:35:04+00:00'><meta name=twitter:title content="Individual Mobility Prediction via Attentive Marked Temporal Point Processes"><meta name=twitter:description content="[Individual Mobility Prediction via Attentive Marked Temporal Point Processes](https://arxiv.org/pdf/2109.02715.pdf)。代码：[https://github.com/Kaimaoge/AMTPP\\_for\\_Mobility](https://github.com/Kaimaoge/AMTPP_for_Mobility)。结合深度学习的TPP，用注意力机制增强对事件的表示，使用混合ALL分布对事件间的时间间隔建模，通过学习OD转移概率矩阵给定O预测D。"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a92d3b55c5d43e55.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#41-self-attention-encoder>4.1 Self-attention Encoder</a></li><li><a href=#42-asymmetrical-log-laplace-mixture-for-inter-trip-time>4.2 Asymmetrical Log-Laplace Mixture for Inter-trip Time</a></li><li><a href=#43-od-matrix-learning>4.3 OD Matrix Learning</a></li><li><a href=#44-model-training>4.4 Model Training</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/>Individual Mobility Prediction via Attentive Marked Temporal Point Processes</a></h2><h3 class=article-subtitle>[Individual Mobility Prediction via Attentive Marked Temporal Point Processes](https://arxiv.org/pdf/2109.02715.pdf)。代码：[https://github.com/Kaimaoge/AMTPP\_for\_Mobility](https://github.com/Kaimaoge/AMTPP_for_Mobility)。结合深度学习的TPP，用注意力机制增强对事件的表示，使用混合ALL分布对事件间的时间间隔建模，通过学习OD转移概率矩阵给定O预测D。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 20, 2022</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 8 分钟</time></div></footer></div></header><section class=article-content><p><a class=link href=https://arxiv.org/pdf/2109.02715.pdf target=_blank rel=noopener>Individual Mobility Prediction via Attentive Marked Temporal Point Processes</a>。代码：<a class=link href=https://github.com/Kaimaoge/AMTPP_for_Mobility target=_blank rel=noopener>https://github.com/Kaimaoge/AMTPP_for_Mobility</a>。结合深度学习的TPP，用注意力机制增强对事件的表示，使用混合ALL分布对事件间的时间间隔建模，通过学习OD转移概率矩阵给定O预测D。</p><p>预测用户下一个trip的开始时间$t$，起点$o$，目的地$d$。AMTPP模型用自注意力机制捕获用户travel behavior内的周期性和regularity。使用非对称的log-Laplace mixture distribution建模起始时间$t$的分布。此外，还开发了一个OD矩阵学习模块。</p><h1 id=1-introduction>1 Introduction</h1><p>本质上，用户的移动数据分为两类：带时间戳的位置序列${ (t_i, l_i) }^n_{i=1}$，表示时间$t_i$的位置$l_i$；trip/activity sequence ${(t_i, o_i, d_i)}^n_{i=1}$，时间$t_i$的从$o_i$出发，目的地是$d_i$。预测下一位置的研究比较多，但是预测下一个trip的工作比较少。相比前者，后者的信息量更大，时空关联更复杂。而且trip记录比轨迹应用的场景更多。但是对OD建模，假设有$S$个位置，那就要$S \times S$这个数量级，考虑到时间和travel的方式，比如car, bike, bus、旅行的目的，work, school, leisure，这个数量级就更大了。</p><p><img src=/blog/images/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/Fig1.jpg loading=lazy alt=Figure1></p><p>本文的目的是给定历史的轨迹${t_i, o_i, d_i}^n_{i=1}$，预测$t_{n+1}, o_{n+1}, d_{n+1}$。如果把时间$t$看作是连续变量，$o, d$看作是离散变量，那么下一个trip的搜索空间是$[t_n, +\infty) \times {1, \dots, S} \times {1, \dots, S}$。现在处理事件序列的方法有两类：</p><ol><li>HMM，隐马尔可夫模型</li><li>marked temporal point processes。</li></ol><p>HMM的缺点是时间是离散的，不是连续的。TPP相比HMM，更通用。</p><p>最近的工作把深度学习和TPP结合在一起。但是这些方法在建模用户移动或旅行数据上有一些挑战。</p><ol><li>OD数据之间的时空关系太复杂了。而且$S \times S$这个数量级太大。有些工作假设time和marker之间的关系是静态的。当marker的维数比较大的时候，参数会变得很多。</li><li>很多TPP方法是用Hawkes过程来建模的，这种过程没法提现travel中的周期性。</li></ol><p>本文提出的AMTPP解决了上述的挑战。用自注意力计算过去的trip对未来trip的影响。并且设计了一个新的position embedding来捕获时间信息。使用asymmetric Log-Laplace mixture distribution建模事件间的时间。ALL分布可以刻画travel behavior的rhythms和regularity。OD矩阵学习模块，可以从数据中学习到一个动态的OD关系矩阵。</p><h1 id=problem-description>Problem Description</h1><p>一个用户$u$直到时间$t$的trip sequence：</p>$$
\tag{1} \mathcal{H}^u\_t = \{(t^u\_1, o^u\_1, d^u\_1), \dots, (t^u\_{n\_u}, o^u\_{n\_u}, d^u\_{n\_u}): t^u\_{n\_u} \leq t \},
$$<p>$n_u$表示序列中的trip个数。$t^u_i, o^u_i, d^u_i$表示第$i$个trip的出发时间、起点和目的地。时间是连续变量，OD是离散变量。后面忽略$u$。$t_i$可以表示为事件间的时间间隔$\tau_i = t_i - t_{i - 1} \in \mathbb{R}^+$。$\tau$可以看作是事件的活动时间。这俩表示是一样的。</p><p>目标：</p>$$
\tag{2} p^\ast(\tau\_{n+1}, o\_{n+1}, d\_{n+1}) = p(\tau\_{n+1}, o\_{n+1}, d\_{n+1} \mid \mathcal{H}\_{t\_n}),
$$<p>$\ast$表示条件概率。本文认为$o_{n+1} = d_n$，也就是上一个trip的目的地等于下一个trip的起点，这样的话，trip的TPP就变成普通的TPP了。</p><h1 id=4-methodology>4 Methodology</h1><p><img src=/blog/images/individual-mobility-prediction-via-attentive-marked-temporal-point-processes/Fig2.jpg loading=lazy alt=Figure2></p><p>图2是AMTPP的架构。</p><h2 id=41-self-attention-encoder>4.1 Self-attention Encoder</h2><p>第一步是获得$t_n, o_n, d_n$的嵌入表示：</p>$$
\tag{3} e\_n = \text{concat}(emb^t\_n, emb^o\_n, emb^d\_n),
$$<p>为了考虑周期和韵律，引入位置编码：</p>$$
\tag{4} \begin{align} pe^n\_n(pos\_n, 2i) &= \text{sin}(pos\_n / L^{2i/J}\_{pos}),\\ pe^h\_n(pos\_n, 2i+1) &= \text{cos}(pos\_n / L^{2i/J}\_{pos}), \end{align},
$$<p>$pos_n \in {0, 1, \dots, 23 }$是第$n$个trip的小时，$J$是嵌入的维数，$i \in {1, \dots, \lfloor J/2 \rfloor }$, $L_{pos}$是缩放因子。很多方法把$L_{pos}$设置成一个定值，比如10000，但是本文把它设定为一个参数。此外，还引入了day of week作为位置编码$pe^w_n$。加上$\tau_n$，最后的事件嵌入表示：</p>$$
\tag{5} emb^t\_n = \text{concat}(pe^w\_n, pe^h\_n, \tau\_n).
$$<p>OD嵌入：</p>$$
\tag{6} \begin{align} emb^o\_n &= \text{concat}(W^o\_{em} \hat{o}\_n + b^o\_{em}, p^o\_n),\\ emb^d\_n &= \text{concat}(W^d\_{em} \hat{d}\_n + b^d\_{em}, p^d\_n), \end{align}
$$<p>$W^o_{em} \in \mathbb{R}^{J_o \times S}, W^d_{em} \in \mathbb{R}^{J_d \times S}, b^o_{em} \in \mathbb{R}^{J_o}, b^d_{em} \in \mathbb{R}^{J_d}$是参数，$J_o, J_d$是OD嵌入向量的维数，$S$是位置的数量，$p^o_n, p^d_n$是OD的其他信息，比如POI什么的。</p><p>给定历史事件序列的嵌入$E_n = [e_1, e_2, \dots, e_n]^\top \in \mathbb{R}^{n \times J}$，用多头自注意力计算第$n$个trip的隐藏状态。注意力的参数矩阵$Q_l = EW^Q_l, K_l = E W^K_l, V_l = E W^V_l, l = 1, 2, \dots, L$。$W^Q_l, W^K_l \in \mathbb{R}^{J \times c_k}, W^V_l \in \mathbb{R}^{J \times C_v}$。</p><p>注意力：</p>$$
\tag{7} \text{Att}(Q\_l, K\_l, V\_l) = \text{softmax}(\frac{Q\_l K^\top\_l}{\sqrt{d\_k}} \cdot M) V\_l,
$$<p>$M \in \mathbb{R}^{n \times n}$是mask矩阵，上三角部分设为$-\infty$，防止信息泄露。</p><p>多头注意力：</p>$$
\tag{8} \begin{align} H &= \text{gelu}(\text{concat}(\text{head}\_1, \dots, \text{head}\_L) W^O),\\ \text{head}\_l &= \text{Att}(EW^Q\_l, EW^K\_l, EW^V\_l), \end{align}
$$<p>$W_O \in \mathbb{R}^{L \cdot c_v \times C_{\text{model}}}$, $c_{\text{model}}$是输出的特征数。$\text{gelu}$表示Gaussian Error Linear Unit，非线性激活函数，$H_n = [h_1, h_2, \dots, h_n]^\top \in \mathbb{R}^{n \times c_{\text{model}}}$是输出。因为用了mask，所以$h_i$只是基于历史生成的。</p><h2 id=42-asymmetrical-log-laplace-mixture-for-inter-trip-time>4.2 Asymmetrical Log-Laplace Mixture for Inter-trip Time</h2><p>这个部分是对事件间的时间间隔的条件概率分布 $p_\theta(\tau_{n+1} \mid h_n)$ 建模，使用参数为$\theta$的深度神经网络建模。《Intensity-Free Learning of Temporal Point Processes》这篇论文认为相比对强度函数建模，直接对时间间隔建模更方便。这篇论文用log-normal mixture model对TPP的条件概率密度$p_\theta(\tau_{n+1} \mid h_n)$建模。但是这个分布对trip之间的interval不适用，因为trip之间的interval表示了事件的持续时间，而且条件分布通常有一些明显的峰。为了更好的刻画trip间的时间间隔，本文用Aysmmetric Log-Laplace分布。这个分布经常用于对非常偏、有峰和长尾的数据建模。ALL分布有三个参数：</p>$$
ALL(\tau; \beta, \lambda, \gamma) = \frac{\lambda \gamma}{\tau(\lambda + \gamma)} \begin{cases} (\frac{\tau}{\beta})^\lambda & \text{if} \ 0 < \tau < \beta,\\ (\frac{\beta}{\tau})^\gamma & \text{if} \ \tau \geq \beta, \end{cases}
$$<p>$\beta$控制模式，$\lambda$和$\gamma$分别是左右长尾的正长尾参数。</p><p>理想的$p_\theta(\tau \mid h)$分布能趋近任意分布。因为混合模型有趋近$\mathbb{R}$上任意概率分布的性质：universal approximation(UA)，我们使用$\mathcal{D}$，作为ALL的混合分布，来趋近$p_\theta(\tau \mid h)$：</p>$$
\tag{9} \mathcal{D}(\tau; w, \beta, \lambda, \gamma) = \sum^K\_{k=1} w\_k ALL(\tau; \beta\_k, \lambda\_k, \gamma\_k),
$$<p>$w$是混合权重。通过这个混合模型，我们可以近似一个用户的多模态旅行模式。举个例子，如果一个旅行者只有早上的通勤数据，我们在24小时内只能看到一个峰。但是对于来回通勤的人，我们希望看到的是早上一个峰，晚上一个峰。这种混合模型可以表示多个峰。</p><p>ALL混合分布下的变量的对数服从$\text{ALMixture}(w,\hat{\beta}, \hat{\lambda}, \hat{\gamma})$，每个部分是：</p>$$
\tag{10} AL(y) = \frac{\hat{\lambda}\_k}{\hat{\gamma}\_k + \frac{1}{\hat{\gamma}\_k}} \begin{cases} \exp (\frac{\hat{\lambda}\_k}{\hat{\gamma}\_k} (y - \hat{\beta}\_k)) & \ \text{if} \ 0 < y < \hat{\beta}\_k,\\ \exp(- \hat{\lambda}\_k \hat{\gamma}\_k (y - \hat{\beta}\_k)) & \ \text{if} \ y \geq \hat{\beta}\_k, \end{cases}
$$<p>$\hat{\beta}_k = \log(\beta_k), \hat{\gamma}_k = \sqrt{\frac{\lambda_k}{\gamma_k}}, \hat{\lambda}_k = \sqrt{\lambda_k \gamma_k}$。</p><p>公式10里面的对数似然比公式9中的原始ALL更容易学习。我们用MDN网络学习ALMixture里面的参数：</p>$$
\tag{11} \begin{align} w\_n &= \text{softmax}(\Phi\_w h\_n + b\_w),\\ \hat{\beta}\_n &= \exp(\Phi\_\beta h\_n + b\_\beta),\\ \hat{\lambda}\_n &= \exp(\Phi\_\lambda h\_n + b\_\lambda),\\ \hat{\gamma}\_n &= \exp(\Phi\_\gamma h\_n + b\_\gamma), \end{align}
$$<p>softmax和exp用来约束分布的参数，$\Phi, b$都是learnable parameters。</p><h2 id=43-od-matrix-learning>4.3 OD Matrix Learning</h2><p>显然OD和$t$是有关的，即$p^\ast(o_{n+1} \mid \tau_{n+1})$，这里我们没有直接对时间$\tau$建模，而是对$\tau$上面的参数${w_n, \beta_n, \lambda_n, \gamma_n }$建模，这样就不用从分布中采样了。因为ALL混合分布中的参数是有物理意义的，从学习到的模型中模拟trip也很容易。通过调整参数就可以看到OD分布的变化。举个例子，减小峰参数$\beta$来观察OD分布的变化，可以理解成一个人的出发时间提前之后他的trip会有什么变化。</p>$$
\tag{12} \begin{align} \hat{h}\_n &= \text{concat}(h\_n, w\_n, \hat{\beta}\_n, \hat{\lambda}\_n, \hat{\gamma}\_n),\\ \hat{o}\_{n+1} &= \text{softmax}(\Phi\_o \hat{h}\_n + b\_o), \end{align}
$$<p>下一个位置$\hat{o}_{n+1}$的分布依赖拼接向量$\hat{h}_n$，这个向量由历史编码$h_n$和trip的时间参数组成。</p><p>$p^\ast(d_{n+1})$通过把$\hat{o}_{n+1}$乘以一个OD矩阵$OD_{n+1}$得到，这个矩阵的每一列包含了从一个O转移到所有D的转移概率。这个OD矩阵很有用，有了这个OD矩阵，我们可以知道地铁线路里面哪个结点的人比较多。但是$S \times S$太大了，学一个实时的OD矩阵太难了。我们用下面的方法学习$OD_{n+1}$里面的参数：</p>$$
\tag{13}
\begin{align}
D^1\_{n+1} &= \text{reshape}(\Phi^1\_m \hat{h}\_n),\\
D^2\_{n+1} &= \text{reshape}(\Phi^2\_m \hat{h}\_n),\\
OD\_{n+1} &= D^1\_{n+1}{D^2\_{n+1}}^\top \cdot M\_{od},\\
OD\_{n+1} &= \text{softmax}(OD\_{n+1}).\\
\hat{d}\_{n+1} &= OD\_{n+1} \hat{o}\_{n+1} 
\end{align}
$$<p>$D^1_{n+1}, D^2_{n+1} \in \mathbb{R}^{S \times r}$, $r \ll S$。$\Phi$是learnable parameters。$M_{od} \in \mathbb{R}^{S \times S}$用来过滤掉不可能的OD pair，方法就是把这些位置设置成 $- \infty$，包括矩阵的对角线。softmax用来约束矩阵的每一列的和都为1。这个矩阵是根据时间编码$\hat{h}_n$动态变化的。输出的$\hat{d}_{n+1}$和输入的$\hat{o}_{n+1}$与参数关联在一起，让网络训练起来更容易。</p><h2 id=44-model-training>4.4 Model Training</h2><p>负对数似然。随机梯度下降。短的序列要加pad。pad部分会被mask掉。损失函数：</p>$$
\tag{14} \mathcal{L} = - \sum^U\_{u=1} \sum^{n\_u}\_{n=1} \log p^\ast\_\Theta(\tau^u\_n) + \log p^\ast\_\Theta(o^u\_n) + \log p^\ast\_\Theta(d^u\_n),
$$<p>$U$是用户数，$n_u$是用户$u$的trip的个数。对于$\tau$的对数似然，在$\tau$上面加一个对数变换，得到非对称Laplace分布：$y = \log(\tau)$，最终得到：</p>$$
\tag{15} \begin{align} \log p^\ast\_\Theta(\tau) &= \log p^\ast\_\Theta(y) - \log(\tau), \ \ \ \ y = \log(\tau),\\ p^\ast\_\Theta(y) &= \text{ALMixture}(w, \hat{\beta}, \hat{\lambda}, \hat{\gamma}). \end{align}
$$</section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/point-process/>Point Process</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 May 20, 2022 15:35 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/semi-supervised-learning-for-marked-temporal-point-processes/><div class=article-details><h2 class=article-title>Semi-supervised Learning for Marked Temporal Point Processes</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>