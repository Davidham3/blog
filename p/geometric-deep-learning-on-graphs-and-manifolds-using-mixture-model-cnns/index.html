<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：[Geometric deep learning on graphs and manifolds using mixture model CNNs](https://arxiv.org/abs/1611.08402.pdf)"><title>Geometric deep learning on graphs and manifolds using mixture model CNNs</title>
<link rel=canonical href=https://davidham3.github.io/blog/p/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Geometric deep learning on graphs and manifolds using mixture model CNNs"><meta property='og:description' content="CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：[Geometric deep learning on graphs and manifolds using mixture model CNNs](https://arxiv.org/abs/1611.08402.pdf)"><meta property='og:url' content='https://davidham3.github.io/blog/p/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='Graph'><meta property='article:tag' content='graph convolutional network'><meta property='article:published_time' content='2018-12-18T20:49:15+00:00'><meta property='article:modified_time' content='2018-12-18T20:49:15+00:00'><meta name=twitter:title content="Geometric deep learning on graphs and manifolds using mixture model CNNs"><meta name=twitter:description content="CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：[Geometric deep learning on graphs and manifolds using mixture model CNNs](https://arxiv.org/abs/1611.08402.pdf)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a92d3b55c5d43e55.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>论文阅读笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/geometric-deep-learning-on-graphs-and-manifolds-using-mixture-model-cnns/>Geometric deep learning on graphs and manifolds using mixture model CNNs</a></h2><h3 class=article-subtitle>CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：[Geometric deep learning on graphs and manifolds using mixture model CNNs](https://arxiv.org/abs/1611.08402.pdf)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Dec 18, 2018</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><p>CVPR 2017. 这篇论文有点难，没看下去。。。原文链接：<a class=link href=https://arxiv.org/abs/1611.08402.pdf target=_blank rel=noopener>Geometric deep learning on graphs and manifolds using mixture model CNNs</a></p><h1 id=abstract>Abstract</h1><p>大部分深度学习处理的是 1D，2D，3D 欧式结构数据，音频信号、图像、视频。最近大家开始研究在非欧氏空间上的数据，如复杂网络、计算社会科学、计算机图形学。我们提出了一个统一的框架，让 CNN 可以泛化到非欧氏空间上，学习局部的、平稳的、针对任务可分解的特征。我们发现之前提出的一些方法都可以放到我们的框架中。我们发现我们的方法效果比前人的方法都要好。</p><h1 id=1-introduction>1. Introduction</h1><h1 id=2-deep-learning-on-graphs>2. Deep learning on graphs</h1><p>无向带权图 $\mathcal{G} = (\lbrace 1, \dots, n\rbrace, \mathcal{E}, \mathbf{W})$，邻接矩阵 $\mathbf{W} = (w_{ij})$，其中 $w_{ij} = w_{ji}$，如果 $(i, j) \notin \mathcal{E}$，则 $w_{ij} = 0$，否则 $w_{ij} > 0$。未归一化的拉普拉斯矩阵是个 $n \times n$ 的 实对称半正定矩阵 $\Delta = \bf D - W$，其中 $\mathbf{D} = \text{diag}(\sum_{j = \not i} w_{ij})$ 是度矩阵。</p><p>拉普拉斯矩阵有特征值分解 $\bf \Delta = \Phi \Lambda \Phi^T$，其中 $\Phi = (\phi_1, \dots, \phi_n)$ 是相互正交的特征向量，$\Lambda = \text{diag}(\lambda_1, &mldr;, \lambda_n)$ 特征值组成的对角矩阵。在传统的谐波分析中，特征向量是拉普拉斯算子，特征值可以看作是频率。给定图上的一个信号 $\mathbf{f} = (f_1, \dots, f_n)^T$，它的图傅里叶变换是 $\hat{\mathbf{f}} = \Phi^T \mathbf{f}$。给定两个信号 $\bf f, g$，他们的谱卷积定义为傅里叶变换的 element-wise product：</p>$$\tag{1}
\mathbf{f} \star \mathbf{g} = \Phi (\Phi^T \mathbf{f}) \odot (\Phi^T g) = \Phi \ \text{diag}(\hat{g}\_1, \dots, \hat{g}\_n) \hat{f},
$$<p>对应了欧氏空间卷积理论。</p><p><strong>其实这里我没理解啊，我记得卷积的定义不是傅里叶变换的乘积的逆变换吗，所以感觉说的有点不对，但公式倒是对了。。。</strong></p><p><strong>Spectral CNN.</strong> Bruna et al. 使用卷积在谱上的定义将 CNN 泛化到图上，得到一个谱卷积层的定义：</p>$$\tag{2}
\mathbf{f}^{out}\_l = \xi (\sum^p\_{l'=1} \Phi\_k \hat{G}\_{l,l'} \Phi^T\_k \mathbf{f}^{in}\_{l'})
$$<p>这里维数为 $n \times p$ 和 $n \times q$ 的矩阵 $\mathbf{F}^{in} = (\mathbf{f}^{in}_1, \dots, \mathbf{f}^{in}_p)$，$\mathbf{F}^{out} = (\mathbf{f}^{out}_1, \dots, \mathbf{f}^{out}_q)$ 分别表示 $p$ 维和 $q$ 维的图上的输入和输出信号，$\Phi = (\phi_1, \dots, \phi_k)$ 是前几个特征向量组成的 $n \times k$ 的矩阵，$\hat{\mathbf{G}_{l,l&rsquo;}} = \text{diag}(\hat{g}_{l,l&rsquo;,1}, \dots, \hat{g}_{l,l&rsquo;,k})$ 是一个 $k \times k$ 的对角矩阵，表示频域内一个可学习的滤波器，$\xi$ 是一个非线性激活单元（e.g. ReLU）。这个框架的池化操作在图上的模拟是一个图的缩减操作，给定一个 $n$ 个结点的图，生成一个 $n&rsquo; &lt; n$ 个结点的图，将信号从原来的图上变换到缩减后的图上。</p><p>这个框架有几个缺点。首先，谱滤波器的系数是 <em>basis dependent</em>，而且，在一个图上学习到的基于谱的 CNN 模型不能应用在其他的图上。其次，图傅里叶变换的计算因为 $\bf \Phi$ 和 $\bf \Phi^T$ 的乘法，会达到 $\mathcal{O}(n^2)$，因为这里没有像 FFT 一样的算法。第三，不能保证在谱域内的滤波器在顶点域上是局部化的；假设使用 $k = O(n)$ 个归一化的拉普拉斯矩阵的特征向量，一个谱卷积层需要 $pqk = O(n)$ 个参数。</p><p><strong>Smooth Spectral CNN.</strong> 之后，Henaff et al. 认为 smooth 谱滤波器系数可以使得卷积核在空间上局部化，使用了这个形式：</p>$$\tag{3}
\hat{g}\_i = \sum^r\_{j=1} \alpha\_i \beta\_j (\Lambda\_i)
$$<p>其中 $\beta_1(\lambda), \dots, \beta_r(\lambda)$ 是一些固定的插值核，$\mathbb{\alpha} = (\alpha_1, \dots, \alpha_r)$ 是插值系数。矩阵形式中，滤波器写为 $\text{diag}(\hat{G}) = \mathbf{B\alpha}$，其中 $\bf{B} = (b_{ij}) = (\beta_j (\lambda_i))$ 是一个 $k \times r$ 的矩阵。这样一个参数化可以使参数保持在 $n$ 个。</p><p><strong>Chebyshev Spectral CNN (ChebNet).</strong> 为了减轻计算图傅里叶变换的代价，Defferrard et al 使用了切比雪夫多项式来表示卷积核：</p>$$\tag{4}
g\_\alpha(\Delta) = \sum^{r-1}\_{j=0} \alpha\_j T\_j(\tilde{\Delta}) = \sum^{r-1}\_{j=0} \alpha\_j \Phi T\_j (\tilde{\Lambda}) \Phi^T,
$$<p>其中 $\tilde{\Delta} = 2 \lambda^{-1}_n \Delta - \bf I$ 是 rescaled 拉普拉斯矩阵，它的特征值 $\tilde{\Lambda} = 2 \lambda^{-1}_n \Lambda - \bf I$ 在区间 $[-1, 1]$ 内，$\alpha$ 是 $r$ 维的滤波器中的多项式系数，</p>$$\tag{5}
T\_j(\lambda) = 2 \lambda T\_{j-1}(\lambda) - T\_{j-2} (\lambda),
$$<p>表示 $j$ 阶切比雪夫多项式，$T_1(\lambda) = \lambda$，$T_0(\lambda) = 1$。</p><p>这样的方法有几个优点。首先，它不需要计算拉普拉斯矩阵的特征向量。由于切比雪夫多项式的递归定义，计算滤波器 $g_\alpha(\Lambda) \bf f$ 要使用拉普拉斯矩阵 $r$ 次，会导致一个 $\mathcal{O}(rn)$ 的操作。其次，因为拉普拉斯矩阵是一个局部操作，只影响顶点的一阶邻居，它的 $(r-1)$次幂影响 $r$阶邻居，得到的滤波器是局部化的。</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/graph/>Graph</a>
<a href=/blog/tags/graph-convolutional-network/>Graph Convolutional Network</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Dec 18, 2018 20:49 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/stg2seq-spatial-temporal-graph-to-sequence-model-for-multi-step-passenger-demand-forecasting/><div class=article-details><h2 class=article-title>STG2Seq: Spatial-temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting</h2></div></a></article><article><a href=/blog/p/self-attention-graph-pooling/><div class=article-details><h2 class=article-title>Self-Attention Graph Pooling</h2></div></a></article><article><a href=/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/><div class=article-details><h2 class=article-title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</h2></div></a></article><article><a href=/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/><div class=article-details><h2 class=article-title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</h2></div></a></article><article><a href=/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/><div class=article-details><h2 class=article-title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>