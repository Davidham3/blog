<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="IJCAI 2018，大体思路：使用Kipf & Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：[Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting](https://arxiv.org/abs/1709.04875v4)"><title>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic</title><link rel=canonical href=https://davidham3.github.io/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/><link rel=stylesheet href=/blog/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic"><meta property='og:description' content="IJCAI 2018，大体思路：使用Kipf & Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：[Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting](https://arxiv.org/abs/1709.04875v4)"><meta property='og:url' content='https://davidham3.github.io/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='ResNet'><meta property='article:tag' content='Spatial-temporal'><meta property='article:tag' content='graph convolutional network'><meta property='article:tag' content='Graph'><meta property='article:tag' content='Time Series'><meta property='article:tag' content='已复现'><meta property='article:published_time' content='2018-05-10T15:35:47+00:00'><meta property='article:modified_time' content='2018-05-10T15:35:47+00:00'><meta name=twitter:title content="Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic"><meta name=twitter:description content="IJCAI 2018，大体思路：使用Kipf & Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：[Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting](https://arxiv.org/abs/1709.04875v4)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a95981f1fc190aef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#路网上的交通预测>路网上的交通预测</a></li><li><a href=#图上的卷积>图上的卷积</a></li></ol><ol><li><a href=#网络架构>网络架构</a></li><li><a href=#提取空间特征的图卷积神经网络>提取空间特征的图卷积神经网络</a></li><li><a href=#抽取时间特征的门控卷积神经网络>抽取时间特征的门控卷积神经网络</a></li><li><a href=#时空卷积块>时空卷积块</a></li></ol><ol><li><a href=#数据集描述>数据集描述</a></li><li><a href=#数据预处理>数据预处理</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>论文阅读笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic</a></h2><h3 class=article-subtitle>IJCAI 2018，大体思路：使用Kipf & Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：[Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting](https://arxiv.org/abs/1709.04875v4)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 10, 2018</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 16 分钟</time></div></footer></div></header><section class=article-content><p>IJCAI 2018，大体思路：使用Kipf & Welling 2017的近似谱图卷积得到的图卷积作为空间上的卷积操作，时间上使用一维卷积对所有顶点进行卷积，两者交替进行，组成了时空卷积块，在加州PeMS和北京市的两个数据集上做了验证。但是图的构建方法并不是基于实际路网，而是通过数学方法构建了一个基于距离关系的网络。原文链接：<a class=link href=https://arxiv.org/abs/1709.04875v4 target=_blank rel=noopener>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting</a></p><h1 id=摘要>摘要</h1><p>实时精确的交通预测对城市交通管控和引导很重要。由于交通流的强非线性以及复杂性，传统方法并不能满足中长期预测的要求，而且传统方法经常忽略对时空数据的依赖。在这篇文章中，我们提出了一个新的深度学习框架，时空图卷积(Spatio-Temporal Graph Convolutional Networks)，来解决交通领域的时间序列预测问题。我们在图上将问题形式化，并且建立了完全卷积的结构，并不是直接应用传统的卷积以及循环神经单元，这可以让训练速度更快，参数更少。实验结果显示通过在多尺度的交通网络上建模，STGCN模型可以有效地捕获到很全面的时空相关性并且在各种真实数据集上表现的要比很多state-of-the-art算法好。</p><h1 id=引言>引言</h1><p>交通运输在每个人的生活中都扮演着重要的角色。根据2015年的调查，美国的司机们平均每天要在车上呆48分钟。这种情况下，精确的实时交通状况预测对于路上的用户，private sector和政府来说变得至关重要。广泛使用的交通服务，如交通流控制、路线规划和导航，也依赖于高质量的交通状况预测。总的来说，多尺度的交通预测的研究很有前景而且是城市交通流控制和引导的基础，也是智能交通系统的一个主要功能。</p><p>在交通研究中，交通流的基本变量，也就是速度、流量和密度，通常作为监控当前交通状态以及未来预测的指示指标。根据预测的长度，交通预测大体分为两个尺度：短期(5~30min)，中和长期预测(超过30min)。大多数流行的统计方法(比如，线性回归)可以在短期预测上表现的很好。然而，由于交通流的不确定性和复杂性，这些方法在相对长期的预测上不是那么的有效。</p><p>之前在中长期交通预测上的研究可以大体的分为两类：动态建模和数据驱动的方法。动态建模使用了数学工具（比如微分方程）和物理知识通过计算模拟来形式化交通问题[Vlahogiani, 2015]。为了达到一个稳定的状态，模拟进程不仅需要复杂的系统编程，还需要消耗大量的计算资源。模型中不切实际的假设和化简也会降低预测的精度。因此，随着交通数据收集和存储技术的快速发展，一大群研究者正在将他们的目光投向数据驱动的方法。
典型的统计学和机器学习模型是数据驱动方法的两种体现。在时间序列分析上，自回归移动平均模型（ARIMA）和它的变形是众多统一的方法中基于传统统计学的方法[Ahmed and Cook, 1979; Williams and Hoel, 2003; Lippi $et al.$, 2013]。然而，这种类型的模型受限于时间序列的平稳分布，而且不能考虑时空相关性。因此，这些方法限制了高度非线性的交通流的表示能力。最近，传统的统计方法在交通预测上已经受到了机器学习方法的冲击。这些模型可以获得更高的精度，对更复杂的数据建模，比如k近邻（KNN），支持向量机（SVM）和神经网络（NN）。</p><p><strong>深度学习方法</strong> 最近，深度学习已经被广泛且成功地应用于各式各样的交通任务中，在最近的工作中已经取得了很显著的成果，比如，深度置信网络（DBN）[Jia <em>et al.</em>, 2016; Huang <em>et al.</em>, 2014]和层叠自编码器(stacked autoencoder)(SAE)[Lv <em>et al.</em>, 2015; Chen <em>et al.</em>, 2016]。然而，这些全连接神经网络很难从输入中提取空间和时间特征。而且，空间属性的严格限制甚至完全缺失，这些网络的表示能力被限制的很严重。</p><p>为了充分利用空间特征，一些研究者使用了卷积神经网络来捕获交通网络中的临近信息，同时也在时间轴上部署了循环神经网络。通过组合长短期记忆网络[Hochreiter and Schmidhuber, 1997]和1维卷积，Wu和Tan[2016]首先提出一个特征层面融合的架构CLTFP来预测短期交通状况。尽管它采取了一个很简单的策略，CLTFP仍然是第一个尝试对时间和空间规律性对齐的方法。后来，Shi <em>et al.</em>[2015]提出了卷积LSTM，这是一个带有嵌入卷积层的全连接LSTM的扩展。然而，常规的卷积操作限制了模型只能处理常规的网格结构（如图像或视频），而不是其他的大部分领域（比如Graph）。与此同时，循环神经网络对于序列的学习需要迭代训练，这会导致误差的积累。更进一步地说，循环神经网络（包括基于LSTM的RNN）的难以训练和计算量大是众所周知的。</p><p>为了克服这些问题，我们引入了一些策略来有效的对交通流的时间动态和空间依赖进行建模。为了完全利用空间信息，我们通过一个广义图对交通网络建模，而不是将交通流看成各个离散的部分（比如网格或碎块）。为了处理循环神经网络的缺陷，我们在时间轴上部署了一个全卷积结构来阻止累积效应（cumulative effects）并且加速模型的训练过程。综上所述，我们提出了一个新的神经网络架构，时空图卷积网络，来预测交通情况。这个架构由多个时空图卷积块组成，这些都是图卷积层和卷积序列学习层（convolutional sequence learning layers）的组合，用来对时间和空间依赖关系进行建模。</p><p>我们的主要贡献可以归纳为以下三点：</p><ol><li>我们研究了在交通领域时间与空间依赖结合的好处。为了充分利用我们的知识，这是在交通研究中第一次应用纯卷积层来同时从图结构的时间序列中提取时空信息。</li><li>我们提出了一个新的由时空块组成的神经网络结构。由于这个架构中是纯卷积操作，它比基于RNN的模型的训练速度快10倍以上，而且需要的参数更少。这个架构可以让我们更有效地处理更大的路网，这部分将在第四部分展示。</li><li>我们在两个真实交通数据集上验证了提出来的网络。这个实验显示出我们的框架比已经存在的在多长度预测和网络尺度上的模型表现的更好。</li></ol><h1 id=准备工作>准备工作</h1><h2 id=路网上的交通预测>路网上的交通预测</h2><p>交通预测是一个典型的时间序列预测问题，也就是预测在给定前M个观测样本接下来H个时间戳后最可能的交通流指标（比如速度或交通流），</p><p>$$</p><pre><code>\tag{1}	\hat{v}\_{t+1}, ..., \hat{v}\_{t+H} = \mathop{\arg\min}\_{v\_{t+1},...,v\_{t+H}}logP(v\_{t+1},...,v\_{t+H}\vert v\_{t-M+1},...v\_t)
</code></pre><p>$$</p><p>这里$v_t \in \mathbb{R}^n$是$n$个路段在时间戳$t$观察到的一个向量，每个元素记录了一条路段的历史观测数据。</p><p>在我们的工作中，我们在一个图上定义了一个交通网络，并专注于结构化的交通时间序列。观测到的样本$v_t$间不是相互独立的，而是在图中两两相互连接的。因此，数据点$v_t$可以被视为定义在权重为$w_{ij}$，如图1展示的无向图（或有向图）$\mathcal{G}$上的一个信号。在第$t$个时间戳，在图$\mathcal{G_t}=(\mathcal{V_t}, \mathcal{\varepsilon}, W)$, $\mathcal{V_t}$是当顶点的有限集，对应在交通网络中$n$个监测站；$\epsilon$是边集，表示观测站之间的连通性；$W \in \mathbb{R^{n \times n}}$表示$\mathcal{G_t}$的邻接矩阵。</p><p><img src=/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig1.PNG loading=lazy alt=Fig1></p><h2 id=图上的卷积>图上的卷积</h2><p>传统网格上的标准卷积很明显是不能应用在广义图上的。现在有两个基本的方法正在探索如何泛化结构化数据上的CNN。一个是扩展卷积的空间定义[Niepert <em>et al.</em>, 2016]，另一个是使用图傅里叶变换在谱域中进行操作[Bruna <em>et al.</em>, 2013]。前一个方法重新将顶点安排至确定的表格形式内，然后就可以使用传统的卷积方法了。后者引入了谱框架，在谱域中应用图卷积，经常被称为谱图卷积。一些后续的研究通过将时间复杂度从$O(n^2)$降至线性[Defferrard <em>et al.</em>, 2016;Kipf and Welling, 2016]使谱图卷积的效果更好。
我们基于谱图卷积的定义引入图卷积操作“$\ast_{\mathcal{G}}$”的符号，也就是一个核$\Theta$和信号$x \in \mathbb{R}^n$的乘法，</p>$$\tag{2} \Theta \ast\_{\mathcal{G}}x=\Theta(L)x=\Theta(U \Lambda U^T)x=U\Theta(\Lambda)U^Tx$$<p>这里图的傅里叶基$U \in \mathbb{R}^{n \times n}$是归一化的拉普拉斯矩阵$L=I_n-D^{-1/2}WD^{-1/2}= U \Lambda U^T \in \mathbb{R}^{n \times n}$的特征向量组成的矩阵，其中$I_n$是单位阵，$D \in \mathbb{R}^{n \times n}$是对角的度矩阵$D_{ii}=\sum_j{W_{ij}}$；$\Lambda \in \mathbb{R}^{n \times n}$是$L$的特征值组成的矩阵，卷积核$\Theta(\Lambda)$是一个对角矩阵。通过这个定义，一个图信号$x$是被一个核$\Theta$通过$\Theta$和图傅里叶变换$U^Tx$[Shuman <em>et al.</em>, 2013]过滤的。</p><h1 id=提出的模型>提出的模型</h1><h2 id=网络架构>网络架构</h2><p>在这部分，我们详细说明了时空图卷积网络的框架。如图二所示，STGCN有多个时空卷积块组成，每一个都是像一个“三明治”结构的组成，有两个门序列卷积层和一个空间图卷积层在中间。每个模块的细节如下。</p><p><img src=/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig2.PNG loading=lazy alt=Fig2></p><p>图二：时空图卷积网络的架构图。STGCN的架构有两个时空卷积块和一个全连接的在末尾的输出层组成。每个ST-Conv块包含了两个时间门卷积层，中间有一个空间图卷积层。每个块中都使用了残差连接和bottleneck策略。输入$v_{t-M+1},&mldr;v_t$被ST-Conv块均匀的（uniformly）处理，来获取时空依赖关系。全部特征由一个输出层来整合，生成最后的预测$\hat{v}$。</p><h2 id=提取空间特征的图卷积神经网络>提取空间特征的图卷积神经网络</h2><p>交通网络大体上是一个图结构。由数学上的图来构成路网是很自然也很合理的。然而，之前的研究忽视了交通网络的空间属性：因为交通网络被分成了块或网格状，所以网络的全局性和连通性被过分的关注了。即使是在网格上的二维卷积，由于数据建模的折中，也只能捕捉到大体的空间局部性。根据以上情况，在我们的模型中，图卷积被直接的应用在了图结构数据上为了在空间中抽取很有意义的模式和特征。集是在图卷积中由式2可以看出核$\Theta$的计算的时间复杂度由于傅里叶基的乘法可以达到$O(n^2)$，两个近似的策略可以解决这个问题。</p><p><strong>切比雪夫多项式趋近</strong></p><p>为了局部化过滤器并且减少参数，核$\Theta$可以被一个关于$\Lambda$的多项式限制起来，也就是$\Theta(\Lambda)=\sum_{k=0}^{K-1} \theta_k \Lambda^k$，其中$\theta \in \mathbb{R}^K$是一个多项式系数的向量。$K$是图卷积核的大小，它决定了卷积从中心节点开始的最大半径。一般来说，切比雪夫多项式$T_k(x)$被用于近似核，作为$K-1$阶展开的一部分，也就是$\Theta(\Lambda) \approx \sum_{k=0}^{K-1} \theta_k T_k(\widetilde{\Lambda})$，其中$\widetilde{\Lambda}=2\Lambda/\lambda_{max}-I_n$（$\lambda_{max}$表示$L$的最大特征值）[Hammond <em>et al.</em>, 2011]。图卷积因此可以被写成</p>$$
\tag{3} \Theta \ast\_{\mathcal{G}} x = \Theta(L)x \approx \sum\_{k=0}^{K-1}\theta\_k T\_k(\widetilde{L})x
$$<p>其中$T_k(\widetilde{L}) \in \mathbb{R}^{n \times n}$是k阶切比雪夫多项式对缩放后（scaled）的拉普拉斯矩阵$\widetilde{L}=2L/\lambda_{max}-I_n$。通过递归地使用趋近后的切比雪夫多项式计算K阶卷积操作，式2的复杂度可以被降低至$O(K\vert \varepsilon \vert)$，如式3所示[Defferrard <em>et al.</em>, 2016]。</p><p><strong>1阶近似</strong></p><p>一个针对层的线性公式可以由堆叠多个使用拉普拉斯矩阵的一阶近似的局部图卷积层[Kipf and Welling, 2016]。结果就是，这样可以构建出一个深的网络，这个网络可以深入地恢复空间信息并且不需要指定多项式中的参数。由于在神经网络中要缩放和归一化，我们可以进一步假设$\lambda_{max} \approx 2$。因此，式3可以简写为</p>$$
\begin{aligned}
\Theta \ast\_{\mathcal{G}}x \approx & \theta\_0x+\theta\_1(\frac{2}{\lambda\_{max}}L-I\_n)x\\
\approx & \theta\_0 x- \theta\_1(D^{-\frac{1}{2}} W D^{-\frac{1}{2}}) x
\end{aligned}
$$<p>其中，$\theta_0$，$\theta_1$是核的两个共享参数。为了约束参数并为稳定数值计算，$\theta_0$和$\theta_1$用一个参数$\theta$来替换，$\theta=\theta_0=-\theta_1$；$W$和$D$是通过$\widetilde{W}=W+I_n$和$\widetilde{D}_{ii}=\sum_j\widetilde{W}_{ij}$重新归一化得到的。之后，图卷积就可以表达为</p>$$
\begin{aligned}
\Theta \ast\_{\mathcal{G}} x = & \theta(I\_n + D^{-\frac{1}{2}} W D^{\frac{1}{2}})x\\
= & \theta (\widetilde{D}^{-\frac{1}{2}} \widetilde{W} \widetilde{D}^{-\frac{1}{2}})x
\end{aligned}
$$<p>竖直地堆叠一阶近似的图卷积可以获得和平行的K阶卷积相同的效果，所有的卷积可以从一个顶点的$K-1$阶邻居中获取到信息。在这里，$K$是连续卷积操作的次数或是模型中的卷积层数。进一步说，针对层的线性结构是节省参数的，并且对大型的图来说是效率很高的，因为多项式趋近的阶数为1。</p><p><strong>图卷积的泛化</strong></p><p>图卷积操作$\ast_{\mathcal{G}}$也可以被扩展到多维张量上。对于一个有着$C_i$个通道的信号$X \in \mathbb{R}^{n \times C_i}$，图卷积操作可以扩展为</p>$$
y\_j = \sum\_{i=1}^{C\_i} \Theta\_{i,j}(L) x\_i \in \mathbb{R}^n, 1 \leq j \leq C\_o
$$<p>其中，$C_i \times C_o$个向量是切比雪夫系数$\Theta_{i,j} \in \mathbb{R}^K$（$C_i$，$C_o$分别是feature map的输入和输出大小）。针对二维变量的图卷积表示为$\Theta \ast_{\mathcal{G}} X$，其中$\Theta \in \mathbb{R}^{K \times C_i \times C_o}$。需要注意的是，输入的交通预测是由$M$帧路网组成的，如图1所示。每帧$v_t$可以被视为一个矩阵，它的第$i$列是图$\mathcal{G_t}$中第$i$个顶点的一个为$C_i$维的值，也就是$X \in \mathbb{R}^{n \times C_i}$（在这个例子中，$C_i=1$）。对于$M$中的每个时间步$t$，相同的核与相同的图卷积操作是在$X_t \in \mathbb{R}^{n \times C_i}$中并行进行的。因此，图卷积操作也可以泛化至三维，记为$\Theta \ast_{\mathcal{G}} \mathcal{X}$，其中$\mathcal{X} \in \mathbb{R}^{M \times n \times C_i}$</p><h2 id=抽取时间特征的门控卷积神经网络>抽取时间特征的门控卷积神经网络</h2><p>尽管基于RNN的模型可以广泛的应用于时间序列分析，用于交通预测的循环神经网络仍然会遇到费时的迭代，复杂的门控机制，对动态变化的响应慢。相反，CNN训练快，结构简单，而且不依赖于前一步。受到[Gehring <em>et al.</em>, 2017]的启发，我们在时间轴上部署了整块的卷积结构，用来捕获交通流的动态时间特征。这个特殊的设计可以让并行而且可控的训练过程通过多层卷积结构形成层次表示。</p><p>如图2右侧所示，时间卷积层包含了一个一维卷积，核的宽度为$K_t$，之后接了一个门控线性单元(GLU)作为激活。对于图$\mathcal{G}$中的每个顶点，时间卷积对输入元素的$K_t$个邻居进行操作，导致每次将序列长度缩短$K_t-1$。因此，每个顶点的时间卷积的输入可以被看做是一个长度为$M$的序列，有着$C_i$个通道，记作$Y \in \mathbb{R}^{M \times C_i}$。卷积核$\Gamma \in \mathbf{R}^{K_t \times C_i \times 2C_o}$是被设计为映射$Y$到一个单个的输出$[P Q] \in \mathbb{R}^{(M-K_t+1) \times (2C_o)}$($P$, $Q$是通道数的一半)。作为结果，时间门控卷积可以定义为：</p>$$
\Gamma \ast\_ \tau Y = P \otimes \sigma (Q) \in \mathbb{R}^{(M-K\_t+1) \times C\_o}
$$<p>其中，$P$, $Q$分别是GLU的输入门，$\otimes$表示哈达玛积，sigmoid门$\sigma(Q)$控制当前状态的哪个输入$P$对于发现时间序列中的组成结构和动态方差是相关的。非线性门通过堆叠时间层对挖掘输入也有贡献。除此以外，在堆叠时间卷积层时，实现了残差连接。相似地，通过在每个节点$\mathcal{Y_i} \in \mathbb{R}^{M \times C_i}$(比如监测站)上都使用同样的卷积核$\Gamma$，时间卷积就可以泛化至3D变量上，记作$\Gamma \ast_\tau \mathcal{Y}$，其中$\mathcal{Y} \in \mathbb{R}^{M \times n \times C_i}$。</p><p><strong>这里我之前认为残差是用了 padding 的，其实不是，看了作者的代码后发现作者是用了一半数量的卷积核完成卷积，这样就和 P 的维度一致了，然后直接和 P 相加，然后与 sigmoid 激活后的值进行点对点的相乘。</strong></p><h2 id=时空卷积块>时空卷积块</h2><p>为了同时从空间和时间领域融合特征，时空卷积块(ST-Conv block)的构建是为了同时处理图结构的时间序列的。如图2（中）所示，bottleneck策略的应用形成了三明治的结构，其中含有两个时间门控卷积层，分别在上下两层，一个空间图卷积层填充中间的部分。空间卷积层导致的通道数$C$的减小促使了参数的减少，并且减少了训练的时间开销。除此以外，每个时空块都使用了层归一化来抑制过拟合。</p><p>ST-Conv块的输入和输出都是3D张量。对于块$l$的输入$v^l \in \mathbb{R}^{M \times n \times C^l}$，输出$v^{l+1} \in \mathbb{R}^{(M-2(K_t-1)) \times n \times C^{l+1}}$通过以下式子计算得到：</p>$$
v^{l+1} = \Gamma^l\_1 \ast\_\tau \rm ReLU(\Theta^l \ast\_{\mathcal{G}}(\Gamma^l\_0 \ast\_\tau v^l))
$$<p>其中$\Gamma^l_0$，$\Gamma^l_1$是块$l$的上下两个时间层；$\Theta^l$是图卷积谱核；$\rm ReLU(·)$表示ReLU激活函数。我们在堆叠两个ST-Conv块后，加了一个额外的时间卷积和全连接层作为最后的输出层（图2左侧）。时间卷积层将最后一个ST-Conv块的输出映射到一个最终的单步预测上。之后，我们可以从模型获得一个最后的输出$Z \in \mathbb{R}^{n \times c}$，通过一个跨$c$个通道的线性变换$\hat{v} = Zw+b$来预测$n$个节点的速度，其中$w \in \mathbb{R}^c$是权重向量,$b$是偏置。对交通预测的STGCN的损失函数可以写成：</p>$$
L(\hat{v}; W\_\theta) = \sum\_t \Vert \hat{v}(v\_{t-M+1, ..., v\_t, W\_\theta}) - v\_{t+1} \Vert^2
$$<p>其中，$W_\theta$是模型中所有的训练参数; $v_{t+1}$是ground truth，$\hat{v}(·)$表示模型的预测。</p><p>我们来总结一下我们的STGCN的主要特征：</p><ol><li>STGCN是处理结构化的时间序列的通用框架，不仅可以解决交通网络建模，还可以应用到其他的时空序列学习的挑战中，比如社交网络和推荐系统。</li><li>时空块融合了图卷积和门控时间卷积，可以同时抽取有用的空间信息，捕获本质上的时间特征。</li><li>模型完全由卷积层组成，因此可以在输入序列上并行运算，空间域中参数少易于训练。更重要的是，这个经济的架构可以使模型更高效的处理大规模的网络。</li></ol><h1 id=实验>实验</h1><h2 id=数据集描述>数据集描述</h2><p>我们在两个真实的数据集上验证了模型，分别是<strong>BJER4</strong>和<strong>PeMSD7</strong>，由北京市交委和加利福尼亚运输部提供。每个数据集包含了交通观测数据的关键属性和对应时间的地图信息。</p><p><strong>BJER4</strong>是通过double-loop detector获取的东四环周边的数据。我们的实验中有12条道路。交通数据每五分钟聚合一次。时间是从2014年的7月1日到8月31日，不含周末。我们选取了第一个月的车速速度记录作为训练集，剩下的分别做验证和测试。</p><p><strong>PeMSD7</strong>是Caltrans Performance Measurement System(PeMS)通过超过39000个监测站实时获取的数据，这些监测站分布在加州高速公路系统主要的都市部分[Chen <em>et al</em>., 2001]。数据是30秒的数据样本聚合成5分钟一次的数据。我们在加州的District 7随机选取了一个小的和一个大的范围作为数据源，分别有228和1026个监测站，分别命名为PeMSD7(S)和PeMSD7(L)（如图3左侧所示）。PeMSD7数据集的时间范围是2012年五月和六月的周末。我们使用同样的原则对数据进行了训练集和测试集的划分。</p><p><img src=/blog/images/spatio-temporal-graph-convolutional-networks-a-deep-learning-framework-for-traffic/Fig3.PNG loading=lazy alt=Fig1></p><h2 id=数据预处理>数据预处理</h2><p>两个数据集的间隔设定为5分钟。因此，路网中的每个顶点每天就有288个数据点。数据清理后使用了线性插值的方法来填补缺失值。通过核对相关性，每条路的方向和OD(origin-destination)点，环路系统可以被数值化成一个有向图。</p><p>在PeMSD7，路网的邻接矩阵通过交通网络中的监测站的距离来计算。带权邻接矩阵$W$通过以下公式计算：</p>$$
w\_{ij} = \begin{cases}
\exp{(-\frac{d^2\_{ij}}{\sigma^2})}&,i \neq j \ \rm and \exp{(-\frac{d^2\_{ij}}{\sigma^2}) \geq \epsilon} \\
0&, \rm otherwise
\end{cases}
$$<p>其中$w_{ij}$是边的权重，通过$d_{ij}$得到，也就是$i$和$j$之间的距离。$\sigma^2$和$\epsilon$是来控制矩阵$W$的分布和稀疏性的阈值，我们用了10和0.5。$W$的可视化在图3的右侧。</p><h1 id=代码>代码</h1><p><a class=link href=https://github.com/VeritasYin/STGCN_IJCAI-18 target=_blank rel=noopener>作者代码</a>，这个是作者提供的代码。</p><p><a class=link href=https://github.com/Davidham3/STGCN target=_blank rel=noopener>仓库地址</a>，我按照论文结合作者的代码进行了复现与修正。</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/resnet/>ResNet</a>
<a href=/blog/tags/spatial-temporal/>Spatial-Temporal</a>
<a href=/blog/tags/graph-convolutional-network/>Graph Convolutional Network</a>
<a href=/blog/tags/graph/>Graph</a>
<a href=/blog/tags/time-series/>Time Series</a>
<a href=/blog/tags/%E5%B7%B2%E5%A4%8D%E7%8E%B0/>已复现</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/><div class=article-details><h2 class=article-title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</h2></div></a></article><article><a href=/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/><div class=article-details><h2 class=article-title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</h2></div></a></article><article><a href=/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/><div class=article-details><h2 class=article-title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/><div class=article-details><h2 class=article-title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</h2></div></a></article><article><a href=/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/><div class=article-details><h2 class=article-title>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>