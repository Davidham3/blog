<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：[Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting](http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf)"><title>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</title><link rel=canonical href=https://davidham3.github.io/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/><link rel=stylesheet href=/blog/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting"><meta property='og:description' content="AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：[Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting](http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf)"><meta property='og:url' content='https://davidham3.github.io/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='Spatial-temporal'><meta property='article:tag' content='graph convolutional network'><meta property='article:tag' content='Graph'><meta property='article:tag' content='Time Series'><meta property='article:published_time' content='2019-02-28T21:12:58+00:00'><meta property='article:modified_time' content='2019-02-28T21:12:58+00:00'><meta name=twitter:title content="Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting"><meta name=twitter:description content="AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：[Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting](http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf)"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a95981f1fc190aef.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#spatiotemporal-prediction-in-urban-computing>Spatiotemporal prediction in urban computing</a></li><li><a href=#graph-convolution-network>Graph convolution network</a></li><li><a href=#channel-wise-attention>Channel-wise attention</a></li></ol><ol><li><a href=#region-level-ride-hailing-demand-forecasting>Region-level ride-hailing demand forecasting</a></li><li><a href=#spatial-dependency-modeling>Spatial dependency modeling</a></li><li><a href=#temporal-correlation-modeling>Temporal correlation modeling</a></li></ol><ol><li><a href=#experimental-settings>Experimental Settings</a></li><li><a href=#performance-comparison>Performance comparison</a></li><li><a href=#effect-of-spatial-dependency-modeling>Effect of spatial dependency modeling</a></li><li><a href=#effect-of-temporal-dependency-modeling>Effect of temporal dependency modeling</a></li><li><a href=#effect-of-model-parameters>Effect of model parameters</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/>论文阅读笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</a></h2><h3 class=article-subtitle>AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：[Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting](http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf)</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Feb 28, 2019</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 14 分钟</time></div></footer></div></header><section class=article-content><p>AAAI 2019，滴滴的网约车需求预测，5个点预测1个点。空间依赖建模上：以图的形式表示数据，从空间地理关系、区域功能相似度、区域交通连通性三个角度构造了三个不同的图，提出了多图卷积，分别用 k 阶 ChebNet 对每个图做图卷积，然后将多个图的卷积结果进行聚合(sum, average 等)成一个图；时间依赖建模上：提出了融合背景信息的 Contextual Gated RNN (CGRNN)，用 ChebNet 对每个结点卷积后，得到他们的邻居表示，即每个结点的背景信息表示，与原结点特征拼接，用一个两层全连接神经网络计算出 T 个权重，将权重乘到历史 T 个时刻的图上，对历史值进行缩放，然后用一个共享的 RNN，针对每个结点形成的长度为 T 的时间序列建模，得到每个结点新的时间表示。最后预测每个点的网约车需求。原文地址：<a class=link href=http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf target=_blank rel=noopener>Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting</a></p><h1 id=abstract>Abstract</h1><p>区域级别的预测是网约车服务的关键任务。精确地对网约车需求预测可以指导车辆调度、提高车辆利用率，减少用户的等待时间，减轻交通拥堵。这个任务的关键在于区域间复杂的时空依赖关系。现存的方法主要关注临近区域的欧式关系建模，但是在距离较远的区域间组成的非欧式关系对精确预测也很关键。我们提出了 <em>spatiotemporal multi-graph convolution network</em> (ST-MGCN)。我们首先将非欧的关系对编码到多个图中，然后使用 multi-graph convolution 对他们建模。为了在时间建模上利用全局的背景信息，我们提出了 <em>contextual gated recurrent neural network</em>，用一个注意背景的门机制对不同的历史观测值重新分配权重。在两个数据集上比当前的 state-of-the-art 强 10%。</p><h1 id=introduction>Introduction</h1><p>我们研究的问题是区域级别网约车需求预测，是智能运输系统的重要部分。目标是通过历史观测值，预测一个城市里面各区域未来的需求。任务的挑战是复杂的时空关系。一方面，不同区域有着复杂的依赖关系。举个例子，一个区域的需求通常受其空间上临近的区域所影响，同时与有着相同背景的较远的区域有联系。另一方面，非线性的依赖关系也存在于不同的时间观测值之间。预测一个时刻通常和多个历史的观测值相关，比如一小时前、一天前、甚至一周前。</p><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig1.JPG loading=lazy alt=Figure1></p><p>最近在深度学习的进步使得对基于区域级别的时空关系预测有了很好的结果。使用卷积神经网络和循环神经网络，得到了很多非常好的效果(Shi et al. 2015; Yu et al. 2017; Shi et al. 2017; Zhang, Zheng, and Qi 2017; Zhang et al. 2018a; Ma et al. 2017; Yao et al. 2018b; 2018a)。尽管有了很好的效果，但是我们认为在对时空关系建模上有两点被忽略了。其一，这些方法主要对不同区域的欧式关系建模，但是我们发现非欧关系很重要。图 1 是一个例子，对于区域 1，以及邻居区域 2，可能和很远的区域 3 有相似的功能，也就是他们都靠近学校和医院。此外，区域 1 还可能被区域 4 影响，区域 4 是通过高速公路直接与区域 1 相连的。其二：这些方法中，在使用 RNN 对时间关系建模时，每个区域是独立处理的，或者只基于局部信息。然而，我们认为全局和背景信息也很重要。举个例子，网约车需求的一个全局性的增长/减小通常表明一些可能会影响未来需求的活动发生了。</p><p>我们提出了 ST-MGCN 解决这些问题。在 ST-MGCN 中，我们提出了将区域间非欧关系编码进多个图的方法。不同于 Yao et al. 2018b 给每个区域使用图嵌入作为额外的不变特征，我们用图卷积对区域间的关系对直接建模。图卷积在预测的时候可以聚合邻居特征，传统的图嵌入难以做到这一点。此外，在对时间关系建模时，为了聚合全局的背景信息，我们提出了 contextual gated recurrent neural network (CGRNN)。通过一个基于全局信息计算的门机制增强 RNN，对不同时间步的观测值重新赋权重。我们在两个大型的真实数据集上做了测试，ST-MGCN 比 baselines 好了一大截。我们主要的贡献是：</p><ul><li>识别了网约车需求预测中的非欧关系，将他们编码进多个图。利用多图卷积对这些关系建模。</li><li>对时间依赖，提出了 Contextual Gated RNN (CGRNN) 来集成全局背景信息。</li><li>在两个大型真实数据集上做了实验，提出的方法比 state-of-the-art 在相对误差上小了 10%.</li></ul><h1 id=related-work>Related work</h1><h2 id=spatiotemporal-prediction-in-urban-computing>Spatiotemporal prediction in urban computing</h2><p>时空预测是数据驱动的城市管理的基础问题。有很多关于这方面的工作，自行车流量预测(Zhang, Zheng, and Qi 2017)，出租车需求(Ke et al. 2017b; Yao et al. 2018b)，到达时间(Li et al. 2018b)，降雨量(Shi et al. 2015; 2017)，对矩形区域的聚合值进行预测，区域关系通过地理距离建模。具体来讲，城市数据的空间结构通过矩阵形式表示，每个元素表示一个矩形区域。在之前的工作中，区域和他们的关系对一般表示成欧式结构，使得卷积神经网络可以有效地利用这个结构来预测。</p><p>非欧结构的数据也存在于城市计算。通常，基于站点或点的预测任务，像流量预测(Li et al. 2018c; Yu, Yin, and Zhu 2018; Yao et al. 2018a)，基于点的出租车需求预测(Tong et al. 2017)以及基于站点的自行车流量预测(Chai, Wang, and Yang 2018)是很自然的非欧结构，数据不再是矩阵形式，卷积神经网络也不那么有效了。人工定制的特征工程或图卷积网络是处理非欧结构数据目前最好的方法。不同于之前的工作，ST-MGCN 将区域间的关系对编码进语义图中。尽管 ST-MGCN 是对基于区域的预测设计的，但是区域关系的非规整性使得它实际是对非欧数据进行预测。</p><p>在 (Yao et al. 2018b)，作者提出 DMVST-Net，将区域间关系编码进图中来预测出租车需求。DMVST-Net 主要使用图嵌入作为额外特征来预测，没有使用相关区域的需求值（目标值）。在 (Yao et al. 2018a) 的工作中，作者通过注意力机制对周期性的平移问题建模提升了性能。但是，这些方法都没有直接对区域间的非欧关系建模。我们的工作中，ST-MGCN 使用提出的多图卷积从相关区域聚合特征，从不同角度的相关区域的预测值中做预测。</p><p>最近在对帕金森的神经图像分析 (Zhang et al. 2018b) 的研究中，图卷积在空间特征提取上很有效。他们使用 GCN 从最相似的区域中学习特征，提出了多视图结构融合了不同的 MRI。然而，上述工作没有考虑时间依赖。ST-GCN 用于基于骨骼的动作识别(Li et al. 2018a; Yan, Xiong, and Lin 2018)。ST-GCN 的变换是一个空间依赖和局部时间循环的组合。然而，我们认为这些模型，在时间依赖建模上，背景信息或全局信息被忽略了。</p><h2 id=graph-convolution-network>Graph convolution network</h2><p>图卷积网络定义在图 $\mathcal{G} = (V, \boldsymbol{A})$ 上，$V$ 是顶点集，$\boldsymbol{A} \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ 是邻接矩阵，元素表示顶点间是否相连。GCN 可以用不同的感受野从不同的非欧结构中提取局部特征(Hammond et al. 2011)。令 $\boldsymbol{L} = \boldsymbol{I} - \boldsymbol{D}^{-1/2} \boldsymbol{A} \boldsymbol{D}^{-1/2}$ 表示图拉普拉斯矩阵，$\boldsymbol{D}$ 是度矩阵，图卷积操作 (Defferrard, Bresson, and Vandergheynst 2016) 定义为：</p>$$
\boldsymbol{X}\_{l+1} = \sigma (\sum^{K-1}\_{k=0} \alpha\_k \boldsymbol{L}^k \boldsymbol{X}\_l),
$$<p>$\boldsymbol{X}_l$ 表示第 $l$ 层的特征，$\alpha_k$ 表示可学习的参数，$\boldsymbol{L}^k$ 是图拉普拉斯矩阵的 $k$ 次幂，$\sigma$ 是激活函数。</p><h2 id=channel-wise-attention>Channel-wise attention</h2><p>Channel-wise attention (Hu, Shen, and Sun 2018; Chen et al. 2017) 在 cv 的论文中提出。本质是给每个通道学习一个权重，为了找到最重要的帧，然后基于他们更高的权重。$\boldsymbol{X} \in \mathbb{R}^{W \times H \times C}$ 表示输入，$W$ 和 $H$ 是输入图像的维度，$C$ 表示通道数，channel-wise attention 计算方式如下：</p>$$\tag{1}
z\_c = F\_{pool}(\boldsymbol{X}\_{:,:,c}) = \frac{1}{WH} \sum^W\_{i=0} \sum^H\_{j=0} X\_{i,j,c} \quad \text{for} c=1,2,\dots,C \\
\boldsymbol{s} = \sigma(\boldsymbol{W}\_2 \delta (\boldsymbol{W}\_1 \boldsymbol{z})) \\
\tilde{\boldsymbol{X}}\_{:,:,c} = \boldsymbol{X}\_{:,:,c} \circ s\_c \quad \text{for} c=1,2,\dots,C
$$<p>$F_{pool}$ 是全局池化操作，把每个通道聚合成一个标量 $\boldsymbol{z}_c$，$c$ 是通道的下标。用一个注意力机制对聚合的向量 $\boldsymbol{z}$ 使用非线性变换生成自适应的通道权重 $\boldsymbol{s}$，$\boldsymbol{W}_1, \boldsymbol{W}_2$ 是对应的权重，$\delta, \sigma$ 是 ReLU 和 sigmoid 激活函数。$\boldsymbol{s}$ 通过矩阵乘法乘到输入上。最后，输入通道基于学习到的权重得到了缩放。我们使用这个方法，针对一系列的图生成了时间依赖的注意力分数。</p><h1 id=methodology>Methodology</h1><h2 id=region-level-ride-hailing-demand-forecasting>Region-level ride-hailing demand forecasting</h2><p>我们将城市分为相同大小的网格，每个格子定义为一个区域 $v \in V$，$V$ 表示城市内所有不相交的区域。$\boldsymbol{X}^{(t)}$ 表示第 $t$ 个时段所有区域的订单。<em>区域级别的网约车需求预测</em> 问题定义为：给定一个定长的输入，对单个时间步进行时空预测，也就是学习一个函数 $f: \mathbb{R}^{\vert V \vert \times T} \rightarrow \mathbb{R}^{\vert V \vert}$，将所有区域的历史需求映射到下一个时间步上。</p>$$
[\boldsymbol{X}^{(t-T+1)}, \dots, \boldsymbol{X}^{(t)}]
$$<p><strong>Framework overview</strong> ST-MGCN 的系统架构如图2。我们从不同的角度表示区域间的关系，顶点表示区域，边对区域间的关系编码。首先，我们使用提出的 CGRNN，考虑全局背景信息对不同时间的观测值进行聚合。然后，使用多图卷积捕获区域间不同类型的关系。最后，使用全连接神经网络将特征映射到预测上。</p><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig2.JPG loading=lazy alt=Figure2></p><h2 id=spatial-dependency-modeling>Spatial dependency modeling</h2><p>我们用图将区域间关系建模成三种类型，（1）邻居图 $\mathcal{G}_N = (V, \boldsymbol{A}_N)$，编码了空间相近程度，（2）功能相似度图 $\mathcal{G}_F = (V, \boldsymbol{A}_F)$，编码了区域的 POI 的相似度，（3）连接图 $\mathcal{G}_T = (V, \boldsymbol{A}_T)$，编码了距离较远的区域的连通性。我们的方法可以轻易地扩展到其他的图上。</p><p><strong>Neighborhood</strong> 区域的邻居基于空间近邻程度定义。我们将 $3 \times 3$ 区域中的最中间的那个区域与他邻接的 8 个区域相连。</p>$$\tag{3}
A\_{N, ij} = \begin{cases}
1, \quad v\_i \quad \text{and} \quad v\_j \quad \text{are} \quad \text{adjacent}\\
0, \quad \text{otherwise}
\end{cases}
$$<p><strong>Functional similarity</strong> 对一个区域做预测的时候，很自然的会想到和这个区域在功能上相似的区域会有帮助。区域功能可以由 POI 刻画，两个顶点间的边定义为 POI 的相似度：</p>$$\tag{3}
A\_{S,i,j} = \text{sim}(P\_{v\_i}, P\_{v\_j}) \in [0, 1]
$$<p>其中 $P_{v_i}, P_{v_j}$ 是区域 $v_i$ 和 $v_j$ 的 POI 向量，维度等于 POI 种类的个数，每个分量表示这个区域内这个 POI 类型的数量。</p><p><strong>Transportation connectivity</strong> 运输系统也是一个重要因素。一般来说，这些空间距离上相距较远但是可以很方便到达的区域可以关联起来。这种连接包含高速公路、公路、地铁这样的公共运输。我们定义：如果两个区域间通过这些路直接相连，那么他们之间有边：</p>$$\tag{4}
A\_{C,i,j} = max(0, \text{conn}(v\_i, v\_j) - A\_{N,i,j}) \in \lbrace 0, 1\rbrace
$$<p>$\text{conn}(u, v)$ 表示 $v_i$ 和 $v_j$ 之间的连通性。邻居的边在这个图中移除掉了，减少冗余的关系，所以这个图最后是一个稀疏图。</p><p><strong>Multi-graph convolution for spatial dependency modeling</strong> 有了这些图，我们提出了多图卷积对空间关系建模：</p>$$\tag{5}
\boldsymbol{X}\_{l+1} = \sigma(\bigsqcup\_{\mathbf{A} \in \mathbb{A}} f(\mathbf{A; \theta\_i}) \boldsymbol{X}\_l \mathbf{W}\_l)
$$<p>其中 $\boldsymbol{X}_l \in \mathbb{R}^{\vert V \vert \times P_l}, \boldsymbol{X}_{l+1} \in \mathbb{R}^{\vert V \vert \times P_{l+1}}$ 是第 $l$ 和 $l+1$ 层的特征向量，$\sigma$ 是激活函数，$\bigsqcup$ 表示聚合函数，如 sum, max, average etc. $\mathbb{A}$ 表示图的集合，$f(\mathbf{A}; \theta_i) \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ 表示参数为 $\theta_i$ 的基于图 $\mathbf{A} \in \mathbb{A}$ 的不同样本组成的矩阵的聚合值，$\mathbf{W}_l \in \mathbb{R}^{P_l \times P_{l+1}}$ 表示特征变换矩阵，举个例子，如果 $f(\mathbf{A}, \theta_i)$ 是拉普拉斯矩阵 $\mathbf{L}$ 的多项式，那么这就是多图上的 ChebNet。如果是 $\mathbf{I}$，那就是全连接神经网络。</p><p>我们实现的是 $K$ 阶 拉普拉斯 $\mathbf{L}$ 多项式，图 3 是一个中心区域通过图卷积层变换后的例子。假设邻接矩阵中的值不是 0 就是 1，$L^k_{ij} \not = 0$ 表示 $v_i$ 在 $k$ 步内可达 $v_j$。根据卷积操作，$k$ 是空间特征提取时的感受野范围。使用图 1 的道路连通性图 $\mathcal{G}_C = (V, \boldsymbol{A}_C)$ 来说明。在邻接矩阵 $\boldsymbol{A}_C$ 中，我们有：</p>$$
A\_{C,1,4} = 1; A\_{C,1,6} = 0; A\_{C,4,6} = 1,
$$<p>在 1 度拉普拉斯矩阵中对应的分量是：</p>$$
L^1\_{C,1,4} \not = 0; L^1\_{C,1,6} = 0; L^1\_{C,4,6} \not = 0
$$<p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig3.JPG loading=lazy alt=Figure3></p><p>如果拉普拉斯矩阵的最大度数 $K$ 设为 $1$，那么区域 1 变换的特征向量，即 $\boldsymbol{X}_{l+1, 1,:}$ 不会包含区域 6: $\boldsymbol{X}_{l,6,:}$，因为 $L^1_{C,1,6}=0$。当 $K$ 增大到 2 的时候，对应的元素 $L^2_{C,1,6}$ 变成非零，$\boldsymbol{X}_{l+1,1,:}$ 就可以利用 $\boldsymbol{X}_{l,6,:}$ 的信息了。</p><p>基于多图卷积的空间依赖建模不限于上述三种图，可以轻易地扩展到其他的图上，适用于其他的时空预测问题上。多图卷积对区域间的关系进行特征提取。感受野小的时候，专注于近邻的区域。增大拉普拉斯阶数，或者堆叠卷积层可以增加感受野的范围，鼓励模型捕获全局依赖关系。</p><p>图嵌入是另一种对区域间关系建模的方法。在 DMVST-Net (Yao et al. 2018b)，作者使用图嵌入表示区域间关系，然后将嵌入作为额外特征加到每个区域上。我们认为 ST-MGCN 中的空间依赖建模方法比之前的方法好，因为：ST-MGCN 将区域间关系编码到图中，通过图卷积从相关区域聚合需求值。但是在 DMVST-Net 中区域关系是嵌入到一个基于区域的不随时间变化的特征中，作为的模型的输入，</p><p>尽管 DMVST-Net 也捕获了拓扑结构信息，但是它很难从相关的区域中通过区域关系聚合需求值。而且不变的特征对模型训练的贡献有限。</p><h2 id=temporal-correlation-modeling>Temporal correlation modeling</h2><p>我们提出 Contextual Gated Recurrent Neural Network (CGRNN) 对不同时间步上的样本建模。CGRNN 通过使用一个上下文注意的门机制增强 RNN 将背景信息集成到时间建模中，结构如图 4。假设我们有 $T$ 个观测样本，$\boldsymbol{X}^{(t)} \in \mathbb{R}^{\vert V \vert \times P}$ 表示第 $t$ 个样本，$P$ 是特征数，如果特征只包含订单数，那就是 1。上下文门控机制如下：</p>$$tag{6}
\hat{\boldsymbol{X}}^{(t)} = [\boldsymbol{X}^{(t)}, F^{K'}\_\mathcal{G}(\boldsymbol{X}^{(t)})] \quad \text{for} \quad t = 1,2,\dots,T
$$<p>首先，上下文门控机制通过将临近区域的历史信息和当前区域拼接，得到了区域的描述信息。从相邻区域来的信息看作是环境信息，通过图卷积 $F^{K&rsquo;}_\mathcal{G}$ 使用最大阶数为 $K&rsquo;$ 的拉普拉斯矩阵提取。上下文门控机制用来用图卷积操作集成临近区域的信息，然后使用一个池化：</p>$$\tag{7}
z^{(t)} = F\_{pool}(\hat{\boldsymbol{X}}^{(t)}) = \frac{1}{\vert V \vert} \sum^{\vert V \vert}\_{i=1} \hat{X}^{(t)}\_{i,:} \quad \text{for} \quad t=1,2,\dots,T
$$<p>然后，我们在所有的区域上使用全局平均池化 $F_{pool}$ 生成每个时间步观测值的平均值。</p>$$tag{8}
\boldsymbol{s} = \sigma(\boldsymbol{W}\_2 \delta(\boldsymbol{W}\_1) \boldsymbol{z})
$$<p>然后使用一个注意力机制，$\boldsymbol{W}_1, \boldsymbol{W}_2$ 是参数，$\delta, \sigma$ 分别是 ReLU 和 sigmoid 激活。</p>$$\tag{9}
\tilde{\boldsymbol{X}^{(t)}} = \boldsymbol{X}^{(t)} \circ s^{(t)} \quad \text{for} \quad t=1,2,\dots,T
$$<p>最后，$\boldsymbol{s}$ 用来对每个时间样本进行缩放：</p>$$tag{10}
\boldsymbol{H}\_{i,:} = \text{RNN}(\tilde{\boldsymbol{X}}^{(1)}\_{i,:}, \dots, \tilde{\boldsymbol{X}}^{(T)}\_{i,:}; \boldsymbol{W}\_3) \quad \text{for} \quad i=1,\dots,\vert V \vert
$$<p>在上下文门控之后，使用一个共享的 RNN 对所有的区域进行计算，将每个区域聚合成单独的向量 $\boldsymbol{H}_{i,:}$。使用共享 RNN 的原因是我们想找到一个对所有区域通用的聚合规则，这个规则鼓励模型泛化且减少模型的复杂度。</p><h1 id=experiments>Experiments</h1><p><strong>Dataset</strong> 北京和上海。时间是从2017年5月1日到2017年12月31日。5月1日到7月31日训练、8月1日到9月30日验证，剩下的测试。POI 数据是2017年的，包含13个类别。每个区域和一个 POI 向量相关，分量是这个 POI 类型在这个区域的个数。用来评估运输可达性的路网使用的是 OpenStreetMap (Haklay and Weber 2008)。</p><h2 id=experimental-settings>Experimental Settings</h2><p>学习任务是：$f: \mathbb{R}^{\vert V \vert \times T} \rightarrow \mathbb{R}^{\vert V \vert}$。实验中，我们将区域以 $1km \times 1km$ 的大小划分成网格。北京和上海分别 1296 和 896 个区域。就像 Zhang, Zheng, and Qi 2017 做的那样，网络的输入包含 5 个历史观测值，三个最近邻的部分，1个周期部分，一个最新的趋势部分。在构建运输可达性网络的时候，我们考虑了高速公路、公路、地铁。两个区域间只要有这样的路直接相连就认为是连通的。</p><p>$f(\mathbf{A}; \theta_i)$ 选择的是 $K = 2$ 时的切比雪夫多项式，$\bigsqcup$ 是 sum 函数。隐藏层为3，每层 64 个隐藏单元，L2 正则，weight decay 是 $1e-4$。CGRNN 中的图卷积 $K&rsquo;$ 是 1。</p><p>我们使用 ReLU 作为图卷积的激活函数。ST-MGCN 的学习率是 $2e-3$，使用验证集上的早停。所有的算法都用 tf 实现，adam 优化 RMSE。ST-MGCN 训练时用了 10G 内存，9G GPU 显存。在 Tesla P40 单卡上训练了一个半小时。</p><p><strong>Methods for evaluation</strong> HA, LASSO, Ridge, Auto-regressive model(VAR, STAR), Gradient boosted machine (GBM), ST-ResNet (Zhang, Zheng and Qi 2017), DMVST-Net (Yao et al. 2018b), DCRNN, ST-GCN。</p><h2 id=performance-comparison>Performance comparison</h2><p>我们在验证集上用网格搜索调整了所有模型的参数，在测试集上跑了多次得到的最后的结果。我们使用 RMSE 和 MAPE 作为评价指标。表 1 展示了不同方法在 10 次以上的预测中的对比结果。</p><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table1.JPG loading=lazy alt=Table1></p><p>我们在两个数据集上观测到了几个现象：（1）基于深度学习的方法能够对非线性的时空依赖关系建模，比其他的方法好；（2）ST-MGCN 在两个数据集上比其他的方法都好，比第二好的高出 10%；（3）对比其他的深度学习方法，ST-MGCN 的方差更小。</p><h2 id=effect-of-spatial-dependency-modeling>Effect of spatial dependency modeling</h2><p>为了研究空间和时间依赖建模的效果，我们通过减少模型中的组成部分评估了 ST-MGCN 的几个变体，包括：（1）邻居图，（2）功能相似性图，（3）运输连通性图。结果如表 2 所示。移除任何一个图都会造成性能损失，证明了每种关系的重要性。这些图编码了重要的先验知识，也就是区域间的相关性。</p><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table2.JPG loading=lazy alt=Table2></p><p>为了评估集成多个区域关系的效果，我们扩展了基于单个图的模型，包括 DCRNN 和 STGCN，分别记为 DCRNN+ 和 ST-GCN+。结果如图 3，两个算法都得到了提升。</p><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table3.JPG loading=lazy alt=Table3></p><h2 id=effect-of-temporal-dependency-modeling>Effect of temporal dependency modeling</h2><p>我们使用不同的方法对时间建模，评估 ST-GCN 对时间关系建模的效果。（1）平均池化：通过平均池化对历史观测值进行聚合，（2）RNN：使用 RNN 对历史观测值聚合，（3）CG：使用上下文门对不同的历史观测值赋权，不适用 RNN，（4）GRNN：不用图卷积的 CGRNN。结果如表 4。我们观察到了以下现象：</p><ul><li>平均池化会盲目地平均不同的样本，导致性能下降，能做上下文依赖非线性时间聚合的 RNN 能显著地提升性能。</li><li>CGRNN 增强了 RNN。移除 RNN 和 图卷积都导致性能下降，证明了每个部件的有效性。</li></ul><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Table4.JPG loading=lazy alt=Table4></p><h2 id=effect-of-model-parameters>Effect of model parameters</h2><p>我们调整了两个最重要的参数来看不同参数对模型的影响，$K$ 和图卷积层数。图 5 展示了测试集上的结果。可以观察到随着层数的增加，错误先降后增。但是随着 $K$ 的增加，错误是先减小，后不变。越大的 $K$ 或层数使得模型能捕获全局关联性，代价是模型的复杂度会增加，更易过拟合。</p><p><img src=/blog/images/spatiotemporal-multi-graph-convolution-network-for-ride-hailing-demand-forecasting/Fig5.JPG loading=lazy alt=Figure5></p><h1 id=conclusion-and-future-work>Conclusion and Future work</h1><p>我们研究的是网约车需求预测，要找寻这个问题唯一的时空依赖关系。我们提出的深度学习模型使用多个图对区域间的非欧关系建模，使用多图卷积明显的捕获了这个关系。然后用上下文门控机制增强了 RNN，在时间建模上集成了全局背景信息。在两个大型真实数据集上评估了模型，比 state-of-the-art好。未来的工作是：（1）在其他的时空预测任务上评估模型；（2）将提出的模型扩展到多步预测上。</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/spatial-temporal/>Spatial-Temporal</a>
<a href=/blog/tags/graph-convolutional-network/>Graph Convolutional Network</a>
<a href=/blog/tags/graph/>Graph</a>
<a href=/blog/tags/time-series/>Time Series</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/deepstn-context-aware-spatial-temporal-neural-network-for-crowd-flow-prediction-in-metropolis/><div class=article-details><h2 class=article-title>DeepSTN+: Context-aware Spatial-Temporal Neural Network for Crowd Flow Prediction in Metropolis</h2></div></a></article><article><a href=/blog/p/flow-prediction-in-spatio-temporal-networks-based-on-multitask-deep-learning/><div class=article-details><h2 class=article-title>Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning</h2></div></a></article><article><a href=/blog/p/revisiting-spatial-temporal-similarity-a-deep-learning-framework-for-traffic-prediction/><div class=article-details><h2 class=article-title>Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction</h2></div></a></article><article><a href=/blog/p/deep-spatio-temporal-residual-networks-for-citywide-crowd-flows-prediction/><div class=article-details><h2 class=article-title>Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction</h2></div></a></article><article><a href=/blog/p/t-gcn-a-temporal-graph-convolutional-network-for-traffic-prediction/><div class=article-details><h2 class=article-title>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>