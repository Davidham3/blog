<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="ICLR 2018 workshop, [Time-dependent representation for neural event sequence prediction](https://arxiv.org/abs/1708.00065)。事件序列的表示学习模型。主要是对事件的嵌入表示有了一些创新，加入了对事件duration的考虑。模型整体还是RNN架构。"><title>Time-dependent representation for neural event sequence prediction</title>
<link rel=canonical href=https://davidham3.github.io/blog/p/time-dependent-representation-for-neural-event-sequence-prediction/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Time-dependent representation for neural event sequence prediction"><meta property='og:description' content="ICLR 2018 workshop, [Time-dependent representation for neural event sequence prediction](https://arxiv.org/abs/1708.00065)。事件序列的表示学习模型。主要是对事件的嵌入表示有了一些创新，加入了对事件duration的考虑。模型整体还是RNN架构。"><meta property='og:url' content='https://davidham3.github.io/blog/p/time-dependent-representation-for-neural-event-sequence-prediction/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='event sequence'><meta property='article:tag' content='learning representations'><meta property='article:published_time' content='2022-04-27T15:37:58+00:00'><meta property='article:modified_time' content='2022-04-27T15:37:58+00:00'><meta name=twitter:title content="Time-dependent representation for neural event sequence prediction"><meta name=twitter:description content="ICLR 2018 workshop, [Time-dependent representation for neural event sequence prediction](https://arxiv.org/abs/1708.00065)。事件序列的表示学习模型。主要是对事件的嵌入表示有了一些创新，加入了对事件duration的考虑。模型整体还是RNN架构。"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a92d3b55c5d43e55.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#31-contextualizing-event-embedding-with-time-mask>3.1 Contextualizing Event Embedding With Time Mask</a></li><li><a href=#32-event-time-joint-embedding>3.2 Event-Time Joint Embedding</a></li></ol><ol><li><a href=#41-negative-log-lieklihood-of-time-prediction-error>4.1 Negative Log Lieklihood of Time Prediction Error</a></li><li><a href=#42-cross-entropy-loss-on-time-projection>4.2 Cross Entropy Loss on Time Projection</a></li></ol><ol><li><a href=#51-数据预处理>5.1 数据预处理</a></li><li><a href=#52-模型配置>5.2 模型配置</a></li><li><a href=#54-实验结果>5.4 实验结果</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/time-dependent-representation-for-neural-event-sequence-prediction/>Time-dependent representation for neural event sequence prediction</a></h2><h3 class=article-subtitle>ICLR 2018 workshop, [Time-dependent representation for neural event sequence prediction](https://arxiv.org/abs/1708.00065)。事件序列的表示学习模型。主要是对事件的嵌入表示有了一些创新，加入了对事件duration的考虑。模型整体还是RNN架构。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Apr 27, 2022</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><p>ICLR 2018 workshop, <a class=link href=https://arxiv.org/abs/1708.00065 target=_blank rel=noopener>Time-dependent representation for neural event sequence prediction</a>。事件序列的表示学习模型。主要是对事件的嵌入表示有了一些创新，加入了对事件duration的考虑。模型整体还是RNN架构。</p><p><img src=/blog/images/time-dependent-representation-for-neural-event-sequence-prediction/Fig1.jpg loading=lazy alt=Figure1></p><p>在事件序列中，有两个时间段(time span)，一个是duration，事件的持续时长，另一个是interval，事件与事件之间的间隔。为了统一这两个时间段，作者将interval看作是一个空闲事件(idle event)。</p><p><img src=/blog/images/time-dependent-representation-for-neural-event-sequence-prediction/Fig2.jpg loading=lazy alt=Figure2></p><p>图2是模型架构，就是把事件做嵌入表示，然后把duration考虑进去，得到事件序列里面每个时间步的嵌入表示，然后丢到RNN里面，最后是要预测下一个event是什么，同时可以把下一个event的duration拿进来计算损失，起到一个正则的作用。</p><h2 id=31-contextualizing-event-embedding-with-time-mask>3.1 Contextualizing Event Embedding With Time Mask</h2><p>这里有一个观点，就是在机器翻译中，RNN会花一定的capacity去区分不同context下一个词的意思。为了解决这个问题，Choi et al., 2016 提出了一个mask计算。本文借助这个思想，提出了一个时间依赖的嵌入表示。</p>$$
\tag{1} c^d = \phi (\log(d\_t);\theta)
$$<p>上式是一个FNN，$\phi$是非线性变换，参数是$\theta$。加对数是为了降低$d_t$的范围。然后用一个单层sigmoid的非线性变换把$c^d$映射到$m^d \in \mathbb{R}^E$上，这个就是mask。</p>$$
\tag{2} m\_d = \sigma(c^d W\_d + b\_d)
$$<p>然后</p>$$
\tag{3} x\_t \leftarrow x\_t \odot m\_d
$$<p>把mask和一个事件的embedding相乘，element-wise production，这个东西放入RNN。</p><h2 id=32-event-time-joint-embedding>3.2 Event-Time Joint Embedding</h2><p>这里有个观点，我们平时只会说“和谁简单地聊了一会儿”，不会说具体聊了多少分钟。我们对于事件时长的感受依赖事件的类型。基于这个直觉，我们用了一个sort one-hot嵌入表示，做了一个事件的联合表示。</p><p>首先把事件时长映射到一个向量上去</p>$$
\tag{4} p^d = d\_t W\_d + b\_d \in \mathbb{R}^P
$$<p>然后在这个向量上面做一个softmax运算</p>$$
\tag{5} s^d\_i = \frac{\exp(p^d\_i)}{\sum^P\_{k=1} \exp(p^d\_k)}
$$<p>然后做一个线性变换</p>$$
\tag{6} g\_d = s^d E^s \in \mathbb{R}^E
$$<p>然后把事件嵌入和这个时间嵌入求平均，得到事件嵌入表示：</p>$$
\tag{7} x\_t \leftarrow \frac{x\_t + g\_d}{2} \in \mathbb{R}^E
$$<h1 id=4-next-event-duration-as-a-regularizer>4 Next Event Duration as A Regularizer</h1><p>这里讨论的是通过让模型去预测下一事件的时长来增强模型。这个时长是通过对RNN循环层做线性变换得到的。对于时间步$t$，来说，需要预测的duration是$d’_{t+1}$。它的损失回传后会起到一个正则的作用。而且可以对事件预测输出层路径上的多个层进行正则。</p><h2 id=41-negative-log-lieklihood-of-time-prediction-error>4.1 Negative Log Lieklihood of Time Prediction Error</h2><p>这里说，对于连续值的预测，一般用MSE，但是MSE这个指标需要和事件预测的损失在同一个数量级上。而事件损失，一般是一个log形式的损失，也就是说这个数会比较小。Hinton & van Camp, 1993研究证明最小化平方损失可以写成最大化0均值高斯分布的概率密度，而且不需要duration服从高斯分布，但是预测误差需要。因此正则项要做一个标准化，</p>$$
\tag{8} R^N\_t = \frac{(d'\_{t+1} - d\_{t+1})^2}{2\sigma^2\_i}
$$<p>$\sigma_i$是通过训练集的duration算出来的，然后在训练的过程中，通过时长预测误差的分布来更新。</p><h2 id=42-cross-entropy-loss-on-time-projection>4.2 Cross Entropy Loss on Time Projection</h2><p>这里说，对于时长的损失计算还可以用softmax。</p><p>因为3.2节提到了一个把连续值映射到向量空间的办法，使用同样的办法可以计算另一种损失：</p>$$
\tag{9} R^X\_t = - \sum^P\_{k=1} Proj\_k (d\_{t+1}) \log{Proj\_k (d'\_{t+1})}
$$<p>$Proj$就是公式4和5定义的投影函数，$Proj_k$是投影向量中的第$k$项。当3.2节的事件与时间的联合嵌入表示和这个损失都使用的时候，可以把投影函数的权重共享。</p><h1 id=5-experiments>5 Experiments</h1><p>用了5个数据集。</p><h2 id=51-数据预处理>5.1 数据预处理</h2><p>做了一些特别稀有的事件的过滤。有些事件少于5次的用OOV代替了。使用MAP@K和Precision@K来评估。</p><p>训练、验证、测试的比例是8:1:1</p><h2 id=52-模型配置>5.2 模型配置</h2><ul><li>NoTime: 就用一个简单的LSTM</li><li>TimeConcat: 把duration做log变换，与事件嵌入表示拼接，输入RNN</li><li>TimeMask: 3.1节的方法</li><li>TimeJoint: 3.2节的方法</li><li>RMTPP: <a class=link href=https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf target=_blank rel=noopener>RMTPP</a></li></ul><h2 id=54-实验结果>5.4 实验结果</h2><p><img src=/blog/images/time-dependent-representation-for-neural-event-sequence-prediction/Fig3.jpg loading=lazy alt=Figure3></p><p>Effectiveness of Temporal Representation: 图3展示出了TimeMask和TimeJoint的有效性。MIMIC II数据集上面没效果，可能是加时间本来就没啥用。结论就是，用这两个东西肯定比只加时间的值到RNN里面要有效。</p><p><img src=/blog/images/time-dependent-representation-for-neural-event-sequence-prediction/Table1_2.jpg loading=lazy alt="Table 1 & 2"></p><p>表1和表2也证明了加入时间的有效性。而且有些时候直接加时间可能会伤害模型的效果。</p><p>Effectiveness of Event Duration Regularization: 表1和表2证明了正则的有效性。</p><p>Learned Time Representation: 这段说的不明所以，论文里面还有错误，图画的也不清晰，没懂。</p><p><img src=/blog/images/time-dependent-representation-for-neural-event-sequence-prediction/Fig4.jpg loading=lazy alt=Figure4></p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/event-sequence/>Event Sequence</a>
<a href=/blog/tags/learning-representations/>Learning Representations</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Apr 27, 2022 15:37 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/modeling-the-intensity-function-of-point-process-via-recurrent-neural-networks/><div class=article-details><h2 class=article-title>Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks</h2></div></a></article><article><a href=/blog/p/unsupervised-scalable-representation-learning-for-multivariate-time-series/><div class=article-details><h2 class=article-title>Unsupervised Scalable Representation Learning for Multivariate Time Series</h2></div></a></article><article><a href=/blog/p/fully-neural-network-based-model-for-general-temporal-point-processes/><div class=article-details><h2 class=article-title>Fully Neural Network based Model for General Temporal Point Processes</h2></div></a></article><article><a href=/blog/p/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/><div class=article-details><h2 class=article-title>Recurrent Marked Temporal Point Processes: Embedding Event History to Vector</h2></div></a></article><article><a href=/blog/p/event-sequence-metric-learning/><div class=article-details><h2 class=article-title>Event sequence metric learning</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>