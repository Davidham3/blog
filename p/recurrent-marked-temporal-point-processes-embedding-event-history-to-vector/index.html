<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="KDD 2016: RMTPP [Recurrent Marked Temporal Point Processes: Embedding Event History to Vector](https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf)。经典论文，利用RNN近似条件强度函数，将传统点过程带入到神经点过程。"><title>Recurrent Marked Temporal Point Processes: Embedding Event History to Vector</title>
<link rel=canonical href=https://davidham3.github.io/blog/p/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Recurrent Marked Temporal Point Processes: Embedding Event History to Vector"><meta property='og:description' content="KDD 2016: RMTPP [Recurrent Marked Temporal Point Processes: Embedding Event History to Vector](https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf)。经典论文，利用RNN近似条件强度函数，将传统点过程带入到神经点过程。"><meta property='og:url' content='https://davidham3.github.io/blog/p/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/'><meta property='og:site_name' content='Davidham的博客'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='deep learning'><meta property='article:tag' content='event sequence'><meta property='article:published_time' content='2022-05-01T09:18:43+00:00'><meta property='article:modified_time' content='2022-05-01T09:18:43+00:00'><meta name=twitter:title content="Recurrent Marked Temporal Point Processes: Embedding Event History to Vector"><meta name=twitter:description content="KDD 2016: RMTPP [Recurrent Marked Temporal Point Processes: Embedding Event History to Vector](https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf)。经典论文，利用RNN近似条件强度函数，将传统点过程带入到神经点过程。"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/avatar_hu_a92d3b55c5d43e55.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🚀</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Davidham的博客</a></h1><h2 class=site-description>随便写写</h2></div></header><ol class=menu-social><li><a href=https://github.com/Davidham3 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#41-parametrizations>4.1 Parametrizations</a></li></ol><ol><li><a href=#51-model-formulation>5.1 Model Formulation</a></li><li><a href=#52-参数学习>5.2 参数学习</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/>Recurrent Marked Temporal Point Processes: Embedding Event History to Vector</a></h2><h3 class=article-subtitle>KDD 2016: RMTPP [Recurrent Marked Temporal Point Processes: Embedding Event History to Vector](https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf)。经典论文，利用RNN近似条件强度函数，将传统点过程带入到神经点过程。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 01, 2022</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 7 分钟</time></div></footer></div></header><section class=article-content><p>KDD 2016: RMTPP <a class=link href=https://www.kdd.org/kdd2016/papers/files/rpp1081-duA.pdf target=_blank rel=noopener>Recurrent Marked Temporal Point Processes: Embedding Event History to Vector</a>。经典论文，利用RNN近似条件强度函数，将传统点过程带入到神经点过程。</p><h1 id=1-introduction>1. Introduction</h1><p>当前方法两类变量马尔可夫模型，把问题看作是discrete-time sequence prediction task。基于观察到的状态序列，预测下一步最可能的状态。缺点是这类模型的时间是单位变化的，在预测下一个事件的时候不能捕获时间的heterogeneity。此外，状态不能太多，要不然算不过来，就没法捕获长距离的依赖关系。半马尔可夫模型</p>\[26\]<p>可以用来建模两个连续事件之间的continuous time-interval，通过假设interval之间是一个简单的分布，但是随着阶数的增加，计算仍然会爆炸。</p><p>第二类是marked temporal point processes和intensity function，这两类是建模这种事件数据更通用的数学框架。地震学中，时间点过程广泛用用在建模地震和余震上面。每个地震表示时空空间中的一个点，地震学已经提出不同的公式来捕获这些事件的随机性。金融领域，时间点过程是经济学的活跃方向，可以给出现代金融市场复杂动态性的一些简答解释。</p><p>但是实际中典型的这些点过程模型的假设一般做不到，而且这些模型的表达能力有限。我们提出了新的marked时间点过程模型，RMTPP，同步建模事件的事件和标记。我们方法的核心是将一个时间点过程的intensity function看作是一个历史过程的非线性函数，这个函数用RNN表示。</p><h1 id=2-问题定义>2. 问题定义</h1><p>一组序列 $\mathcal{C} = { S^1, S^2, \dots, }$</p><p>序列 $\mathcal{S}^i = ((t^i_1, y^i_1), (t^i_2, y^i_2), \dots)$ 是$(t^i_j, y^i_j)$组成的序列，$t^i_j$是事件发生的时间，$y^i_j$是事件的类别。</p><ul><li>给定实体$i$，预测下一个事件pair $(t^i_{n+1}, y^i_{n+1})$</li><li>计算一个给定序列的likelihood</li><li>通过学习得到的模型模拟一个新的序列</li></ul><h1 id=3-related-work>3. Related Work</h1><p>现存工作的一个主要的限制就是对latent dynamics的各种参数假设，latent dynamics控制了观测到的点过程的生成。</p><h1 id=4-marked-temporal-point-process>4. Marked Temporal Point Process</h1><p>这个第四节主要介绍了之前的一些点过程使用的条件强度函数。</p><p>标记时间点过程是一个对观测到的随时间发生的随机事件模式进行建模的强有力工具。因为一个事件的出现与历史发生了什么有关，我们可以指定一些模型，给定我们已知的过去，对下一个事件建模。严格来讲，一个标记时间点过程是一个随机过程，这个随机过程包含了一个带有时间信息的离散事件的列表，${ t_j, y_j }$，$t_j \in \mathbb{R}^+, y_j \in \mathcal{Y}, j \in \mathbb{Z}^+$，$t$是时间，$y$是标记。历史 $\mathcal{H}_t$ 是直到时间$t$的事件时间和标记组成的list。连续事件时间之间的时间差 $d_{j+1} = t_{j+1} - t_j$ 称为事件间的duration。</p><p>给定过去事件的历史，我们可以指定下一个事件类型$y$在时间$t$发生的条件密度函数为 $f^{\ast}(t, y) = f(t, y \mid \mathcal{H}_t)$，$f^{\ast}(t, y)$强调了这个密度是基于历史的这个条件。利用链式法则，可以得到一个序列的联合似然为：</p>$$
\tag{1} f(\{ (t\_j, y\_j) \}^n\_{j=1}) = \prod\_j f(t\_j, y\_j \mid \mathcal{H}\_t) = \prod\_j f^{\ast}(t\_j, y\_j)
$$<p>$f^{\ast}(t_j, y_j)$ 有很多种形式可以选择。但是实际中人们一般选择非常简单可分解的形式，比如$f(t_j, y_j \mid \mathcal{H}_t) = f(y_j) f(t_j \mid \dots, t_{j-2}, t_{j-1})$，要不然对事件标记和时间进行联合建模会非常复杂。我们可以认为在$y_j$只可取有限个值且与历史完全无关的时候，$f(y_j)$是一个多项式分布。$f(t_j \mid \dots, t_{j-2}, t_{j-1})$是给定过去事件的时间的序列时，事件发生在$t_j$的条件密度。而且需要注意的是，$f^{\ast}(t_j)$不能捕获过去事件标记的影响。</p><h2 id=41-parametrizations>4.1 Parametrizations</h2><p>一个标记点过程的时间信息可以通过一个典型的时间点过程来捕获。一个刻画时间点过程的重要方式是通过条件强度函数——给定过去所有事件，对下一个事件建模的随机模型。在一个小的时间窗口$[t, t + dt)$里，$\lambda^{\ast}(t)dt$是一个新事件在给定历史$\mathcal{H}_t$时出现的概率：</p>$$
\tag{2} \lambda^{\ast}(t)dt = \mathbb{P}\{ \text{event in }[t, t+dt) \mid \mathcal{H}\_t \}
$$<p>$\ast$是用来提醒我们这个函数是依赖历史的。给定条件密度函数$f^{\ast}(t)$，条件强度函数为：</p>$$
\tag{3} \lambda^{\ast}(t)dt = \frac{f^{\ast}(t)dt}{S^{\ast}(t)} = \frac{f^{\ast}(t)dt}{1 - F^{\ast}(t)},
$$<p>$F^{\ast}(t)$是在最后一个事件时间$t_n$之后，一个新事件发生在$t$之前的累积概率，$S^{\ast}(t) = \text{exp}(- \int^t_{t_n} \lambda^{\ast}(\tau) d\tau)$ 是$t_n$到$t$之间没有新事件发生的概率。因此条件密度函数可以写成：</p>$$
\tag{4} f^{\ast}(t) = \lambda^{\ast}(t) \text{exp}(- \int^t\_{t\_n} \lambda^{\ast}(\tau) d\tau).
$$<h1 id=5-recurrent-marked-temporal-point-process>5. Recurrent Marked Temporal Point Process</h1><p>条件强度函数的形式决定了一类点过程的事件性质。但是，为了考虑marker和事件信息，在缺少前沿知识的情况下很难决定使用哪种形式的条件强度函数。为了解决这个问题，作者提出了一个统一的模型，可以在历史的事件和marker信息上对非线性依赖建模的模型。</p><h2 id=51-model-formulation>5.1 Model Formulation</h2><p>公式5，6，7有不同的表达形式，而且是对过去事件不同类型的依赖结构。受到这一点的启发，我们希望能学习到一个趋近于历史未知依赖结构的通用表示。</p><p><img src=/blog/images/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/Fig2.jpg loading=lazy alt=Figure2></p><p>我们的想法是用RNN来实现这一步。如图2所示，RNN在时间步$t_j$的输入是$(t_j, y_j)$。$y_i$是事件的类型。$h_{j-1}$表示从过去事件和事件得到的影响的memory，在更新的时候会考虑当前的事件和时间。因为$h_j$表示过去一直到第$j$个事件的影响，那么下一个事件时间的条件强度函数就可以表示为：</p>$$
\tag{8} f^{\ast}(t\_{j + 1}) = f(t\_{j+1} \mid \mathcal{H}\_t) = f(t\_{j+1} \mid h\_j) = f(d\_{j + 1} \mid h\_j),
$$<p>$d_{j+1} = t_{j+1} - t_j$。因此，我们可以用$h_j$去预测时间$\hat{t}_{j + 1}$和下一事件类型$\hat{y}_{j + 1}$。</p><p>这个公式的好处是我们将历史事件嵌入到了一个隐向量空间，然后通过公式4，我们不用指定一个固定的参数形式来建模历史的依赖结构，可以用一个更简单的形式得到条件强度函数$\lambda^{\ast}(t)$。图3展示了RMTPP模型的架构。给定一个事件序列$\mathcal{S} = ((t_j, y_j)^n_{j=1})$，通过迭代以下组件，得到一个隐藏单元${ h_j }$的序列。</p><p><strong>Input Layer</strong>，先用一个input layer对one-hot的事件表示进行投影。$y_j = W^T_{em} y_j + b_{em}$。然后事件步$t_j$也投影成一个向量$t_j$。</p><p><img src=/blog/images/recurrent-marked-temporal-point-processes-embedding-event-history-to-vector/Fig3.jpg loading=lazy alt=Figure3></p><p><strong>Hidden Layer</strong></p>$$
\tag{9} h\_j = \text{max} \{ W^y y\_j + W^t t\_j + W^h h\_{j-1} + b\_h, 0 \}
$$<p><strong>Marker Generation</strong>，给定表示$h_j$，我们用一个多项式分布建模marker的生成：</p>$$
\tag{10} P(y\_{j+1} = k \mid h\_j) = \frac{ \text{exp}(V^y\_{k,:} h\_j + b^y\_k) }{ \sum^K\_{k=1} \text{exp} ( V^y\_{k,:} h\_j + b^y\_k ) },
$$<p>$K$是marker的个数，$V^y_{k,:}$是矩阵$V^y$的第$k$行。</p><p><strong>Conditional Intensity</strong>，基于$h_j$，可以得到条件强度函数：</p>$$
\tag{11} \lambda^{\ast}(t) = \text{exp}( \mathcal{v}^{t^T} \cdot h\_j + w^t (t - t\_j) + b^t ),
$$<p>$\mathcal{v}^t$是一个列向量，$w^t, b^t$是标量。</p><ul><li>第一项 $\mathcal{v}^{t^T} \cdot h_j$ 表示过去的事件和时间信息累积的影响。对比公式5，6，7对过去影响固定的公式，现在这个是对过去影响的高度非线性通用表示。</li><li>第二项强调当前事件$j$的影响。</li><li>最后一项对下一个事件的出现给了一个基础的强度等级。</li><li>指数函数是一个非线性函数，且保证强度永远是正的。</li></ul><p>通过公式4，我们可以得到给定历史的情况下，下一个事件在时间$t$出现的likelihood：</p>$$
\tag{12} f^{\ast}(t) = \lambda^{\ast}(t) \text{exp}( - \int^t\_{t\_j} \lambda^{\ast}(\tau) d\tau) \ = \text{exp} \{ \mathcal{v}^{t^T} \cdot h\_j + w^t (t - t\_j) + b^t + \frac{1}{w} \text{exp}(\mathcal{v}^{t^T} + b^t) \ - \frac{1}{w} \text{exp}(\mathcal{v}^{t^T} \cdot h\_j + w^t(t - t\_j) + b^t) \}
$$<p>然后，下一个事件的时间可以用期望来计算</p>$$
\tag{13} \hat{t}\_{j+1} = \int^\infty\_{t\_j} t \cdot f^{\ast}(t) dt.
$$<p>一般来说，公式13的积分没有解析解，我们可以用</p>\[32\]<p>的用于一维函数的数值积分技术来计算公式13。</p><p><strong>Remark</strong>。因为我们用RNN表示历史，所以条件强度函数$\lambda^{\ast}(t_{j+1})$的公式11，捕获了过去事件和时间两部分信息。另一方面，因为marker的预测也依赖于过去的时间信息，当时间和事件信息相互关联的时候，就可以提升模型的性能。后面的实验证明了这种互相提升的现象确实存在。</p><h2 id=52-参数学习>5.2 参数学习</h2><p>最大对数似然</p>$$
\tag{14} \ell(\{\mathcal{S}^i \}) = \sum\_i \sum\_j (\text{log} P(y^i\_{j+1} \mid h\_j) + \text{log} f(d^i\_{j+1} \mid h\_j) ),
$$<p>$\mathcal{C} = { \mathcal{S}^i }$是一组序列, $\mathcal{S}^i = ((t^i_j, y^i_j)^{n_i}_{j=1})$。用BPTT训练。</p></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/deep-learning/>Deep Learning</a>
<a href=/blog/tags/event-sequence/>Event Sequence</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 May 01, 2022 09:18 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/modeling-the-intensity-function-of-point-process-via-recurrent-neural-networks/><div class=article-details><h2 class=article-title>Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks</h2></div></a></article><article><a href=/blog/p/fully-neural-network-based-model-for-general-temporal-point-processes/><div class=article-details><h2 class=article-title>Fully Neural Network based Model for General Temporal Point Processes</h2></div></a></article><article><a href=/blog/p/time-dependent-representation-for-neural-event-sequence-prediction/><div class=article-details><h2 class=article-title>Time-dependent representation for neural event sequence prediction</h2></div></a></article><article><a href=/blog/p/event-sequence-metric-learning/><div class=article-details><h2 class=article-title>Event sequence metric learning</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Davidham的博客</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>