---
categories:
- software
date: 2019-08-02 20:22:10+0000
description: 最近在做实验的时候发现了一个非常神奇的问题，搞得我一度很郁闷。我在 kaggle 上面写了个 mxnet symbolic 的程序，在测试集上效果不错，论文都写完了，结果拿回实验室的
  GPU 上一跑，发现结果复现不了了，差了两个点。但我所有的实验都做了 10 次，如果说 1 次实验效果好还可以说是巧合，但这是 10 次实验啊。
draft: false
math: null
tags:
- software
- deep learning
title: MXNet 与 cuda 版本兼容的问题
---
最近在做实验的时候发现了一个非常神奇的问题，搞得我一度很郁闷。我在 kaggle 上面写了个 mxnet symbolic 的程序，在测试集上效果不错，论文都写完了，结果拿回实验室的 GPU 上一跑，发现结果复现不了了，差了两个点。但我所有的实验都做了 10 次，如果说 1 次实验效果好还可以说是巧合，但这是 10 次实验啊。

<!--more-->

尝试找了一下问题在哪里，首先是 GPU 型号，kaggle 上面提供的是 Tesla P100，非常强劲的 GPU，16G 的显存，而且好像还支持半精度浮点运算。我在实验室使用了 RTX 2080 跑实验。在 4 台 RTX 2080 上面搭建了 OpenPAI，微软的一个开源深度学习资源调度平台。

我在 kaggle 上跑 10 次，测试集指标是 18.039，做了 10 次实验取的平均值，方差是 0.075，非常稳定，也就是对于随机性不敏感，所以不需要指定随机种子什么的，我也不爱指定随机种子，因为我觉得好的模型就应该对随机性不敏感。

为了验证是哪里出了问题，我打印了 kaggle 的环境配置，kaggle 使用的 mxnet_cu100 1.5.0，numpy 1.16.4。

我用 Docker 构建了 4 个镜像：

softwares|cuda 100|cuda 101|
-|-|-
**mxnet 1.41**|mx1.41_cu100|mx1.41_cu101
**mxnet 1.50**|mx1.50_cu100|mx1.50_cu101

在安装的时候没有安装mkl。

每个镜像跑同一个实验 3 次吧，最近没什么时间跑 10 次，结果等我跑完了再更新。

2019年8月9日更新：

跑完了，发现结果全都一样，和显卡，cuda，mxnet 版本都无关。。。

后来找了一下问题，问题出在 training set 的 dataloader，忘了给 training set shuffle 了，所以效果变差了。。。